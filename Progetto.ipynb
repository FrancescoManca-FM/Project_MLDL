{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di LWF funzionante.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfp19qRVa7l"
      },
      "source": [
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2iq0PaVWC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3dfae9-e104-45ad-cacc-aeeac16c2412"
      },
      "source": [
        "# Check GPU assigned\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul  7 09:56:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OWtqytyzmMF"
      },
      "source": [
        "## Network, dataset, functions and parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itMjhanGVTUp"
      },
      "source": [
        "### LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nHVORYbiZRx"
      },
      "source": [
        "### Resnet32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIdSy6PnibZA"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\"\"\"\n",
        "Credits to @hshustc\n",
        "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "from torch.nn import init\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_relu=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.stride = stride\n",
        "        self.use_relu = use_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        if self.use_relu:\n",
        "            out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, nIn, nOut, stride):\n",
        "        super(Downsample, self).__init__()\n",
        "        assert stride == 2\n",
        "        self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        return torch.cat((x, x.mul(0)), 1)\n",
        "\n",
        "\n",
        "class CifarResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block=BasicBlock, depth=32, num_classes=0, channels=3):\n",
        "\n",
        "        super(CifarResNet, self).__init__()\n",
        "\n",
        "        # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be one of 20, 32, 44, 56, 110'\n",
        "        layer_blocks = (depth - 2) // 6\n",
        "        bn = nn.BatchNorm2d\n",
        "        self.inplanes = 16\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(channels, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn_1 = bn(self.inplanes)\n",
        "\n",
        "        self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n",
        "        self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n",
        "        self.stage_3 = self._make_layer(block, 64, layer_blocks, 2, last=True)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.relu = nn.ReLU()\n",
        "        #self.linear = nn.Linear(64, num_classes)\n",
        "        self.fcs = nn.ModuleList([nn.Linear(64, num_classes)])\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, math.sqrt(1. / 64.))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, last=False):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = Downsample(self.\n",
        "inplanes, planes * block.expansion, stride)\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
        "\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        if last:\n",
        "            for i in range(1, blocks - 1):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            layers.append(block(self.inplanes, planes, use_relu=False))\n",
        "\n",
        "        else:\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_1_3x3(x)\n",
        "\n",
        "        x = self.bn_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.stage_1(x)\n",
        "        x = self.stage_2(x)\n",
        "        x = self.stage_3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = []\n",
        "        for fc in self.fcs:\n",
        "            out.append(fc(x))\n",
        "        out = torch.cat(out, dim=1)\n",
        "        return out\n",
        "\n",
        "    def addOutputNodes(self, num_classes):\n",
        "        self.fcs.append(nn.Linear(64, num_classes))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ga-SaCsjkYV"
      },
      "source": [
        "### Cifar100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHAyljuejmkd"
      },
      "source": [
        "# ref:\n",
        "# https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py\n",
        "# https://pytorch.org/docs/stable/_modules/torchvision/datasets/cifar.html#CIFAR10\n",
        "# homework2 (caltech)\n",
        "\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# This is an handler class for the Cifar dataset\n",
        "class CIFAR100(VisionDataset):\n",
        "    \"\"\"\n",
        "    `CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "    This is a subclass of the `CIFAR100` Dataset.\n",
        "    \"\"\"\n",
        "    base_folder = 'cifar-100-python'\n",
        "    train_file = 'train'\n",
        "    test_file = 'test'\n",
        "    meta_file = 'meta'\n",
        "\n",
        "    def __init__(self, root, split = 'train', transform = None):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "              root (string): Root directory of the dataset where directory\n",
        "                  cifar-100-python exists.\n",
        "              split (string, optional): If 'train', creates dataset from training\n",
        "                  set, otherwise creates from test set.\n",
        "              transform (callable, optional): A function/transform that takes in a\n",
        "                  PIL image and returns a transformed version.\n",
        "        \"\"\"\n",
        "        super(CIFAR100, self).__init__(root, transform=transform)\n",
        "\n",
        "        self.split = split\n",
        "        if split == 'train':\n",
        "            filename = self.train_file\n",
        "        else:\n",
        "            filename = self.test_file\n",
        "\n",
        "        data_path = os.path.join(self.root, self.base_folder, filename)\n",
        "        data = None\n",
        "        labels = None\n",
        "\n",
        "        with open(data_path, 'rb') as f:\n",
        "            entry = pickle.load(f, encoding='latin1')\n",
        "            data = entry['data']\n",
        "            labels = entry['fine_labels']\n",
        "        \n",
        "        data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
        "        data = data.transpose((0, 2, 3, 1))  # Convert to HWC\n",
        "        \n",
        "        labels = np.array(labels)\n",
        "\n",
        "        self.df = pd.DataFrame()\n",
        "        self.df['data'] = pd.Series(list(data))\n",
        "        self.df['labels'] = labels\n",
        "\n",
        "        self.data = self.df['data']\n",
        "        self.labels = self.df['labels']\n",
        "\n",
        "        self._load_meta()\n",
        "\n",
        "    def _load_meta(self):\n",
        "        meta_path = os.path.join(self.root, self.base_folder, self.meta_file)\n",
        "        with open(meta_path, 'rb') as f:\n",
        "            meta = pickle.load(f, encoding='latin1')\n",
        "            self.label_names = meta['fine_label_names']\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.df.loc[index, 'data'], self.df.loc[index, 'labels']\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img) # Return a PIL image\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return index, img, target\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def getTargets(self):\n",
        "        return set(self.labels)\n",
        "     \n",
        "    # test\n",
        "    def get_indices(self, labels):\n",
        "        return list(self.df[self.df['labels'].isin(labels)].index)\n",
        "\n",
        "    def split_classes(self, n_splits=10, seed=None, dictionary_of='dataframes'):\n",
        "        if dictionary_of not in ['dataframes','indices']:\n",
        "            raise ValueError(\"'dictionary_of' must be equal to 'dataframes' or 'indices'\")\n",
        "\n",
        "        all_classes = list(self.df['labels'].value_counts().index)\n",
        "        dictionary = {}\n",
        "        random.seed(seed)\n",
        "        random.shuffle(all_classes)\n",
        "        split_size = int(len(all_classes)/n_splits)\n",
        "        for j in range(n_splits):\n",
        "            if ((j+1)*split_size < len(all_classes)):\n",
        "                split_end = (j+1)*split_size\n",
        "            else:\n",
        "                split_end = None\n",
        "            subgroup = all_classes[j*split_size:split_end]\n",
        "            if dictionary_of == 'dataframes':\n",
        "                dictionary[j] = self.df[self.df['labels'].isin(subgroup)]\n",
        "            elif dictionary_of == 'indices':\n",
        "                dictionary[j] = list(self.df[self.df['labels'].isin(subgroup)].index)\n",
        "        return dictionary\n",
        "\n",
        "    def split_groups_in_train_validation(self, groups, ratio=0.5, seed=None):\n",
        "        groups_train_val = dict()\n",
        "        for k, subdf in groups.items():\n",
        "            train_indexes = []\n",
        "            val_indexes = []\n",
        "            split_labels = list(subdf['labels'].value_counts().index)\n",
        "            for l in split_labels:\n",
        "                indexes_to_sample = list(subdf[subdf['labels'] == l].index)\n",
        "                random.seed(seed)\n",
        "                train_samples = random.sample(indexes_to_sample, int(len(indexes_to_sample)*ratio))\n",
        "                train_indexes = train_indexes + train_samples\n",
        "                val_indexes = val_indexes + list(set(indexes_to_sample).difference(set(train_samples)))\n",
        "            groups_train_val[k] = {\n",
        "                'train': train_indexes,\n",
        "                'val': val_indexes\n",
        "            }\n",
        "        return groups_train_val\n",
        "    \n",
        "    def split_in_train_val_groups(self, n_splits=10, ratio=0.5, seed=None):\n",
        "        groups = self.split_classes(n_splits=n_splits, seed=seed)\n",
        "        return self.split_groups_in_train_validation(groups, ratio=ratio, seed=seed)\n",
        "\n",
        "    # given a tensors returns an image (used in exemplars)\n",
        "    #def tensorToImg(self, tensor):\n",
        "    #   return Variable(transform(Image.fromarray(img)), volatile=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_M1anVYkRnF"
      },
      "source": [
        "### Reverse Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j66mUOXekTlM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "__all__ = ['ReverseIndex']\n",
        "\n",
        "class ReverseIndex():\n",
        "\n",
        "    def __init__(self, dataset, splits, device='cuda'):\n",
        "\n",
        "        self.df = pd.DataFrame(columns=['group', 'labels'])\n",
        "\n",
        "        for k in splits.keys():\n",
        "            labels = list(dataset.df.loc[splits[k]['train'],'labels'].value_counts().index)\n",
        "            group = [k for i in range(len(labels))]\n",
        "            data = pd.DataFrame(np.array([group, labels]).T, columns=['group', 'labels'])\n",
        "            self.df = self.df.append(data, ignore_index=True)\n",
        "\n",
        "        self.df['nodes'] = self.df.index\n",
        "        self.device = device\n",
        "    \n",
        "    def _changeIndex(self, reverse_index, column):\n",
        "        reverse_index = reverse_index.set_index(column)\n",
        "        reverse_index[column] = reverse_index.index\n",
        "        return reverse_index\n",
        "\n",
        "    def getLabels(self, outputs):\n",
        "        outs = outputs.cpu().numpy()\n",
        "        reverse_index = self._changeIndex(self.df, 'nodes')\n",
        "        labels = reverse_index.loc[outs, 'labels']\n",
        "\n",
        "        labels = torch.tensor(list(labels))\n",
        "        return labels.to(self.device)\n",
        "\n",
        "    def getNodes(self, labels):\n",
        "        labels = labels.cpu().numpy()\n",
        "       \n",
        "        reverse_index = self._changeIndex(self.df, 'labels')\n",
        "\n",
        "        nodes = reverse_index.loc[labels, 'nodes']\n",
        "\n",
        "        nodes = torch.tensor(list(nodes))\n",
        "        return nodes.to(self.device)\n",
        "\n",
        "    def getGroups(self, distinct=True):\n",
        "        return self.df['group'].value_counts().index.sort_values()\n",
        "    \n",
        "    def getLabelsOfGroup(self, group):\n",
        "        return self.df.loc[self.df['group'] == group, 'labels']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVfOeOCuknB8"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4QpAHzFkoW0"
      },
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import Module\n",
        "\n",
        "# These are the default iCaRL hyper-parameters\n",
        "def getHyperparams():\n",
        "\tdictHyperparams = {\n",
        "\t\t\"LR\": 2,\n",
        "\t\t\"MOMENTUM\": 0.9,\n",
        "\t\t\"WEIGHT_DECAY\": 1e-5,\n",
        "\t\t\"NUM_EPOCHS\": 70,\n",
        "\t\t\"MILESTONES\": [49, 63],\n",
        "\t\t\"BATCH_SIZE\": 128,\n",
        "\t\t\"DEVICE\": 'cuda',\n",
        "\t\t\"GAMMA\": 0.2,\n",
        "\t\t\"SEED\": 66, #use 30, 42, 16\n",
        "\t\t\"LOG_FREQUENCY\": 10,\n",
        "\t\t\"NUM_CLASSES\": 100\n",
        "\t}\n",
        "\treturn dictHyperparams\n",
        "\n",
        "def getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize):\n",
        "\toptimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\tscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA, last_epoch=-1) \n",
        "\treturn optimizer, scheduler\n",
        "\n",
        "# the mean and the std have been found on the web as mean and std of cifar100\n",
        "# alternative (realistic): compute mean and std for the dataset\n",
        "def getTransformations():\n",
        "\t# Define transforms for training phase\n",
        "\ttrain_transform = transforms.Compose([transforms.RandomHorizontalFlip(), # Randomly flip the image with probability of 0.5\n",
        "\t                                      transforms.Pad(4), # Add padding\n",
        "\t                                      transforms.RandomCrop(32),# Crops a random squares of the image\n",
        "\t                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "\t                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
        "\t])\n",
        "\t# Define transforms for the evaluation phase\n",
        "\teval_transform = transforms.Compose([\n",
        "\t                                      transforms.ToTensor(),\n",
        "\t                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
        "\t])\n",
        "\treturn train_transform, eval_transform\n",
        "\n",
        "# BCEWithLogits = Sigmoid + BCE, is the loss used in iCaRL\n",
        "def getLossCriterion():\n",
        "\tcriterion = nn.BCEWithLogitsLoss(reduction = 'mean') \n",
        "\treturn criterion\n",
        "\n",
        "# CrossEntropyLoss \n",
        "def computeLoss(criterion, outputs, labels):\n",
        "\treturn criterion(outputs, labels)\n",
        " \n",
        "# Loss L2\n",
        "def l2Loss (outputs, labels):\n",
        "  criterion = nn.MSELoss()\n",
        "  return criterion(outputs, labels)\n",
        "\n",
        "# Loss L1\n",
        "def l1Loss(outputs, labels):\n",
        "  criterion = nn.L1Loss()\n",
        "  return criterion(outputs, labels)\n",
        "\n",
        "# support BCE\n",
        "def _one_hot_encode(labels, n_classes, reverse_index, dtype=None, device='cuda'):\n",
        "\tbatch_size = len(labels)\n",
        "\tenconded = torch.zeros(batch_size, n_classes, dtype=dtype, device=device)\n",
        "\tlabels=map_to_outputs(labels, reverse_index)\n",
        "\tfor i, l in enumerate(labels):\n",
        "\t  enconded[i, l] = 1\n",
        "\treturn enconded\n",
        "\n",
        "def map_to_outputs(labels, reverse_index):\n",
        "\tif reverse_index is None:\n",
        "\t  return labels\n",
        "\tif type(labels) == int:\n",
        "\t  return int(reverse_index.getNodes(torch.tensor([labels])))\n",
        "\telif type(labels) == torch.Tensor:\n",
        "\t\treturn reverse_index.getNodes(labels)\n",
        "\n",
        "\n",
        "def plotAccuracyTrend(method, data_plot_line, seed):\n",
        "\tplt.figure(figsize=(20,7))\n",
        "\taccuracyDF=pd.DataFrame(data_plot_line, columns = ['Classes','Accuracy'])\n",
        "\tax = sns.lineplot(x=\"Classes\", y=\"Accuracy\",data=accuracyDF, marker = 'o')\n",
        "\tax.minorticks_on()\n",
        "\tax.set_xticks(np.arange(10,110,10))\n",
        "\tax.set_xlim(xmin=9, xmax=101)\n",
        "\tax.set_ylim(ymin=0, ymax=1)\n",
        "\tplt.legend(['Accuracy {}'.format(method)])\n",
        "\tax.grid(axis='y')\n",
        "\tplt.title(\"Accuracies against seen classes {} - seed: {}\".format(method, seed))\n",
        "\t\n",
        "\tfilename = \"acc_{}_{}.jpg\".format(method, seed) # ex. acc_lwf_30\n",
        "\tplt.savefig(filename, format='png', dpi=300)\n",
        "\tplt.show()\n",
        "\n",
        "def plotConfusionMatrix(method, confusionMatrixData, seed):\n",
        "\tfig,ax=plt.subplots(figsize=(10,10))\n",
        "\tsns.heatmap(confusionMatrixData,cmap='terrain',ax=ax)\n",
        "\tplt.ylabel('True label')\n",
        "\tplt.xlabel('Predicted label')\n",
        "\tplt.title(\"Confusion Matrix {} - seed: {}\".format(method, seed))\n",
        "\n",
        "\tfilename = \"cm_{}_{}.jpg\".format(method, seed) # ex. cm_lwf_30\n",
        "\tplt.savefig(filename, format='png', dpi=300)\n",
        "\tplt.show()\n",
        "\n",
        "# Write down the metrics (accuracy trand and confusion matrix)\n",
        "# this method is a shortcut when perfoming multiple tests with different splits (random_seed)\n",
        "# and allow us to plot on the same graph the data from multiple models (accuracy)\n",
        "def writeMetrics(method, seed, accuracies, confusionMatrixData):\n",
        "  data = {}\n",
        "  data['accuracies'] = []\n",
        "  data['cm'] = [] #cm line\n",
        "  i = 0\n",
        "  for classes_seen in range(10, 110, 10): #x axis on the plot\n",
        "    data['accuracies'].append({classes_seen : accuracies[i]}) \n",
        "    i += 1\n",
        "\n",
        "  i = 0\n",
        "  for class_num in range(0,len(confusionMatrixData)): #rows of the cm\n",
        "    data['cm'].append({class_num : confusionMatrixData[i].tolist()}) \n",
        "    i += 1\n",
        "  \n",
        "  # dump to file\n",
        "  aus = method + '_' + str(seed)\n",
        "  filename = 'data_{}.json'.format(aus)\n",
        "  with open(filename, 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "\n",
        "# Functions\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = CifarResNet()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler\n",
        "def softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfJj1z2LSxp0"
      },
      "source": [
        "### DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c89d9ec-c5f2-44cd-b451-12087087fcd0"
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-07 09:56:18--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  50.4MB/s    in 3.6s    \n",
            "\n",
            "2021-07-07 09:56:22 (45.3 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "mv: cannot move 'cifar-100-python' to 'DATA/cifar-100-python/cifar-100-python': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY10HfpTS1lq"
      },
      "source": [
        "### HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "NUM_CLASSES = 100\n",
        "BATCH_SIZE = 128 \n",
        "LR = 0.1    \n",
        "MOMENTUM = 0.9     \n",
        "WEIGHT_DECAY = 1e-05\n",
        "NUM_EPOCHS = 70\n",
        "NUM_EPOCHS_FINETUNE = 50\n",
        "GAMMA = 0.2\n",
        "LOG_FREQUENCY = 10\n",
        "MILESTONES = [49,63]\n",
        "RANDOM_SEED = 66\n",
        "THRESHOLD = 0.5"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW7WxV_QS4re"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk"
      },
      "source": [
        "train_transform, eval_transform = getTransformations()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPrwhTcIqUbA"
      },
      "source": [
        "### train & test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJKwvGljJj2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6238ca-09c7-41fc-8862-44de6dff740f"
      },
      "source": [
        "# Import dataset and apply transformations \n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# Check datasets length \n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnooWwcyS_YN"
      },
      "source": [
        "### SPLIT DATA IN CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckn3H69iJj2X"
      },
      "source": [
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6873c8d9-6159-4b30-f090-e60405f2980a"
      },
      "source": [
        "# TRAIN / VAL split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "print(outputs_labels_mapping.getGroups())\n",
        "\n",
        "# TEST split\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn"
      },
      "source": [
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpWv5ZkhxTPJ"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NQa-wNxWL1"
      },
      "source": [
        "### train, validate, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pisadUTPxcRP"
      },
      "source": [
        "import copy\n",
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "  \n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            # # if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            # if (group_id > 1):\n",
        "            #   old_features = old_net.forward(images)\n",
        "            #   old_outputs = old_net.predict(old_features)\n",
        "            #   labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX_61nSuxh3v"
      },
      "source": [
        "### sequential learning fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM0GysHZxk1B"
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearningFineTuning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    old_net = None\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen, group_id, old_net)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    #confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2X2IVZ-xrVT"
      },
      "source": [
        "### execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DGpd8lslxtUW",
        "outputId": "2a7a5171-8688-4b1f-fe52-f88f4b532a6a"
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningFineTuning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7173749208450317\n",
            "Train step - Step 10, Loss 0.31387636065483093\n",
            "Train step - Step 20, Loss 0.2874338626861572\n",
            "Train step - Step 30, Loss 0.2654590606689453\n",
            "Train epoch - Accuracy: 0.318989898989899 Loss: 0.34560690457772725 Corrects: 1579\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.26789265871047974\n",
            "Train step - Step 50, Loss 0.258944034576416\n",
            "Train step - Step 60, Loss 0.2350231260061264\n",
            "Train step - Step 70, Loss 0.23865528404712677\n",
            "Train epoch - Accuracy: 0.44363636363636366 Loss: 0.24301170718790305 Corrects: 2196\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.23784291744232178\n",
            "Train step - Step 90, Loss 0.22167158126831055\n",
            "Train step - Step 100, Loss 0.22836807370185852\n",
            "Train step - Step 110, Loss 0.21694694459438324\n",
            "Train epoch - Accuracy: 0.48707070707070704 Loss: 0.22610946089330344 Corrects: 2411\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.21196965873241425\n",
            "Train step - Step 130, Loss 0.20575585961341858\n",
            "Train step - Step 140, Loss 0.22211872041225433\n",
            "Train step - Step 150, Loss 0.20619133114814758\n",
            "Train epoch - Accuracy: 0.5016161616161616 Loss: 0.21912972303954037 Corrects: 2483\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.2055768072605133\n",
            "Train step - Step 170, Loss 0.20553207397460938\n",
            "Train step - Step 180, Loss 0.22383907437324524\n",
            "Train step - Step 190, Loss 0.19269728660583496\n",
            "Train epoch - Accuracy: 0.5418181818181819 Loss: 0.20608459960932685 Corrects: 2682\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.19962547719478607\n",
            "Train step - Step 210, Loss 0.1956397444009781\n",
            "Train step - Step 220, Loss 0.23317204415798187\n",
            "Train step - Step 230, Loss 0.1870502084493637\n",
            "Train epoch - Accuracy: 0.5523232323232323 Loss: 0.19966931800047558 Corrects: 2734\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.19728612899780273\n",
            "Train step - Step 250, Loss 0.17967957258224487\n",
            "Train step - Step 260, Loss 0.1929226964712143\n",
            "Train step - Step 270, Loss 0.19188766181468964\n",
            "Train epoch - Accuracy: 0.5834343434343434 Loss: 0.19277908541939476 Corrects: 2888\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.1998911201953888\n",
            "Train step - Step 290, Loss 0.18329913914203644\n",
            "Train step - Step 300, Loss 0.16586630046367645\n",
            "Train step - Step 310, Loss 0.17675089836120605\n",
            "Train epoch - Accuracy: 0.598989898989899 Loss: 0.1864176897809963 Corrects: 2965\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.17738604545593262\n",
            "Train step - Step 330, Loss 0.18055176734924316\n",
            "Train step - Step 340, Loss 0.17641305923461914\n",
            "Train step - Step 350, Loss 0.14969894289970398\n",
            "Train epoch - Accuracy: 0.6155555555555555 Loss: 0.17903075204955207 Corrects: 3047\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.1671830266714096\n",
            "Train step - Step 370, Loss 0.1687958985567093\n",
            "Train step - Step 380, Loss 0.159011110663414\n",
            "Train epoch - Accuracy: 0.6309090909090909 Loss: 0.1738420210462628 Corrects: 3123\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.15419088304042816\n",
            "Train step - Step 400, Loss 0.14775967597961426\n",
            "Train step - Step 410, Loss 0.16979841887950897\n",
            "Train step - Step 420, Loss 0.1525963395833969\n",
            "Train epoch - Accuracy: 0.6539393939393939 Loss: 0.1639658623993999 Corrects: 3237\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.19196446239948273\n",
            "Train step - Step 440, Loss 0.1466265171766281\n",
            "Train step - Step 450, Loss 0.17056730389595032\n",
            "Train step - Step 460, Loss 0.18163080513477325\n",
            "Train epoch - Accuracy: 0.6608080808080808 Loss: 0.16202940798167026 Corrects: 3271\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.176211878657341\n",
            "Train step - Step 480, Loss 0.1588747799396515\n",
            "Train step - Step 490, Loss 0.1342204362154007\n",
            "Train step - Step 500, Loss 0.14058950543403625\n",
            "Train epoch - Accuracy: 0.6767676767676768 Loss: 0.15383696049752862 Corrects: 3350\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.1555892676115036\n",
            "Train step - Step 520, Loss 0.13571906089782715\n",
            "Train step - Step 530, Loss 0.1515876054763794\n",
            "Train step - Step 540, Loss 0.1359780877828598\n",
            "Train epoch - Accuracy: 0.702020202020202 Loss: 0.14594818502363532 Corrects: 3475\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.15486030280590057\n",
            "Train step - Step 560, Loss 0.13412602245807648\n",
            "Train step - Step 570, Loss 0.15869688987731934\n",
            "Train step - Step 580, Loss 0.13754160702228546\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.14330182038172326 Corrects: 3482\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 590, Loss 0.13797789812088013\n",
            "Train step - Step 600, Loss 0.14471013844013214\n",
            "Train step - Step 610, Loss 0.1659015417098999\n",
            "Train step - Step 620, Loss 0.13035106658935547\n",
            "Train epoch - Accuracy: 0.712929292929293 Loss: 0.1402043603164981 Corrects: 3529\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 630, Loss 0.10688119381666183\n",
            "Train step - Step 640, Loss 0.10551120340824127\n",
            "Train step - Step 650, Loss 0.11231940239667892\n",
            "Train step - Step 660, Loss 0.12159333378076553\n",
            "Train epoch - Accuracy: 0.7434343434343434 Loss: 0.1296956703397963 Corrects: 3680\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 670, Loss 0.13172531127929688\n",
            "Train step - Step 680, Loss 0.142404243350029\n",
            "Train step - Step 690, Loss 0.12234494835138321\n",
            "Train step - Step 700, Loss 0.14414963126182556\n",
            "Train epoch - Accuracy: 0.756969696969697 Loss: 0.12469814313180519 Corrects: 3747\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.1333446353673935\n",
            "Train step - Step 720, Loss 0.15927483141422272\n",
            "Train step - Step 730, Loss 0.11001887172460556\n",
            "Train step - Step 740, Loss 0.12100914865732193\n",
            "Train epoch - Accuracy: 0.7450505050505051 Loss: 0.12714890332836093 Corrects: 3688\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 750, Loss 0.11506552994251251\n",
            "Train step - Step 760, Loss 0.10524898767471313\n",
            "Train step - Step 770, Loss 0.0984029471874237\n",
            "Train epoch - Accuracy: 0.7668686868686869 Loss: 0.11733168877435453 Corrects: 3796\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 780, Loss 0.12441835552453995\n",
            "Train step - Step 790, Loss 0.11353017389774323\n",
            "Train step - Step 800, Loss 0.13449843227863312\n",
            "Train step - Step 810, Loss 0.12670955061912537\n",
            "Train epoch - Accuracy: 0.7739393939393939 Loss: 0.11266988289175611 Corrects: 3831\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 820, Loss 0.10420570522546768\n",
            "Train step - Step 830, Loss 0.10050588846206665\n",
            "Train step - Step 840, Loss 0.09052333980798721\n",
            "Train step - Step 850, Loss 0.07840898633003235\n",
            "Train epoch - Accuracy: 0.7808080808080808 Loss: 0.11037116950509523 Corrects: 3865\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 860, Loss 0.13141851127147675\n",
            "Train step - Step 870, Loss 0.11617157608270645\n",
            "Train step - Step 880, Loss 0.11001942306756973\n",
            "Train step - Step 890, Loss 0.08741968870162964\n",
            "Train epoch - Accuracy: 0.7844444444444445 Loss: 0.10794938291564132 Corrects: 3883\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 900, Loss 0.11431687325239182\n",
            "Train step - Step 910, Loss 0.0919078066945076\n",
            "Train step - Step 920, Loss 0.1131000742316246\n",
            "Train step - Step 930, Loss 0.12487182766199112\n",
            "Train epoch - Accuracy: 0.7935353535353535 Loss: 0.10410453104310566 Corrects: 3928\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.0851389467716217\n",
            "Train step - Step 950, Loss 0.10327544063329697\n",
            "Train step - Step 960, Loss 0.09313042461872101\n",
            "Train step - Step 970, Loss 0.12224413454532623\n",
            "Train epoch - Accuracy: 0.8014141414141415 Loss: 0.10208582940125706 Corrects: 3967\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.10216508060693741\n",
            "Train step - Step 990, Loss 0.10625173896551132\n",
            "Train step - Step 1000, Loss 0.12439626455307007\n",
            "Train step - Step 1010, Loss 0.09492490440607071\n",
            "Train epoch - Accuracy: 0.805050505050505 Loss: 0.10121105768764863 Corrects: 3985\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1020, Loss 0.1075296625494957\n",
            "Train step - Step 1030, Loss 0.08558668196201324\n",
            "Train step - Step 1040, Loss 0.10448060184717178\n",
            "Train step - Step 1050, Loss 0.0987623855471611\n",
            "Train epoch - Accuracy: 0.8115151515151515 Loss: 0.09598487866647316 Corrects: 4017\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1060, Loss 0.11706822365522385\n",
            "Train step - Step 1070, Loss 0.08957835286855698\n",
            "Train step - Step 1080, Loss 0.1004997119307518\n",
            "Train step - Step 1090, Loss 0.10269360989332199\n",
            "Train epoch - Accuracy: 0.8151515151515152 Loss: 0.093790872918837 Corrects: 4035\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10780717432498932\n",
            "Train step - Step 1110, Loss 0.0829559937119484\n",
            "Train step - Step 1120, Loss 0.06946247071027756\n",
            "Train step - Step 1130, Loss 0.08679612725973129\n",
            "Train epoch - Accuracy: 0.8232323232323232 Loss: 0.09224864899811118 Corrects: 4075\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.0877915769815445\n",
            "Train step - Step 1150, Loss 0.07081689685583115\n",
            "Train step - Step 1160, Loss 0.09684779495000839\n",
            "Train epoch - Accuracy: 0.8305050505050505 Loss: 0.08737428996298048 Corrects: 4111\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1170, Loss 0.08674424141645432\n",
            "Train step - Step 1180, Loss 0.08422601222991943\n",
            "Train step - Step 1190, Loss 0.09191498905420303\n",
            "Train step - Step 1200, Loss 0.09191594272851944\n",
            "Train epoch - Accuracy: 0.834949494949495 Loss: 0.08547621402174535 Corrects: 4133\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.07304417341947556\n",
            "Train step - Step 1220, Loss 0.09637052565813065\n",
            "Train step - Step 1230, Loss 0.08423800766468048\n",
            "Train step - Step 1240, Loss 0.09754743427038193\n",
            "Train epoch - Accuracy: 0.8418181818181818 Loss: 0.0811596822106477 Corrects: 4167\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.08752617239952087\n",
            "Train step - Step 1260, Loss 0.08612791448831558\n",
            "Train step - Step 1270, Loss 0.09345199167728424\n",
            "Train step - Step 1280, Loss 0.06988094002008438\n",
            "Train epoch - Accuracy: 0.8432323232323232 Loss: 0.08195995536717501 Corrects: 4174\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1290, Loss 0.063926100730896\n",
            "Train step - Step 1300, Loss 0.09519979357719421\n",
            "Train step - Step 1310, Loss 0.0794561430811882\n",
            "Train step - Step 1320, Loss 0.09330239146947861\n",
            "Train epoch - Accuracy: 0.8434343434343434 Loss: 0.08210123597973525 Corrects: 4175\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1330, Loss 0.06706669181585312\n",
            "Train step - Step 1340, Loss 0.07936250418424606\n",
            "Train step - Step 1350, Loss 0.08014490455389023\n",
            "Train step - Step 1360, Loss 0.08957503736019135\n",
            "Train epoch - Accuracy: 0.8488888888888889 Loss: 0.07934777613541093 Corrects: 4202\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1370, Loss 0.08020991086959839\n",
            "Train step - Step 1380, Loss 0.09724964946508408\n",
            "Train step - Step 1390, Loss 0.06381719559431076\n",
            "Train step - Step 1400, Loss 0.06528539955615997\n",
            "Train epoch - Accuracy: 0.8549494949494949 Loss: 0.07585879642855037 Corrects: 4232\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.07746966183185577\n",
            "Train step - Step 1420, Loss 0.08617367595434189\n",
            "Train step - Step 1430, Loss 0.06970410794019699\n",
            "Train step - Step 1440, Loss 0.08160582929849625\n",
            "Train epoch - Accuracy: 0.8527272727272728 Loss: 0.07876499318715298 Corrects: 4221\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 1450, Loss 0.06916437298059464\n",
            "Train step - Step 1460, Loss 0.06720501184463501\n",
            "Train step - Step 1470, Loss 0.06595558673143387\n",
            "Train step - Step 1480, Loss 0.0707656592130661\n",
            "Train epoch - Accuracy: 0.8654545454545455 Loss: 0.07132082007449082 Corrects: 4284\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.05659304931759834\n",
            "Train step - Step 1500, Loss 0.06974741071462631\n",
            "Train step - Step 1510, Loss 0.0784800574183464\n",
            "Train step - Step 1520, Loss 0.06901217252016068\n",
            "Train epoch - Accuracy: 0.8672727272727273 Loss: 0.07315080337753199 Corrects: 4293\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 1530, Loss 0.07148046046495438\n",
            "Train step - Step 1540, Loss 0.08015324175357819\n",
            "Train step - Step 1550, Loss 0.07519340515136719\n",
            "Train epoch - Accuracy: 0.8682828282828283 Loss: 0.06976768631826748 Corrects: 4298\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 1560, Loss 0.061872996389865875\n",
            "Train step - Step 1570, Loss 0.08952672779560089\n",
            "Train step - Step 1580, Loss 0.0770217701792717\n",
            "Train step - Step 1590, Loss 0.06781128793954849\n",
            "Train epoch - Accuracy: 0.8719191919191919 Loss: 0.06902587638659911 Corrects: 4316\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.0734851062297821\n",
            "Train step - Step 1610, Loss 0.055662430822849274\n",
            "Train step - Step 1620, Loss 0.08112241327762604\n",
            "Train step - Step 1630, Loss 0.07834818959236145\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.06590250587222551 Corrects: 4326\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 1640, Loss 0.05307411774992943\n",
            "Train step - Step 1650, Loss 0.04475534334778786\n",
            "Train step - Step 1660, Loss 0.06450628489255905\n",
            "Train step - Step 1670, Loss 0.06469791382551193\n",
            "Train epoch - Accuracy: 0.8838383838383839 Loss: 0.06405000432874217 Corrects: 4375\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.055307772010564804\n",
            "Train step - Step 1690, Loss 0.06018352508544922\n",
            "Train step - Step 1700, Loss 0.05738571286201477\n",
            "Train step - Step 1710, Loss 0.07564640045166016\n",
            "Train epoch - Accuracy: 0.883030303030303 Loss: 0.06291912011124871 Corrects: 4371\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 1720, Loss 0.0579797700047493\n",
            "Train step - Step 1730, Loss 0.05599530413746834\n",
            "Train step - Step 1740, Loss 0.07791357487440109\n",
            "Train step - Step 1750, Loss 0.07570113986730576\n",
            "Train epoch - Accuracy: 0.8860606060606061 Loss: 0.06122048602411241 Corrects: 4386\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.046970587223768234\n",
            "Train step - Step 1770, Loss 0.05448814854025841\n",
            "Train step - Step 1780, Loss 0.0570836178958416\n",
            "Train step - Step 1790, Loss 0.052846431732177734\n",
            "Train epoch - Accuracy: 0.8921212121212121 Loss: 0.05948092536342264 Corrects: 4416\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 1800, Loss 0.0464363619685173\n",
            "Train step - Step 1810, Loss 0.056273628026247025\n",
            "Train step - Step 1820, Loss 0.0658160001039505\n",
            "Train step - Step 1830, Loss 0.0690997764468193\n",
            "Train epoch - Accuracy: 0.8955555555555555 Loss: 0.05688923456151076 Corrects: 4433\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.059149112552404404\n",
            "Train step - Step 1850, Loss 0.05253974348306656\n",
            "Train step - Step 1860, Loss 0.07070215791463852\n",
            "Train step - Step 1870, Loss 0.05269395932555199\n",
            "Train epoch - Accuracy: 0.8927272727272727 Loss: 0.05812157820571553 Corrects: 4419\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 1880, Loss 0.04611649736762047\n",
            "Train step - Step 1890, Loss 0.06521129608154297\n",
            "Train step - Step 1900, Loss 0.0597667470574379\n",
            "Train step - Step 1910, Loss 0.07057886570692062\n",
            "Train epoch - Accuracy: 0.9002020202020202 Loss: 0.05608734115506663 Corrects: 4456\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 1920, Loss 0.042010191828012466\n",
            "Train step - Step 1930, Loss 0.043184537440538406\n",
            "Train step - Step 1940, Loss 0.0397011898458004\n",
            "Train epoch - Accuracy: 0.9242424242424242 Loss: 0.04325935698518849 Corrects: 4575\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1950, Loss 0.039822064340114594\n",
            "Train step - Step 1960, Loss 0.036546554416418076\n",
            "Train step - Step 1970, Loss 0.04635452851653099\n",
            "Train step - Step 1980, Loss 0.033635109663009644\n",
            "Train epoch - Accuracy: 0.9432323232323232 Loss: 0.037418713830035144 Corrects: 4669\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1990, Loss 0.03440694510936737\n",
            "Train step - Step 2000, Loss 0.04546314477920532\n",
            "Train step - Step 2010, Loss 0.03715860843658447\n",
            "Train step - Step 2020, Loss 0.050867773592472076\n",
            "Train epoch - Accuracy: 0.9412121212121212 Loss: 0.03600090804876703 Corrects: 4659\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2030, Loss 0.02928098477423191\n",
            "Train step - Step 2040, Loss 0.03901729732751846\n",
            "Train step - Step 2050, Loss 0.037106212228536606\n",
            "Train step - Step 2060, Loss 0.03669671341776848\n",
            "Train epoch - Accuracy: 0.9452525252525252 Loss: 0.03400145272564406 Corrects: 4679\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2070, Loss 0.0314776748418808\n",
            "Train step - Step 2080, Loss 0.031674575060606\n",
            "Train step - Step 2090, Loss 0.018039535731077194\n",
            "Train step - Step 2100, Loss 0.0348820686340332\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.033380321872354755 Corrects: 4687\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2110, Loss 0.02144073322415352\n",
            "Train step - Step 2120, Loss 0.029142146930098534\n",
            "Train step - Step 2130, Loss 0.03788841888308525\n",
            "Train step - Step 2140, Loss 0.032097745686769485\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.03260654991022264 Corrects: 4701\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2150, Loss 0.027982238680124283\n",
            "Train step - Step 2160, Loss 0.020777106285095215\n",
            "Train step - Step 2170, Loss 0.030742371454834938\n",
            "Train step - Step 2180, Loss 0.0357779823243618\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.03025592699345916 Corrects: 4724\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2190, Loss 0.031895961612463\n",
            "Train step - Step 2200, Loss 0.025660132989287376\n",
            "Train step - Step 2210, Loss 0.038197994232177734\n",
            "Train step - Step 2220, Loss 0.025359375402331352\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.03145596713730783 Corrects: 4715\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2230, Loss 0.03523494675755501\n",
            "Train step - Step 2240, Loss 0.02871292270720005\n",
            "Train step - Step 2250, Loss 0.028518855571746826\n",
            "Train step - Step 2260, Loss 0.028394445776939392\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.031200148419599342 Corrects: 4703\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2270, Loss 0.026044586673378944\n",
            "Train step - Step 2280, Loss 0.03078872337937355\n",
            "Train step - Step 2290, Loss 0.03193800523877144\n",
            "Train step - Step 2300, Loss 0.05611391365528107\n",
            "Train epoch - Accuracy: 0.9555555555555556 Loss: 0.030103796654277377 Corrects: 4730\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2310, Loss 0.02573627233505249\n",
            "Train step - Step 2320, Loss 0.026890838518738747\n",
            "Train step - Step 2330, Loss 0.03133704885840416\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.0305143504032884 Corrects: 4722\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2340, Loss 0.029058242216706276\n",
            "Train step - Step 2350, Loss 0.02426040545105934\n",
            "Train step - Step 2360, Loss 0.03160322457551956\n",
            "Train step - Step 2370, Loss 0.04511835798621178\n",
            "Train epoch - Accuracy: 0.9563636363636364 Loss: 0.029337084354324774 Corrects: 4734\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2380, Loss 0.031107379123568535\n",
            "Train step - Step 2390, Loss 0.029924381524324417\n",
            "Train step - Step 2400, Loss 0.024590641260147095\n",
            "Train step - Step 2410, Loss 0.020830800756812096\n",
            "Train epoch - Accuracy: 0.961010101010101 Loss: 0.02768125159346094 Corrects: 4757\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2420, Loss 0.02306819148361683\n",
            "Train step - Step 2430, Loss 0.05020679160952568\n",
            "Train step - Step 2440, Loss 0.032019324600696564\n",
            "Train step - Step 2450, Loss 0.035698115825653076\n",
            "Train epoch - Accuracy: 0.9587878787878787 Loss: 0.028257839812172784 Corrects: 4746\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 2460, Loss 0.03360297158360481\n",
            "Train step - Step 2470, Loss 0.02808537892997265\n",
            "Train step - Step 2480, Loss 0.01882505789399147\n",
            "Train step - Step 2490, Loss 0.01958288811147213\n",
            "Train epoch - Accuracy: 0.96 Loss: 0.026811572033347504 Corrects: 4752\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2500, Loss 0.024240998551249504\n",
            "Train step - Step 2510, Loss 0.015550089068710804\n",
            "Train step - Step 2520, Loss 0.01995779201388359\n",
            "Train step - Step 2530, Loss 0.02513287402689457\n",
            "Train epoch - Accuracy: 0.962020202020202 Loss: 0.025361865840174934 Corrects: 4762\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2540, Loss 0.021166345104575157\n",
            "Train step - Step 2550, Loss 0.018641367554664612\n",
            "Train step - Step 2560, Loss 0.021410910412669182\n",
            "Train step - Step 2570, Loss 0.03057834319770336\n",
            "Train epoch - Accuracy: 0.9646464646464646 Loss: 0.023534335130167127 Corrects: 4775\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2580, Loss 0.029833734035491943\n",
            "Train step - Step 2590, Loss 0.018363453447818756\n",
            "Train step - Step 2600, Loss 0.026480138301849365\n",
            "Train step - Step 2610, Loss 0.028178563341498375\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.024363452725187695 Corrects: 4782\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2620, Loss 0.0342327281832695\n",
            "Train step - Step 2630, Loss 0.02055048942565918\n",
            "Train step - Step 2640, Loss 0.020426509901881218\n",
            "Train step - Step 2650, Loss 0.021581510081887245\n",
            "Train epoch - Accuracy: 0.9648484848484848 Loss: 0.025252315486320343 Corrects: 4776\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2660, Loss 0.03008689358830452\n",
            "Train step - Step 2670, Loss 0.0230241846293211\n",
            "Train step - Step 2680, Loss 0.019735518842935562\n",
            "Train step - Step 2690, Loss 0.01372586376965046\n",
            "Train epoch - Accuracy: 0.9644444444444444 Loss: 0.024579011685769966 Corrects: 4774\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.02005911059677601\n",
            "Train step - Step 2710, Loss 0.023675382137298584\n",
            "Train step - Step 2720, Loss 0.02118927799165249\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.024567253339772274 Corrects: 4769\n",
            "Training finished in 203.4930591583252 seconds\n",
            "EVALUATION:  0.78 0.12797264754772186\n",
            "TEST GROUP:  0.836\n",
            "TEST ALL:  0.836\n",
            "GROUP:  2\n",
            "Starting epoch 1/70, LR = [0.1]\n",
            "Train step - Step 0, Loss 0.5198947787284851\n",
            "Train step - Step 10, Loss 0.18119554221630096\n",
            "Train step - Step 20, Loss 0.1347174048423767\n",
            "Train step - Step 30, Loss 0.10982789844274521\n",
            "Train epoch - Accuracy: 0.36808080808080806 Loss: 0.17154767145111102 Corrects: 1822\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.09604242444038391\n",
            "Train step - Step 50, Loss 0.09236812591552734\n",
            "Train step - Step 60, Loss 0.08287163078784943\n",
            "Train step - Step 70, Loss 0.08627394586801529\n",
            "Train epoch - Accuracy: 0.6482828282828282 Loss: 0.08684955637563359 Corrects: 3209\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.08100271224975586\n",
            "Train step - Step 90, Loss 0.07603686302900314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-754cea9f07ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequentialLearningFineTuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-31e6b3e7dcf7>\u001b[0m in \u001b[0;36msequentialLearningFineTuning\u001b[0;34m(train_subsets, val_subsets, test_subsets)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSchedulerOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset learning rate and step_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Validate on current group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-20cff53f0192>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Bring images and labels to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aakVopSdyeGr"
      },
      "source": [
        "### plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0VbtGQygRH"
      },
      "source": [
        "method = \"finetuning\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-J8aC_xx-c"
      },
      "source": [
        "## LWF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZBNivOix1FB"
      },
      "source": [
        "### train, validate, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdfIllqBx59v"
      },
      "source": [
        "import copy\n",
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            # if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            if (group_id > 1):\n",
        "              old_features = old_net.forward(images)\n",
        "              old_outputs = old_net.predict(old_features)\n",
        "              labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkzFiDVDyAm_"
      },
      "source": [
        "### sequential learning LWF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf7REFkIyEiQ"
      },
      "source": [
        "### LWF\n",
        "def sequentialLearningLWF(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen, group_id, old_net)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZTwTS_4TcES"
      },
      "source": [
        "### execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb"
      },
      "source": [
        "# train\n",
        "# net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningLWF(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2qUxVyMTfB4"
      },
      "source": [
        "### plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz"
      },
      "source": [
        "method = \"Learning Without Forgetting\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI"
      },
      "source": [
        "\"\"\"num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjGRIqDtNQP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nX10znUi6qd"
      },
      "source": [
        "## iCaRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKBdrJ8Csy2a"
      },
      "source": [
        "### classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAPTOU9bszTY"
      },
      "source": [
        "def classify(batch_img, net, exemplar_sets):\n",
        "  \"\"\" classify images by nearest mean-of-exemplars \"\"\" \n",
        "  \"\"\" \n",
        "  class1: list_of_indices for images that represent class1\n",
        "  class2: list_of_indices for images that represent class2\n",
        "  ...\n",
        "  class100: list_of_indices for images that represent class 100\n",
        "  with Subset I retrieve the images from the train_dataset\n",
        "  iterate over it to calculate mean for each class\n",
        "  \"\"\"\n",
        "  net.eval()\n",
        "  classes_mean = []\n",
        "  for k, exemplars_indices in exemplar_sets.items():\n",
        "    features = []\n",
        "    class_images_set = Subset(train_dataset, exemplars_indices)\n",
        "    class_images = DataLoader(class_images_set, batch_size=BATCH_SIZE, num_workers=2)\n",
        "    for _, images, labels in class_images:\n",
        "      # for each class (paper from y=1...t) calculate features and then mean\n",
        "      feature = net.forward(images)\n",
        "      features.append(feature)\n",
        "    features_s = torch.cat(features)\n",
        "    class_mean = features_s.mean(0)\n",
        "    classes_mean.append(class_mean)\n",
        "    means_exemplars = torch.cat(classes_mean, dim=0)\n",
        "    means_exemplars = torch.stack([means_exemplars] * BATCH_SIZE)\n",
        "    means_exemplars = means_exemplars.transpose(1,2)\n",
        "  feature_images_to_classify = net.forward(batch_img)\n",
        "  # sono da normalizzare?\n",
        "  feature_images_to_classify = feature_images_to_classify.unsqueeze(2)\n",
        "  feature_images_to_classify = feature_images_to_classify.expand_as(means_exemplars) # expand_as to get the same dimension\n",
        "  preds = torch.argmin((feature_images_to_classify - means_exemplars).pow(2).sum(1), dim=1)\n",
        "  return preds"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5HRagcujHgM"
      },
      "source": [
        "### construct exemplar set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blwBqG6BjNsM"
      },
      "source": [
        "import sys\n",
        "\n",
        "def constructExemplarSet(net, Xclass, m):\n",
        "#Xclass contiene immagini e label della classe X\n",
        "  exemplars_set = []\n",
        "  feature_exemplars = []\n",
        "  indexes = []\n",
        "  features = [] \n",
        "  class_images = []\n",
        "  net.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    XtrainLoader = torch.utils.data.DataLoader(Xclass, shuffle = True, batch_size=1, num_workers=2)\n",
        "    for _, image, labels in XtrainLoader:\n",
        "      image = image.to(DEVICE)\n",
        "      class_images.append(image)\n",
        "      # per ogni immagine della classe x, prendiamo le rispettive feature e le uniamo nel vettore features, che contiene tutte quelle delle immagini della classe x\n",
        "      feature = net.forward(image)\n",
        "      #feature = net.predict(featuretmp)\n",
        "      feature = feature/np.linalg.norm(feature.cpu())\n",
        "      features.append(feature)\n",
        "\n",
        "    features = torch.cat(features, dim=0) #cat solve the problem of inequal size of tensors \n",
        "    current_class_mean = features.mean(0) # mu = media delle features delle immagini della classe\n",
        "\n",
        "    for k in range(1, m+1):\n",
        "      min = 100000\n",
        "      sum = 0\n",
        "      for j in range(k-1):\n",
        "        sum += feature_exemplars[j]\n",
        "      for x in range(len(Xclass)): \n",
        "        if (x not in indexes):\n",
        "          phiX = features[x]\n",
        "          val = current_class_mean - ((phiX + sum)/k)\n",
        "          val = np.linalg.norm(val.cpu().numpy()) ## NORMA \n",
        "          if (val < min):\n",
        "            min = val\n",
        "            feature_min = phiX\n",
        "            index_min = x\n",
        "      feature_exemplars.append(feature_min)\n",
        "      exemplars_set.append(Xclass[index_min][0])\n",
        "\n",
        "    print(\"lunghezza exemplar set: \", len(exemplars_set))\n",
        "    return exemplars_set"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy_HVL-tjZcb"
      },
      "source": [
        "### reduce exemplar set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7kuQ5DnjcCP"
      },
      "source": [
        "# DA CHIAMARE PER OGNI CLASSE k: riduce il numero di exemplars all'interno dell'exemplar_set della classe k \n",
        "# EXEMPLAR SET è una lista di indici che rappresentano la posizione dell'immagine selezionata per l'exemplar della classe corrente nel dataset di partenza\n",
        "def reduceExemplarSet(m, exemplars_set):\n",
        "  exemplars_new = []\n",
        "  for i in range(m):\n",
        "    if (exemplars_set != []):\n",
        "      exemplars_new.append(exemplars_set[i])\n",
        "\n",
        "  return exemplars_new"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMMlEpLsjfaj"
      },
      "source": [
        "### update representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRdA9RtDjhak"
      },
      "source": [
        "def updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes, group_id, K, exemplars_set_tot, old_net):\n",
        "  #exemplars_set_tot contiene tutti gli exemplars set ottenuti fino ad ora\n",
        "  #train_iter contiene tutti i dati (immagini + labels) delle classi nuove (s, .., t)\n",
        "  exemplars_subset = []\n",
        "  exemplars_indices = []\n",
        "  total_exemplars = []\n",
        "  labels_tot = []\n",
        "\n",
        "  for k, exemplar_set_class_k in exemplars_set_tot.items():\n",
        "    # exemplar_set_class_k is the list of indices of images that belongs to the exemplar set selected for class k \n",
        "    if (exemplar_set_class_k != []):\n",
        "      exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "      total_exemplars = torch.utils.data.ConcatDataset([total_exemplars, exemplars_subset])\n",
        "\n",
        "  if group_id > 1:\n",
        "    train_subset_total = torch.utils.data.ConcatDataset([train_subset, total_exemplars])\n",
        "  else:\n",
        "    train_subset_total = train_subset\n",
        "    \n",
        "  print(\"Len TOTAL train susbset: \", len(train_subset_total))\n",
        "  train_loader = torch.utils.data.DataLoader(train_subset_total, shuffle = True, batch_size=BATCH_SIZE, num_workers=2)\n",
        "  # train_loader è la concatenazione delle nuove classi con gli exemplar_sets calcolati fino a questo punto \n",
        "  print(\"training\")\n",
        "  train(net, train_loader, criterion, optimizer, scheduler, num_classes, group_id, old_net)\n",
        "  #trainWithOtherLosses(net, train_loader, criterion, optimizer, scheduler, num_classes, group_id, old_net)\n",
        "  #trainCEandL1(net, train_loader, criterion, optimizer, scheduler, num_classes, group_id, old_net)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac65-6QGjm9O"
      },
      "source": [
        "### incremental train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPU_32ArjpPH"
      },
      "source": [
        "import copy\n",
        "def incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_until_now):\n",
        "  print(\"Starting the update representation\")\n",
        "  exemplar_indices = None\n",
        "  num_classes = 10\n",
        "  new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "  print(\"NEW CLASSES: \", new_classes_examined)\n",
        "\n",
        "  updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net)\n",
        "                \n",
        "  iteration = group_id - 1\n",
        "  t = (num_classes * iteration) + num_classes # num_classes ricevute fino a questo momento \n",
        "  m = int(K/t) #casto ad intero ? per difetto o eccesso?\n",
        "  #s = num_classes * iteration\n",
        "\n",
        "  # REDUCING EXEMPLAR SET FOR EXISTING CLASSES\n",
        "  print(\"reducing exemplars for each class\")\n",
        "  print(total_classes_until_now)\n",
        "  for y in total_classes_until_now: #ci serve un set con tutte le classi fino ad ora viste\n",
        "    exemplar_y_new = reduceExemplarSet(m, exemplars_set_tot[y]) # valore associato alla chiave y che rappresenta il label della classe \n",
        "    print(\"REDUCED EXEMPLAR: \", len(exemplar_y_new))\n",
        "    exemplars_set_tot[y] = exemplar_y_new\n",
        "\n",
        "  \n",
        "  # CONSTRUCTION EXEMPLAR SET FOR NEW CLASSES\n",
        "  for y in new_classes_examined: # nuovi classi in arrivo di cui vogliamo costruire il set rappresentativo\n",
        "    images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data']\n",
        "    imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "    class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "    print(\"class train: \", class_train_subset)\n",
        "    print(\"Constructing exemplars of class\", y)\n",
        "    exemplars_set = constructExemplarSet(net, class_train_subset, m) # exemplar set è un set di indici\n",
        "    #devo recuperare dal dataset iniziale l'indice delle immagini dell'exemplar set creato \n",
        "    #for image in exemplars_set:\n",
        "     # exemplars_set = train_dataset.df.index[train_dataset.df['data'] == image].tolist()\n",
        "    exemplars_set_tot[y] = exemplars_set\n",
        "    print(\"exemplar set: \", exemplars_set)\n",
        "\n",
        "  # IMPLEMENTATION 'END-to-END Incremental Learning' PAPER\n",
        "  balancedFinetune(net, group_id, exemplars_set_tot, NUM_EPOCHS_FINETUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDxmsQlWjp5D"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQznGoEju9J"
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes_till_now, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "    print(\"num classes till now: \", num_classes_till_now)\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes_till_now, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "           \n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            #if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            if (group_id > 1):\n",
        "              old_features = old_net.forward(images)\n",
        "              old_outputs = old_net.predict(old_features)\n",
        "              labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcZUqVCjeMG4"
      },
      "source": [
        "### Train con CE + L1Loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl4zFMYGtAEJ"
      },
      "source": [
        "import copy\n",
        "def trainCEandL1(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "    distillation_loss = 0\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "  \n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "            # Classification LOSS\n",
        "            lr = 0.01\n",
        "            classification_loss = nn.CrossEntropyLoss()(outputs, labels) # BCE\n",
        "\n",
        "            # Distillation LOSS \n",
        "            if (group_id > 1):\n",
        "               old_features = old_net.forward(images)\n",
        "               old_outputs = old_net.predict(old_features)\n",
        "               #labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "               new_labels = torch.sigmoid(old_outputs)\n",
        "               new_outputs = outputs[:, 0:num_classes_till_previous_step]\n",
        "               lr = 1e-3\n",
        "               distillation_loss = l1Loss(new_outputs, new_labels) # L2\n",
        "               print(distillation_loss)\n",
        "\n",
        "            loss = classification_loss + distillation_loss\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrbPsdT2eRho"
      },
      "source": [
        "### Train con CE + KLDiv Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzTrBE-Dea1S"
      },
      "source": [
        "import copy\n",
        "def trainWithOtherLosses(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "    distillation_loss = 0\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "  \n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "            # Classification LOSS\n",
        "            classification_loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            # Distillation LOSS \n",
        "            if (group_id > 1):\n",
        "               old_features = old_net.forward(images)\n",
        "               old_outputs = old_net.predict(old_features)\n",
        "               T = 2\n",
        "               beta = 0.25\n",
        "               distillation_loss = nn.KLDivLoss()(F.log_softmax(outputs[:, 0:num_classes_till_previous_step]/T, dim = 1), F.softmax(old_outputs.detach()/T, dim = 1)) * T * T * beta * num_classes_till_previous_step\n",
        "\n",
        "            loss = classification_loss + distillation_loss\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHpi410ljzWD"
      },
      "source": [
        "### test and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQYB0-cLj0sP"
      },
      "source": [
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        #_, preds = classify(images, )\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "246M7j-s4Chq"
      },
      "source": [
        "### Balanced Finetune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFJY_fB5ymS"
      },
      "source": [
        "def data_augmentation_e2e(img, lab):\n",
        "    \"\"\"\n",
        "        Realize the data augmentation in End-to-End paper\n",
        "        Parameters\n",
        "        ----------\n",
        "        img: the original images, size = (n, c, w, h)\n",
        "        lab: the original labels, size = (n)\n",
        "        Returns\n",
        "        ----------\n",
        "        img_aug: the original images, size = (n * 12, c, w, h)\n",
        "        lab_aug: the original labels, size = (n * 12)\n",
        "    \"\"\"\n",
        "    \n",
        "    shape = np.shape(img)\n",
        "    # print(\"IMG is: \",img)\n",
        "    # print(shape[0], 1, shape[1], shape[2], shape[3])\n",
        "    img_aug = np.zeros((shape[0], 6, shape[1], shape[2], shape[3]))\n",
        "    img_aug[:, 0, :, :, :] = img\n",
        "    lab_aug = np.zeros((shape[0], 6))\n",
        "    # print(\"IMG_AUG is: \", img_aug)\n",
        "\n",
        "    for i in range(shape[0]):\n",
        "        # np.random.seed(int(time.time()) % 1000)\n",
        "\n",
        "        # convert image from tensor to numpy\n",
        "        image=img.numpy()\n",
        "        im = image[i]\n",
        "      \n",
        "        # # brightness\n",
        "        brightness = (np.random.rand(1)-0.5)*2*63\n",
        "        im_temp = im + brightness\n",
        "\n",
        "        img_aug[i, 1] = im_temp\n",
        "\n",
        "\n",
        "        # constrast\n",
        "        constrast = (np.random.rand(1)-0.5)*2*0.8+1\n",
        "        m0 = np.mean(im[0])\n",
        "        m1 = np.mean(im[1])\n",
        "        m2 = np.mean(im[2])\n",
        "        im_temp = im\n",
        "        im_temp[0] = (im_temp[0]-m0)*constrast + m0\n",
        "        im_temp[1] = (im_temp[1]-m1)*constrast + m1\n",
        "        im_temp[2] = (im_temp[2]-m2)*constrast + m2\n",
        "        img_aug[i, 2] = im_temp\n",
        "\n",
        "        # crop\n",
        "        im_temp = img_aug[i, :3]\n",
        "        for j in range(3):\n",
        "            x_ = int(np.random.rand(1)*1000)%8\n",
        "            y_ = int(np.random.rand(1)*1000)%8\n",
        "            im_temp = np.zeros(shape=(shape[1], shape[2]+8, shape[3]+8))\n",
        "            im_temp[:, 4:-4, 4:-4] = img_aug[i, j]\n",
        "            img_aug[i, 3+j] = im_temp[:, x_:x_+shape[2], y_:y_+shape[3]]\n",
        "\n",
        "\n",
        "\n",
        "        # mirror\n",
        "        # for j in range(6):\n",
        "        #     im_temp = img_aug[i, j]\n",
        "        #     img_aug[i, 6 + j] = im_temp[:,-1::-1,:]\n",
        "\n",
        "        lab_aug[i, :] = lab[i]\n",
        "\n",
        "    # idx = np.where(img_aug>255)\n",
        "    # img_aug[idx] = 255\n",
        "    # idx = np.where(img_aug<0)\n",
        "    # img_aug[idx] = 0\n",
        "\n",
        "    img_aug = np.reshape(img_aug, newshape=(shape[0]*6, shape[1], shape[2], shape[3]))\n",
        "    img_aug = np.array(img_aug, dtype=np.float64)\n",
        "    lab_aug = np.reshape(lab_aug, newshape=(shape[0]*6))\n",
        "    lab_aug = np.array(lab_aug, dtype=np.float64)\n",
        "    return img_aug, lab_aug"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC_zGBOB4B4J"
      },
      "source": [
        "def balancedFinetune(net, iteration, exemplars_set_tot, NUM_EPOCHS):\n",
        "  num_classes_till_previous_step = iteration * 10 - 10\n",
        "  num_classes = iteration * 10\n",
        "  total_exemplars = []\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  old_net = copy.deepcopy(net)\n",
        "  old_net.eval()\n",
        "\n",
        "  #if iteration > 1:\n",
        "  for k, exemplar_set_class_k in exemplars_set_tot.items():\n",
        "    if (exemplar_set_class_k != []):\n",
        "      exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "      total_exemplars = torch.utils.data.ConcatDataset([total_exemplars, exemplars_subset])\n",
        "    \n",
        "  reduced_train_loader = torch.utils.data.DataLoader(total_exemplars, shuffle = True, batch_size=BATCH_SIZE, num_workers=2)\n",
        "  # reduced train loader is the sets of all exemplars of new and old classes\n",
        "\n",
        "  # finetune\n",
        "  lrc = LR *0.05 # small learning rate for finetune\n",
        "  print('current lr = %f' % (lrc))\n",
        "  softmax = nn.Softmax(dim=-1).cuda()\n",
        "  current_step = 0\n",
        "  acc_finetune_train = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS_FINETUNE):\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    print('Starting epoch {}/{}'.format(epoch+1, NUM_EPOCHS_FINETUNE))\n",
        "    for _, images, labels in reduced_train_loader:\n",
        "      images, labels = data_augmentation_e2e(images,labels) \n",
        "      images = torch.from_numpy(images) \n",
        "      labels = torch.from_numpy(labels) \n",
        "    # reduced_train_loader contains the same number of images for both new classes and old classes\n",
        "      images = images.to(DEVICE, dtype=torch.float32)\n",
        "      labels = labels.to(DEVICE, dtype=torch.float32)\n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "      optimizer = torch.optim.SGD(net.parameters(), lr=lrc, momentum=MOMENTUM,\n",
        "                                    weight_decay= WEIGHT_DECAY, nesterov=True)\n",
        "\n",
        "\n",
        "      # print(\"Outside: input size\", img.size(), \"output_size\", lab.size())\n",
        "      features = net.forward(images)\n",
        "      outputs = net.predict(features)\n",
        "\n",
        "      # classification loss\n",
        "      prob_cls = softmax(outputs)\n",
        "      labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "      labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "    # distillation loss for all classes (maybe the author only distillates for novel classes)\n",
        "      if iteration > 1:\n",
        "        old_features = old_net.forward(images)\n",
        "        old_outputs = old_net.predict(old_features)\n",
        "        labels_enc[:, 0:num_classes_till_previous_step] = torch.sigmoid(old_outputs[:, 0:num_classes_till_previous_step])\n",
        "\n",
        "\n",
        "      loss = computeLoss(criterion, outputs, labels_enc)\n",
        "\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "          \n",
        "    # Update Corrects & Loss\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Log loss\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss = running_loss / float(len(reduced_train_loader.dataset)*6)\n",
        "      epoch_acc = running_corrects / float(len(reduced_train_loader.dataset)*6)\n",
        "      \n",
        "    print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T96WcHWlIYGR"
      },
      "source": [
        "### CLASSIFIERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZTGxaotIXBI"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def classifierTrain(net, exemplars_set_tot):\n",
        "  torch.no_grad()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  X_train, y_train = [], []\n",
        "  total_exemplars = []\n",
        "  counter = 0\n",
        "\n",
        "  for k, exemplar_set_class_k in exemplars_set_tot.items():\n",
        "    # exemplar_set_class_k is the list of indices of images that belongs to the exemplar set selected for class k \n",
        "    if (exemplar_set_class_k != []):\n",
        "      counter += 1\n",
        "      exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "      total_exemplars = torch.utils.data.ConcatDataset([total_exemplars, exemplars_subset])\n",
        "\n",
        "\n",
        "  exemplar_sets = torch.utils.data.DataLoader(total_exemplars, shuffle = True, batch_size=1, num_workers=2)\n",
        "  for _, exemplar, label in exemplar_sets:\n",
        "    exemplar = exemplar.to(DEVICE)\n",
        "    features = net.forward(exemplar)\n",
        "    outputs = net.predict(features)\n",
        "    outputs = outputs.squeeze()\n",
        "    outputs.data = outputs.data / outputs.data.norm()\n",
        "    X_train.append(outputs.cpu().detach().numpy())\n",
        "    y_train.append(label)\n",
        "\n",
        "  K_nn = math.ceil(2000/counter)\n",
        "  model1 = LinearSVC()\n",
        "  model2 = KNeighborsClassifier(n_neighbors = K_nn)\n",
        "  print(\"x train: \", X_train[0])\n",
        "  print(\"y_train: \", y_train)\n",
        "  model = model2.fit(X_train, y_train)\n",
        "  return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYs6xKy1J-pQ"
      },
      "source": [
        "def classifySVM_KNN(net, images, model):\n",
        "  torch.no_grad()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  X_pred = []\n",
        "  images = images.to(DEVICE)\n",
        "  features = net.forward(images)\n",
        "  outputs = net.predict(features)\n",
        "\n",
        "  for feature in outputs:\n",
        "    feature = feature.squeeze()\n",
        "    feature.data = feature.data / feature.data.norm()\n",
        "    X_pred.append(feature.cpu().detach().numpy())\n",
        "\n",
        "  preds = model.predict(X_pred)\n",
        "  return torch.tensor(preds)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7WwJLGnJcXC"
      },
      "source": [
        "def validateSVM(net, val_dataloader, criterion, num_classes, model):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        #images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        preds = classifySVM_KNN(net, images, model)\n",
        "        preds = preds.to(DEVICE)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def testSVM(net, test_dataloader, num_classes, model):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validateSVM(net, test_dataloader, None, num_classes, model)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTv6zBetj3Cb"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_cnELYdkap4"
      },
      "source": [
        "def sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    K = 2000\n",
        "    iterations = 10\n",
        "    num_classes = 10\n",
        "    exemplars_set_tot = {new_list: [] for new_list in range(100)}\n",
        "    labels_train = []\n",
        "    total_classes_seen = []\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "\n",
        "      print(\"TRAIN: \", len(train_subset))\n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      print(\"TEST SET LENGHT: \", len(test_set))\n",
        "      print(\"TEST CURRENT GROUP SET LENGHT: \", len(test_subset))\n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      test_classes = list(test_dataset.df.loc[test_set.indices, 'labels'].value_counts().index)\n",
        "      train_classes = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "      validation_classes = list(train_dataset.df.loc[val_subset.indices, 'labels'].value_counts().index)\n",
        "      for i in train_classes:\n",
        "        total_classes_seen.append(i)\n",
        "      print(\"TEST_SET CLASSES: \", test_classes)\n",
        "      print(\"TRAIN_SET CLASSES: \", train_classes)\n",
        "      print(\"VALIDATION CLASSES: \", validation_classes)\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "\n",
        "      incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_seen) # Train the network with 10 classes at a time\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTV1Gxq6yF5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fbb78f-a36f-449c-fcfb-9ac9a08a434b"
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  1000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [67, 65, 59, 56, 49, 39, 22, 20, 18, 4]\n",
            "TRAIN_SET CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "VALIDATION CLASSES:  [59, 56, 49, 39, 22, 20, 18, 4, 67, 65]\n",
            "GROUP:  1\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "Len TOTAL train susbset:  4950\n",
            "training\n",
            "num classes till now:  10\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7586106657981873\n",
            "Train step - Step 10, Loss 0.30439433455467224\n",
            "Train step - Step 20, Loss 0.3009668290615082\n",
            "Train step - Step 30, Loss 0.27255502343177795\n",
            "Train epoch - Accuracy: 0.2725252525252525 Loss: 0.3634068099416868 Corrects: 1349\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.243915393948555\n",
            "Train step - Step 50, Loss 0.2507122755050659\n",
            "Train step - Step 60, Loss 0.2574337422847748\n",
            "Train step - Step 70, Loss 0.24681983888149261\n",
            "Train epoch - Accuracy: 0.4090909090909091 Loss: 0.2539203481300913 Corrects: 2025\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.2331002801656723\n",
            "Train step - Step 90, Loss 0.236083984375\n",
            "Train step - Step 100, Loss 0.2242729216814041\n",
            "Train step - Step 110, Loss 0.22879250347614288\n",
            "Train epoch - Accuracy: 0.4812121212121212 Loss: 0.23024384696074207 Corrects: 2382\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.21990866959095\n",
            "Train step - Step 130, Loss 0.21456484496593475\n",
            "Train step - Step 140, Loss 0.21369753777980804\n",
            "Train step - Step 150, Loss 0.22638459503650665\n",
            "Train epoch - Accuracy: 0.5157575757575757 Loss: 0.2180185188669147 Corrects: 2553\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.22205086052417755\n",
            "Train step - Step 170, Loss 0.20034904778003693\n",
            "Train step - Step 180, Loss 0.20659957826137543\n",
            "Train step - Step 190, Loss 0.19989827275276184\n",
            "Train epoch - Accuracy: 0.5276767676767676 Loss: 0.20989411434139868 Corrects: 2612\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.19992320239543915\n",
            "Train step - Step 210, Loss 0.22280697524547577\n",
            "Train step - Step 220, Loss 0.20618276298046112\n",
            "Train step - Step 230, Loss 0.20507340133190155\n",
            "Train epoch - Accuracy: 0.5490909090909091 Loss: 0.2008100777322596 Corrects: 2718\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.18876080214977264\n",
            "Train step - Step 250, Loss 0.20299172401428223\n",
            "Train step - Step 260, Loss 0.20944491028785706\n",
            "Train step - Step 270, Loss 0.20528648793697357\n",
            "Train epoch - Accuracy: 0.5775757575757576 Loss: 0.19410575198404717 Corrects: 2859\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.17262206971645355\n",
            "Train step - Step 290, Loss 0.20038561522960663\n",
            "Train step - Step 300, Loss 0.1595049649477005\n",
            "Train step - Step 310, Loss 0.16833733022212982\n",
            "Train epoch - Accuracy: 0.6012121212121212 Loss: 0.18449744473804128 Corrects: 2976\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.17479510605335236\n",
            "Train step - Step 330, Loss 0.17957337200641632\n",
            "Train step - Step 340, Loss 0.1823665350675583\n",
            "Train step - Step 350, Loss 0.18572086095809937\n",
            "Train epoch - Accuracy: 0.6038383838383838 Loss: 0.18198708266922922 Corrects: 2989\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.1912810355424881\n",
            "Train step - Step 370, Loss 0.17802993953227997\n",
            "Train step - Step 380, Loss 0.1729671210050583\n",
            "Train epoch - Accuracy: 0.62 Loss: 0.1752269655405873 Corrects: 3069\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.17059598863124847\n",
            "Train step - Step 400, Loss 0.15756651759147644\n",
            "Train step - Step 410, Loss 0.18338875472545624\n",
            "Train step - Step 420, Loss 0.16237853467464447\n",
            "Train epoch - Accuracy: 0.6428282828282829 Loss: 0.16998167923604598 Corrects: 3182\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.15927660465240479\n",
            "Train step - Step 440, Loss 0.17285965383052826\n",
            "Train step - Step 450, Loss 0.17046736180782318\n",
            "Train step - Step 460, Loss 0.16367971897125244\n",
            "Train epoch - Accuracy: 0.655959595959596 Loss: 0.16435116453604265 Corrects: 3247\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.13132037222385406\n",
            "Train step - Step 480, Loss 0.15747110545635223\n",
            "Train step - Step 490, Loss 0.15674246847629547\n",
            "Train step - Step 500, Loss 0.14822879433631897\n",
            "Train epoch - Accuracy: 0.6553535353535354 Loss: 0.15902542891526464 Corrects: 3244\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.12547169625759125\n",
            "Train step - Step 520, Loss 0.15335123240947723\n",
            "Train step - Step 530, Loss 0.15545326471328735\n",
            "Train step - Step 540, Loss 0.1609473079442978\n",
            "Train epoch - Accuracy: 0.6797979797979798 Loss: 0.15312296669290523 Corrects: 3365\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.1432950794696808\n",
            "Train step - Step 560, Loss 0.14243042469024658\n",
            "Train step - Step 570, Loss 0.13233153522014618\n",
            "Train step - Step 580, Loss 0.13551801443099976\n",
            "Train epoch - Accuracy: 0.6868686868686869 Loss: 0.14659959756364727 Corrects: 3400\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 590, Loss 0.14388182759284973\n",
            "Train step - Step 600, Loss 0.16547362506389618\n",
            "Train step - Step 610, Loss 0.15157823264598846\n",
            "Train step - Step 620, Loss 0.16388332843780518\n",
            "Train epoch - Accuracy: 0.7018181818181818 Loss: 0.14317355021683856 Corrects: 3474\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 630, Loss 0.12655459344387054\n",
            "Train step - Step 640, Loss 0.14036455750465393\n",
            "Train step - Step 650, Loss 0.13990066945552826\n",
            "Train step - Step 660, Loss 0.15482330322265625\n",
            "Train epoch - Accuracy: 0.7202020202020202 Loss: 0.13870644215381506 Corrects: 3565\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 670, Loss 0.12713885307312012\n",
            "Train step - Step 680, Loss 0.1415306180715561\n",
            "Train step - Step 690, Loss 0.1526023894548416\n",
            "Train step - Step 700, Loss 0.13567426800727844\n",
            "Train epoch - Accuracy: 0.7280808080808081 Loss: 0.1324107587096667 Corrects: 3604\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.12491533905267715\n",
            "Train step - Step 720, Loss 0.1356750726699829\n",
            "Train step - Step 730, Loss 0.10865228623151779\n",
            "Train step - Step 740, Loss 0.15271824598312378\n",
            "Train epoch - Accuracy: 0.7353535353535353 Loss: 0.13015473743881842 Corrects: 3640\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 750, Loss 0.11063029617071152\n",
            "Train step - Step 760, Loss 0.12355981022119522\n",
            "Train step - Step 770, Loss 0.1384476125240326\n",
            "Train epoch - Accuracy: 0.7393939393939394 Loss: 0.12739893134796257 Corrects: 3660\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 780, Loss 0.12358248233795166\n",
            "Train step - Step 790, Loss 0.118726447224617\n",
            "Train step - Step 800, Loss 0.12389712780714035\n",
            "Train step - Step 810, Loss 0.12035959959030151\n",
            "Train epoch - Accuracy: 0.7545454545454545 Loss: 0.12309080251539596 Corrects: 3735\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 820, Loss 0.12365638464689255\n",
            "Train step - Step 830, Loss 0.1078202947974205\n",
            "Train step - Step 840, Loss 0.0883571207523346\n",
            "Train step - Step 850, Loss 0.10994193702936172\n",
            "Train epoch - Accuracy: 0.7626262626262627 Loss: 0.11916446765263876 Corrects: 3775\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 860, Loss 0.11857340484857559\n",
            "Train step - Step 870, Loss 0.12575428187847137\n",
            "Train step - Step 880, Loss 0.09329762309789658\n",
            "Train step - Step 890, Loss 0.12016689777374268\n",
            "Train epoch - Accuracy: 0.768080808080808 Loss: 0.11666959002764538 Corrects: 3802\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 900, Loss 0.10187243670225143\n",
            "Train step - Step 910, Loss 0.12082016468048096\n",
            "Train step - Step 920, Loss 0.10793714970350266\n",
            "Train step - Step 930, Loss 0.11971278488636017\n",
            "Train epoch - Accuracy: 0.7854545454545454 Loss: 0.10954809880918927 Corrects: 3888\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.11176474392414093\n",
            "Train step - Step 950, Loss 0.10952915996313095\n",
            "Train step - Step 960, Loss 0.10990144312381744\n",
            "Train step - Step 970, Loss 0.11726939678192139\n",
            "Train epoch - Accuracy: 0.793939393939394 Loss: 0.10701187830380719 Corrects: 3930\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.09425022453069687\n",
            "Train step - Step 990, Loss 0.11140070110559464\n",
            "Train step - Step 1000, Loss 0.0942263975739479\n",
            "Train step - Step 1010, Loss 0.1128518357872963\n",
            "Train epoch - Accuracy: 0.7911111111111111 Loss: 0.10645978030231264 Corrects: 3916\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1020, Loss 0.11882276833057404\n",
            "Train step - Step 1030, Loss 0.10062382370233536\n",
            "Train step - Step 1040, Loss 0.10386891663074493\n",
            "Train step - Step 1050, Loss 0.10297460854053497\n",
            "Train epoch - Accuracy: 0.796969696969697 Loss: 0.10470722421853229 Corrects: 3945\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1060, Loss 0.093207947909832\n",
            "Train step - Step 1070, Loss 0.10320266336202621\n",
            "Train step - Step 1080, Loss 0.10445874184370041\n",
            "Train step - Step 1090, Loss 0.1001843810081482\n",
            "Train epoch - Accuracy: 0.8088888888888889 Loss: 0.1000981322322229 Corrects: 4004\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10184919834136963\n",
            "Train step - Step 1110, Loss 0.08116624504327774\n",
            "Train step - Step 1120, Loss 0.09229448437690735\n",
            "Train step - Step 1130, Loss 0.12891283631324768\n",
            "Train epoch - Accuracy: 0.813939393939394 Loss: 0.09863874260825341 Corrects: 4029\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.08032858371734619\n",
            "Train step - Step 1150, Loss 0.08641248196363449\n",
            "Train step - Step 1160, Loss 0.1198798418045044\n",
            "Train epoch - Accuracy: 0.8197979797979797 Loss: 0.0933080866601732 Corrects: 4058\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1170, Loss 0.09790181368589401\n",
            "Train step - Step 1180, Loss 0.09387199580669403\n",
            "Train step - Step 1190, Loss 0.11733164638280869\n",
            "Train step - Step 1200, Loss 0.07946731895208359\n",
            "Train epoch - Accuracy: 0.8228282828282828 Loss: 0.09377168269169452 Corrects: 4073\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.08680088818073273\n",
            "Train step - Step 1220, Loss 0.09441955387592316\n",
            "Train step - Step 1230, Loss 0.08751673251390457\n",
            "Train step - Step 1240, Loss 0.08537764102220535\n",
            "Train epoch - Accuracy: 0.8262626262626263 Loss: 0.0906850110762047 Corrects: 4090\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.10023118555545807\n",
            "Train step - Step 1260, Loss 0.10338225215673447\n",
            "Train step - Step 1270, Loss 0.10467612743377686\n",
            "Train step - Step 1280, Loss 0.09952870011329651\n",
            "Train epoch - Accuracy: 0.8222222222222222 Loss: 0.09324934129462098 Corrects: 4070\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1290, Loss 0.08069112151861191\n",
            "Train step - Step 1300, Loss 0.09422199428081512\n",
            "Train step - Step 1310, Loss 0.07182888686656952\n",
            "Train step - Step 1320, Loss 0.05950532108545303\n",
            "Train epoch - Accuracy: 0.8387878787878787 Loss: 0.08641556154296856 Corrects: 4152\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1330, Loss 0.08253573626279831\n",
            "Train step - Step 1340, Loss 0.09996362775564194\n",
            "Train step - Step 1350, Loss 0.09874977171421051\n",
            "Train step - Step 1360, Loss 0.06407777965068817\n",
            "Train epoch - Accuracy: 0.8363636363636363 Loss: 0.0870378069684963 Corrects: 4140\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1370, Loss 0.08214571326971054\n",
            "Train step - Step 1380, Loss 0.06935819238424301\n",
            "Train step - Step 1390, Loss 0.09289944916963577\n",
            "Train step - Step 1400, Loss 0.09290742129087448\n",
            "Train epoch - Accuracy: 0.8406060606060606 Loss: 0.08414538630632439 Corrects: 4161\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.08200173079967499\n",
            "Train step - Step 1420, Loss 0.06629711389541626\n",
            "Train step - Step 1430, Loss 0.06340741366147995\n",
            "Train step - Step 1440, Loss 0.08742045611143112\n",
            "Train epoch - Accuracy: 0.8535353535353535 Loss: 0.07839919220618527 Corrects: 4225\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 1450, Loss 0.06009857729077339\n",
            "Train step - Step 1460, Loss 0.08709734678268433\n",
            "Train step - Step 1470, Loss 0.0713123232126236\n",
            "Train step - Step 1480, Loss 0.09093865752220154\n",
            "Train epoch - Accuracy: 0.8549494949494949 Loss: 0.07677581754597751 Corrects: 4232\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.0801796242594719\n",
            "Train step - Step 1500, Loss 0.08183139562606812\n",
            "Train step - Step 1510, Loss 0.06683652848005295\n",
            "Train step - Step 1520, Loss 0.09391305595636368\n",
            "Train epoch - Accuracy: 0.8476767676767677 Loss: 0.07935335399827571 Corrects: 4196\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 1530, Loss 0.06984978914260864\n",
            "Train step - Step 1540, Loss 0.08744487911462784\n",
            "Train step - Step 1550, Loss 0.08432864397764206\n",
            "Train epoch - Accuracy: 0.861010101010101 Loss: 0.0732644176031604 Corrects: 4262\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 1560, Loss 0.06872029602527618\n",
            "Train step - Step 1570, Loss 0.07968562096357346\n",
            "Train step - Step 1580, Loss 0.08951978385448456\n",
            "Train step - Step 1590, Loss 0.08243467658758163\n",
            "Train epoch - Accuracy: 0.8557575757575757 Loss: 0.0757904710748581 Corrects: 4236\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.060094524174928665\n",
            "Train step - Step 1610, Loss 0.07018805295228958\n",
            "Train step - Step 1620, Loss 0.08875808119773865\n",
            "Train step - Step 1630, Loss 0.05709940195083618\n",
            "Train epoch - Accuracy: 0.8662626262626263 Loss: 0.07154586022550409 Corrects: 4288\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 1640, Loss 0.06231668218970299\n",
            "Train step - Step 1650, Loss 0.0792706087231636\n",
            "Train step - Step 1660, Loss 0.05333273485302925\n",
            "Train step - Step 1670, Loss 0.07878505438566208\n",
            "Train epoch - Accuracy: 0.8628282828282828 Loss: 0.07143375181188487 Corrects: 4271\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.06794357299804688\n",
            "Train step - Step 1690, Loss 0.08571650087833405\n",
            "Train step - Step 1700, Loss 0.06137126684188843\n",
            "Train step - Step 1710, Loss 0.06091366335749626\n",
            "Train epoch - Accuracy: 0.8775757575757576 Loss: 0.06881372088284203 Corrects: 4344\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 1720, Loss 0.0940733477473259\n",
            "Train step - Step 1730, Loss 0.05217862129211426\n",
            "Train step - Step 1740, Loss 0.06487579643726349\n",
            "Train step - Step 1750, Loss 0.07444285601377487\n",
            "Train epoch - Accuracy: 0.8711111111111111 Loss: 0.06800830983453326 Corrects: 4312\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.07912907749414444\n",
            "Train step - Step 1770, Loss 0.05436766892671585\n",
            "Train step - Step 1780, Loss 0.07131894677877426\n",
            "Train step - Step 1790, Loss 0.07297174632549286\n",
            "Train epoch - Accuracy: 0.8808080808080808 Loss: 0.06446711818979244 Corrects: 4360\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 1800, Loss 0.07369213551282883\n",
            "Train step - Step 1810, Loss 0.06902008503675461\n",
            "Train step - Step 1820, Loss 0.05500223860144615\n",
            "Train step - Step 1830, Loss 0.07666786760091782\n",
            "Train epoch - Accuracy: 0.8836363636363637 Loss: 0.06266882457365894 Corrects: 4374\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.05603542923927307\n",
            "Train step - Step 1850, Loss 0.0606544129550457\n",
            "Train step - Step 1860, Loss 0.03638310357928276\n",
            "Train step - Step 1870, Loss 0.08041524887084961\n",
            "Train epoch - Accuracy: 0.8781818181818182 Loss: 0.06416438774027006 Corrects: 4347\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 1880, Loss 0.04564887285232544\n",
            "Train step - Step 1890, Loss 0.04615909233689308\n",
            "Train step - Step 1900, Loss 0.05180143192410469\n",
            "Train step - Step 1910, Loss 0.07128937542438507\n",
            "Train epoch - Accuracy: 0.8854545454545455 Loss: 0.06028510685520943 Corrects: 4383\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 1920, Loss 0.050461020320653915\n",
            "Train step - Step 1930, Loss 0.04074237495660782\n",
            "Train step - Step 1940, Loss 0.05157828330993652\n",
            "Train epoch - Accuracy: 0.915959595959596 Loss: 0.04784543407535312 Corrects: 4534\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1950, Loss 0.04706873744726181\n",
            "Train step - Step 1960, Loss 0.051363445818424225\n",
            "Train step - Step 1970, Loss 0.03819550201296806\n",
            "Train step - Step 1980, Loss 0.044488776475191116\n",
            "Train epoch - Accuracy: 0.9361616161616162 Loss: 0.040568168061700736 Corrects: 4634\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1990, Loss 0.04542255029082298\n",
            "Train step - Step 2000, Loss 0.06275742501020432\n",
            "Train step - Step 2010, Loss 0.032568901777267456\n",
            "Train step - Step 2020, Loss 0.06093253567814827\n",
            "Train epoch - Accuracy: 0.9298989898989899 Loss: 0.041155720154444374 Corrects: 4603\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2030, Loss 0.032943230122327805\n",
            "Train step - Step 2040, Loss 0.045569173991680145\n",
            "Train step - Step 2050, Loss 0.030588382855057716\n",
            "Train step - Step 2060, Loss 0.046663615852594376\n",
            "Train epoch - Accuracy: 0.9377777777777778 Loss: 0.03842762348853578 Corrects: 4642\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2070, Loss 0.042078401893377304\n",
            "Train step - Step 2080, Loss 0.04250689968466759\n",
            "Train step - Step 2090, Loss 0.043268751353025436\n",
            "Train step - Step 2100, Loss 0.03457432612776756\n",
            "Train epoch - Accuracy: 0.9361616161616162 Loss: 0.03787329194070113 Corrects: 4634\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2110, Loss 0.042250387370586395\n",
            "Train step - Step 2120, Loss 0.03363800048828125\n",
            "Train step - Step 2130, Loss 0.03610466793179512\n",
            "Train step - Step 2140, Loss 0.04285714030265808\n",
            "Train epoch - Accuracy: 0.9402020202020202 Loss: 0.03633489466375775 Corrects: 4654\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2150, Loss 0.05419269949197769\n",
            "Train step - Step 2160, Loss 0.045982033014297485\n",
            "Train step - Step 2170, Loss 0.043733734637498856\n",
            "Train step - Step 2180, Loss 0.03030426613986492\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.03550421701988789 Corrects: 4658\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2190, Loss 0.027635950595140457\n",
            "Train step - Step 2200, Loss 0.028052717447280884\n",
            "Train step - Step 2210, Loss 0.040526680648326874\n",
            "Train step - Step 2220, Loss 0.040906261652708054\n",
            "Train epoch - Accuracy: 0.9444444444444444 Loss: 0.03562748930670998 Corrects: 4675\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2230, Loss 0.031162826344370842\n",
            "Train step - Step 2240, Loss 0.043204933404922485\n",
            "Train step - Step 2250, Loss 0.04440772905945778\n",
            "Train step - Step 2260, Loss 0.04358961060643196\n",
            "Train epoch - Accuracy: 0.9470707070707071 Loss: 0.034391553666856554 Corrects: 4688\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2270, Loss 0.0208109263330698\n",
            "Train step - Step 2280, Loss 0.02689114771783352\n",
            "Train step - Step 2290, Loss 0.03568577021360397\n",
            "Train step - Step 2300, Loss 0.026205716654658318\n",
            "Train epoch - Accuracy: 0.9436363636363636 Loss: 0.034072677478796304 Corrects: 4671\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2310, Loss 0.026545623317360878\n",
            "Train step - Step 2320, Loss 0.03947168588638306\n",
            "Train step - Step 2330, Loss 0.0258526261895895\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.03289212272173227 Corrects: 4700\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2340, Loss 0.036884136497974396\n",
            "Train step - Step 2350, Loss 0.02440650202333927\n",
            "Train step - Step 2360, Loss 0.03440644219517708\n",
            "Train step - Step 2370, Loss 0.02610270120203495\n",
            "Train epoch - Accuracy: 0.9492929292929293 Loss: 0.03254496044055982 Corrects: 4699\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2380, Loss 0.0328805074095726\n",
            "Train step - Step 2390, Loss 0.04228295013308525\n",
            "Train step - Step 2400, Loss 0.03704283386468887\n",
            "Train step - Step 2410, Loss 0.04146307334303856\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.031971014480699195 Corrects: 4706\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2420, Loss 0.02611568383872509\n",
            "Train step - Step 2430, Loss 0.026353919878602028\n",
            "Train step - Step 2440, Loss 0.02501925826072693\n",
            "Train step - Step 2450, Loss 0.03363362327218056\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.030832070836214105 Corrects: 4711\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 2460, Loss 0.028508663177490234\n",
            "Train step - Step 2470, Loss 0.02739722840487957\n",
            "Train step - Step 2480, Loss 0.02460264414548874\n",
            "Train step - Step 2490, Loss 0.024985214695334435\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.029887394143475427 Corrects: 4723\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2500, Loss 0.028383105993270874\n",
            "Train step - Step 2510, Loss 0.023468701168894768\n",
            "Train step - Step 2520, Loss 0.024882441386580467\n",
            "Train step - Step 2530, Loss 0.04564083367586136\n",
            "Train epoch - Accuracy: 0.9587878787878787 Loss: 0.02818843812728771 Corrects: 4746\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2540, Loss 0.024311451241374016\n",
            "Train step - Step 2550, Loss 0.025167513638734818\n",
            "Train step - Step 2560, Loss 0.02742443047463894\n",
            "Train step - Step 2570, Loss 0.027118170633912086\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.0268938463331774 Corrects: 4766\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2580, Loss 0.027797823771834373\n",
            "Train step - Step 2590, Loss 0.022819651290774345\n",
            "Train step - Step 2600, Loss 0.03111562691628933\n",
            "Train step - Step 2610, Loss 0.03398090973496437\n",
            "Train epoch - Accuracy: 0.9565656565656566 Loss: 0.027540451201676117 Corrects: 4735\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2620, Loss 0.023994863033294678\n",
            "Train step - Step 2630, Loss 0.02910252846777439\n",
            "Train step - Step 2640, Loss 0.033028457313776016\n",
            "Train step - Step 2650, Loss 0.026837199926376343\n",
            "Train epoch - Accuracy: 0.9632323232323232 Loss: 0.02846930064185701 Corrects: 4768\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2660, Loss 0.017881963402032852\n",
            "Train step - Step 2670, Loss 0.024474238976836205\n",
            "Train step - Step 2680, Loss 0.02428095042705536\n",
            "Train step - Step 2690, Loss 0.01657242141664028\n",
            "Train epoch - Accuracy: 0.9624242424242424 Loss: 0.026235638363945362 Corrects: 4764\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.023415355011820793\n",
            "Train step - Step 2710, Loss 0.030852986499667168\n",
            "Train step - Step 2720, Loss 0.030554592609405518\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.026037303353048335 Corrects: 4772\n",
            "Training finished in 196.62564182281494 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30abe4990>\n",
            "Constructing exemplars of class 67\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [12149, 41855, 30023, 40581, 26975, 22817, 15270, 49439, 29674, 9181, 7752, 25833, 10946, 42128, 9853, 37561, 715, 32224, 7768, 13704, 3928, 125, 49094, 3847, 46588, 32978, 41609, 14249, 28403, 34006, 1014, 13341, 32328, 18812, 5825, 31732, 47059, 21813, 4609, 48523, 27036, 7164, 15324, 22434, 47314, 41721, 12995, 5807, 35298, 38422, 5385, 21663, 31039, 191, 17612, 49439, 20984, 1088, 31918, 40285, 8812, 20452, 18577, 14843, 17881, 9702, 18295, 23985, 15674, 25278, 5825, 16346, 22925, 13905, 12908, 17411, 6919, 46588, 40906, 14711, 25833, 46443, 40605, 18812, 39243, 10380, 34036, 9331, 7739, 7631, 26910, 35093, 16878, 18488, 18713, 22085, 34036, 43844, 29694, 48250, 2742, 7164, 37338, 5107, 35158, 8206, 28625, 32604, 40570, 49244, 21286, 44900, 28209, 39089, 34332, 35199, 21143, 4411, 4362, 23259, 27612, 2860, 27183, 19810, 30115, 6978, 25844, 39089, 27157, 26294, 4076, 1088, 17411, 14711, 18314, 7029, 27036, 49458, 48252, 21031, 25145, 20646, 30890, 35749, 29048, 18423, 1796, 17612, 4516, 19244, 44902, 2742, 4970, 49340, 6928, 13208, 7631, 35199, 17514, 5543, 32082, 21663, 8692, 9702, 29694, 37188, 16820, 5107, 37338, 6815, 20646, 2816, 30412, 44902, 2742, 38197, 25145, 6455, 48251, 7739, 44686, 1356, 38330, 48574, 35433, 26910, 28657, 46574, 19810, 9092, 17411, 5543, 15465, 2860, 16592, 42872, 30391, 8812, 14843, 32328]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff379bf8a50>\n",
            "Constructing exemplars of class 59\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [28806, 17943, 13656, 48169, 10927, 19136, 30615, 38991, 13093, 18828, 11004, 41971, 21382, 4649, 32372, 13420, 45659, 16738, 23695, 16189, 9677, 26884, 41434, 27541, 32648, 8324, 29352, 15418, 18512, 38957, 25112, 32022, 973, 19092, 2530, 14376, 28258, 40888, 14671, 29367, 14758, 517, 39867, 36584, 34560, 2688, 40222, 610, 26194, 809, 17404, 7093, 26194, 34949, 6283, 34163, 46059, 4708, 517, 11637, 18250, 24503, 25654, 31674, 38061, 8931, 34949, 39034, 24, 7093, 34129, 17894, 26213, 21624, 29320, 22470, 31097, 27956, 26113, 36637, 28212, 34455, 43534, 29872, 10020, 8271, 38991, 36945, 46938, 7118, 31685, 19092, 18467, 31559, 23289, 34560, 39361, 30474, 38957, 973, 10167, 22797, 31097, 38195, 34562, 45838, 9981, 25629, 43758, 47614, 18938, 48148, 27824, 16086, 110, 11016, 17831, 46059, 19677, 22797, 30553, 8324, 15950, 46093, 17831, 34862, 18757, 36999, 19709, 27821, 8918, 33020, 7065, 11710, 25891, 1270, 41434, 27541, 48359, 16650, 28860, 18865, 3995, 45448, 25654, 45267, 33173, 41434, 26688, 40888, 14413, 35106, 32778, 47268, 38216, 23695, 4649, 38279, 11710, 25654, 39361, 26213, 13328, 32372, 8676, 28218, 32614, 47683, 1160, 36701, 6746, 37490, 1237, 46599, 6973, 4010, 23695, 15810, 22130, 19183, 8843, 14376, 2530, 567, 9981, 21144, 39600, 5848, 17090, 11016, 17831, 14758, 8183, 31685, 16295, 4022, 45838, 16650, 12006, 24627]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1a8a50>\n",
            "Constructing exemplars of class 39\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [11265, 36912, 12135, 16303, 13387, 32039, 7060, 17437, 2213, 12386, 3495, 28733, 12786, 26504, 19303, 29734, 38449, 3970, 13745, 38593, 32758, 42181, 6776, 8962, 18637, 37929, 30788, 28004, 21575, 15156, 18147, 46187, 33368, 11883, 41951, 101, 42815, 17472, 6006, 8683, 5632, 17307, 19268, 25284, 38593, 5451, 33421, 33694, 19899, 30158, 38449, 2300, 47456, 24427, 20687, 27640, 101, 23668, 6407, 39280, 44085, 28132, 33518, 12412, 37628, 31964, 46089, 25704, 11082, 47788, 38449, 4519, 42644, 44285, 12931, 38868, 29160, 41876, 49887, 42637, 10386, 35268, 2946, 30307, 40640, 33518, 28132, 38868, 13473, 8031, 34160, 42224, 44790, 38592, 6124, 16316, 9660, 30725, 12168, 20919, 17931, 17522, 30930, 32439, 14172, 27032, 32758, 23215, 7493, 48932, 11011, 49899, 5525, 5621, 33421, 29160, 25126, 18522, 13724, 37909, 46089, 8082, 31843, 16303, 4155, 10689, 4457, 6006, 16816, 30647, 41383, 12931, 36912, 33238, 27805, 33518, 22556, 28001, 49952, 3495, 34507, 14438, 6639, 32620, 44285, 44315, 35280, 5414, 22599, 34501, 14670, 3745, 32848, 47632, 49952, 11500, 48448, 45385, 40449, 14670, 42181, 48544, 22776, 26504, 10125, 3307, 22753, 29450, 42552, 8962, 3991, 42637, 49920, 29377, 49378, 23668, 21506, 40488, 39069, 15580, 35280, 13724, 39686, 38449, 36581, 6006, 30930, 5752, 36418, 13825, 40488, 15044, 8962, 44285, 32037, 8422, 32835, 41196, 13745, 20453]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30abe4990>\n",
            "Constructing exemplars of class 22\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [13447, 26696, 10240, 10662, 3849, 16753, 8706, 7341, 6027, 6674, 22222, 22605, 1442, 7678, 45699, 46817, 7678, 19434, 42062, 16072, 18614, 22367, 11299, 21913, 4647, 27093, 39093, 46837, 37478, 12306, 47317, 6771, 3447, 16283, 25186, 48778, 9221, 33853, 25990, 18636, 28968, 10422, 12429, 19131, 10817, 41791, 19401, 5885, 34873, 22605, 5088, 40206, 11443, 18366, 20180, 9221, 43175, 8603, 8920, 3943, 26767, 20184, 39395, 30254, 40151, 11203, 30469, 35236, 48379, 14867, 26441, 14862, 14460, 1851, 31477, 18163, 18894, 39731, 2752, 8942, 46997, 40349, 49320, 18636, 37858, 38451, 29247, 29969, 24970, 35685, 46230, 47317, 8638, 38469, 31292, 29247, 31931, 5794, 15708, 35337, 17646, 24590, 17623, 28109, 21219, 11972, 37382, 35194, 26441, 49180, 18902, 38235, 8126, 10240, 4961, 48485, 47145, 7696, 36367, 6027, 48870, 18614, 39093, 46837, 49069, 17464, 23664, 12726, 5766, 29366, 43824, 32180, 15708, 20770, 46837, 21712, 29153, 42949, 37554, 31053, 2503, 24147, 23454, 6544, 37915, 37478, 20024, 46817, 4688, 36367, 19765, 48485, 10976, 25178, 33574, 36310, 39093, 5725, 2752, 38235, 6544, 26070, 35926, 5766, 27911, 7678, 48870, 10422, 17542, 36122, 12994, 35703, 15708, 5794, 45478, 10652, 5641, 36844, 8638, 8016, 2251, 41791, 6881, 48737, 42668, 9305, 15329, 12627, 6526, 37915, 37478, 29021, 21481, 36375, 28244, 32180, 11972, 29950, 27911, 6669]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a8eb190>\n",
            "Constructing exemplars of class 18\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [32500, 40498, 16527, 17748, 35525, 11276, 1859, 1242, 21877, 19077, 39460, 30885, 32431, 27981, 9718, 40752, 5966, 17430, 18836, 13269, 31722, 21650, 33185, 5477, 18176, 30555, 20720, 14633, 27989, 18500, 12009, 27169, 49032, 2778, 12541, 44530, 45598, 12585, 45162, 15212, 28829, 9782, 14279, 43586, 35395, 6306, 36886, 36791, 20174, 13292, 32952, 32191, 43183, 5966, 35917, 12530, 44655, 31539, 36687, 4107, 9605, 27698, 4386, 42153, 89, 33131, 4605, 1454, 36152, 26792, 27830, 32779, 46578, 22467, 33288, 5169, 26756, 36152, 5169, 35267, 29926, 43156, 31539, 44655, 18683, 13403, 838, 30489, 5966, 14283, 9622, 18500, 34023, 28389, 31256, 35793, 42406, 27343, 36791, 38676, 43183, 27483, 13785, 21877, 407, 31512, 26101, 13277, 32963, 14918, 31961, 27371, 38676, 42406, 24839, 6605, 5520, 19796, 8583, 6028, 407, 41949, 17134, 49145, 5477, 45663, 28829, 30306, 25714, 13913, 33199, 14128, 46500, 46386, 45188, 11893, 49032, 19596, 48813, 4461, 9774, 49243, 11893, 45833, 18332, 14977, 12619, 18836, 46578, 43649, 13785, 15174, 23875, 16819, 46386, 22397, 6028, 9654, 21877, 24472, 35917, 43870, 21552, 15833, 22416, 5809, 16017, 22467, 33465, 23705, 38498, 10127, 39583, 34561, 9718, 14811, 32963, 11385, 19577, 4107, 13148, 13732, 27748, 45817, 11132, 49129, 42724, 32122, 33465, 9645, 44991, 3343, 43287, 7149, 12530, 4386, 32779, 27830, 19921, 42420]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a913e10>\n",
            "Constructing exemplars of class 65\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [22447, 25106, 7024, 1917, 23942, 11441, 21059, 12943, 19294, 17480, 16057, 38833, 18252, 25365, 19667, 40512, 48464, 46475, 17959, 9073, 5505, 14676, 7322, 45132, 27400, 848, 38115, 39907, 42785, 47845, 2175, 4755, 40984, 9010, 15789, 6040, 3105, 5103, 3505, 35425, 14941, 13022, 49210, 20934, 37105, 28375, 15605, 21354, 432, 42701, 26757, 26586, 247, 23819, 16647, 47709, 44002, 37671, 14712, 29364, 46043, 615, 23825, 37635, 5505, 31386, 27493, 4550, 32834, 17681, 14308, 44708, 23766, 44002, 28855, 33597, 21445, 17681, 38907, 34260, 48692, 9979, 22746, 1175, 37018, 27400, 848, 46170, 49140, 41212, 14887, 17388, 10579, 20016, 11176, 37671, 38833, 35007, 32585, 594, 44363, 5505, 28532, 7777, 20579, 33596, 3807, 44459, 5294, 7322, 16039, 18550, 33229, 45632, 44741, 40984, 22746, 46475, 43618, 47207, 49140, 38799, 1738, 47845, 2424, 21975, 44708, 27615, 42979, 32212, 47804, 39587, 26627, 35862, 19161, 396, 23682, 37671, 645, 37153, 24847, 15499, 41695, 32583, 33781, 20934, 8123, 23464, 8255, 5820, 10038, 16041, 18580, 17959, 13022, 34206, 39196, 5331, 20396, 11569, 10695, 1982, 46250, 46848, 44741, 31657, 33472, 34559, 23766, 25214, 11632, 17406, 11632, 14410, 18570, 15657, 8009, 14200, 34302, 20348, 11836, 11925, 20396, 5443, 28544, 24775, 10333, 25046, 22341, 958, 4603, 29364, 49845, 33366, 802, 48711, 1917, 15842, 42353, 13399]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30c9da450>\n",
            "Constructing exemplars of class 49\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [28827, 33031, 23913, 34975, 17576, 49922, 30052, 38381, 6898, 20753, 35400, 5662, 15430, 33271, 38404, 4193, 29051, 13859, 33332, 45597, 36585, 17790, 40727, 13663, 38731, 33433, 19127, 26204, 24778, 15342, 46075, 27122, 23870, 14018, 30522, 41320, 31975, 38105, 34446, 49972, 46044, 14543, 8515, 26063, 30826, 41698, 25822, 43713, 4264, 20532, 5471, 32260, 40727, 45760, 28054, 49922, 4869, 12555, 15623, 34982, 40890, 49412, 31003, 4264, 49659, 29526, 15563, 13850, 34303, 33988, 38851, 5061, 40318, 6245, 12554, 38236, 18189, 27276, 42122, 23821, 14611, 47253, 7209, 46595, 1097, 14246, 19048, 45718, 19312, 15430, 12554, 3897, 11731, 42230, 36073, 12554, 19676, 41320, 15544, 35911, 23742, 35671, 11059, 2844, 34951, 1610, 45236, 37725, 18189, 33565, 4974, 14823, 13663, 44670, 19048, 1542, 49525, 15430, 36778, 26063, 9142, 5444, 12189, 1610, 45236, 1787, 44090, 14890, 16668, 38236, 46041, 46931, 14533, 28201, 2737, 20532, 40727, 17524, 27289, 34092, 38851, 16668, 11308, 14890, 46595, 20753, 43883, 7209, 1140, 9020, 1610, 30052, 17576, 10421, 34270, 8856, 47247, 36073, 43883, 19075, 22164, 515, 38105, 423, 4974, 11397, 26777, 40747, 29051, 25127, 7209, 23169, 37546, 34982, 3029, 41037, 13755, 42230, 617, 37363, 3897, 16668, 33562, 6758, 34270, 28844, 30826, 617, 36585, 2361, 42122, 18138, 43738, 7903, 6873, 49972, 16421, 16326, 36235, 42370]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1ad210>\n",
            "Constructing exemplars of class 56\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [36578, 36374, 8663, 4430, 31185, 38889, 49476, 43869, 39945, 43027, 19681, 16233, 25780, 42907, 4845, 35579, 37299, 8914, 787, 6522, 43633, 6243, 34776, 5316, 17919, 28823, 40795, 47805, 9061, 27809, 26765, 9503, 9102, 6766, 12819, 37089, 32509, 20482, 4387, 18984, 47336, 9811, 4787, 4656, 2255, 15636, 25104, 2196, 11023, 21522, 37622, 4458, 39721, 35305, 48440, 45627, 12921, 49475, 8063, 47956, 28828, 44416, 18984, 9632, 37259, 34242, 27163, 26492, 48035, 34183, 22460, 21020, 15636, 14787, 12244, 49557, 11727, 27809, 5929, 8628, 17027, 17919, 30076, 26150, 7492, 7619, 4554, 25059, 11727, 6165, 36165, 38960, 13025, 4857, 11376, 37090, 36843, 49633, 34146, 26492, 12499, 24562, 19240, 4314, 16924, 14167, 24562, 14972, 39591, 7156, 36374, 22401, 16233, 21594, 35305, 41553, 36137, 48466, 31995, 20038, 15023, 27174, 5316, 42019, 14825, 26153, 34776, 17799, 9333, 1410, 27809, 11760, 29110, 48478, 4314, 1862, 39500, 41011, 20482, 42697, 47106, 11376, 6486, 40003, 30758, 49475, 12571, 37299, 29639, 787, 4387, 38988, 32111, 43308, 32111, 14334, 19946, 38779, 42287, 25059, 27001, 36165, 45142, 44, 15511, 36623, 26410, 48429, 18368, 15511, 40271, 16068, 7829, 44068, 45033, 425, 24562, 30079, 36843, 36165, 36623, 9050, 29454, 25104, 5351, 40994, 6595, 108, 27163, 6165, 23486, 39599, 18867, 18801, 43869, 18984, 269, 33536, 9259, 1783]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1a9910>\n",
            "Constructing exemplars of class 20\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [8767, 26973, 5940, 17446, 46212, 38924, 10269, 10234, 26613, 17415, 28364, 22243, 764, 19354, 2395, 35384, 12599, 22713, 37971, 26830, 34447, 34663, 25504, 34855, 49354, 7606, 11488, 47108, 31251, 23045, 24084, 42094, 39206, 6072, 23897, 49630, 44839, 34819, 19132, 43565, 4833, 29591, 44986, 19222, 23602, 27325, 25198, 509, 45704, 25185, 13760, 34189, 43657, 27669, 44408, 33837, 36588, 30824, 31009, 38013, 19354, 13794, 46108, 44408, 32262, 29591, 44986, 12086, 25511, 18167, 34447, 25015, 26111, 44209, 41499, 47138, 4213, 23976, 5284, 29137, 49792, 11001, 23045, 34447, 49630, 30824, 32921, 46547, 36986, 30704, 5560, 13094, 31326, 16302, 19354, 14269, 17299, 6937, 33837, 36946, 49792, 46878, 30546, 44861, 12198, 8882, 1827, 41520, 39206, 6038, 30025, 1505, 19671, 23976, 37138, 19444, 45035, 38234, 13382, 26973, 13794, 35018, 33837, 2655, 5284, 44861, 21572, 43121, 24829, 14139, 18320, 2604, 26613, 8128, 17446, 37657, 44408, 26701, 17470, 12065, 46341, 31197, 48767, 43736, 29097, 42375, 37831, 34663, 8685, 37138, 46677, 23772, 9374, 42375, 12086, 18723, 4989, 19277, 32672, 8767, 23838, 17318, 32395, 44111, 14269, 4768, 14139, 43013, 26405, 9807, 19853, 388, 8685, 21615, 37898, 42375, 24829, 49986, 49855, 2758, 46183, 30069, 15166, 19622, 17362, 43121, 49657, 42123, 14329, 25504, 2395, 37538, 47303, 41235, 45704, 5231, 14710, 26407, 23772, 28825]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1a94d0>\n",
            "Constructing exemplars of class 4\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [35361, 14996, 29391, 20735, 5880, 35445, 20620, 6514, 36371, 41626, 5034, 49252, 44629, 15117, 19967, 25090, 43660, 19597, 11074, 39730, 23361, 41796, 15585, 38612, 44629, 5677, 41665, 35445, 30378, 23270, 37339, 48043, 7932, 11038, 49483, 14305, 22450, 45664, 43943, 13693, 10417, 30185, 21069, 488, 14691, 2429, 17304, 12897, 14058, 27342, 13422, 27342, 995, 28116, 38272, 12526, 18449, 22647, 47410, 42937, 32331, 7290, 40806, 15442, 46523, 19191, 5841, 34888, 27607, 951, 11798, 7372, 15117, 45436, 10104, 43098, 37030, 27921, 9579, 23853, 3951, 29391, 4588, 36241, 13695, 33004, 35445, 36339, 33634, 49000, 34481, 14826, 48043, 43943, 11687, 33329, 23853, 23909, 5542, 30665, 40659, 48332, 27342, 44629, 30378, 38565, 488, 35445, 4449, 24293, 30665, 6565, 49257, 15766, 37339, 40048, 24635, 37645, 23853, 4704, 24358, 42349, 17197, 43660, 954, 11985, 993, 29496, 6051, 33003, 7819, 33003, 41304, 43286, 20699, 26299, 22274, 19191, 34481, 39400, 7031, 37049, 7524, 44264, 20970, 46335, 23505, 11950, 19181, 41705, 45163, 43786, 40069, 40588, 26319, 11798, 4449, 45163, 24228, 42050, 14826, 18400, 17903, 10417, 48043, 32066, 7015, 37547, 25399, 19967, 10061, 21103, 45664, 42869, 7819, 4813, 27560, 42467, 7932, 42844, 18460, 4304, 36340, 13211, 46335, 11074, 45465, 3067, 13422, 38039, 1302, 10417, 26476, 37055, 2769, 916, 42661, 26476, 10058, 41481]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 9.359236717224121\n",
            "Train step - Step 0, Loss 11.853431701660156\n",
            "Train step - Step 0, Loss 13.706266403198242\n",
            "Train step - Step 0, Loss 7.491241931915283\n",
            "Train step - Step 0, Loss 4.265637397766113\n",
            "Train step - Step 0, Loss 3.155231475830078\n",
            "Train step - Step 0, Loss 1.3472864627838135\n",
            "Train step - Step 0, Loss 1.2327725887298584\n",
            "Train step - Step 0, Loss 1.1509547233581543\n",
            "Train step - Step 0, Loss 1.0233385562896729\n",
            "Train step - Step 0, Loss 0.791019082069397\n",
            "Train step - Step 0, Loss 0.8672433495521545\n",
            "Train step - Step 0, Loss 0.649448812007904\n",
            "Train step - Step 0, Loss 0.5290513038635254\n",
            "Train step - Step 0, Loss 0.5865703821182251\n",
            "Train step - Step 0, Loss 0.5754814147949219\n",
            "Train epoch - Accuracy: 0.24608333333333332 Loss: 3.7355780334472657 Corrects: 2953\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.4827127158641815\n",
            "Train step - Step 0, Loss 0.5317351222038269\n",
            "Train step - Step 0, Loss 0.49222224950790405\n",
            "Train step - Step 0, Loss 0.4661550521850586\n",
            "Train step - Step 0, Loss 0.4361068904399872\n",
            "Train step - Step 0, Loss 0.44336023926734924\n",
            "Train step - Step 0, Loss 0.4645991623401642\n",
            "Train step - Step 0, Loss 0.402842253446579\n",
            "Train step - Step 0, Loss 0.4419785439968109\n",
            "Train step - Step 0, Loss 0.4265497624874115\n",
            "Train step - Step 0, Loss 0.3840125501155853\n",
            "Train step - Step 0, Loss 0.38065314292907715\n",
            "Train step - Step 0, Loss 0.3807637691497803\n",
            "Train step - Step 0, Loss 0.3628118634223938\n",
            "Train step - Step 0, Loss 0.37000277638435364\n",
            "Train step - Step 0, Loss 0.3608100414276123\n",
            "Train epoch - Accuracy: 0.347 Loss: 0.42828879165649414 Corrects: 4164\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.34645533561706543\n",
            "Train step - Step 0, Loss 0.34006062150001526\n",
            "Train step - Step 0, Loss 0.3520500957965851\n",
            "Train step - Step 0, Loss 0.3570522367954254\n",
            "Train step - Step 0, Loss 0.3220517039299011\n",
            "Train step - Step 0, Loss 0.3272104263305664\n",
            "Train step - Step 0, Loss 0.3539726436138153\n",
            "Train step - Step 0, Loss 0.3470916748046875\n",
            "Train step - Step 0, Loss 0.33150556683540344\n",
            "Train step - Step 0, Loss 0.3367023766040802\n",
            "Train step - Step 0, Loss 0.32108038663864136\n",
            "Train step - Step 0, Loss 0.3330264091491699\n",
            "Train step - Step 0, Loss 0.3060651123523712\n",
            "Train step - Step 0, Loss 0.34488558769226074\n",
            "Train step - Step 0, Loss 0.3386300206184387\n",
            "Train step - Step 0, Loss 0.35022255778312683\n",
            "Train epoch - Accuracy: 0.40041666666666664 Loss: 0.33771067500114443 Corrects: 4805\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.30844375491142273\n",
            "Train step - Step 0, Loss 0.30906596779823303\n",
            "Train step - Step 0, Loss 0.3059285581111908\n",
            "Train step - Step 0, Loss 0.2967645823955536\n",
            "Train step - Step 0, Loss 0.2953353226184845\n",
            "Train step - Step 0, Loss 0.2935340404510498\n",
            "Train step - Step 0, Loss 0.28432148694992065\n",
            "Train step - Step 0, Loss 0.2972133755683899\n",
            "Train step - Step 0, Loss 0.2863959074020386\n",
            "Train step - Step 0, Loss 0.3249441385269165\n",
            "Train step - Step 0, Loss 0.3259944021701813\n",
            "Train step - Step 0, Loss 0.3007744550704956\n",
            "Train step - Step 0, Loss 0.2906781733036041\n",
            "Train step - Step 0, Loss 0.28086259961128235\n",
            "Train step - Step 0, Loss 0.3117406368255615\n",
            "Train step - Step 0, Loss 0.29161736369132996\n",
            "Train epoch - Accuracy: 0.43683333333333335 Loss: 0.30043252825737 Corrects: 5242\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.29533445835113525\n",
            "Train step - Step 0, Loss 0.2805255949497223\n",
            "Train step - Step 0, Loss 0.31533509492874146\n",
            "Train step - Step 0, Loss 0.2936156988143921\n",
            "Train step - Step 0, Loss 0.29313114285469055\n",
            "Train step - Step 0, Loss 0.2792390286922455\n",
            "Train step - Step 0, Loss 0.28512272238731384\n",
            "Train step - Step 0, Loss 0.28333455324172974\n",
            "Train step - Step 0, Loss 0.28259941935539246\n",
            "Train step - Step 0, Loss 0.29051268100738525\n",
            "Train step - Step 0, Loss 0.27215999364852905\n",
            "Train step - Step 0, Loss 0.27848780155181885\n",
            "Train step - Step 0, Loss 0.2930963337421417\n",
            "Train step - Step 0, Loss 0.2576137185096741\n",
            "Train step - Step 0, Loss 0.25821200013160706\n",
            "Train step - Step 0, Loss 0.2767886519432068\n",
            "Train epoch - Accuracy: 0.4661666666666667 Loss: 0.2836040415763855 Corrects: 5594\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.27885526418685913\n",
            "Train step - Step 0, Loss 0.2570108473300934\n",
            "Train step - Step 0, Loss 0.26738372445106506\n",
            "Train step - Step 0, Loss 0.2752111554145813\n",
            "Train step - Step 0, Loss 0.264897882938385\n",
            "Train step - Step 0, Loss 0.2710932791233063\n",
            "Train step - Step 0, Loss 0.2593507766723633\n",
            "Train step - Step 0, Loss 0.2404840588569641\n",
            "Train step - Step 0, Loss 0.26697689294815063\n",
            "Train step - Step 0, Loss 0.27408885955810547\n",
            "Train step - Step 0, Loss 0.2929441034793854\n",
            "Train step - Step 0, Loss 0.26590657234191895\n",
            "Train step - Step 0, Loss 0.27700552344322205\n",
            "Train step - Step 0, Loss 0.25664249062538147\n",
            "Train step - Step 0, Loss 0.26522770524024963\n",
            "Train step - Step 0, Loss 0.29159241914749146\n",
            "Train epoch - Accuracy: 0.4795833333333333 Loss: 0.26850076150894164 Corrects: 5755\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.265560120344162\n",
            "Train step - Step 0, Loss 0.24835757911205292\n",
            "Train step - Step 0, Loss 0.24493835866451263\n",
            "Train step - Step 0, Loss 0.2576865255832672\n",
            "Train step - Step 0, Loss 0.2614496350288391\n",
            "Train step - Step 0, Loss 0.2620951533317566\n",
            "Train step - Step 0, Loss 0.26064538955688477\n",
            "Train step - Step 0, Loss 0.24010461568832397\n",
            "Train step - Step 0, Loss 0.24977099895477295\n",
            "Train step - Step 0, Loss 0.2589832842350006\n",
            "Train step - Step 0, Loss 0.261409729719162\n",
            "Train step - Step 0, Loss 0.24386683106422424\n",
            "Train step - Step 0, Loss 0.24772226810455322\n",
            "Train step - Step 0, Loss 0.253775417804718\n",
            "Train step - Step 0, Loss 0.24229153990745544\n",
            "Train step - Step 0, Loss 0.25025463104248047\n",
            "Train epoch - Accuracy: 0.49016666666666664 Loss: 0.2531242618560791 Corrects: 5882\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.24026711285114288\n",
            "Train step - Step 0, Loss 0.24385328590869904\n",
            "Train step - Step 0, Loss 0.2709319591522217\n",
            "Train step - Step 0, Loss 0.24311360716819763\n",
            "Train step - Step 0, Loss 0.24698567390441895\n",
            "Train step - Step 0, Loss 0.2384154498577118\n",
            "Train step - Step 0, Loss 0.23292644321918488\n",
            "Train step - Step 0, Loss 0.25521793961524963\n",
            "Train step - Step 0, Loss 0.28239619731903076\n",
            "Train step - Step 0, Loss 0.24941188097000122\n",
            "Train step - Step 0, Loss 0.2321401983499527\n",
            "Train step - Step 0, Loss 0.2539505958557129\n",
            "Train step - Step 0, Loss 0.24220871925354004\n",
            "Train step - Step 0, Loss 0.23653057217597961\n",
            "Train step - Step 0, Loss 0.2445109486579895\n",
            "Train step - Step 0, Loss 0.24760717153549194\n",
            "Train epoch - Accuracy: 0.5051666666666667 Loss: 0.2475273642539978 Corrects: 6062\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.2583093047142029\n",
            "Train step - Step 0, Loss 0.24762822687625885\n",
            "Train step - Step 0, Loss 0.21930542588233948\n",
            "Train step - Step 0, Loss 0.23511207103729248\n",
            "Train step - Step 0, Loss 0.23352716863155365\n",
            "Train step - Step 0, Loss 0.25476908683776855\n",
            "Train step - Step 0, Loss 0.25678545236587524\n",
            "Train step - Step 0, Loss 0.24151962995529175\n",
            "Train step - Step 0, Loss 0.2360304296016693\n",
            "Train step - Step 0, Loss 0.24108724296092987\n",
            "Train step - Step 0, Loss 0.23562107980251312\n",
            "Train step - Step 0, Loss 0.25933530926704407\n",
            "Train step - Step 0, Loss 0.2476264238357544\n",
            "Train step - Step 0, Loss 0.2402258664369583\n",
            "Train step - Step 0, Loss 0.24009615182876587\n",
            "Train step - Step 0, Loss 0.23160947859287262\n",
            "Train epoch - Accuracy: 0.5096666666666667 Loss: 0.24267102682590486 Corrects: 6116\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.23697905242443085\n",
            "Train step - Step 0, Loss 0.22645646333694458\n",
            "Train step - Step 0, Loss 0.2471459060907364\n",
            "Train step - Step 0, Loss 0.22114090621471405\n",
            "Train step - Step 0, Loss 0.24985197186470032\n",
            "Train step - Step 0, Loss 0.23562932014465332\n",
            "Train step - Step 0, Loss 0.24494525790214539\n",
            "Train step - Step 0, Loss 0.23393170535564423\n",
            "Train step - Step 0, Loss 0.2607557773590088\n",
            "Train step - Step 0, Loss 0.2342415750026703\n",
            "Train step - Step 0, Loss 0.23003052175045013\n",
            "Train step - Step 0, Loss 0.22217591106891632\n",
            "Train step - Step 0, Loss 0.2294214367866516\n",
            "Train step - Step 0, Loss 0.2325221598148346\n",
            "Train step - Step 0, Loss 0.23530808091163635\n",
            "Train step - Step 0, Loss 0.2307821661233902\n",
            "Train epoch - Accuracy: 0.5155 Loss: 0.23582559359073638 Corrects: 6186\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.23516765236854553\n",
            "Train step - Step 0, Loss 0.23704861104488373\n",
            "Train step - Step 0, Loss 0.2340569943189621\n",
            "Train step - Step 0, Loss 0.23545648157596588\n",
            "Train step - Step 0, Loss 0.24126407504081726\n",
            "Train step - Step 0, Loss 0.25372132658958435\n",
            "Train step - Step 0, Loss 0.24591350555419922\n",
            "Train step - Step 0, Loss 0.21639354526996613\n",
            "Train step - Step 0, Loss 0.22248618304729462\n",
            "Train step - Step 0, Loss 0.2266855686903\n",
            "Train step - Step 0, Loss 0.24202373623847961\n",
            "Train step - Step 0, Loss 0.22806306183338165\n",
            "Train step - Step 0, Loss 0.20205631852149963\n",
            "Train step - Step 0, Loss 0.23111280798912048\n",
            "Train step - Step 0, Loss 0.2173326015472412\n",
            "Train step - Step 0, Loss 0.23231549561023712\n",
            "Train epoch - Accuracy: 0.5251666666666667 Loss: 0.23129469788074494 Corrects: 6302\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.2418309599161148\n",
            "Train step - Step 0, Loss 0.217791348695755\n",
            "Train step - Step 0, Loss 0.23388469219207764\n",
            "Train step - Step 0, Loss 0.2111338973045349\n",
            "Train step - Step 0, Loss 0.22325065732002258\n",
            "Train step - Step 0, Loss 0.22828957438468933\n",
            "Train step - Step 0, Loss 0.22769033908843994\n",
            "Train step - Step 0, Loss 0.22360624372959137\n",
            "Train step - Step 0, Loss 0.22738714516162872\n",
            "Train step - Step 0, Loss 0.2205979824066162\n",
            "Train step - Step 0, Loss 0.22340436279773712\n",
            "Train step - Step 0, Loss 0.23687241971492767\n",
            "Train step - Step 0, Loss 0.20430050790309906\n",
            "Train step - Step 0, Loss 0.21357223391532898\n",
            "Train step - Step 0, Loss 0.21635624766349792\n",
            "Train step - Step 0, Loss 0.21819855272769928\n",
            "Train epoch - Accuracy: 0.535 Loss: 0.2231259332895279 Corrects: 6420\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.22357632219791412\n",
            "Train step - Step 0, Loss 0.2242046445608139\n",
            "Train step - Step 0, Loss 0.2282869815826416\n",
            "Train step - Step 0, Loss 0.22163869440555573\n",
            "Train step - Step 0, Loss 0.22390888631343842\n",
            "Train step - Step 0, Loss 0.21114830672740936\n",
            "Train step - Step 0, Loss 0.21960851550102234\n",
            "Train step - Step 0, Loss 0.21468757092952728\n",
            "Train step - Step 0, Loss 0.2191816121339798\n",
            "Train step - Step 0, Loss 0.2147100865840912\n",
            "Train step - Step 0, Loss 0.21708358824253082\n",
            "Train step - Step 0, Loss 0.200188547372818\n",
            "Train step - Step 0, Loss 0.20449155569076538\n",
            "Train step - Step 0, Loss 0.21164189279079437\n",
            "Train step - Step 0, Loss 0.22579993307590485\n",
            "Train step - Step 0, Loss 0.24061986804008484\n",
            "Train epoch - Accuracy: 0.5388333333333334 Loss: 0.21827485156059265 Corrects: 6466\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.2228117138147354\n",
            "Train step - Step 0, Loss 0.2473563551902771\n",
            "Train step - Step 0, Loss 0.21781706809997559\n",
            "Train step - Step 0, Loss 0.21038253605365753\n",
            "Train step - Step 0, Loss 0.21743892133235931\n",
            "Train step - Step 0, Loss 0.2083427608013153\n",
            "Train step - Step 0, Loss 0.21149976551532745\n",
            "Train step - Step 0, Loss 0.21690025925636292\n",
            "Train step - Step 0, Loss 0.2297016680240631\n",
            "Train step - Step 0, Loss 0.22539980709552765\n",
            "Train step - Step 0, Loss 0.21094538271427155\n",
            "Train step - Step 0, Loss 0.2083713710308075\n",
            "Train step - Step 0, Loss 0.2216527760028839\n",
            "Train step - Step 0, Loss 0.21804386377334595\n",
            "Train step - Step 0, Loss 0.22136281430721283\n",
            "Train step - Step 0, Loss 0.20797008275985718\n",
            "Train epoch - Accuracy: 0.5385833333333333 Loss: 0.21875253534317016 Corrects: 6463\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.2137550413608551\n",
            "Train step - Step 0, Loss 0.21654652059078217\n",
            "Train step - Step 0, Loss 0.21766941249370575\n",
            "Train step - Step 0, Loss 0.2203971892595291\n",
            "Train step - Step 0, Loss 0.20965734124183655\n",
            "Train step - Step 0, Loss 0.21610921621322632\n",
            "Train step - Step 0, Loss 0.21355274319648743\n",
            "Train step - Step 0, Loss 0.21537651121616364\n",
            "Train step - Step 0, Loss 0.21431800723075867\n",
            "Train step - Step 0, Loss 0.22119472920894623\n",
            "Train step - Step 0, Loss 0.2064666897058487\n",
            "Train step - Step 0, Loss 0.19259017705917358\n",
            "Train step - Step 0, Loss 0.20934316515922546\n",
            "Train step - Step 0, Loss 0.2086726576089859\n",
            "Train step - Step 0, Loss 0.2163904458284378\n",
            "Train step - Step 0, Loss 0.2139369249343872\n",
            "Train epoch - Accuracy: 0.5449166666666667 Loss: 0.2128480272293091 Corrects: 6539\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.24292978644371033\n",
            "Train step - Step 0, Loss 0.22403381764888763\n",
            "Train step - Step 0, Loss 0.20604977011680603\n",
            "Train step - Step 0, Loss 0.20135271549224854\n",
            "Train step - Step 0, Loss 0.21239325404167175\n",
            "Train step - Step 0, Loss 0.21482080221176147\n",
            "Train step - Step 0, Loss 0.2157738208770752\n",
            "Train step - Step 0, Loss 0.20817801356315613\n",
            "Train step - Step 0, Loss 0.22173461318016052\n",
            "Train step - Step 0, Loss 0.18977980315685272\n",
            "Train step - Step 0, Loss 0.20093348622322083\n",
            "Train step - Step 0, Loss 0.2120356410741806\n",
            "Train step - Step 0, Loss 0.1942555010318756\n",
            "Train step - Step 0, Loss 0.214797243475914\n",
            "Train step - Step 0, Loss 0.22791679203510284\n",
            "Train step - Step 0, Loss 0.2195390909910202\n",
            "Train epoch - Accuracy: 0.5521666666666667 Loss: 0.21274860751628877 Corrects: 6626\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.21739384531974792\n",
            "Train step - Step 0, Loss 0.1977742314338684\n",
            "Train step - Step 0, Loss 0.2050289511680603\n",
            "Train step - Step 0, Loss 0.20002900063991547\n",
            "Train step - Step 0, Loss 0.21863391995429993\n",
            "Train step - Step 0, Loss 0.2030150294303894\n",
            "Train step - Step 0, Loss 0.2151070386171341\n",
            "Train step - Step 0, Loss 0.21586045622825623\n",
            "Train step - Step 0, Loss 0.19444507360458374\n",
            "Train step - Step 0, Loss 0.21560585498809814\n",
            "Train step - Step 0, Loss 0.2121804803609848\n",
            "Train step - Step 0, Loss 0.1987040638923645\n",
            "Train step - Step 0, Loss 0.21026523411273956\n",
            "Train step - Step 0, Loss 0.21560436487197876\n",
            "Train step - Step 0, Loss 0.2240549474954605\n",
            "Train step - Step 0, Loss 0.20348167419433594\n",
            "Train epoch - Accuracy: 0.5450833333333334 Loss: 0.20933622646331787 Corrects: 6541\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.20323678851127625\n",
            "Train step - Step 0, Loss 0.20086660981178284\n",
            "Train step - Step 0, Loss 0.21040497720241547\n",
            "Train step - Step 0, Loss 0.20327553153038025\n",
            "Train step - Step 0, Loss 0.19614194333553314\n",
            "Train step - Step 0, Loss 0.21156157553195953\n",
            "Train step - Step 0, Loss 0.21208004653453827\n",
            "Train step - Step 0, Loss 0.19443240761756897\n",
            "Train step - Step 0, Loss 0.2167145311832428\n",
            "Train step - Step 0, Loss 0.2019214779138565\n",
            "Train step - Step 0, Loss 0.19848264753818512\n",
            "Train step - Step 0, Loss 0.21274235844612122\n",
            "Train step - Step 0, Loss 0.2106008380651474\n",
            "Train step - Step 0, Loss 0.20869383215904236\n",
            "Train step - Step 0, Loss 0.21511155366897583\n",
            "Train step - Step 0, Loss 0.19708125293254852\n",
            "Train epoch - Accuracy: 0.5589166666666666 Loss: 0.2060443457365036 Corrects: 6707\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.20788542926311493\n",
            "Train step - Step 0, Loss 0.20151151716709137\n",
            "Train step - Step 0, Loss 0.19899916648864746\n",
            "Train step - Step 0, Loss 0.21522046625614166\n",
            "Train step - Step 0, Loss 0.19956575334072113\n",
            "Train step - Step 0, Loss 0.18179863691329956\n",
            "Train step - Step 0, Loss 0.20447836816310883\n",
            "Train step - Step 0, Loss 0.19504252076148987\n",
            "Train step - Step 0, Loss 0.21119627356529236\n",
            "Train step - Step 0, Loss 0.18726716935634613\n",
            "Train step - Step 0, Loss 0.208486407995224\n",
            "Train step - Step 0, Loss 0.1999906301498413\n",
            "Train step - Step 0, Loss 0.18848571181297302\n",
            "Train step - Step 0, Loss 0.19737476110458374\n",
            "Train step - Step 0, Loss 0.2016981542110443\n",
            "Train step - Step 0, Loss 0.20019972324371338\n",
            "Train epoch - Accuracy: 0.5625833333333333 Loss: 0.1999440507888794 Corrects: 6751\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.19490575790405273\n",
            "Train step - Step 0, Loss 0.19710443913936615\n",
            "Train step - Step 0, Loss 0.19138924777507782\n",
            "Train step - Step 0, Loss 0.20208877325057983\n",
            "Train step - Step 0, Loss 0.19353966414928436\n",
            "Train step - Step 0, Loss 0.21153515577316284\n",
            "Train step - Step 0, Loss 0.19867955148220062\n",
            "Train step - Step 0, Loss 0.21332255005836487\n",
            "Train step - Step 0, Loss 0.20289228856563568\n",
            "Train step - Step 0, Loss 0.19530154764652252\n",
            "Train step - Step 0, Loss 0.19676998257637024\n",
            "Train step - Step 0, Loss 0.19927354156970978\n",
            "Train step - Step 0, Loss 0.20755670964717865\n",
            "Train step - Step 0, Loss 0.18769370019435883\n",
            "Train step - Step 0, Loss 0.19657625257968903\n",
            "Train step - Step 0, Loss 0.21832691133022308\n",
            "Train epoch - Accuracy: 0.5730833333333333 Loss: 0.20000534284114838 Corrects: 6877\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.20368482172489166\n",
            "Train step - Step 0, Loss 0.20057660341262817\n",
            "Train step - Step 0, Loss 0.17867311835289001\n",
            "Train step - Step 0, Loss 0.2129170149564743\n",
            "Train step - Step 0, Loss 0.196808859705925\n",
            "Train step - Step 0, Loss 0.1961860954761505\n",
            "Train step - Step 0, Loss 0.2175981104373932\n",
            "Train step - Step 0, Loss 0.20556466281414032\n",
            "Train step - Step 0, Loss 0.21390898525714874\n",
            "Train step - Step 0, Loss 0.19330035150051117\n",
            "Train step - Step 0, Loss 0.1942838728427887\n",
            "Train step - Step 0, Loss 0.19541054964065552\n",
            "Train step - Step 0, Loss 0.18987926840782166\n",
            "Train step - Step 0, Loss 0.1981913447380066\n",
            "Train step - Step 0, Loss 0.2000737339258194\n",
            "Train step - Step 0, Loss 0.20487242937088013\n",
            "Train epoch - Accuracy: 0.5616666666666666 Loss: 0.20000657033920288 Corrects: 6740\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.18648312985897064\n",
            "Train step - Step 0, Loss 0.1863768994808197\n",
            "Train step - Step 0, Loss 0.20017386972904205\n",
            "Train step - Step 0, Loss 0.18702897429466248\n",
            "Train step - Step 0, Loss 0.19988864660263062\n",
            "Train step - Step 0, Loss 0.20651353895664215\n",
            "Train step - Step 0, Loss 0.19091013073921204\n",
            "Train step - Step 0, Loss 0.1944354772567749\n",
            "Train step - Step 0, Loss 0.20505830645561218\n",
            "Train step - Step 0, Loss 0.20219695568084717\n",
            "Train step - Step 0, Loss 0.19120466709136963\n",
            "Train step - Step 0, Loss 0.20005449652671814\n",
            "Train step - Step 0, Loss 0.1908828765153885\n",
            "Train step - Step 0, Loss 0.2020512968301773\n",
            "Train step - Step 0, Loss 0.2057003378868103\n",
            "Train step - Step 0, Loss 0.1918390691280365\n",
            "Train epoch - Accuracy: 0.5713333333333334 Loss: 0.19640697741508484 Corrects: 6856\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.2035650610923767\n",
            "Train step - Step 0, Loss 0.19501614570617676\n",
            "Train step - Step 0, Loss 0.19681568443775177\n",
            "Train step - Step 0, Loss 0.19492745399475098\n",
            "Train step - Step 0, Loss 0.2017432004213333\n",
            "Train step - Step 0, Loss 0.1979154348373413\n",
            "Train step - Step 0, Loss 0.21028873324394226\n",
            "Train step - Step 0, Loss 0.21151161193847656\n",
            "Train step - Step 0, Loss 0.189941868185997\n",
            "Train step - Step 0, Loss 0.1816278100013733\n",
            "Train step - Step 0, Loss 0.16861777007579803\n",
            "Train step - Step 0, Loss 0.1877162754535675\n",
            "Train step - Step 0, Loss 0.1924010068178177\n",
            "Train step - Step 0, Loss 0.181039959192276\n",
            "Train step - Step 0, Loss 0.19417645037174225\n",
            "Train step - Step 0, Loss 0.2005578726530075\n",
            "Train epoch - Accuracy: 0.5775 Loss: 0.19408980071544646 Corrects: 6930\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.1893298625946045\n",
            "Train step - Step 0, Loss 0.1884089559316635\n",
            "Train step - Step 0, Loss 0.18539009988307953\n",
            "Train step - Step 0, Loss 0.1821662038564682\n",
            "Train step - Step 0, Loss 0.1907709538936615\n",
            "Train step - Step 0, Loss 0.19383561611175537\n",
            "Train step - Step 0, Loss 0.20688766241073608\n",
            "Train step - Step 0, Loss 0.19789093732833862\n",
            "Train step - Step 0, Loss 0.20637667179107666\n",
            "Train step - Step 0, Loss 0.19398286938667297\n",
            "Train step - Step 0, Loss 0.20531630516052246\n",
            "Train step - Step 0, Loss 0.209599569439888\n",
            "Train step - Step 0, Loss 0.19216418266296387\n",
            "Train step - Step 0, Loss 0.19307547807693481\n",
            "Train step - Step 0, Loss 0.1889028400182724\n",
            "Train step - Step 0, Loss 0.1886739581823349\n",
            "Train epoch - Accuracy: 0.5791666666666667 Loss: 0.19468924367427826 Corrects: 6950\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.20050515234470367\n",
            "Train step - Step 0, Loss 0.19903483986854553\n",
            "Train step - Step 0, Loss 0.1999312788248062\n",
            "Train step - Step 0, Loss 0.20122277736663818\n",
            "Train step - Step 0, Loss 0.1849580854177475\n",
            "Train step - Step 0, Loss 0.1901518851518631\n",
            "Train step - Step 0, Loss 0.17560458183288574\n",
            "Train step - Step 0, Loss 0.1831713765859604\n",
            "Train step - Step 0, Loss 0.18368294835090637\n",
            "Train step - Step 0, Loss 0.19121555984020233\n",
            "Train step - Step 0, Loss 0.21431928873062134\n",
            "Train step - Step 0, Loss 0.1918545514345169\n",
            "Train step - Step 0, Loss 0.18427015841007233\n",
            "Train step - Step 0, Loss 0.1977270096540451\n",
            "Train step - Step 0, Loss 0.200681671500206\n",
            "Train step - Step 0, Loss 0.1800866276025772\n",
            "Train epoch - Accuracy: 0.5756666666666667 Loss: 0.1926966596841812 Corrects: 6908\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.1874788999557495\n",
            "Train step - Step 0, Loss 0.1947033405303955\n",
            "Train step - Step 0, Loss 0.19564257562160492\n",
            "Train step - Step 0, Loss 0.18894310295581818\n",
            "Train step - Step 0, Loss 0.20249870419502258\n",
            "Train step - Step 0, Loss 0.1845851093530655\n",
            "Train step - Step 0, Loss 0.17798392474651337\n",
            "Train step - Step 0, Loss 0.18003667891025543\n",
            "Train step - Step 0, Loss 0.18597954511642456\n",
            "Train step - Step 0, Loss 0.187256321310997\n",
            "Train step - Step 0, Loss 0.19988025724887848\n",
            "Train step - Step 0, Loss 0.17774657905101776\n",
            "Train step - Step 0, Loss 0.1934976726770401\n",
            "Train step - Step 0, Loss 0.18510688841342926\n",
            "Train step - Step 0, Loss 0.17919549345970154\n",
            "Train step - Step 0, Loss 0.19255445897579193\n",
            "Train epoch - Accuracy: 0.5936666666666667 Loss: 0.18821642434597016 Corrects: 7124\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.19586245715618134\n",
            "Train step - Step 0, Loss 0.18535083532333374\n",
            "Train step - Step 0, Loss 0.18414704501628876\n",
            "Train step - Step 0, Loss 0.18756161630153656\n",
            "Train step - Step 0, Loss 0.1871434897184372\n",
            "Train step - Step 0, Loss 0.20006701350212097\n",
            "Train step - Step 0, Loss 0.19218744337558746\n",
            "Train step - Step 0, Loss 0.18558554351329803\n",
            "Train step - Step 0, Loss 0.18162564933300018\n",
            "Train step - Step 0, Loss 0.18903584778308868\n",
            "Train step - Step 0, Loss 0.1894250065088272\n",
            "Train step - Step 0, Loss 0.1783772110939026\n",
            "Train step - Step 0, Loss 0.17837142944335938\n",
            "Train step - Step 0, Loss 0.18390707671642303\n",
            "Train step - Step 0, Loss 0.18548601865768433\n",
            "Train step - Step 0, Loss 0.20231957733631134\n",
            "Train epoch - Accuracy: 0.5895 Loss: 0.1875573388338089 Corrects: 7074\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.18574245274066925\n",
            "Train step - Step 0, Loss 0.21283447742462158\n",
            "Train step - Step 0, Loss 0.20211678743362427\n",
            "Train step - Step 0, Loss 0.17434950172901154\n",
            "Train step - Step 0, Loss 0.18222755193710327\n",
            "Train step - Step 0, Loss 0.18219536542892456\n",
            "Train step - Step 0, Loss 0.19574016332626343\n",
            "Train step - Step 0, Loss 0.17904645204544067\n",
            "Train step - Step 0, Loss 0.18869149684906006\n",
            "Train step - Step 0, Loss 0.19208090007305145\n",
            "Train step - Step 0, Loss 0.18102745711803436\n",
            "Train step - Step 0, Loss 0.1939399391412735\n",
            "Train step - Step 0, Loss 0.2013949751853943\n",
            "Train step - Step 0, Loss 0.18501056730747223\n",
            "Train step - Step 0, Loss 0.18476133048534393\n",
            "Train step - Step 0, Loss 0.20792821049690247\n",
            "Train epoch - Accuracy: 0.5828333333333333 Loss: 0.19015133118629454 Corrects: 6994\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.17969390749931335\n",
            "Train step - Step 0, Loss 0.17866434156894684\n",
            "Train step - Step 0, Loss 0.18002009391784668\n",
            "Train step - Step 0, Loss 0.18292538821697235\n",
            "Train step - Step 0, Loss 0.1777074933052063\n",
            "Train step - Step 0, Loss 0.1913067102432251\n",
            "Train step - Step 0, Loss 0.18077833950519562\n",
            "Train step - Step 0, Loss 0.19079457223415375\n",
            "Train step - Step 0, Loss 0.18576212227344513\n",
            "Train step - Step 0, Loss 0.1944284290075302\n",
            "Train step - Step 0, Loss 0.18115518987178802\n",
            "Train step - Step 0, Loss 0.19760437309741974\n",
            "Train step - Step 0, Loss 0.18525269627571106\n",
            "Train step - Step 0, Loss 0.18559493124485016\n",
            "Train step - Step 0, Loss 0.19262264668941498\n",
            "Train step - Step 0, Loss 0.19876986742019653\n",
            "Train epoch - Accuracy: 0.588 Loss: 0.18614671373367309 Corrects: 7056\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.17181499302387238\n",
            "Train step - Step 0, Loss 0.1849323958158493\n",
            "Train step - Step 0, Loss 0.18390275537967682\n",
            "Train step - Step 0, Loss 0.18538112938404083\n",
            "Train step - Step 0, Loss 0.1726207137107849\n",
            "Train step - Step 0, Loss 0.18319076299667358\n",
            "Train step - Step 0, Loss 0.18586976826190948\n",
            "Train step - Step 0, Loss 0.18594896793365479\n",
            "Train step - Step 0, Loss 0.19980615377426147\n",
            "Train step - Step 0, Loss 0.18573807179927826\n",
            "Train step - Step 0, Loss 0.19045591354370117\n",
            "Train step - Step 0, Loss 0.18176913261413574\n",
            "Train step - Step 0, Loss 0.18826310336589813\n",
            "Train step - Step 0, Loss 0.18243634700775146\n",
            "Train step - Step 0, Loss 0.1826755553483963\n",
            "Train step - Step 0, Loss 0.17354445159435272\n",
            "Train epoch - Accuracy: 0.592 Loss: 0.18388934695720674 Corrects: 7104\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.19036903977394104\n",
            "Train step - Step 0, Loss 0.18156102299690247\n",
            "Train step - Step 0, Loss 0.16923820972442627\n",
            "Train step - Step 0, Loss 0.18588407337665558\n",
            "Train step - Step 0, Loss 0.19288963079452515\n",
            "Train step - Step 0, Loss 0.17324942350387573\n",
            "Train step - Step 0, Loss 0.20252706110477448\n",
            "Train step - Step 0, Loss 0.17335958778858185\n",
            "Train step - Step 0, Loss 0.1887923926115036\n",
            "Train step - Step 0, Loss 0.19114194810390472\n",
            "Train step - Step 0, Loss 0.17890360951423645\n",
            "Train step - Step 0, Loss 0.18047292530536652\n",
            "Train step - Step 0, Loss 0.1712893396615982\n",
            "Train step - Step 0, Loss 0.1797201782464981\n",
            "Train step - Step 0, Loss 0.1814861297607422\n",
            "Train step - Step 0, Loss 0.20201373100280762\n",
            "Train epoch - Accuracy: 0.5931666666666666 Loss: 0.18349716186523438 Corrects: 7118\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.17487335205078125\n",
            "Train step - Step 0, Loss 0.18663983047008514\n",
            "Train step - Step 0, Loss 0.18827198445796967\n",
            "Train step - Step 0, Loss 0.1889679729938507\n",
            "Train step - Step 0, Loss 0.20170718431472778\n",
            "Train step - Step 0, Loss 0.17552849650382996\n",
            "Train step - Step 0, Loss 0.18016110360622406\n",
            "Train step - Step 0, Loss 0.17341700196266174\n",
            "Train step - Step 0, Loss 0.1783292442560196\n",
            "Train step - Step 0, Loss 0.18112148344516754\n",
            "Train step - Step 0, Loss 0.18659818172454834\n",
            "Train step - Step 0, Loss 0.17793338000774384\n",
            "Train step - Step 0, Loss 0.1709776073694229\n",
            "Train step - Step 0, Loss 0.17916302382946014\n",
            "Train step - Step 0, Loss 0.19189046323299408\n",
            "Train step - Step 0, Loss 0.15897749364376068\n",
            "Train epoch - Accuracy: 0.5983333333333334 Loss: 0.18143623960018157 Corrects: 7180\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.1687970608472824\n",
            "Train step - Step 0, Loss 0.17022289335727692\n",
            "Train step - Step 0, Loss 0.17167334258556366\n",
            "Train step - Step 0, Loss 0.18588127195835114\n",
            "Train step - Step 0, Loss 0.17847940325737\n",
            "Train step - Step 0, Loss 0.18118727207183838\n",
            "Train step - Step 0, Loss 0.17191563546657562\n",
            "Train step - Step 0, Loss 0.17198729515075684\n",
            "Train step - Step 0, Loss 0.17126205563545227\n",
            "Train step - Step 0, Loss 0.17920072376728058\n",
            "Train step - Step 0, Loss 0.1831676959991455\n",
            "Train step - Step 0, Loss 0.18111127614974976\n",
            "Train step - Step 0, Loss 0.17874574661254883\n",
            "Train step - Step 0, Loss 0.17977693676948547\n",
            "Train step - Step 0, Loss 0.18533237278461456\n",
            "Train step - Step 0, Loss 0.1790163666009903\n",
            "Train epoch - Accuracy: 0.6084166666666667 Loss: 0.1773200775384903 Corrects: 7301\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.20141065120697021\n",
            "Train step - Step 0, Loss 0.17802748084068298\n",
            "Train step - Step 0, Loss 0.17958588898181915\n",
            "Train step - Step 0, Loss 0.17640423774719238\n",
            "Train step - Step 0, Loss 0.177286759018898\n",
            "Train step - Step 0, Loss 0.17111849784851074\n",
            "Train step - Step 0, Loss 0.1709081083536148\n",
            "Train step - Step 0, Loss 0.1844494640827179\n",
            "Train step - Step 0, Loss 0.18640662729740143\n",
            "Train step - Step 0, Loss 0.18458989262580872\n",
            "Train step - Step 0, Loss 0.16721494495868683\n",
            "Train step - Step 0, Loss 0.18482573330402374\n",
            "Train step - Step 0, Loss 0.17145487666130066\n",
            "Train step - Step 0, Loss 0.16760136187076569\n",
            "Train step - Step 0, Loss 0.1699119508266449\n",
            "Train step - Step 0, Loss 0.1730184704065323\n",
            "Train epoch - Accuracy: 0.611 Loss: 0.17787731325626374 Corrects: 7332\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.17068196833133698\n",
            "Train step - Step 0, Loss 0.172817200422287\n",
            "Train step - Step 0, Loss 0.1787547618150711\n",
            "Train step - Step 0, Loss 0.18438906967639923\n",
            "Train step - Step 0, Loss 0.16881199181079865\n",
            "Train step - Step 0, Loss 0.17220520973205566\n",
            "Train step - Step 0, Loss 0.18106846511363983\n",
            "Train step - Step 0, Loss 0.17253774404525757\n",
            "Train step - Step 0, Loss 0.17537327110767365\n",
            "Train step - Step 0, Loss 0.17666026949882507\n",
            "Train step - Step 0, Loss 0.1696041077375412\n",
            "Train step - Step 0, Loss 0.1757204681634903\n",
            "Train step - Step 0, Loss 0.18894921243190765\n",
            "Train step - Step 0, Loss 0.17969033122062683\n",
            "Train step - Step 0, Loss 0.18724143505096436\n",
            "Train step - Step 0, Loss 0.17036952078342438\n",
            "Train epoch - Accuracy: 0.6045 Loss: 0.17670313322544098 Corrects: 7254\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.18694007396697998\n",
            "Train step - Step 0, Loss 0.18251949548721313\n",
            "Train step - Step 0, Loss 0.1721382588148117\n",
            "Train step - Step 0, Loss 0.18593183159828186\n",
            "Train step - Step 0, Loss 0.16957713663578033\n",
            "Train step - Step 0, Loss 0.19053564965724945\n",
            "Train step - Step 0, Loss 0.177652969956398\n",
            "Train step - Step 0, Loss 0.17382018268108368\n",
            "Train step - Step 0, Loss 0.1745934635400772\n",
            "Train step - Step 0, Loss 0.18189765512943268\n",
            "Train step - Step 0, Loss 0.17333336174488068\n",
            "Train step - Step 0, Loss 0.18712003529071808\n",
            "Train step - Step 0, Loss 0.17904126644134521\n",
            "Train step - Step 0, Loss 0.1806974560022354\n",
            "Train step - Step 0, Loss 0.17562517523765564\n",
            "Train step - Step 0, Loss 0.1860518753528595\n",
            "Train epoch - Accuracy: 0.6008333333333333 Loss: 0.17969321179389955 Corrects: 7210\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.18273082375526428\n",
            "Train step - Step 0, Loss 0.16966375708580017\n",
            "Train step - Step 0, Loss 0.1822851300239563\n",
            "Train step - Step 0, Loss 0.1822383552789688\n",
            "Train step - Step 0, Loss 0.185576930642128\n",
            "Train step - Step 0, Loss 0.17307120561599731\n",
            "Train step - Step 0, Loss 0.17722783982753754\n",
            "Train step - Step 0, Loss 0.17565056681632996\n",
            "Train step - Step 0, Loss 0.16696012020111084\n",
            "Train step - Step 0, Loss 0.17110688984394073\n",
            "Train step - Step 0, Loss 0.1717638075351715\n",
            "Train step - Step 0, Loss 0.16097842156887054\n",
            "Train step - Step 0, Loss 0.17295093834400177\n",
            "Train step - Step 0, Loss 0.18277175724506378\n",
            "Train step - Step 0, Loss 0.16652218997478485\n",
            "Train step - Step 0, Loss 0.17677724361419678\n",
            "Train epoch - Accuracy: 0.61025 Loss: 0.17484700870513917 Corrects: 7323\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.1912105679512024\n",
            "Train step - Step 0, Loss 0.18218953907489777\n",
            "Train step - Step 0, Loss 0.16913148760795593\n",
            "Train step - Step 0, Loss 0.17072315514087677\n",
            "Train step - Step 0, Loss 0.1754796802997589\n",
            "Train step - Step 0, Loss 0.17069803178310394\n",
            "Train step - Step 0, Loss 0.1595068722963333\n",
            "Train step - Step 0, Loss 0.1730237454175949\n",
            "Train step - Step 0, Loss 0.17342476546764374\n",
            "Train step - Step 0, Loss 0.16580386459827423\n",
            "Train step - Step 0, Loss 0.17938290536403656\n",
            "Train step - Step 0, Loss 0.18086504936218262\n",
            "Train step - Step 0, Loss 0.1716006100177765\n",
            "Train step - Step 0, Loss 0.1644507497549057\n",
            "Train step - Step 0, Loss 0.1725788414478302\n",
            "Train step - Step 0, Loss 0.1835421323776245\n",
            "Train epoch - Accuracy: 0.6139166666666667 Loss: 0.17374615669250487 Corrects: 7367\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.17212480306625366\n",
            "Train step - Step 0, Loss 0.16253937780857086\n",
            "Train step - Step 0, Loss 0.17332978546619415\n",
            "Train step - Step 0, Loss 0.1848503202199936\n",
            "Train step - Step 0, Loss 0.16854776442050934\n",
            "Train step - Step 0, Loss 0.19073818624019623\n",
            "Train step - Step 0, Loss 0.16188214719295502\n",
            "Train step - Step 0, Loss 0.19484566152095795\n",
            "Train step - Step 0, Loss 0.17671850323677063\n",
            "Train step - Step 0, Loss 0.17188997566699982\n",
            "Train step - Step 0, Loss 0.1735493391752243\n",
            "Train step - Step 0, Loss 0.16762502491474152\n",
            "Train step - Step 0, Loss 0.17338433861732483\n",
            "Train step - Step 0, Loss 0.17883500456809998\n",
            "Train step - Step 0, Loss 0.16518534719944\n",
            "Train step - Step 0, Loss 0.1645374596118927\n",
            "Train epoch - Accuracy: 0.611 Loss: 0.17400841546058654 Corrects: 7332\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.1801641583442688\n",
            "Train step - Step 0, Loss 0.15841789543628693\n",
            "Train step - Step 0, Loss 0.17579245567321777\n",
            "Train step - Step 0, Loss 0.1839948445558548\n",
            "Train step - Step 0, Loss 0.17534027993679047\n",
            "Train step - Step 0, Loss 0.17847663164138794\n",
            "Train step - Step 0, Loss 0.17432846128940582\n",
            "Train step - Step 0, Loss 0.17204660177230835\n",
            "Train step - Step 0, Loss 0.17063015699386597\n",
            "Train step - Step 0, Loss 0.16348329186439514\n",
            "Train step - Step 0, Loss 0.17595794796943665\n",
            "Train step - Step 0, Loss 0.16694746911525726\n",
            "Train step - Step 0, Loss 0.16606788337230682\n",
            "Train step - Step 0, Loss 0.18086710572242737\n",
            "Train step - Step 0, Loss 0.17191486060619354\n",
            "Train step - Step 0, Loss 0.19022923707962036\n",
            "Train epoch - Accuracy: 0.6104166666666667 Loss: 0.17365269231796265 Corrects: 7325\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.17064419388771057\n",
            "Train step - Step 0, Loss 0.1705562323331833\n",
            "Train step - Step 0, Loss 0.17945647239685059\n",
            "Train step - Step 0, Loss 0.1740831732749939\n",
            "Train step - Step 0, Loss 0.17117896676063538\n",
            "Train step - Step 0, Loss 0.1769513338804245\n",
            "Train step - Step 0, Loss 0.17169639468193054\n",
            "Train step - Step 0, Loss 0.1652420163154602\n",
            "Train step - Step 0, Loss 0.18391616642475128\n",
            "Train step - Step 0, Loss 0.17106562852859497\n",
            "Train step - Step 0, Loss 0.18128818273544312\n",
            "Train step - Step 0, Loss 0.16499079763889313\n",
            "Train step - Step 0, Loss 0.17122353613376617\n",
            "Train step - Step 0, Loss 0.17219510674476624\n",
            "Train step - Step 0, Loss 0.16800634562969208\n",
            "Train step - Step 0, Loss 0.1830623596906662\n",
            "Train epoch - Accuracy: 0.6143333333333333 Loss: 0.17324214541912078 Corrects: 7372\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.17231334745883942\n",
            "Train step - Step 0, Loss 0.1608663648366928\n",
            "Train step - Step 0, Loss 0.1737709790468216\n",
            "Train step - Step 0, Loss 0.1614341139793396\n",
            "Train step - Step 0, Loss 0.1751047670841217\n",
            "Train step - Step 0, Loss 0.17503252625465393\n",
            "Train step - Step 0, Loss 0.15460531413555145\n",
            "Train step - Step 0, Loss 0.17589551210403442\n",
            "Train step - Step 0, Loss 0.17172980308532715\n",
            "Train step - Step 0, Loss 0.18359917402267456\n",
            "Train step - Step 0, Loss 0.15534137189388275\n",
            "Train step - Step 0, Loss 0.16558751463890076\n",
            "Train step - Step 0, Loss 0.1938333362340927\n",
            "Train step - Step 0, Loss 0.17069554328918457\n",
            "Train step - Step 0, Loss 0.16384609043598175\n",
            "Train step - Step 0, Loss 0.1571929007768631\n",
            "Train epoch - Accuracy: 0.6223333333333333 Loss: 0.16972168457508088 Corrects: 7468\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.16584216058254242\n",
            "Train step - Step 0, Loss 0.1726551502943039\n",
            "Train step - Step 0, Loss 0.16904819011688232\n",
            "Train step - Step 0, Loss 0.18125584721565247\n",
            "Train step - Step 0, Loss 0.16557063162326813\n",
            "Train step - Step 0, Loss 0.17745062708854675\n",
            "Train step - Step 0, Loss 0.1787596493959427\n",
            "Train step - Step 0, Loss 0.16590774059295654\n",
            "Train step - Step 0, Loss 0.16543181240558624\n",
            "Train step - Step 0, Loss 0.17167474329471588\n",
            "Train step - Step 0, Loss 0.17347489297389984\n",
            "Train step - Step 0, Loss 0.1755688339471817\n",
            "Train step - Step 0, Loss 0.166276216506958\n",
            "Train step - Step 0, Loss 0.1717216968536377\n",
            "Train step - Step 0, Loss 0.16782689094543457\n",
            "Train step - Step 0, Loss 0.1636376529932022\n",
            "Train epoch - Accuracy: 0.6218333333333333 Loss: 0.17092727148532869 Corrects: 7462\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.17723923921585083\n",
            "Train step - Step 0, Loss 0.16155308485031128\n",
            "Train step - Step 0, Loss 0.17571868002414703\n",
            "Train step - Step 0, Loss 0.17390640079975128\n",
            "Train step - Step 0, Loss 0.17888784408569336\n",
            "Train step - Step 0, Loss 0.17061829566955566\n",
            "Train step - Step 0, Loss 0.18332132697105408\n",
            "Train step - Step 0, Loss 0.1616559773683548\n",
            "Train step - Step 0, Loss 0.1775917261838913\n",
            "Train step - Step 0, Loss 0.16593505442142487\n",
            "Train step - Step 0, Loss 0.1819358766078949\n",
            "Train step - Step 0, Loss 0.16912992298603058\n",
            "Train step - Step 0, Loss 0.16385352611541748\n",
            "Train step - Step 0, Loss 0.17745615541934967\n",
            "Train step - Step 0, Loss 0.16151617467403412\n",
            "Train step - Step 0, Loss 0.14550817012786865\n",
            "Train epoch - Accuracy: 0.6185 Loss: 0.17096076107025146 Corrects: 7422\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.15836355090141296\n",
            "Train step - Step 0, Loss 0.16931548714637756\n",
            "Train step - Step 0, Loss 0.1708831787109375\n",
            "Train step - Step 0, Loss 0.18236859142780304\n",
            "Train step - Step 0, Loss 0.18240518867969513\n",
            "Train step - Step 0, Loss 0.16147233545780182\n",
            "Train step - Step 0, Loss 0.17043505609035492\n",
            "Train step - Step 0, Loss 0.17135512828826904\n",
            "Train step - Step 0, Loss 0.15462008118629456\n",
            "Train step - Step 0, Loss 0.17652086913585663\n",
            "Train step - Step 0, Loss 0.17063701152801514\n",
            "Train step - Step 0, Loss 0.17188216745853424\n",
            "Train step - Step 0, Loss 0.1803760677576065\n",
            "Train step - Step 0, Loss 0.15842746198177338\n",
            "Train step - Step 0, Loss 0.16815337538719177\n",
            "Train step - Step 0, Loss 0.17843297123908997\n",
            "Train epoch - Accuracy: 0.6191666666666666 Loss: 0.17015911412239074 Corrects: 7430\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.1551969349384308\n",
            "Train step - Step 0, Loss 0.1779857724905014\n",
            "Train step - Step 0, Loss 0.1727578043937683\n",
            "Train step - Step 0, Loss 0.17016874253749847\n",
            "Train step - Step 0, Loss 0.16243532299995422\n",
            "Train step - Step 0, Loss 0.1605595052242279\n",
            "Train step - Step 0, Loss 0.15378297865390778\n",
            "Train step - Step 0, Loss 0.1633962094783783\n",
            "Train step - Step 0, Loss 0.1796422302722931\n",
            "Train step - Step 0, Loss 0.15889045596122742\n",
            "Train step - Step 0, Loss 0.1803579330444336\n",
            "Train step - Step 0, Loss 0.1592928022146225\n",
            "Train step - Step 0, Loss 0.16474243998527527\n",
            "Train step - Step 0, Loss 0.17936955392360687\n",
            "Train step - Step 0, Loss 0.17769744992256165\n",
            "Train step - Step 0, Loss 0.17728197574615479\n",
            "Train epoch - Accuracy: 0.6243333333333333 Loss: 0.1681329517364502 Corrects: 7492\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.1813463568687439\n",
            "Train step - Step 0, Loss 0.16329488158226013\n",
            "Train step - Step 0, Loss 0.17644751071929932\n",
            "Train step - Step 0, Loss 0.16510812938213348\n",
            "Train step - Step 0, Loss 0.17166490852832794\n",
            "Train step - Step 0, Loss 0.15368786454200745\n",
            "Train step - Step 0, Loss 0.1648666113615036\n",
            "Train step - Step 0, Loss 0.16060039401054382\n",
            "Train step - Step 0, Loss 0.1537178009748459\n",
            "Train step - Step 0, Loss 0.17087408900260925\n",
            "Train step - Step 0, Loss 0.1605934500694275\n",
            "Train step - Step 0, Loss 0.16369296610355377\n",
            "Train step - Step 0, Loss 0.1659104824066162\n",
            "Train step - Step 0, Loss 0.1677934229373932\n",
            "Train step - Step 0, Loss 0.16715872287750244\n",
            "Train step - Step 0, Loss 0.18052589893341064\n",
            "Train epoch - Accuracy: 0.6288333333333334 Loss: 0.16637352180480958 Corrects: 7546\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.18371354043483734\n",
            "Train step - Step 0, Loss 0.16704042255878448\n",
            "Train step - Step 0, Loss 0.15543042123317719\n",
            "Train step - Step 0, Loss 0.1719888299703598\n",
            "Train step - Step 0, Loss 0.15990497171878815\n",
            "Train step - Step 0, Loss 0.16623102128505707\n",
            "Train step - Step 0, Loss 0.1583608090877533\n",
            "Train step - Step 0, Loss 0.16835014522075653\n",
            "Train step - Step 0, Loss 0.1584344059228897\n",
            "Train step - Step 0, Loss 0.15744143724441528\n",
            "Train step - Step 0, Loss 0.1661456972360611\n",
            "Train step - Step 0, Loss 0.16466611623764038\n",
            "Train step - Step 0, Loss 0.17750045657157898\n",
            "Train step - Step 0, Loss 0.15781109035015106\n",
            "Train step - Step 0, Loss 0.17884430289268494\n",
            "Train step - Step 0, Loss 0.17074137926101685\n",
            "Train epoch - Accuracy: 0.6274166666666666 Loss: 0.16630892992019652 Corrects: 7529\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.16233019530773163\n",
            "Train step - Step 0, Loss 0.16421723365783691\n",
            "Train step - Step 0, Loss 0.18382681906223297\n",
            "Train step - Step 0, Loss 0.17945732176303864\n",
            "Train step - Step 0, Loss 0.17429223656654358\n",
            "Train step - Step 0, Loss 0.1639263778924942\n",
            "Train step - Step 0, Loss 0.1667061150074005\n",
            "Train step - Step 0, Loss 0.1615537405014038\n",
            "Train step - Step 0, Loss 0.16985028982162476\n",
            "Train step - Step 0, Loss 0.17395024001598358\n",
            "Train step - Step 0, Loss 0.15341946482658386\n",
            "Train step - Step 0, Loss 0.15715090930461884\n",
            "Train step - Step 0, Loss 0.17017480731010437\n",
            "Train step - Step 0, Loss 0.15635612607002258\n",
            "Train step - Step 0, Loss 0.16860608756542206\n",
            "Train step - Step 0, Loss 0.15622900426387787\n",
            "Train epoch - Accuracy: 0.62825 Loss: 0.16662150990962982 Corrects: 7539\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.15461061894893646\n",
            "Train step - Step 0, Loss 0.1620289832353592\n",
            "Train step - Step 0, Loss 0.162965789437294\n",
            "Train step - Step 0, Loss 0.17326675355434418\n",
            "Train step - Step 0, Loss 0.1684066653251648\n",
            "Train step - Step 0, Loss 0.16394497454166412\n",
            "Train step - Step 0, Loss 0.17759771645069122\n",
            "Train step - Step 0, Loss 0.16157637536525726\n",
            "Train step - Step 0, Loss 0.16927914321422577\n",
            "Train step - Step 0, Loss 0.1650381088256836\n",
            "Train step - Step 0, Loss 0.16267932951450348\n",
            "Train step - Step 0, Loss 0.15463878214359283\n",
            "Train step - Step 0, Loss 0.1623237133026123\n",
            "Train step - Step 0, Loss 0.15527082979679108\n",
            "Train step - Step 0, Loss 0.16706067323684692\n",
            "Train step - Step 0, Loss 0.16279655694961548\n",
            "Train epoch - Accuracy: 0.6328333333333334 Loss: 0.16399592351913453 Corrects: 7594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.8 0.10368277132511139\n",
            "TEST GROUP:  0.784\n",
            "TEST ALL:  0.784\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  2000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [82, 81, 7, 16, 18, 20, 21, 22, 34, 39, 47, 49, 56, 59, 65, 67, 68, 79, 80, 4]\n",
            "TRAIN_SET CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "VALIDATION CLASSES:  [47, 34, 21, 16, 82, 81, 80, 79, 7, 68]\n",
            "GROUP:  2\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  20\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.6371297240257263\n",
            "Train step - Step 10, Loss 0.23396754264831543\n",
            "Train step - Step 20, Loss 0.22108104825019836\n",
            "Train step - Step 30, Loss 0.17696289718151093\n",
            "Train step - Step 40, Loss 0.18279656767845154\n",
            "Train step - Step 50, Loss 0.1719575971364975\n",
            "Train epoch - Accuracy: 0.2710791366906475 Loss: 0.22203104276880087 Corrects: 1884\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.15855954587459564\n",
            "Train step - Step 70, Loss 0.15287040174007416\n",
            "Train step - Step 80, Loss 0.15348570048809052\n",
            "Train step - Step 90, Loss 0.14665475487709045\n",
            "Train step - Step 100, Loss 0.16603527963161469\n",
            "Train epoch - Accuracy: 0.3722302158273381 Loss: 0.15918699614006837 Corrects: 2587\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.1479906439781189\n",
            "Train step - Step 120, Loss 0.1614740788936615\n",
            "Train step - Step 130, Loss 0.1593627780675888\n",
            "Train step - Step 140, Loss 0.14892934262752533\n",
            "Train step - Step 150, Loss 0.13271693885326385\n",
            "Train step - Step 160, Loss 0.14411385357379913\n",
            "Train epoch - Accuracy: 0.4418705035971223 Loss: 0.14902324346758478 Corrects: 3071\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.14022447168827057\n",
            "Train step - Step 180, Loss 0.15517844259738922\n",
            "Train step - Step 190, Loss 0.15337760746479034\n",
            "Train step - Step 200, Loss 0.13538004457950592\n",
            "Train step - Step 210, Loss 0.1527988463640213\n",
            "Train epoch - Accuracy: 0.47683453237410073 Loss: 0.14359592965609735 Corrects: 3314\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1406293660402298\n",
            "Train step - Step 230, Loss 0.12181546539068222\n",
            "Train step - Step 240, Loss 0.15298400819301605\n",
            "Train step - Step 250, Loss 0.138921856880188\n",
            "Train step - Step 260, Loss 0.1421595811843872\n",
            "Train step - Step 270, Loss 0.1387949138879776\n",
            "Train epoch - Accuracy: 0.5099280575539569 Loss: 0.13981186759986466 Corrects: 3544\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.14255598187446594\n",
            "Train step - Step 290, Loss 0.13289384543895721\n",
            "Train step - Step 300, Loss 0.13174311816692352\n",
            "Train step - Step 310, Loss 0.12773601710796356\n",
            "Train step - Step 320, Loss 0.13013756275177002\n",
            "Train epoch - Accuracy: 0.5353956834532374 Loss: 0.13632779402698544 Corrects: 3721\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.13480158150196075\n",
            "Train step - Step 340, Loss 0.13333724439144135\n",
            "Train step - Step 350, Loss 0.1357312649488449\n",
            "Train step - Step 360, Loss 0.12894070148468018\n",
            "Train step - Step 370, Loss 0.13285444676876068\n",
            "Train step - Step 380, Loss 0.14365777373313904\n",
            "Train epoch - Accuracy: 0.543884892086331 Loss: 0.13474093125449668 Corrects: 3780\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.1297622174024582\n",
            "Train step - Step 400, Loss 0.12949712574481964\n",
            "Train step - Step 410, Loss 0.1280815452337265\n",
            "Train step - Step 420, Loss 0.12525475025177002\n",
            "Train step - Step 430, Loss 0.1417350471019745\n",
            "Train epoch - Accuracy: 0.5618705035971223 Loss: 0.13332926622612012 Corrects: 3905\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.1363774836063385\n",
            "Train step - Step 450, Loss 0.13917139172554016\n",
            "Train step - Step 460, Loss 0.13617409765720367\n",
            "Train step - Step 470, Loss 0.13215585052967072\n",
            "Train step - Step 480, Loss 0.12064792960882187\n",
            "Train step - Step 490, Loss 0.12656275928020477\n",
            "Train epoch - Accuracy: 0.5730935251798561 Loss: 0.13069924008503234 Corrects: 3983\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.12112680822610855\n",
            "Train step - Step 510, Loss 0.12159042805433273\n",
            "Train step - Step 520, Loss 0.12870338559150696\n",
            "Train step - Step 530, Loss 0.13522975146770477\n",
            "Train step - Step 540, Loss 0.12370093911886215\n",
            "Train epoch - Accuracy: 0.5923741007194244 Loss: 0.12850716412496224 Corrects: 4117\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.12055617570877075\n",
            "Train step - Step 560, Loss 0.13084648549556732\n",
            "Train step - Step 570, Loss 0.12871268391609192\n",
            "Train step - Step 580, Loss 0.1192297488451004\n",
            "Train step - Step 590, Loss 0.12741903960704803\n",
            "Train step - Step 600, Loss 0.12961742281913757\n",
            "Train epoch - Accuracy: 0.602158273381295 Loss: 0.12807005707094138 Corrects: 4185\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.1166275292634964\n",
            "Train step - Step 620, Loss 0.11463043838739395\n",
            "Train step - Step 630, Loss 0.12282770127058029\n",
            "Train step - Step 640, Loss 0.12026405334472656\n",
            "Train step - Step 650, Loss 0.1258261501789093\n",
            "Train epoch - Accuracy: 0.6110791366906475 Loss: 0.12559115271774127 Corrects: 4247\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.12301137298345566\n",
            "Train step - Step 670, Loss 0.12701945006847382\n",
            "Train step - Step 680, Loss 0.1309642642736435\n",
            "Train step - Step 690, Loss 0.12425637245178223\n",
            "Train step - Step 700, Loss 0.12251198291778564\n",
            "Train step - Step 710, Loss 0.1165752187371254\n",
            "Train epoch - Accuracy: 0.6184172661870504 Loss: 0.124936974646805 Corrects: 4298\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.12045571953058243\n",
            "Train step - Step 730, Loss 0.11445154249668121\n",
            "Train step - Step 740, Loss 0.12571708858013153\n",
            "Train step - Step 750, Loss 0.11261583864688873\n",
            "Train step - Step 760, Loss 0.12765014171600342\n",
            "Train epoch - Accuracy: 0.6338129496402878 Loss: 0.12372242559203141 Corrects: 4405\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.11588376015424728\n",
            "Train step - Step 780, Loss 0.12132614105939865\n",
            "Train step - Step 790, Loss 0.11827009171247482\n",
            "Train step - Step 800, Loss 0.1245756670832634\n",
            "Train step - Step 810, Loss 0.12709486484527588\n",
            "Train step - Step 820, Loss 0.12671595811843872\n",
            "Train epoch - Accuracy: 0.6388489208633094 Loss: 0.12371091261184473 Corrects: 4440\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.1177220344543457\n",
            "Train step - Step 840, Loss 0.1159958615899086\n",
            "Train step - Step 850, Loss 0.12473966181278229\n",
            "Train step - Step 860, Loss 0.10936305671930313\n",
            "Train step - Step 870, Loss 0.12944048643112183\n",
            "Train epoch - Accuracy: 0.6463309352517985 Loss: 0.12126418331972987 Corrects: 4492\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.13661639392375946\n",
            "Train step - Step 890, Loss 0.12722961604595184\n",
            "Train step - Step 900, Loss 0.11475653946399689\n",
            "Train step - Step 910, Loss 0.12262000888586044\n",
            "Train step - Step 920, Loss 0.13190801441669464\n",
            "Train step - Step 930, Loss 0.11553321033716202\n",
            "Train epoch - Accuracy: 0.6538129496402878 Loss: 0.12009808109604198 Corrects: 4544\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.12922175228595734\n",
            "Train step - Step 950, Loss 0.11857600510120392\n",
            "Train step - Step 960, Loss 0.13117335736751556\n",
            "Train step - Step 970, Loss 0.11520913988351822\n",
            "Train step - Step 980, Loss 0.11817779392004013\n",
            "Train epoch - Accuracy: 0.656978417266187 Loss: 0.11919074210331594 Corrects: 4566\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.12007492035627365\n",
            "Train step - Step 1000, Loss 0.11220233887434006\n",
            "Train step - Step 1010, Loss 0.10325498878955841\n",
            "Train step - Step 1020, Loss 0.12616752088069916\n",
            "Train step - Step 1030, Loss 0.11826574802398682\n",
            "Train step - Step 1040, Loss 0.1107669398188591\n",
            "Train epoch - Accuracy: 0.6670503597122303 Loss: 0.1182113015737465 Corrects: 4636\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.11505407094955444\n",
            "Train step - Step 1060, Loss 0.11307394504547119\n",
            "Train step - Step 1070, Loss 0.13415417075157166\n",
            "Train step - Step 1080, Loss 0.11473973840475082\n",
            "Train step - Step 1090, Loss 0.112260602414608\n",
            "Train epoch - Accuracy: 0.6717985611510792 Loss: 0.1183058575824868 Corrects: 4669\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.1147698163986206\n",
            "Train step - Step 1110, Loss 0.11815863102674484\n",
            "Train step - Step 1120, Loss 0.10690188407897949\n",
            "Train step - Step 1130, Loss 0.11289932578802109\n",
            "Train step - Step 1140, Loss 0.10853630304336548\n",
            "Train step - Step 1150, Loss 0.11833205074071884\n",
            "Train epoch - Accuracy: 0.6814388489208633 Loss: 0.11695913464474164 Corrects: 4736\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11166203022003174\n",
            "Train step - Step 1170, Loss 0.11306669563055038\n",
            "Train step - Step 1180, Loss 0.12376232445240021\n",
            "Train step - Step 1190, Loss 0.1192847266793251\n",
            "Train step - Step 1200, Loss 0.11299610137939453\n",
            "Train epoch - Accuracy: 0.6831654676258992 Loss: 0.11602031741639693 Corrects: 4748\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.11107869446277618\n",
            "Train step - Step 1220, Loss 0.11499469727277756\n",
            "Train step - Step 1230, Loss 0.10580053180456161\n",
            "Train step - Step 1240, Loss 0.12012972682714462\n",
            "Train step - Step 1250, Loss 0.12040211260318756\n",
            "Train step - Step 1260, Loss 0.11443618685007095\n",
            "Train epoch - Accuracy: 0.696115107913669 Loss: 0.11556676441388164 Corrects: 4838\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10957162827253342\n",
            "Train step - Step 1280, Loss 0.1193966194987297\n",
            "Train step - Step 1290, Loss 0.11043477058410645\n",
            "Train step - Step 1300, Loss 0.1241040974855423\n",
            "Train step - Step 1310, Loss 0.1094554215669632\n",
            "Train epoch - Accuracy: 0.6946762589928057 Loss: 0.11410765376880015 Corrects: 4828\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.10700972378253937\n",
            "Train step - Step 1330, Loss 0.11135821789503098\n",
            "Train step - Step 1340, Loss 0.11313902586698532\n",
            "Train step - Step 1350, Loss 0.10795384645462036\n",
            "Train step - Step 1360, Loss 0.116119883954525\n",
            "Train step - Step 1370, Loss 0.1263429969549179\n",
            "Train epoch - Accuracy: 0.6984172661870504 Loss: 0.11274357460171198 Corrects: 4854\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.11471769958734512\n",
            "Train step - Step 1390, Loss 0.11148273199796677\n",
            "Train step - Step 1400, Loss 0.11634033173322678\n",
            "Train step - Step 1410, Loss 0.11057662963867188\n",
            "Train step - Step 1420, Loss 0.1145574077963829\n",
            "Train epoch - Accuracy: 0.7037410071942446 Loss: 0.11364594340324402 Corrects: 4891\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.11224260181188583\n",
            "Train step - Step 1440, Loss 0.11314934492111206\n",
            "Train step - Step 1450, Loss 0.10572942346334457\n",
            "Train step - Step 1460, Loss 0.11783736944198608\n",
            "Train step - Step 1470, Loss 0.11312615871429443\n",
            "Train step - Step 1480, Loss 0.12016554176807404\n",
            "Train epoch - Accuracy: 0.7084892086330935 Loss: 0.11223627936925819 Corrects: 4924\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.11428146809339523\n",
            "Train step - Step 1500, Loss 0.11749029159545898\n",
            "Train step - Step 1510, Loss 0.12336816638708115\n",
            "Train step - Step 1520, Loss 0.11585451662540436\n",
            "Train step - Step 1530, Loss 0.1018003448843956\n",
            "Train epoch - Accuracy: 0.7149640287769784 Loss: 0.11158161160328406 Corrects: 4969\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.10472168773412704\n",
            "Train step - Step 1550, Loss 0.11396079510450363\n",
            "Train step - Step 1560, Loss 0.12021762132644653\n",
            "Train step - Step 1570, Loss 0.11119551956653595\n",
            "Train step - Step 1580, Loss 0.10858499258756638\n",
            "Train step - Step 1590, Loss 0.11384110897779465\n",
            "Train epoch - Accuracy: 0.7194244604316546 Loss: 0.1118157350631069 Corrects: 5000\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.11928965896368027\n",
            "Train step - Step 1610, Loss 0.12270873039960861\n",
            "Train step - Step 1620, Loss 0.1107599064707756\n",
            "Train step - Step 1630, Loss 0.11392384022474289\n",
            "Train step - Step 1640, Loss 0.11174078285694122\n",
            "Train epoch - Accuracy: 0.7235971223021582 Loss: 0.11044008462549114 Corrects: 5029\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.11238696426153183\n",
            "Train step - Step 1660, Loss 0.10235247761011124\n",
            "Train step - Step 1670, Loss 0.11983124166727066\n",
            "Train step - Step 1680, Loss 0.11154907196760178\n",
            "Train step - Step 1690, Loss 0.10544774681329727\n",
            "Train step - Step 1700, Loss 0.11583763360977173\n",
            "Train epoch - Accuracy: 0.7355395683453237 Loss: 0.10956418111169938 Corrects: 5112\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.11693125218153\n",
            "Train step - Step 1720, Loss 0.1103314682841301\n",
            "Train step - Step 1730, Loss 0.11213471740484238\n",
            "Train step - Step 1740, Loss 0.11534740775823593\n",
            "Train step - Step 1750, Loss 0.10679688304662704\n",
            "Train epoch - Accuracy: 0.7349640287769784 Loss: 0.10879714154082236 Corrects: 5108\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.11097532510757446\n",
            "Train step - Step 1770, Loss 0.10912471264600754\n",
            "Train step - Step 1780, Loss 0.11738558113574982\n",
            "Train step - Step 1790, Loss 0.10195982456207275\n",
            "Train step - Step 1800, Loss 0.11204331368207932\n",
            "Train step - Step 1810, Loss 0.10661079734563828\n",
            "Train epoch - Accuracy: 0.7424460431654676 Loss: 0.1082589141156176 Corrects: 5160\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.10871975868940353\n",
            "Train step - Step 1830, Loss 0.10357010364532471\n",
            "Train step - Step 1840, Loss 0.10997208207845688\n",
            "Train step - Step 1850, Loss 0.10833992809057236\n",
            "Train step - Step 1860, Loss 0.11843018978834152\n",
            "Train epoch - Accuracy: 0.7433093525179856 Loss: 0.10772992752010016 Corrects: 5166\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.1169353723526001\n",
            "Train step - Step 1880, Loss 0.1072101965546608\n",
            "Train step - Step 1890, Loss 0.10586251318454742\n",
            "Train step - Step 1900, Loss 0.1020691767334938\n",
            "Train step - Step 1910, Loss 0.10514362156391144\n",
            "Train step - Step 1920, Loss 0.10021104663610458\n",
            "Train epoch - Accuracy: 0.7463309352517986 Loss: 0.10745413113197834 Corrects: 5187\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.11205606907606125\n",
            "Train step - Step 1940, Loss 0.11446452140808105\n",
            "Train step - Step 1950, Loss 0.11215479671955109\n",
            "Train step - Step 1960, Loss 0.10615988075733185\n",
            "Train step - Step 1970, Loss 0.11597414314746857\n",
            "Train epoch - Accuracy: 0.7453237410071942 Loss: 0.10635480194640674 Corrects: 5180\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.10793758928775787\n",
            "Train step - Step 1990, Loss 0.109298937022686\n",
            "Train step - Step 2000, Loss 0.10582661628723145\n",
            "Train step - Step 2010, Loss 0.10060334205627441\n",
            "Train step - Step 2020, Loss 0.10905984789133072\n",
            "Train step - Step 2030, Loss 0.10304417461156845\n",
            "Train epoch - Accuracy: 0.756546762589928 Loss: 0.10662568976553224 Corrects: 5258\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10282062739133835\n",
            "Train step - Step 2050, Loss 0.098351389169693\n",
            "Train step - Step 2060, Loss 0.10720192641019821\n",
            "Train step - Step 2070, Loss 0.10270488262176514\n",
            "Train step - Step 2080, Loss 0.10620822757482529\n",
            "Train epoch - Accuracy: 0.7509352517985611 Loss: 0.10605471427492101 Corrects: 5219\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10309374332427979\n",
            "Train step - Step 2100, Loss 0.09854420274496078\n",
            "Train step - Step 2110, Loss 0.10889899730682373\n",
            "Train step - Step 2120, Loss 0.10458540916442871\n",
            "Train step - Step 2130, Loss 0.10306710004806519\n",
            "Train step - Step 2140, Loss 0.11494471877813339\n",
            "Train epoch - Accuracy: 0.7562589928057554 Loss: 0.10498494225869076 Corrects: 5256\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.1063426062464714\n",
            "Train step - Step 2160, Loss 0.10014300793409348\n",
            "Train step - Step 2170, Loss 0.09483750909566879\n",
            "Train step - Step 2180, Loss 0.10161073505878448\n",
            "Train step - Step 2190, Loss 0.11371155083179474\n",
            "Train epoch - Accuracy: 0.7638848920863309 Loss: 0.10454729755576565 Corrects: 5309\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.10831111669540405\n",
            "Train step - Step 2210, Loss 0.10442449897527695\n",
            "Train step - Step 2220, Loss 0.10345163196325302\n",
            "Train step - Step 2230, Loss 0.1027822270989418\n",
            "Train step - Step 2240, Loss 0.10254199802875519\n",
            "Train step - Step 2250, Loss 0.10197971016168594\n",
            "Train epoch - Accuracy: 0.7690647482014389 Loss: 0.10339295894765167 Corrects: 5345\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.0914819985628128\n",
            "Train step - Step 2270, Loss 0.11512484401464462\n",
            "Train step - Step 2280, Loss 0.10543402284383774\n",
            "Train step - Step 2290, Loss 0.10192910581827164\n",
            "Train step - Step 2300, Loss 0.09771251678466797\n",
            "Train epoch - Accuracy: 0.7696402877697842 Loss: 0.10382701619280328 Corrects: 5349\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10511469095945358\n",
            "Train step - Step 2320, Loss 0.11403735727071762\n",
            "Train step - Step 2330, Loss 0.10304798930883408\n",
            "Train step - Step 2340, Loss 0.11380161345005035\n",
            "Train step - Step 2350, Loss 0.09708143025636673\n",
            "Train step - Step 2360, Loss 0.10776872932910919\n",
            "Train epoch - Accuracy: 0.7717985611510791 Loss: 0.10321810366438447 Corrects: 5364\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.11013203859329224\n",
            "Train step - Step 2380, Loss 0.09847428649663925\n",
            "Train step - Step 2390, Loss 0.10420610010623932\n",
            "Train step - Step 2400, Loss 0.10812318325042725\n",
            "Train step - Step 2410, Loss 0.09380894899368286\n",
            "Train epoch - Accuracy: 0.7722302158273381 Loss: 0.10252611253758986 Corrects: 5367\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.10441714525222778\n",
            "Train step - Step 2430, Loss 0.10024211555719376\n",
            "Train step - Step 2440, Loss 0.10782312601804733\n",
            "Train step - Step 2450, Loss 0.09997113049030304\n",
            "Train step - Step 2460, Loss 0.1017216369509697\n",
            "Train step - Step 2470, Loss 0.09131771326065063\n",
            "Train epoch - Accuracy: 0.7785611510791367 Loss: 0.10149997599690938 Corrects: 5411\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10168462246656418\n",
            "Train step - Step 2490, Loss 0.10459230095148087\n",
            "Train step - Step 2500, Loss 0.0925513282418251\n",
            "Train step - Step 2510, Loss 0.10087847709655762\n",
            "Train step - Step 2520, Loss 0.09390120953321457\n",
            "Train epoch - Accuracy: 0.7810071942446043 Loss: 0.10157024208375875 Corrects: 5428\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.09822956472635269\n",
            "Train step - Step 2540, Loss 0.09878477454185486\n",
            "Train step - Step 2550, Loss 0.10392165184020996\n",
            "Train step - Step 2560, Loss 0.09153345972299576\n",
            "Train step - Step 2570, Loss 0.09853579849004745\n",
            "Train step - Step 2580, Loss 0.10602477937936783\n",
            "Train epoch - Accuracy: 0.7867625899280576 Loss: 0.10047565068272378 Corrects: 5468\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.10474157333374023\n",
            "Train step - Step 2600, Loss 0.10560277849435806\n",
            "Train step - Step 2610, Loss 0.10810641199350357\n",
            "Train step - Step 2620, Loss 0.10637287050485611\n",
            "Train step - Step 2630, Loss 0.10577215254306793\n",
            "Train epoch - Accuracy: 0.7877697841726619 Loss: 0.10145985381637546 Corrects: 5475\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.09706953912973404\n",
            "Train step - Step 2650, Loss 0.10862546414136887\n",
            "Train step - Step 2660, Loss 0.09413053095340729\n",
            "Train step - Step 2670, Loss 0.09762393683195114\n",
            "Train step - Step 2680, Loss 0.10121645778417587\n",
            "Train step - Step 2690, Loss 0.09702310711145401\n",
            "Train epoch - Accuracy: 0.7848920863309352 Loss: 0.10027592327526147 Corrects: 5455\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.09416741132736206\n",
            "Train step - Step 2710, Loss 0.09236328303813934\n",
            "Train step - Step 2720, Loss 0.09629526734352112\n",
            "Train step - Step 2730, Loss 0.08822254091501236\n",
            "Train step - Step 2740, Loss 0.08850528299808502\n",
            "Train epoch - Accuracy: 0.8092086330935252 Loss: 0.09605916929330757 Corrects: 5624\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10367870330810547\n",
            "Train step - Step 2760, Loss 0.0983353778719902\n",
            "Train step - Step 2770, Loss 0.0902106910943985\n",
            "Train step - Step 2780, Loss 0.09410519897937775\n",
            "Train step - Step 2790, Loss 0.08957541733980179\n",
            "Train step - Step 2800, Loss 0.09555628150701523\n",
            "Train epoch - Accuracy: 0.8123741007194245 Loss: 0.09473515741044669 Corrects: 5646\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.09291362762451172\n",
            "Train step - Step 2820, Loss 0.09879391640424728\n",
            "Train step - Step 2830, Loss 0.09082494676113129\n",
            "Train step - Step 2840, Loss 0.09082160145044327\n",
            "Train step - Step 2850, Loss 0.09451151639223099\n",
            "Train epoch - Accuracy: 0.8151079136690648 Loss: 0.09459090384862406 Corrects: 5665\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.08878382295370102\n",
            "Train step - Step 2870, Loss 0.09093713760375977\n",
            "Train step - Step 2880, Loss 0.10050878673791885\n",
            "Train step - Step 2890, Loss 0.09152235835790634\n",
            "Train step - Step 2900, Loss 0.08797403424978256\n",
            "Train step - Step 2910, Loss 0.09818156063556671\n",
            "Train epoch - Accuracy: 0.8273381294964028 Loss: 0.0934166377096725 Corrects: 5750\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.09226136654615402\n",
            "Train step - Step 2930, Loss 0.08513256162405014\n",
            "Train step - Step 2940, Loss 0.09757053852081299\n",
            "Train step - Step 2950, Loss 0.08814103901386261\n",
            "Train step - Step 2960, Loss 0.09338837116956711\n",
            "Train epoch - Accuracy: 0.8136690647482014 Loss: 0.09351790431377699 Corrects: 5655\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09020357578992844\n",
            "Train step - Step 2980, Loss 0.0905219241976738\n",
            "Train step - Step 2990, Loss 0.09024585783481598\n",
            "Train step - Step 3000, Loss 0.09404709190130234\n",
            "Train step - Step 3010, Loss 0.09385718405246735\n",
            "Train step - Step 3020, Loss 0.09311401844024658\n",
            "Train epoch - Accuracy: 0.8299280575539568 Loss: 0.09302761042932813 Corrects: 5768\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.08435244858264923\n",
            "Train step - Step 3040, Loss 0.09346295893192291\n",
            "Train step - Step 3050, Loss 0.09216561168432236\n",
            "Train step - Step 3060, Loss 0.09539970755577087\n",
            "Train step - Step 3070, Loss 0.0872049555182457\n",
            "Train epoch - Accuracy: 0.824748201438849 Loss: 0.0923866783028884 Corrects: 5732\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.08974534273147583\n",
            "Train step - Step 3090, Loss 0.10515930503606796\n",
            "Train step - Step 3100, Loss 0.09195759147405624\n",
            "Train step - Step 3110, Loss 0.08917982876300812\n",
            "Train step - Step 3120, Loss 0.08973151445388794\n",
            "Train step - Step 3130, Loss 0.0957925096154213\n",
            "Train epoch - Accuracy: 0.8280575539568346 Loss: 0.09262400619632048 Corrects: 5755\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10313592106103897\n",
            "Train step - Step 3150, Loss 0.09908431023359299\n",
            "Train step - Step 3160, Loss 0.08867435902357101\n",
            "Train step - Step 3170, Loss 0.08710142225027084\n",
            "Train step - Step 3180, Loss 0.09448602050542831\n",
            "Train epoch - Accuracy: 0.8258992805755395 Loss: 0.09252585575091753 Corrects: 5740\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09065989404916763\n",
            "Train step - Step 3200, Loss 0.0861406996846199\n",
            "Train step - Step 3210, Loss 0.0920528769493103\n",
            "Train step - Step 3220, Loss 0.09468420594930649\n",
            "Train step - Step 3230, Loss 0.09423160552978516\n",
            "Train step - Step 3240, Loss 0.09199856221675873\n",
            "Train epoch - Accuracy: 0.8264748201438848 Loss: 0.09263036476407978 Corrects: 5744\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09322919696569443\n",
            "Train step - Step 3260, Loss 0.10087158530950546\n",
            "Train step - Step 3270, Loss 0.09879018366336823\n",
            "Train step - Step 3280, Loss 0.09844039380550385\n",
            "Train step - Step 3290, Loss 0.09045003354549408\n",
            "Train epoch - Accuracy: 0.8269064748201439 Loss: 0.09235658360899782 Corrects: 5747\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.0894227921962738\n",
            "Train step - Step 3310, Loss 0.0856194868683815\n",
            "Train step - Step 3320, Loss 0.08858861774206161\n",
            "Train step - Step 3330, Loss 0.09060206264257431\n",
            "Train step - Step 3340, Loss 0.09101209789514542\n",
            "Train step - Step 3350, Loss 0.09693785756826401\n",
            "Train epoch - Accuracy: 0.8315107913669064 Loss: 0.09192456235559725 Corrects: 5779\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.0912981778383255\n",
            "Train step - Step 3370, Loss 0.08556187152862549\n",
            "Train step - Step 3380, Loss 0.08618155866861343\n",
            "Train step - Step 3390, Loss 0.09008868038654327\n",
            "Train step - Step 3400, Loss 0.08595284819602966\n",
            "Train epoch - Accuracy: 0.8294964028776979 Loss: 0.09214238940383034 Corrects: 5765\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09264662116765976\n",
            "Train step - Step 3420, Loss 0.08917542546987534\n",
            "Train step - Step 3430, Loss 0.09076141566038132\n",
            "Train step - Step 3440, Loss 0.09371162950992584\n",
            "Train step - Step 3450, Loss 0.09288028627634048\n",
            "Train step - Step 3460, Loss 0.10086601972579956\n",
            "Train epoch - Accuracy: 0.8366906474820144 Loss: 0.09184937053018337 Corrects: 5815\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.09656411409378052\n",
            "Train step - Step 3480, Loss 0.09298856556415558\n",
            "Train step - Step 3490, Loss 0.09377148747444153\n",
            "Train step - Step 3500, Loss 0.08330263942480087\n",
            "Train step - Step 3510, Loss 0.08471386879682541\n",
            "Train epoch - Accuracy: 0.8402877697841726 Loss: 0.090843174290314 Corrects: 5840\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.08986593782901764\n",
            "Train step - Step 3530, Loss 0.08505317568778992\n",
            "Train step - Step 3540, Loss 0.09503304213285446\n",
            "Train step - Step 3550, Loss 0.08371474593877792\n",
            "Train step - Step 3560, Loss 0.089354008436203\n",
            "Train step - Step 3570, Loss 0.09424658864736557\n",
            "Train epoch - Accuracy: 0.8362589928057554 Loss: 0.09060831444083357 Corrects: 5812\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.1016269102692604\n",
            "Train step - Step 3590, Loss 0.08854279667139053\n",
            "Train step - Step 3600, Loss 0.09059742838144302\n",
            "Train step - Step 3610, Loss 0.089933380484581\n",
            "Train step - Step 3620, Loss 0.09486418217420578\n",
            "Train epoch - Accuracy: 0.8351079136690648 Loss: 0.09088919743573923 Corrects: 5804\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09377578645944595\n",
            "Train step - Step 3640, Loss 0.08839131891727448\n",
            "Train step - Step 3650, Loss 0.09057315438985825\n",
            "Train step - Step 3660, Loss 0.08526960760354996\n",
            "Train step - Step 3670, Loss 0.09931959956884384\n",
            "Train step - Step 3680, Loss 0.09442750364542007\n",
            "Train epoch - Accuracy: 0.8312230215827339 Loss: 0.09110341667700157 Corrects: 5777\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.08239143341779709\n",
            "Train step - Step 3700, Loss 0.09329796582460403\n",
            "Train step - Step 3710, Loss 0.07973335683345795\n",
            "Train step - Step 3720, Loss 0.09236984699964523\n",
            "Train step - Step 3730, Loss 0.09083414822816849\n",
            "Train epoch - Accuracy: 0.8388489208633093 Loss: 0.09056133625533083 Corrects: 5830\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.0926351472735405\n",
            "Train step - Step 3750, Loss 0.09469976276159286\n",
            "Train step - Step 3760, Loss 0.09311243146657944\n",
            "Train step - Step 3770, Loss 0.09012613445520401\n",
            "Train step - Step 3780, Loss 0.0875728651881218\n",
            "Train step - Step 3790, Loss 0.08398007601499557\n",
            "Train epoch - Accuracy: 0.8353956834532374 Loss: 0.09060406866047879 Corrects: 5806\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.09154132753610611\n",
            "Train step - Step 3810, Loss 0.08945425599813461\n",
            "Train step - Step 3820, Loss 0.0902312695980072\n",
            "Train step - Step 3830, Loss 0.10563905537128448\n",
            "Train step - Step 3840, Loss 0.09276280552148819\n",
            "Train epoch - Accuracy: 0.8411510791366906 Loss: 0.09043352185179003 Corrects: 5846\n",
            "Training finished in 446.9848122596741 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f9ba50>\n",
            "Constructing exemplars of class 79\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [34453, 14492, 34523, 26456, 36864, 14222, 49842, 15080, 30418, 31173, 25718, 37370, 39586, 45394, 48539, 941, 40441, 47158, 26021, 17088, 30339, 42723, 44724, 20986, 13365, 32435, 20820, 38515, 9735, 7470, 8811, 16005, 7016, 45693, 42723, 38725, 15305, 45432, 21796, 7940, 45005, 43857, 4307, 32267, 40781, 45774, 7140, 16194, 14978, 8007, 2081, 9793, 14467, 37810, 47983, 38926, 42535, 49503, 47938, 8033, 18433, 11984, 14441, 25934, 35060, 32127, 12495, 41590, 34350, 14390, 24288, 19085, 5507, 47983, 26456, 38711, 45432, 7338, 24547, 39726, 15080, 20345, 44802, 3762, 27639, 47689, 24772, 232, 34523, 20820, 4517, 4324, 43154, 13921, 37348, 43687, 29775, 32547, 13411, 13365]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a158610>\n",
            "Constructing exemplars of class 47\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [40763, 6659, 23229, 14666, 43224, 5363, 25262, 8193, 8653, 10799, 18966, 29535, 21131, 19157, 2344, 28964, 17534, 20152, 27083, 48495, 8193, 40637, 2836, 47305, 45130, 19664, 45028, 29029, 19202, 3797, 22495, 27598, 22954, 20152, 28065, 47931, 23407, 40884, 14296, 20873, 6681, 45759, 42408, 19157, 15719, 26541, 44092, 24953, 9291, 49886, 5911, 43446, 11823, 14038, 41102, 49852, 48953, 9511, 24646, 31137, 35823, 49852, 36619, 47672, 48080, 2278, 17883, 1980, 33359, 19646, 36131, 7333, 21131, 43381, 33014, 11263, 28046, 37972, 20697, 40647, 16867, 42985, 2831, 44246, 45979, 19882, 36842, 16605, 24422, 32807, 32268, 28027, 14505, 2042, 13301, 6659, 31553, 5598, 1620, 17620]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a5c2650>\n",
            "Constructing exemplars of class 7\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [48087, 23198, 41588, 43201, 35405, 17286, 2164, 8444, 31764, 13985, 47435, 26112, 290, 14352, 47924, 13177, 23066, 17356, 30814, 15852, 29018, 6367, 4085, 19432, 20284, 16035, 36966, 41650, 39756, 27051, 2386, 42116, 7173, 16537, 39555, 41071, 48406, 40343, 49996, 38254, 19279, 13986, 26573, 4085, 3618, 805, 27712, 22784, 46653, 47136, 9226, 28111, 37389, 34244, 7237, 14762, 23198, 36222, 42172, 18989, 13297, 24934, 25539, 49282, 27018, 33239, 46769, 33207, 5440, 7420, 36382, 6616, 16537, 30265, 290, 45770, 15243, 3618, 1015, 6399, 3846, 26031, 19348, 45221, 5516, 31764, 9765, 40476, 31684, 26394, 4498, 46095, 44801, 5819, 30165, 31829, 35781, 42288, 24755, 31650]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a5a5b10>\n",
            "Constructing exemplars of class 82\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [5450, 3314, 41968, 10309, 27314, 18202, 48590, 49858, 17455, 42973, 14557, 26852, 36194, 32602, 38355, 21512, 25817, 34471, 10505, 45688, 32349, 23402, 6271, 11501, 7334, 19817, 22190, 19595, 18937, 47306, 35285, 30468, 41719, 48832, 32349, 35369, 27707, 1029, 44523, 13944, 23431, 24024, 8727, 23071, 32028, 42626, 30639, 28893, 5454, 30528, 46768, 24024, 30203, 28783, 11470, 15304, 25771, 29103, 20263, 31443, 9700, 41181, 1402, 43429, 16791, 49832, 45373, 18922, 30102, 48590, 27709, 3833, 41968, 41221, 45076, 16905, 19657, 8170, 31456, 5904, 31065, 36705, 32175, 5658, 21973, 36437, 19817, 32349, 33090, 24178, 32858, 6057, 5904, 16784, 36301, 12518, 14398, 45189, 6578, 26562]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a12f4d0>\n",
            "Constructing exemplars of class 34\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [40428, 22477, 8406, 20766, 19814, 45666, 9108, 11804, 24499, 12228, 42112, 1472, 18308, 36393, 35104, 16183, 49918, 48468, 8316, 18893, 20590, 1951, 47530, 37004, 7368, 17105, 1292, 40428, 13313, 30846, 5884, 15366, 23687, 18632, 4001, 3019, 44357, 13038, 33633, 7194, 48505, 34859, 1550, 39095, 14378, 4098, 25116, 12636, 38512, 439, 23411, 22146, 42093, 36393, 48048, 17839, 41170, 14859, 22282, 34833, 1969, 21502, 16299, 20338, 29332, 12666, 17110, 45766, 13313, 28310, 18632, 4577, 11594, 26172, 33386, 6338, 20609, 27418, 35708, 38484, 8316, 9271, 31750, 7399, 43022, 49348, 48286, 42463, 3439, 25110, 17247, 4901, 45165, 3077, 45900, 21197, 41992, 17841, 25992, 25116]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a030550>\n",
            "Constructing exemplars of class 81\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [47035, 1105, 33016, 31727, 43513, 15308, 11223, 24756, 675, 5633, 40920, 11566, 40070, 14232, 28071, 28906, 13015, 12395, 23286, 30059, 28908, 18771, 16078, 20715, 15119, 8276, 12195, 47989, 14578, 19916, 22504, 8760, 24532, 5539, 12746, 8699, 10584, 21919, 37599, 22191, 37741, 12523, 11681, 45865, 9254, 49479, 30151, 12395, 21151, 35547, 42338, 30920, 20081, 9106, 45143, 39373, 975, 20328, 8976, 24481, 43513, 33016, 24743, 18735, 41333, 20148, 40563, 20185, 14183, 196, 13158, 22512, 47989, 45585, 37599, 14290, 36, 38053, 20783, 31655, 13364, 46119, 27479, 47568, 20278, 4954, 40631, 41333, 39819, 47154, 16318, 34777, 18656, 11347, 15149, 27527, 27896, 21025, 1395, 34156]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f89690>\n",
            "Constructing exemplars of class 21\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [42101, 15103, 19919, 5105, 11455, 2225, 44955, 29330, 32570, 6133, 47005, 37883, 10546, 11090, 6663, 49739, 26154, 28841, 13912, 18533, 23422, 41589, 44706, 44393, 37378, 6133, 19147, 23567, 34948, 11483, 1955, 26498, 18613, 34933, 16014, 32825, 43302, 44887, 46315, 30132, 4610, 21686, 36592, 41374, 28523, 5029, 24348, 19147, 35176, 28247, 25561, 41092, 33578, 39743, 45961, 47005, 31178, 18399, 4810, 38611, 34069, 43407, 42053, 11210, 15256, 46521, 37378, 18613, 42100, 28247, 47005, 42274, 44316, 42040, 7991, 27211, 44887, 46315, 38444, 22895, 43392, 3692, 31206, 30797, 46760, 49688, 21237, 1955, 34403, 12055, 11210, 11888, 44706, 42274, 20365, 38444, 27947, 17263, 49881, 1955]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a51f9d0>\n",
            "Constructing exemplars of class 80\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [17990, 12901, 43009, 45814, 2938, 16681, 41469, 32727, 36436, 24968, 28928, 16276, 42906, 17508, 26827, 30641, 5829, 2385, 10725, 11791, 11461, 14495, 16582, 31568, 44974, 49167, 33348, 25422, 8777, 49995, 47546, 29240, 11142, 24088, 35871, 47546, 3484, 39496, 6459, 29136, 41023, 19368, 22492, 23564, 28928, 39805, 7599, 15025, 38312, 28508, 40322, 3331, 45486, 19750, 15008, 16625, 12158, 2969, 15026, 47287, 40719, 8094, 26961, 3768, 9446, 41098, 42828, 15669, 14541, 37614, 22492, 21740, 45998, 14495, 10017, 16276, 19429, 10133, 11502, 36436, 38761, 17170, 11991, 26961, 41354, 40423, 28931, 43277, 11791, 11461, 38972, 4561, 11768, 33526, 35376, 38932, 43939, 40095, 41737, 25986]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f89750>\n",
            "Constructing exemplars of class 68\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [32945, 29117, 24320, 16812, 42431, 47799, 36879, 11854, 30842, 10969, 31450, 28797, 18381, 22188, 22100, 28655, 13154, 33864, 39615, 11158, 3836, 11147, 12647, 15322, 36461, 28074, 46683, 116, 45993, 35058, 48177, 46100, 15046, 28443, 13044, 7915, 39776, 1185, 37274, 12103, 17753, 44821, 4138, 37932, 29548, 42388, 28217, 16834, 49013, 46686, 2815, 37974, 48034, 11147, 40600, 31522, 31765, 34470, 17614, 30478, 26591, 19950, 15384, 28450, 37232, 42007, 9591, 7421, 20265, 35628, 8399, 7778, 10361, 44121, 26732, 7817, 28636, 28450, 39776, 49464, 6875, 28797, 717, 46305, 28877, 21083, 28443, 45993, 21516, 31749, 24915, 16812, 6378, 27410, 45199, 33270, 4342, 41493, 13583, 3208]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f78c90>\n",
            "Constructing exemplars of class 16\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [15164, 24721, 25541, 4502, 23065, 25870, 3869, 33299, 10793, 8702, 10509, 25632, 3552, 9860, 20240, 32995, 21145, 1414, 44130, 22338, 20019, 26206, 34311, 18798, 29901, 7822, 13725, 21588, 42185, 47473, 38148, 23380, 31581, 45060, 26760, 22297, 2888, 22162, 49654, 12966, 596, 21595, 43404, 24725, 30251, 24132, 22248, 20703, 41893, 25870, 6409, 12709, 46134, 13413, 28892, 6305, 40901, 48455, 26400, 37475, 12985, 45983, 16732, 14037, 35872, 18945, 18607, 28715, 20019, 37198, 22441, 28856, 48582, 13988, 26145, 26387, 12966, 30494, 37520, 14037, 12044, 45357, 15979, 2868, 22012, 29373, 29244, 48907, 21274, 30017, 7514, 20051, 21082, 28715, 25118, 15957, 23435, 11166, 4687, 2888]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.4972657263278961\n",
            "Train step - Step 0, Loss 0.3635580837726593\n",
            "Train step - Step 0, Loss 0.41218098998069763\n",
            "Train step - Step 0, Loss 0.3726711571216583\n",
            "Train step - Step 0, Loss 0.37291985750198364\n",
            "Train step - Step 0, Loss 0.37783631682395935\n",
            "Train step - Step 0, Loss 0.35907575488090515\n",
            "Train step - Step 0, Loss 0.33762848377227783\n",
            "Train step - Step 0, Loss 0.2920428216457367\n",
            "Train step - Step 0, Loss 0.27600589394569397\n",
            "Train step - Step 0, Loss 0.22671055793762207\n",
            "Train step - Step 0, Loss 0.3033275902271271\n",
            "Train step - Step 0, Loss 0.28506171703338623\n",
            "Train step - Step 0, Loss 0.22962160408496857\n",
            "Train step - Step 0, Loss 0.2518947124481201\n",
            "Train step - Step 0, Loss 0.2864972651004791\n",
            "Train epoch - Accuracy: 0.5491666666666667 Loss: 0.32875917172431945 Corrects: 6590\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.254379540681839\n",
            "Train step - Step 0, Loss 0.2561797499656677\n",
            "Train step - Step 0, Loss 0.2848131060600281\n",
            "Train step - Step 0, Loss 0.26016518473625183\n",
            "Train step - Step 0, Loss 0.28848549723625183\n",
            "Train step - Step 0, Loss 0.2668939530849457\n",
            "Train step - Step 0, Loss 0.23491671681404114\n",
            "Train step - Step 0, Loss 0.23347559571266174\n",
            "Train step - Step 0, Loss 0.22481143474578857\n",
            "Train step - Step 0, Loss 0.23332171142101288\n",
            "Train step - Step 0, Loss 0.242878258228302\n",
            "Train step - Step 0, Loss 0.2315925657749176\n",
            "Train step - Step 0, Loss 0.24493080377578735\n",
            "Train step - Step 0, Loss 0.2377241551876068\n",
            "Train step - Step 0, Loss 0.26996371150016785\n",
            "Train step - Step 0, Loss 0.2506079077720642\n",
            "Train epoch - Accuracy: 0.5394166666666667 Loss: 0.25095436334609983 Corrects: 6473\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.21652273833751678\n",
            "Train step - Step 0, Loss 0.2193615734577179\n",
            "Train step - Step 0, Loss 0.21393074095249176\n",
            "Train step - Step 0, Loss 0.25243109464645386\n",
            "Train step - Step 0, Loss 0.21022199094295502\n",
            "Train step - Step 0, Loss 0.19204118847846985\n",
            "Train step - Step 0, Loss 0.1966724842786789\n",
            "Train step - Step 0, Loss 0.21771754324436188\n",
            "Train step - Step 0, Loss 0.20733454823493958\n",
            "Train step - Step 0, Loss 0.1917676031589508\n",
            "Train step - Step 0, Loss 0.2061612457036972\n",
            "Train step - Step 0, Loss 0.18336287140846252\n",
            "Train step - Step 0, Loss 0.20385637879371643\n",
            "Train step - Step 0, Loss 0.19770017266273499\n",
            "Train step - Step 0, Loss 0.2021731436252594\n",
            "Train step - Step 0, Loss 0.18274109065532684\n",
            "Train epoch - Accuracy: 0.5419166666666667 Loss: 0.20642998397350312 Corrects: 6503\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.2308117300271988\n",
            "Train step - Step 0, Loss 0.20158514380455017\n",
            "Train step - Step 0, Loss 0.16860812902450562\n",
            "Train step - Step 0, Loss 0.20484913885593414\n",
            "Train step - Step 0, Loss 0.18978117406368256\n",
            "Train step - Step 0, Loss 0.18005861341953278\n",
            "Train step - Step 0, Loss 0.19347156584262848\n",
            "Train step - Step 0, Loss 0.16808420419692993\n",
            "Train step - Step 0, Loss 0.19538766145706177\n",
            "Train step - Step 0, Loss 0.2127605527639389\n",
            "Train step - Step 0, Loss 0.1994067281484604\n",
            "Train step - Step 0, Loss 0.17267274856567383\n",
            "Train step - Step 0, Loss 0.1739620566368103\n",
            "Train step - Step 0, Loss 0.18652300536632538\n",
            "Train step - Step 0, Loss 0.19938568770885468\n",
            "Train step - Step 0, Loss 0.1704331487417221\n",
            "Train epoch - Accuracy: 0.5404166666666667 Loss: 0.1909676069021225 Corrects: 6485\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.17752505838871002\n",
            "Train step - Step 0, Loss 0.1721934825181961\n",
            "Train step - Step 0, Loss 0.18365198373794556\n",
            "Train step - Step 0, Loss 0.1637832671403885\n",
            "Train step - Step 0, Loss 0.17004884779453278\n",
            "Train step - Step 0, Loss 0.15134471654891968\n",
            "Train step - Step 0, Loss 0.19672515988349915\n",
            "Train step - Step 0, Loss 0.16266798973083496\n",
            "Train step - Step 0, Loss 0.17475052177906036\n",
            "Train step - Step 0, Loss 0.1815725713968277\n",
            "Train step - Step 0, Loss 0.17868854105472565\n",
            "Train step - Step 0, Loss 0.16330647468566895\n",
            "Train step - Step 0, Loss 0.17279833555221558\n",
            "Train step - Step 0, Loss 0.18279138207435608\n",
            "Train step - Step 0, Loss 0.19933949410915375\n",
            "Train step - Step 0, Loss 0.17044563591480255\n",
            "Train epoch - Accuracy: 0.5473333333333333 Loss: 0.17521384632587433 Corrects: 6568\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.17007766664028168\n",
            "Train step - Step 0, Loss 0.150944322347641\n",
            "Train step - Step 0, Loss 0.15673011541366577\n",
            "Train step - Step 0, Loss 0.14505790174007416\n",
            "Train step - Step 0, Loss 0.15150921046733856\n",
            "Train step - Step 0, Loss 0.1704569011926651\n",
            "Train step - Step 0, Loss 0.18226712942123413\n",
            "Train step - Step 0, Loss 0.13976521790027618\n",
            "Train step - Step 0, Loss 0.1690874844789505\n",
            "Train step - Step 0, Loss 0.1649685502052307\n",
            "Train step - Step 0, Loss 0.15789805352687836\n",
            "Train step - Step 0, Loss 0.16167692840099335\n",
            "Train step - Step 0, Loss 0.17039400339126587\n",
            "Train step - Step 0, Loss 0.17929783463478088\n",
            "Train step - Step 0, Loss 0.1572353094816208\n",
            "Train step - Step 0, Loss 0.15602979063987732\n",
            "Train epoch - Accuracy: 0.5404166666666667 Loss: 0.1615926558971405 Corrects: 6485\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.16805341839790344\n",
            "Train step - Step 0, Loss 0.16395896673202515\n",
            "Train step - Step 0, Loss 0.16098757088184357\n",
            "Train step - Step 0, Loss 0.1641024351119995\n",
            "Train step - Step 0, Loss 0.156317338347435\n",
            "Train step - Step 0, Loss 0.1514015942811966\n",
            "Train step - Step 0, Loss 0.16472353041172028\n",
            "Train step - Step 0, Loss 0.1578623503446579\n",
            "Train step - Step 0, Loss 0.1497131735086441\n",
            "Train step - Step 0, Loss 0.16270476579666138\n",
            "Train step - Step 0, Loss 0.15091614425182343\n",
            "Train step - Step 0, Loss 0.1461065411567688\n",
            "Train step - Step 0, Loss 0.16793794929981232\n",
            "Train step - Step 0, Loss 0.14500275254249573\n",
            "Train step - Step 0, Loss 0.13069292902946472\n",
            "Train step - Step 0, Loss 0.12965001165866852\n",
            "Train epoch - Accuracy: 0.5408333333333334 Loss: 0.15497681391239165 Corrects: 6490\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.16067476570606232\n",
            "Train step - Step 0, Loss 0.14900997281074524\n",
            "Train step - Step 0, Loss 0.15497052669525146\n",
            "Train step - Step 0, Loss 0.14687451720237732\n",
            "Train step - Step 0, Loss 0.15939566493034363\n",
            "Train step - Step 0, Loss 0.15069720149040222\n",
            "Train step - Step 0, Loss 0.1428489089012146\n",
            "Train step - Step 0, Loss 0.133039191365242\n",
            "Train step - Step 0, Loss 0.1451088935136795\n",
            "Train step - Step 0, Loss 0.1468479037284851\n",
            "Train step - Step 0, Loss 0.1436433047056198\n",
            "Train step - Step 0, Loss 0.1501038819551468\n",
            "Train step - Step 0, Loss 0.14022290706634521\n",
            "Train step - Step 0, Loss 0.1366482824087143\n",
            "Train step - Step 0, Loss 0.12556922435760498\n",
            "Train step - Step 0, Loss 0.14442893862724304\n",
            "Train epoch - Accuracy: 0.5371666666666667 Loss: 0.14565908694267274 Corrects: 6446\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.1465190201997757\n",
            "Train step - Step 0, Loss 0.1508283019065857\n",
            "Train step - Step 0, Loss 0.14760860800743103\n",
            "Train step - Step 0, Loss 0.12718740105628967\n",
            "Train step - Step 0, Loss 0.15483516454696655\n",
            "Train step - Step 0, Loss 0.16305147111415863\n",
            "Train step - Step 0, Loss 0.1492268592119217\n",
            "Train step - Step 0, Loss 0.13038460910320282\n",
            "Train step - Step 0, Loss 0.14918626844882965\n",
            "Train step - Step 0, Loss 0.12914913892745972\n",
            "Train step - Step 0, Loss 0.1345442235469818\n",
            "Train step - Step 0, Loss 0.14988188445568085\n",
            "Train step - Step 0, Loss 0.13997861742973328\n",
            "Train step - Step 0, Loss 0.1469990760087967\n",
            "Train step - Step 0, Loss 0.14392270147800446\n",
            "Train step - Step 0, Loss 0.15133759379386902\n",
            "Train epoch - Accuracy: 0.5378333333333334 Loss: 0.14450491786003114 Corrects: 6454\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.16142696142196655\n",
            "Train step - Step 0, Loss 0.12537018954753876\n",
            "Train step - Step 0, Loss 0.13846798241138458\n",
            "Train step - Step 0, Loss 0.13813427090644836\n",
            "Train step - Step 0, Loss 0.14197641611099243\n",
            "Train step - Step 0, Loss 0.13995657861232758\n",
            "Train step - Step 0, Loss 0.13340625166893005\n",
            "Train step - Step 0, Loss 0.15124614536762238\n",
            "Train step - Step 0, Loss 0.14649824798107147\n",
            "Train step - Step 0, Loss 0.13245807588100433\n",
            "Train step - Step 0, Loss 0.12668581306934357\n",
            "Train step - Step 0, Loss 0.14153429865837097\n",
            "Train step - Step 0, Loss 0.13796289265155792\n",
            "Train step - Step 0, Loss 0.1469290554523468\n",
            "Train step - Step 0, Loss 0.14594843983650208\n",
            "Train step - Step 0, Loss 0.1337512731552124\n",
            "Train epoch - Accuracy: 0.5435 Loss: 0.1402621545791626 Corrects: 6522\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.13217376172542572\n",
            "Train step - Step 0, Loss 0.13236230611801147\n",
            "Train step - Step 0, Loss 0.13244600594043732\n",
            "Train step - Step 0, Loss 0.1513347178697586\n",
            "Train step - Step 0, Loss 0.13363556563854218\n",
            "Train step - Step 0, Loss 0.14016728103160858\n",
            "Train step - Step 0, Loss 0.14692173898220062\n",
            "Train step - Step 0, Loss 0.13142907619476318\n",
            "Train step - Step 0, Loss 0.13559788465499878\n",
            "Train step - Step 0, Loss 0.12075067311525345\n",
            "Train step - Step 0, Loss 0.13409383594989777\n",
            "Train step - Step 0, Loss 0.13435176014900208\n",
            "Train step - Step 0, Loss 0.13218586146831512\n",
            "Train step - Step 0, Loss 0.13557878136634827\n",
            "Train step - Step 0, Loss 0.1311127245426178\n",
            "Train step - Step 0, Loss 0.1415916532278061\n",
            "Train epoch - Accuracy: 0.5325 Loss: 0.13520875251293182 Corrects: 6390\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.14219599962234497\n",
            "Train step - Step 0, Loss 0.1308610886335373\n",
            "Train step - Step 0, Loss 0.13312335312366486\n",
            "Train step - Step 0, Loss 0.13138315081596375\n",
            "Train step - Step 0, Loss 0.1316448152065277\n",
            "Train step - Step 0, Loss 0.1332060694694519\n",
            "Train step - Step 0, Loss 0.13606637716293335\n",
            "Train step - Step 0, Loss 0.13015086948871613\n",
            "Train step - Step 0, Loss 0.131321519613266\n",
            "Train step - Step 0, Loss 0.14209938049316406\n",
            "Train step - Step 0, Loss 0.13692651689052582\n",
            "Train step - Step 0, Loss 0.11955159902572632\n",
            "Train step - Step 0, Loss 0.13774409890174866\n",
            "Train step - Step 0, Loss 0.14491425454616547\n",
            "Train step - Step 0, Loss 0.1341024935245514\n",
            "Train step - Step 0, Loss 0.12297651171684265\n",
            "Train epoch - Accuracy: 0.5385 Loss: 0.13389772200584413 Corrects: 6462\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.13637703657150269\n",
            "Train step - Step 0, Loss 0.12219070643186569\n",
            "Train step - Step 0, Loss 0.13453878462314606\n",
            "Train step - Step 0, Loss 0.1282954216003418\n",
            "Train step - Step 0, Loss 0.13421249389648438\n",
            "Train step - Step 0, Loss 0.13375534117221832\n",
            "Train step - Step 0, Loss 0.14412759244441986\n",
            "Train step - Step 0, Loss 0.133158341050148\n",
            "Train step - Step 0, Loss 0.13453331589698792\n",
            "Train step - Step 0, Loss 0.12205689400434494\n",
            "Train step - Step 0, Loss 0.1390206664800644\n",
            "Train step - Step 0, Loss 0.14944519102573395\n",
            "Train step - Step 0, Loss 0.13367733359336853\n",
            "Train step - Step 0, Loss 0.12858301401138306\n",
            "Train step - Step 0, Loss 0.13573898375034332\n",
            "Train step - Step 0, Loss 0.13638517260551453\n",
            "Train epoch - Accuracy: 0.5370833333333334 Loss: 0.13407691836357116 Corrects: 6445\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.12527620792388916\n",
            "Train step - Step 0, Loss 0.13456730544567108\n",
            "Train step - Step 0, Loss 0.1378706842660904\n",
            "Train step - Step 0, Loss 0.12748880684375763\n",
            "Train step - Step 0, Loss 0.12846258282661438\n",
            "Train step - Step 0, Loss 0.12802419066429138\n",
            "Train step - Step 0, Loss 0.12539106607437134\n",
            "Train step - Step 0, Loss 0.1179308220744133\n",
            "Train step - Step 0, Loss 0.1283135861158371\n",
            "Train step - Step 0, Loss 0.12786540389060974\n",
            "Train step - Step 0, Loss 0.13036303222179413\n",
            "Train step - Step 0, Loss 0.13339269161224365\n",
            "Train step - Step 0, Loss 0.1308135688304901\n",
            "Train step - Step 0, Loss 0.13999371230602264\n",
            "Train step - Step 0, Loss 0.13513803482055664\n",
            "Train step - Step 0, Loss 0.12921695411205292\n",
            "Train epoch - Accuracy: 0.5429166666666667 Loss: 0.1300257467031479 Corrects: 6515\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.1349867433309555\n",
            "Train step - Step 0, Loss 0.13561739027500153\n",
            "Train step - Step 0, Loss 0.1297396719455719\n",
            "Train step - Step 0, Loss 0.1345253735780716\n",
            "Train step - Step 0, Loss 0.1292978674173355\n",
            "Train step - Step 0, Loss 0.12803220748901367\n",
            "Train step - Step 0, Loss 0.13104909658432007\n",
            "Train step - Step 0, Loss 0.12010751664638519\n",
            "Train step - Step 0, Loss 0.12560783326625824\n",
            "Train step - Step 0, Loss 0.14166294038295746\n",
            "Train step - Step 0, Loss 0.12615419924259186\n",
            "Train step - Step 0, Loss 0.13006632030010223\n",
            "Train step - Step 0, Loss 0.13378280401229858\n",
            "Train step - Step 0, Loss 0.1400539129972458\n",
            "Train step - Step 0, Loss 0.11886757612228394\n",
            "Train step - Step 0, Loss 0.12127866595983505\n",
            "Train epoch - Accuracy: 0.5396666666666666 Loss: 0.13026243966817855 Corrects: 6476\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.12867029011249542\n",
            "Train step - Step 0, Loss 0.1260100156068802\n",
            "Train step - Step 0, Loss 0.13385337591171265\n",
            "Train step - Step 0, Loss 0.12686395645141602\n",
            "Train step - Step 0, Loss 0.12142081558704376\n",
            "Train step - Step 0, Loss 0.1225145235657692\n",
            "Train step - Step 0, Loss 0.13276182115077972\n",
            "Train step - Step 0, Loss 0.12435190379619598\n",
            "Train step - Step 0, Loss 0.12647445499897003\n",
            "Train step - Step 0, Loss 0.12299904227256775\n",
            "Train step - Step 0, Loss 0.12930695712566376\n",
            "Train step - Step 0, Loss 0.11820840835571289\n",
            "Train step - Step 0, Loss 0.12145964056253433\n",
            "Train step - Step 0, Loss 0.12773951888084412\n",
            "Train step - Step 0, Loss 0.12941956520080566\n",
            "Train step - Step 0, Loss 0.12842799723148346\n",
            "Train epoch - Accuracy: 0.539 Loss: 0.12622859442234038 Corrects: 6468\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.12560537457466125\n",
            "Train step - Step 0, Loss 0.11369073390960693\n",
            "Train step - Step 0, Loss 0.13451401889324188\n",
            "Train step - Step 0, Loss 0.12127707898616791\n",
            "Train step - Step 0, Loss 0.1357402801513672\n",
            "Train step - Step 0, Loss 0.12203327566385269\n",
            "Train step - Step 0, Loss 0.13566498458385468\n",
            "Train step - Step 0, Loss 0.11566056311130524\n",
            "Train step - Step 0, Loss 0.13211940228939056\n",
            "Train step - Step 0, Loss 0.12479566782712936\n",
            "Train step - Step 0, Loss 0.13805857300758362\n",
            "Train step - Step 0, Loss 0.12209443002939224\n",
            "Train step - Step 0, Loss 0.11946523934602737\n",
            "Train step - Step 0, Loss 0.12863239645957947\n",
            "Train step - Step 0, Loss 0.1345493644475937\n",
            "Train step - Step 0, Loss 0.12525342404842377\n",
            "Train epoch - Accuracy: 0.5395833333333333 Loss: 0.12685982549190522 Corrects: 6475\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.12716946005821228\n",
            "Train step - Step 0, Loss 0.12213931977748871\n",
            "Train step - Step 0, Loss 0.1469997763633728\n",
            "Train step - Step 0, Loss 0.11268080770969391\n",
            "Train step - Step 0, Loss 0.12989495694637299\n",
            "Train step - Step 0, Loss 0.13186384737491608\n",
            "Train step - Step 0, Loss 0.1359342485666275\n",
            "Train step - Step 0, Loss 0.11961711943149567\n",
            "Train step - Step 0, Loss 0.13547971844673157\n",
            "Train step - Step 0, Loss 0.11950299888849258\n",
            "Train step - Step 0, Loss 0.12913793325424194\n",
            "Train step - Step 0, Loss 0.1238173097372055\n",
            "Train step - Step 0, Loss 0.11796402186155319\n",
            "Train step - Step 0, Loss 0.12029159814119339\n",
            "Train step - Step 0, Loss 0.13023820519447327\n",
            "Train step - Step 0, Loss 0.12090646475553513\n",
            "Train epoch - Accuracy: 0.5386666666666666 Loss: 0.12661106318235396 Corrects: 6464\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.13011512160301208\n",
            "Train step - Step 0, Loss 0.13453072309494019\n",
            "Train step - Step 0, Loss 0.12027159333229065\n",
            "Train step - Step 0, Loss 0.1119634285569191\n",
            "Train step - Step 0, Loss 0.12370117008686066\n",
            "Train step - Step 0, Loss 0.12600910663604736\n",
            "Train step - Step 0, Loss 0.1190904825925827\n",
            "Train step - Step 0, Loss 0.12391392886638641\n",
            "Train step - Step 0, Loss 0.12508521974086761\n",
            "Train step - Step 0, Loss 0.12306838482618332\n",
            "Train step - Step 0, Loss 0.12273576110601425\n",
            "Train step - Step 0, Loss 0.14386337995529175\n",
            "Train step - Step 0, Loss 0.13427750766277313\n",
            "Train step - Step 0, Loss 0.1270865797996521\n",
            "Train step - Step 0, Loss 0.11896765977144241\n",
            "Train step - Step 0, Loss 0.1162601113319397\n",
            "Train epoch - Accuracy: 0.5443333333333333 Loss: 0.12526992750167848 Corrects: 6532\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.1202966719865799\n",
            "Train step - Step 0, Loss 0.1308409720659256\n",
            "Train step - Step 0, Loss 0.1271105408668518\n",
            "Train step - Step 0, Loss 0.12236491590738297\n",
            "Train step - Step 0, Loss 0.11909274011850357\n",
            "Train step - Step 0, Loss 0.12037133425474167\n",
            "Train step - Step 0, Loss 0.11822621524333954\n",
            "Train step - Step 0, Loss 0.13237865269184113\n",
            "Train step - Step 0, Loss 0.11592449247837067\n",
            "Train step - Step 0, Loss 0.1384212225675583\n",
            "Train step - Step 0, Loss 0.12139586359262466\n",
            "Train step - Step 0, Loss 0.13042233884334564\n",
            "Train step - Step 0, Loss 0.12140131741762161\n",
            "Train step - Step 0, Loss 0.11523137241601944\n",
            "Train step - Step 0, Loss 0.12193412333726883\n",
            "Train step - Step 0, Loss 0.11752740293741226\n",
            "Train epoch - Accuracy: 0.5381666666666667 Loss: 0.12344751363992691 Corrects: 6458\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.12061634659767151\n",
            "Train step - Step 0, Loss 0.12027877569198608\n",
            "Train step - Step 0, Loss 0.13909482955932617\n",
            "Train step - Step 0, Loss 0.11956995725631714\n",
            "Train step - Step 0, Loss 0.12190456688404083\n",
            "Train step - Step 0, Loss 0.12917540967464447\n",
            "Train step - Step 0, Loss 0.1181342601776123\n",
            "Train step - Step 0, Loss 0.1288854330778122\n",
            "Train step - Step 0, Loss 0.13296093046665192\n",
            "Train step - Step 0, Loss 0.11442692577838898\n",
            "Train step - Step 0, Loss 0.11898855119943619\n",
            "Train step - Step 0, Loss 0.1383928656578064\n",
            "Train step - Step 0, Loss 0.11652389168739319\n",
            "Train step - Step 0, Loss 0.12170207500457764\n",
            "Train step - Step 0, Loss 0.11703382432460785\n",
            "Train step - Step 0, Loss 0.1143604964017868\n",
            "Train epoch - Accuracy: 0.5371666666666667 Loss: 0.12346649301052094 Corrects: 6446\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.11994178593158722\n",
            "Train step - Step 0, Loss 0.11906372010707855\n",
            "Train step - Step 0, Loss 0.11311279237270355\n",
            "Train step - Step 0, Loss 0.11349380016326904\n",
            "Train step - Step 0, Loss 0.12130776792764664\n",
            "Train step - Step 0, Loss 0.12135415524244308\n",
            "Train step - Step 0, Loss 0.11289872229099274\n",
            "Train step - Step 0, Loss 0.13242195546627045\n",
            "Train step - Step 0, Loss 0.12974949181079865\n",
            "Train step - Step 0, Loss 0.11728616058826447\n",
            "Train step - Step 0, Loss 0.12796300649642944\n",
            "Train step - Step 0, Loss 0.12176862359046936\n",
            "Train step - Step 0, Loss 0.12497685849666595\n",
            "Train step - Step 0, Loss 0.1276959776878357\n",
            "Train step - Step 0, Loss 0.1260865181684494\n",
            "Train step - Step 0, Loss 0.12440965324640274\n",
            "Train epoch - Accuracy: 0.5390833333333334 Loss: 0.12204015165567399 Corrects: 6469\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.1277269572019577\n",
            "Train step - Step 0, Loss 0.12089160084724426\n",
            "Train step - Step 0, Loss 0.12451471388339996\n",
            "Train step - Step 0, Loss 0.12238215655088425\n",
            "Train step - Step 0, Loss 0.11418870836496353\n",
            "Train step - Step 0, Loss 0.11418703943490982\n",
            "Train step - Step 0, Loss 0.1296263188123703\n",
            "Train step - Step 0, Loss 0.12899412214756012\n",
            "Train step - Step 0, Loss 0.12885920703411102\n",
            "Train step - Step 0, Loss 0.1178923174738884\n",
            "Train step - Step 0, Loss 0.12122104316949844\n",
            "Train step - Step 0, Loss 0.12334921956062317\n",
            "Train step - Step 0, Loss 0.1158747673034668\n",
            "Train step - Step 0, Loss 0.11230316758155823\n",
            "Train step - Step 0, Loss 0.11854046583175659\n",
            "Train step - Step 0, Loss 0.1145426481962204\n",
            "Train epoch - Accuracy: 0.5406666666666666 Loss: 0.12109702146053314 Corrects: 6488\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.1212601438164711\n",
            "Train step - Step 0, Loss 0.1243906244635582\n",
            "Train step - Step 0, Loss 0.1181001290678978\n",
            "Train step - Step 0, Loss 0.1202317550778389\n",
            "Train step - Step 0, Loss 0.11763418465852737\n",
            "Train step - Step 0, Loss 0.12231432646512985\n",
            "Train step - Step 0, Loss 0.11489717662334442\n",
            "Train step - Step 0, Loss 0.1161605715751648\n",
            "Train step - Step 0, Loss 0.11432036012411118\n",
            "Train step - Step 0, Loss 0.1223212331533432\n",
            "Train step - Step 0, Loss 0.12696631252765656\n",
            "Train step - Step 0, Loss 0.12322874367237091\n",
            "Train step - Step 0, Loss 0.12726271152496338\n",
            "Train step - Step 0, Loss 0.12402746826410294\n",
            "Train step - Step 0, Loss 0.12652011215686798\n",
            "Train step - Step 0, Loss 0.13349629938602448\n",
            "Train epoch - Accuracy: 0.542 Loss: 0.12179654657840729 Corrects: 6504\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.12203048914670944\n",
            "Train step - Step 0, Loss 0.13805250823497772\n",
            "Train step - Step 0, Loss 0.11651384830474854\n",
            "Train step - Step 0, Loss 0.12962384521961212\n",
            "Train step - Step 0, Loss 0.12816457450389862\n",
            "Train step - Step 0, Loss 0.11969597637653351\n",
            "Train step - Step 0, Loss 0.11843739449977875\n",
            "Train step - Step 0, Loss 0.1261790543794632\n",
            "Train step - Step 0, Loss 0.11759664863348007\n",
            "Train step - Step 0, Loss 0.11376804858446121\n",
            "Train step - Step 0, Loss 0.10867727547883987\n",
            "Train step - Step 0, Loss 0.11908873915672302\n",
            "Train step - Step 0, Loss 0.12432067096233368\n",
            "Train step - Step 0, Loss 0.1101074293255806\n",
            "Train step - Step 0, Loss 0.1324450671672821\n",
            "Train step - Step 0, Loss 0.12485621124505997\n",
            "Train epoch - Accuracy: 0.5410833333333334 Loss: 0.12177514892816543 Corrects: 6493\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.11975795775651932\n",
            "Train step - Step 0, Loss 0.11841166019439697\n",
            "Train step - Step 0, Loss 0.12901948392391205\n",
            "Train step - Step 0, Loss 0.12453465163707733\n",
            "Train step - Step 0, Loss 0.1180647760629654\n",
            "Train step - Step 0, Loss 0.11512650549411774\n",
            "Train step - Step 0, Loss 0.12448310106992722\n",
            "Train step - Step 0, Loss 0.12872187793254852\n",
            "Train step - Step 0, Loss 0.1259579211473465\n",
            "Train step - Step 0, Loss 0.11828747391700745\n",
            "Train step - Step 0, Loss 0.11279664933681488\n",
            "Train step - Step 0, Loss 0.12783753871917725\n",
            "Train step - Step 0, Loss 0.11393878608942032\n",
            "Train step - Step 0, Loss 0.11444415152072906\n",
            "Train step - Step 0, Loss 0.12417196482419968\n",
            "Train step - Step 0, Loss 0.11380638182163239\n",
            "Train epoch - Accuracy: 0.53625 Loss: 0.12074774324893951 Corrects: 6435\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.12757503986358643\n",
            "Train step - Step 0, Loss 0.12160850316286087\n",
            "Train step - Step 0, Loss 0.1395852118730545\n",
            "Train step - Step 0, Loss 0.12185381352901459\n",
            "Train step - Step 0, Loss 0.11201933771371841\n",
            "Train step - Step 0, Loss 0.11610665917396545\n",
            "Train step - Step 0, Loss 0.11441212147474289\n",
            "Train step - Step 0, Loss 0.11859921365976334\n",
            "Train step - Step 0, Loss 0.13149401545524597\n",
            "Train step - Step 0, Loss 0.11377516388893127\n",
            "Train step - Step 0, Loss 0.1231941431760788\n",
            "Train step - Step 0, Loss 0.1165088564157486\n",
            "Train step - Step 0, Loss 0.11886081844568253\n",
            "Train step - Step 0, Loss 0.11453772336244583\n",
            "Train step - Step 0, Loss 0.10867258906364441\n",
            "Train step - Step 0, Loss 0.1270366758108139\n",
            "Train epoch - Accuracy: 0.5459166666666667 Loss: 0.12020487248897553 Corrects: 6551\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.10035889595746994\n",
            "Train step - Step 0, Loss 0.11548321694135666\n",
            "Train step - Step 0, Loss 0.12339546531438828\n",
            "Train step - Step 0, Loss 0.12583039700984955\n",
            "Train step - Step 0, Loss 0.12468700110912323\n",
            "Train step - Step 0, Loss 0.12334690988063812\n",
            "Train step - Step 0, Loss 0.1191449910402298\n",
            "Train step - Step 0, Loss 0.11977770924568176\n",
            "Train step - Step 0, Loss 0.11946111172437668\n",
            "Train step - Step 0, Loss 0.12650267779827118\n",
            "Train step - Step 0, Loss 0.11668110638856888\n",
            "Train step - Step 0, Loss 0.11983169615268707\n",
            "Train step - Step 0, Loss 0.11664893478155136\n",
            "Train step - Step 0, Loss 0.12458401173353195\n",
            "Train step - Step 0, Loss 0.13461355865001678\n",
            "Train step - Step 0, Loss 0.11594546586275101\n",
            "Train epoch - Accuracy: 0.5416666666666666 Loss: 0.12050007039308548 Corrects: 6500\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.12965576350688934\n",
            "Train step - Step 0, Loss 0.10990677028894424\n",
            "Train step - Step 0, Loss 0.12667405605316162\n",
            "Train step - Step 0, Loss 0.11182669550180435\n",
            "Train step - Step 0, Loss 0.11883364617824554\n",
            "Train step - Step 0, Loss 0.12450118362903595\n",
            "Train step - Step 0, Loss 0.11558210849761963\n",
            "Train step - Step 0, Loss 0.12731066346168518\n",
            "Train step - Step 0, Loss 0.122409887611866\n",
            "Train step - Step 0, Loss 0.12238499522209167\n",
            "Train step - Step 0, Loss 0.11502864211797714\n",
            "Train step - Step 0, Loss 0.11950176954269409\n",
            "Train step - Step 0, Loss 0.11995729804039001\n",
            "Train step - Step 0, Loss 0.11036881059408188\n",
            "Train step - Step 0, Loss 0.1179240271449089\n",
            "Train step - Step 0, Loss 0.11629491299390793\n",
            "Train epoch - Accuracy: 0.5495 Loss: 0.11933124083280564 Corrects: 6594\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.11931756883859634\n",
            "Train step - Step 0, Loss 0.11793834716081619\n",
            "Train step - Step 0, Loss 0.11581437289714813\n",
            "Train step - Step 0, Loss 0.11569367349147797\n",
            "Train step - Step 0, Loss 0.11309807002544403\n",
            "Train step - Step 0, Loss 0.13380667567253113\n",
            "Train step - Step 0, Loss 0.12044312804937363\n",
            "Train step - Step 0, Loss 0.12072530388832092\n",
            "Train step - Step 0, Loss 0.11508278548717499\n",
            "Train step - Step 0, Loss 0.11236825585365295\n",
            "Train step - Step 0, Loss 0.13786867260932922\n",
            "Train step - Step 0, Loss 0.11637867987155914\n",
            "Train step - Step 0, Loss 0.10713785141706467\n",
            "Train step - Step 0, Loss 0.11382056027650833\n",
            "Train step - Step 0, Loss 0.11489366739988327\n",
            "Train step - Step 0, Loss 0.12083427608013153\n",
            "Train epoch - Accuracy: 0.5414166666666667 Loss: 0.11839417827129364 Corrects: 6497\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.12428448349237442\n",
            "Train step - Step 0, Loss 0.10872367024421692\n",
            "Train step - Step 0, Loss 0.11784543097019196\n",
            "Train step - Step 0, Loss 0.11473455280065536\n",
            "Train step - Step 0, Loss 0.11067122220993042\n",
            "Train step - Step 0, Loss 0.10843294113874435\n",
            "Train step - Step 0, Loss 0.11609852313995361\n",
            "Train step - Step 0, Loss 0.13134151697158813\n",
            "Train step - Step 0, Loss 0.11665652692317963\n",
            "Train step - Step 0, Loss 0.11458919197320938\n",
            "Train step - Step 0, Loss 0.12571027874946594\n",
            "Train step - Step 0, Loss 0.11661387979984283\n",
            "Train step - Step 0, Loss 0.12253105640411377\n",
            "Train step - Step 0, Loss 0.12130799889564514\n",
            "Train step - Step 0, Loss 0.10649507492780685\n",
            "Train step - Step 0, Loss 0.11531364917755127\n",
            "Train epoch - Accuracy: 0.5449166666666667 Loss: 0.11699887228012085 Corrects: 6539\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.1146164983510971\n",
            "Train step - Step 0, Loss 0.1145186796784401\n",
            "Train step - Step 0, Loss 0.12003806978464127\n",
            "Train step - Step 0, Loss 0.12795668840408325\n",
            "Train step - Step 0, Loss 0.1242704764008522\n",
            "Train step - Step 0, Loss 0.11359609663486481\n",
            "Train step - Step 0, Loss 0.12322496622800827\n",
            "Train step - Step 0, Loss 0.12481175363063812\n",
            "Train step - Step 0, Loss 0.1106860414147377\n",
            "Train step - Step 0, Loss 0.12038367986679077\n",
            "Train step - Step 0, Loss 0.12448039650917053\n",
            "Train step - Step 0, Loss 0.11536426842212677\n",
            "Train step - Step 0, Loss 0.1141820028424263\n",
            "Train step - Step 0, Loss 0.12048622965812683\n",
            "Train step - Step 0, Loss 0.11151555180549622\n",
            "Train step - Step 0, Loss 0.11375574767589569\n",
            "Train epoch - Accuracy: 0.5403333333333333 Loss: 0.11847863948345184 Corrects: 6484\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.1193413957953453\n",
            "Train step - Step 0, Loss 0.1109127476811409\n",
            "Train step - Step 0, Loss 0.11028032749891281\n",
            "Train step - Step 0, Loss 0.12260913103818893\n",
            "Train step - Step 0, Loss 0.12483850866556168\n",
            "Train step - Step 0, Loss 0.12952660024166107\n",
            "Train step - Step 0, Loss 0.10894519090652466\n",
            "Train step - Step 0, Loss 0.11956066638231277\n",
            "Train step - Step 0, Loss 0.12224125862121582\n",
            "Train step - Step 0, Loss 0.12004771828651428\n",
            "Train step - Step 0, Loss 0.1220945417881012\n",
            "Train step - Step 0, Loss 0.12042655795812607\n",
            "Train step - Step 0, Loss 0.11694256961345673\n",
            "Train step - Step 0, Loss 0.11551476269960403\n",
            "Train step - Step 0, Loss 0.1287778615951538\n",
            "Train step - Step 0, Loss 0.11604328453540802\n",
            "Train epoch - Accuracy: 0.5411666666666667 Loss: 0.1193335610628128 Corrects: 6494\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.12375355511903763\n",
            "Train step - Step 0, Loss 0.12207107990980148\n",
            "Train step - Step 0, Loss 0.10780886560678482\n",
            "Train step - Step 0, Loss 0.1128392443060875\n",
            "Train step - Step 0, Loss 0.12631535530090332\n",
            "Train step - Step 0, Loss 0.12156794220209122\n",
            "Train step - Step 0, Loss 0.1226930320262909\n",
            "Train step - Step 0, Loss 0.11183460801839828\n",
            "Train step - Step 0, Loss 0.11097056418657303\n",
            "Train step - Step 0, Loss 0.11229277402162552\n",
            "Train step - Step 0, Loss 0.11276578158140182\n",
            "Train step - Step 0, Loss 0.11927919834852219\n",
            "Train step - Step 0, Loss 0.1266936957836151\n",
            "Train step - Step 0, Loss 0.1049288660287857\n",
            "Train step - Step 0, Loss 0.12481410056352615\n",
            "Train step - Step 0, Loss 0.12140551209449768\n",
            "Train epoch - Accuracy: 0.53475 Loss: 0.11753645491600037 Corrects: 6417\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.12654809653759003\n",
            "Train step - Step 0, Loss 0.12389371544122696\n",
            "Train step - Step 0, Loss 0.11505833268165588\n",
            "Train step - Step 0, Loss 0.12040822207927704\n",
            "Train step - Step 0, Loss 0.1114555075764656\n",
            "Train step - Step 0, Loss 0.10497850179672241\n",
            "Train step - Step 0, Loss 0.11318252235651016\n",
            "Train step - Step 0, Loss 0.11638829857110977\n",
            "Train step - Step 0, Loss 0.12573735415935516\n",
            "Train step - Step 0, Loss 0.1259218454360962\n",
            "Train step - Step 0, Loss 0.10655585676431656\n",
            "Train step - Step 0, Loss 0.12141826748847961\n",
            "Train step - Step 0, Loss 0.12601089477539062\n",
            "Train step - Step 0, Loss 0.11608771234750748\n",
            "Train step - Step 0, Loss 0.1237986832857132\n",
            "Train step - Step 0, Loss 0.10679593682289124\n",
            "Train epoch - Accuracy: 0.5395833333333333 Loss: 0.11802824139595032 Corrects: 6475\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.11081562936306\n",
            "Train step - Step 0, Loss 0.11705763638019562\n",
            "Train step - Step 0, Loss 0.10748277604579926\n",
            "Train step - Step 0, Loss 0.11141999810934067\n",
            "Train step - Step 0, Loss 0.12568078935146332\n",
            "Train step - Step 0, Loss 0.11312397569417953\n",
            "Train step - Step 0, Loss 0.11310746520757675\n",
            "Train step - Step 0, Loss 0.11207866668701172\n",
            "Train step - Step 0, Loss 0.12891314923763275\n",
            "Train step - Step 0, Loss 0.11946074664592743\n",
            "Train step - Step 0, Loss 0.11210926622152328\n",
            "Train step - Step 0, Loss 0.11340480297803879\n",
            "Train step - Step 0, Loss 0.11345887184143066\n",
            "Train step - Step 0, Loss 0.11952459812164307\n",
            "Train step - Step 0, Loss 0.12735360860824585\n",
            "Train step - Step 0, Loss 0.11741989105939865\n",
            "Train epoch - Accuracy: 0.5483333333333333 Loss: 0.11637628239393234 Corrects: 6580\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.11325161904096603\n",
            "Train step - Step 0, Loss 0.11332347989082336\n",
            "Train step - Step 0, Loss 0.11456640064716339\n",
            "Train step - Step 0, Loss 0.11216767132282257\n",
            "Train step - Step 0, Loss 0.11753612011671066\n",
            "Train step - Step 0, Loss 0.10264934599399567\n",
            "Train step - Step 0, Loss 0.11676620692014694\n",
            "Train step - Step 0, Loss 0.11587156355381012\n",
            "Train step - Step 0, Loss 0.11388088762760162\n",
            "Train step - Step 0, Loss 0.11202777922153473\n",
            "Train step - Step 0, Loss 0.11915957927703857\n",
            "Train step - Step 0, Loss 0.13806508481502533\n",
            "Train step - Step 0, Loss 0.12771974503993988\n",
            "Train step - Step 0, Loss 0.1221177950501442\n",
            "Train step - Step 0, Loss 0.11283785849809647\n",
            "Train step - Step 0, Loss 0.12262798845767975\n",
            "Train epoch - Accuracy: 0.5416666666666666 Loss: 0.11702935230731965 Corrects: 6500\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.11988400667905807\n",
            "Train step - Step 0, Loss 0.11206072568893433\n",
            "Train step - Step 0, Loss 0.11186618357896805\n",
            "Train step - Step 0, Loss 0.1178085207939148\n",
            "Train step - Step 0, Loss 0.12339743971824646\n",
            "Train step - Step 0, Loss 0.11939842998981476\n",
            "Train step - Step 0, Loss 0.12155578285455704\n",
            "Train step - Step 0, Loss 0.12370803207159042\n",
            "Train step - Step 0, Loss 0.11265614628791809\n",
            "Train step - Step 0, Loss 0.12069541960954666\n",
            "Train step - Step 0, Loss 0.11433973908424377\n",
            "Train step - Step 0, Loss 0.11165555566549301\n",
            "Train step - Step 0, Loss 0.11968345940113068\n",
            "Train step - Step 0, Loss 0.11130088567733765\n",
            "Train step - Step 0, Loss 0.12058227509260178\n",
            "Train step - Step 0, Loss 0.11907031387090683\n",
            "Train epoch - Accuracy: 0.5431666666666667 Loss: 0.11744073909521104 Corrects: 6518\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.11465316265821457\n",
            "Train step - Step 0, Loss 0.11688798666000366\n",
            "Train step - Step 0, Loss 0.1244034543633461\n",
            "Train step - Step 0, Loss 0.10645487159490585\n",
            "Train step - Step 0, Loss 0.11506035178899765\n",
            "Train step - Step 0, Loss 0.11896124482154846\n",
            "Train step - Step 0, Loss 0.10889605432748795\n",
            "Train step - Step 0, Loss 0.11465965956449509\n",
            "Train step - Step 0, Loss 0.10957454144954681\n",
            "Train step - Step 0, Loss 0.1163654699921608\n",
            "Train step - Step 0, Loss 0.11133288592100143\n",
            "Train step - Step 0, Loss 0.12840436398983002\n",
            "Train step - Step 0, Loss 0.11974573880434036\n",
            "Train step - Step 0, Loss 0.11680110543966293\n",
            "Train step - Step 0, Loss 0.12032730877399445\n",
            "Train step - Step 0, Loss 0.11279366165399551\n",
            "Train epoch - Accuracy: 0.5463333333333333 Loss: 0.11603355127573013 Corrects: 6556\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.1209661066532135\n",
            "Train step - Step 0, Loss 0.12230207771062851\n",
            "Train step - Step 0, Loss 0.11564063280820847\n",
            "Train step - Step 0, Loss 0.12158189713954926\n",
            "Train step - Step 0, Loss 0.10223636031150818\n",
            "Train step - Step 0, Loss 0.11367564648389816\n",
            "Train step - Step 0, Loss 0.11034582555294037\n",
            "Train step - Step 0, Loss 0.11514700949192047\n",
            "Train step - Step 0, Loss 0.12266705185174942\n",
            "Train step - Step 0, Loss 0.10014097392559052\n",
            "Train step - Step 0, Loss 0.11432080715894699\n",
            "Train step - Step 0, Loss 0.10712672024965286\n",
            "Train step - Step 0, Loss 0.1241864338517189\n",
            "Train step - Step 0, Loss 0.10831256210803986\n",
            "Train step - Step 0, Loss 0.11279422789812088\n",
            "Train step - Step 0, Loss 0.12721307575702667\n",
            "Train epoch - Accuracy: 0.5485 Loss: 0.114620960354805 Corrects: 6582\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.11793439835309982\n",
            "Train step - Step 0, Loss 0.11473037302494049\n",
            "Train step - Step 0, Loss 0.11277443170547485\n",
            "Train step - Step 0, Loss 0.11142850667238235\n",
            "Train step - Step 0, Loss 0.12626656889915466\n",
            "Train step - Step 0, Loss 0.11500144004821777\n",
            "Train step - Step 0, Loss 0.10745448619127274\n",
            "Train step - Step 0, Loss 0.10756634920835495\n",
            "Train step - Step 0, Loss 0.11994440108537674\n",
            "Train step - Step 0, Loss 0.10920237004756927\n",
            "Train step - Step 0, Loss 0.12383882701396942\n",
            "Train step - Step 0, Loss 0.11791489273309708\n",
            "Train step - Step 0, Loss 0.11142225563526154\n",
            "Train step - Step 0, Loss 0.11870291084051132\n",
            "Train step - Step 0, Loss 0.11046279966831207\n",
            "Train step - Step 0, Loss 0.11140167713165283\n",
            "Train epoch - Accuracy: 0.5455833333333333 Loss: 0.11483334779739379 Corrects: 6547\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.1223493367433548\n",
            "Train step - Step 0, Loss 0.12493348866701126\n",
            "Train step - Step 0, Loss 0.1227843314409256\n",
            "Train step - Step 0, Loss 0.11480610072612762\n",
            "Train step - Step 0, Loss 0.11492222547531128\n",
            "Train step - Step 0, Loss 0.10665349662303925\n",
            "Train step - Step 0, Loss 0.1256428062915802\n",
            "Train step - Step 0, Loss 0.11449259519577026\n",
            "Train step - Step 0, Loss 0.12657004594802856\n",
            "Train step - Step 0, Loss 0.11497490108013153\n",
            "Train step - Step 0, Loss 0.10681731253862381\n",
            "Train step - Step 0, Loss 0.11745089292526245\n",
            "Train step - Step 0, Loss 0.11114468425512314\n",
            "Train step - Step 0, Loss 0.1100480780005455\n",
            "Train step - Step 0, Loss 0.10982102155685425\n",
            "Train step - Step 0, Loss 0.12171394377946854\n",
            "Train epoch - Accuracy: 0.5471666666666667 Loss: 0.11644688206911087 Corrects: 6566\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.11565274745225906\n",
            "Train step - Step 0, Loss 0.10585910826921463\n",
            "Train step - Step 0, Loss 0.12604978680610657\n",
            "Train step - Step 0, Loss 0.1132017970085144\n",
            "Train step - Step 0, Loss 0.11313343048095703\n",
            "Train step - Step 0, Loss 0.11679734289646149\n",
            "Train step - Step 0, Loss 0.11401204019784927\n",
            "Train step - Step 0, Loss 0.10480561852455139\n",
            "Train step - Step 0, Loss 0.11728968471288681\n",
            "Train step - Step 0, Loss 0.1066715270280838\n",
            "Train step - Step 0, Loss 0.11571234464645386\n",
            "Train step - Step 0, Loss 0.11148682236671448\n",
            "Train step - Step 0, Loss 0.11712809652090073\n",
            "Train step - Step 0, Loss 0.11843101680278778\n",
            "Train step - Step 0, Loss 0.11269979923963547\n",
            "Train step - Step 0, Loss 0.1149558424949646\n",
            "Train epoch - Accuracy: 0.54575 Loss: 0.1139698281288147 Corrects: 6549\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.1225859671831131\n",
            "Train step - Step 0, Loss 0.11827642470598221\n",
            "Train step - Step 0, Loss 0.10859144479036331\n",
            "Train step - Step 0, Loss 0.11616913974285126\n",
            "Train step - Step 0, Loss 0.11618613451719284\n",
            "Train step - Step 0, Loss 0.11671403795480728\n",
            "Train step - Step 0, Loss 0.11810560524463654\n",
            "Train step - Step 0, Loss 0.11385446041822433\n",
            "Train step - Step 0, Loss 0.11439903825521469\n",
            "Train step - Step 0, Loss 0.11925888806581497\n",
            "Train step - Step 0, Loss 0.12352600693702698\n",
            "Train step - Step 0, Loss 0.12149876356124878\n",
            "Train step - Step 0, Loss 0.1099540963768959\n",
            "Train step - Step 0, Loss 0.11332782357931137\n",
            "Train step - Step 0, Loss 0.11098174005746841\n",
            "Train step - Step 0, Loss 0.11368416249752045\n",
            "Train epoch - Accuracy: 0.5435833333333333 Loss: 0.11612685906887055 Corrects: 6523\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.12093006074428558\n",
            "Train step - Step 0, Loss 0.09899479150772095\n",
            "Train step - Step 0, Loss 0.11063086986541748\n",
            "Train step - Step 0, Loss 0.10684879124164581\n",
            "Train step - Step 0, Loss 0.11185874044895172\n",
            "Train step - Step 0, Loss 0.11036625504493713\n",
            "Train step - Step 0, Loss 0.12293538451194763\n",
            "Train step - Step 0, Loss 0.1183895543217659\n",
            "Train step - Step 0, Loss 0.12815406918525696\n",
            "Train step - Step 0, Loss 0.11834830045700073\n",
            "Train step - Step 0, Loss 0.1137128472328186\n",
            "Train step - Step 0, Loss 0.11389292031526566\n",
            "Train step - Step 0, Loss 0.10678299516439438\n",
            "Train step - Step 0, Loss 0.11830764263868332\n",
            "Train step - Step 0, Loss 0.11126717180013657\n",
            "Train step - Step 0, Loss 0.10004047304391861\n",
            "Train epoch - Accuracy: 0.5466666666666666 Loss: 0.11353252416849137 Corrects: 6560\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.12135078758001328\n",
            "Train step - Step 0, Loss 0.11556115746498108\n",
            "Train step - Step 0, Loss 0.11412308365106583\n",
            "Train step - Step 0, Loss 0.11969070881605148\n",
            "Train step - Step 0, Loss 0.11174577474594116\n",
            "Train step - Step 0, Loss 0.10608309507369995\n",
            "Train step - Step 0, Loss 0.1123933345079422\n",
            "Train step - Step 0, Loss 0.11138338595628738\n",
            "Train step - Step 0, Loss 0.11639373004436493\n",
            "Train step - Step 0, Loss 0.11807724088430405\n",
            "Train step - Step 0, Loss 0.1095878854393959\n",
            "Train step - Step 0, Loss 0.11967695504426956\n",
            "Train step - Step 0, Loss 0.12190304696559906\n",
            "Train step - Step 0, Loss 0.11531355232000351\n",
            "Train step - Step 0, Loss 0.10473210364580154\n",
            "Train step - Step 0, Loss 0.113551564514637\n",
            "Train epoch - Accuracy: 0.5420833333333334 Loss: 0.11449507647752762 Corrects: 6505\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.1260789930820465\n",
            "Train step - Step 0, Loss 0.10913531482219696\n",
            "Train step - Step 0, Loss 0.11659853905439377\n",
            "Train step - Step 0, Loss 0.1062353253364563\n",
            "Train step - Step 0, Loss 0.12671828269958496\n",
            "Train step - Step 0, Loss 0.10890694707632065\n",
            "Train step - Step 0, Loss 0.1205727607011795\n",
            "Train step - Step 0, Loss 0.11970306187868118\n",
            "Train step - Step 0, Loss 0.10642699152231216\n",
            "Train step - Step 0, Loss 0.1154668852686882\n",
            "Train step - Step 0, Loss 0.10710234940052032\n",
            "Train step - Step 0, Loss 0.11825957894325256\n",
            "Train step - Step 0, Loss 0.11641231179237366\n",
            "Train step - Step 0, Loss 0.10688414424657822\n",
            "Train step - Step 0, Loss 0.11320260912179947\n",
            "Train step - Step 0, Loss 0.11140388995409012\n",
            "Train epoch - Accuracy: 0.542 Loss: 0.1143892176747322 Corrects: 6504\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.11426013708114624\n",
            "Train step - Step 0, Loss 0.10802579671144485\n",
            "Train step - Step 0, Loss 0.11095873266458511\n",
            "Train step - Step 0, Loss 0.11691512912511826\n",
            "Train step - Step 0, Loss 0.10976933687925339\n",
            "Train step - Step 0, Loss 0.10267946124076843\n",
            "Train step - Step 0, Loss 0.10507412254810333\n",
            "Train step - Step 0, Loss 0.11353852599859238\n",
            "Train step - Step 0, Loss 0.10732369869947433\n",
            "Train step - Step 0, Loss 0.1261172741651535\n",
            "Train step - Step 0, Loss 0.11934471130371094\n",
            "Train step - Step 0, Loss 0.1225082129240036\n",
            "Train step - Step 0, Loss 0.11352355033159256\n",
            "Train step - Step 0, Loss 0.11210004985332489\n",
            "Train step - Step 0, Loss 0.1124168410897255\n",
            "Train step - Step 0, Loss 0.11404814571142197\n",
            "Train epoch - Accuracy: 0.552 Loss: 0.1130134829878807 Corrects: 6624\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.10744155943393707\n",
            "Train step - Step 0, Loss 0.11918001621961594\n",
            "Train step - Step 0, Loss 0.12562747299671173\n",
            "Train step - Step 0, Loss 0.11516988277435303\n",
            "Train step - Step 0, Loss 0.1253983974456787\n",
            "Train step - Step 0, Loss 0.10820263624191284\n",
            "Train step - Step 0, Loss 0.1192643791437149\n",
            "Train step - Step 0, Loss 0.10908271372318268\n",
            "Train step - Step 0, Loss 0.10571755468845367\n",
            "Train step - Step 0, Loss 0.11666253954172134\n",
            "Train step - Step 0, Loss 0.11215893924236298\n",
            "Train step - Step 0, Loss 0.12752583622932434\n",
            "Train step - Step 0, Loss 0.11356671899557114\n",
            "Train step - Step 0, Loss 0.11055241525173187\n",
            "Train step - Step 0, Loss 0.11258311569690704\n",
            "Train step - Step 0, Loss 0.11187688261270523\n",
            "Train epoch - Accuracy: 0.5531666666666667 Loss: 0.11507566267251969 Corrects: 6638\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.11732888966798782\n",
            "Train step - Step 0, Loss 0.1150657907128334\n",
            "Train step - Step 0, Loss 0.10057833045721054\n",
            "Train step - Step 0, Loss 0.11043103784322739\n",
            "Train step - Step 0, Loss 0.11899477988481522\n",
            "Train step - Step 0, Loss 0.11331568658351898\n",
            "Train step - Step 0, Loss 0.12033717334270477\n",
            "Train step - Step 0, Loss 0.10345155745744705\n",
            "Train step - Step 0, Loss 0.10505395382642746\n",
            "Train step - Step 0, Loss 0.11193443834781647\n",
            "Train step - Step 0, Loss 0.113414466381073\n",
            "Train step - Step 0, Loss 0.1067403107881546\n",
            "Train step - Step 0, Loss 0.10807035863399506\n",
            "Train step - Step 0, Loss 0.11983661353588104\n",
            "Train step - Step 0, Loss 0.11932472139596939\n",
            "Train step - Step 0, Loss 0.12420970946550369\n",
            "Train epoch - Accuracy: 0.554 Loss: 0.11273658734560013 Corrects: 6648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.68 0.13402265310287476\n",
            "TEST GROUP:  0.668\n",
            "TEST ALL:  0.705\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  3000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [81, 79, 4, 10, 16, 18, 20, 22, 24, 32, 34, 56, 64, 68, 76, 80, 82, 90, 7, 21, 23, 39, 47, 49, 59, 61, 65, 67, 75, 0]\n",
            "TRAIN_SET CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "VALIDATION CLASSES:  [61, 32, 90, 24, 23, 76, 75, 10, 0, 64]\n",
            "GROUP:  3\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  30\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.38324716687202454\n",
            "Train step - Step 10, Loss 0.16655233502388\n",
            "Train step - Step 20, Loss 0.1694132685661316\n",
            "Train step - Step 30, Loss 0.14863178133964539\n",
            "Train step - Step 40, Loss 0.14255289733409882\n",
            "Train step - Step 50, Loss 0.13499441742897034\n",
            "Train epoch - Accuracy: 0.28345323741007195 Loss: 0.17022445923132862 Corrects: 1970\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.13450779020786285\n",
            "Train step - Step 70, Loss 0.13380900025367737\n",
            "Train step - Step 80, Loss 0.13550600409507751\n",
            "Train step - Step 90, Loss 0.13184824585914612\n",
            "Train step - Step 100, Loss 0.13286587595939636\n",
            "Train epoch - Accuracy: 0.3530935251798561 Loss: 0.13492522705373147 Corrects: 2454\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.14303778111934662\n",
            "Train step - Step 120, Loss 0.13294589519500732\n",
            "Train step - Step 130, Loss 0.12963394820690155\n",
            "Train step - Step 140, Loss 0.14003045856952667\n",
            "Train step - Step 150, Loss 0.12749534845352173\n",
            "Train step - Step 160, Loss 0.12450975179672241\n",
            "Train epoch - Accuracy: 0.40215827338129495 Loss: 0.13013331234455108 Corrects: 2795\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.12676018476486206\n",
            "Train step - Step 180, Loss 0.12234102189540863\n",
            "Train step - Step 190, Loss 0.129355788230896\n",
            "Train step - Step 200, Loss 0.12836086750030518\n",
            "Train step - Step 210, Loss 0.11602499336004257\n",
            "Train epoch - Accuracy: 0.43381294964028777 Loss: 0.1278539524404265 Corrects: 3015\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.11999903619289398\n",
            "Train step - Step 230, Loss 0.12733310461044312\n",
            "Train step - Step 240, Loss 0.12899763882160187\n",
            "Train step - Step 250, Loss 0.1224716380238533\n",
            "Train step - Step 260, Loss 0.13316215574741364\n",
            "Train step - Step 270, Loss 0.11862068623304367\n",
            "Train epoch - Accuracy: 0.45870503597122303 Loss: 0.1255637644585088 Corrects: 3188\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.12956340610980988\n",
            "Train step - Step 290, Loss 0.12738022208213806\n",
            "Train step - Step 300, Loss 0.12846410274505615\n",
            "Train step - Step 310, Loss 0.12779481709003448\n",
            "Train step - Step 320, Loss 0.11496535688638687\n",
            "Train epoch - Accuracy: 0.47338129496402875 Loss: 0.12406915809610765 Corrects: 3290\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.1252650022506714\n",
            "Train step - Step 340, Loss 0.12214212119579315\n",
            "Train step - Step 350, Loss 0.12104091793298721\n",
            "Train step - Step 360, Loss 0.12473784387111664\n",
            "Train step - Step 370, Loss 0.12419091165065765\n",
            "Train step - Step 380, Loss 0.12893858551979065\n",
            "Train epoch - Accuracy: 0.49683453237410075 Loss: 0.12313518796464522 Corrects: 3453\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.12325761467218399\n",
            "Train step - Step 400, Loss 0.11795465648174286\n",
            "Train step - Step 410, Loss 0.1179502084851265\n",
            "Train step - Step 420, Loss 0.12781663239002228\n",
            "Train step - Step 430, Loss 0.11815094202756882\n",
            "Train epoch - Accuracy: 0.5080575539568345 Loss: 0.12166887613294794 Corrects: 3531\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.12588176131248474\n",
            "Train step - Step 450, Loss 0.1177220568060875\n",
            "Train step - Step 460, Loss 0.13006038963794708\n",
            "Train step - Step 470, Loss 0.11694139242172241\n",
            "Train step - Step 480, Loss 0.1207059696316719\n",
            "Train step - Step 490, Loss 0.12548062205314636\n",
            "Train epoch - Accuracy: 0.5325179856115108 Loss: 0.12070924515346829 Corrects: 3701\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.12138903141021729\n",
            "Train step - Step 510, Loss 0.11569266766309738\n",
            "Train step - Step 520, Loss 0.12216992676258087\n",
            "Train step - Step 530, Loss 0.1259954571723938\n",
            "Train step - Step 540, Loss 0.12818372249603271\n",
            "Train epoch - Accuracy: 0.5428776978417266 Loss: 0.11987157440657238 Corrects: 3773\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.11268270015716553\n",
            "Train step - Step 560, Loss 0.11342095583677292\n",
            "Train step - Step 570, Loss 0.11229849606752396\n",
            "Train step - Step 580, Loss 0.11428352445363998\n",
            "Train step - Step 590, Loss 0.12570896744728088\n",
            "Train step - Step 600, Loss 0.11805052310228348\n",
            "Train epoch - Accuracy: 0.5575539568345323 Loss: 0.11846316524761186 Corrects: 3875\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.11840834468603134\n",
            "Train step - Step 620, Loss 0.12042646110057831\n",
            "Train step - Step 630, Loss 0.12472610175609589\n",
            "Train step - Step 640, Loss 0.11934047192335129\n",
            "Train step - Step 650, Loss 0.11312421411275864\n",
            "Train epoch - Accuracy: 0.5707913669064748 Loss: 0.11884166781422045 Corrects: 3967\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.12141794711351395\n",
            "Train step - Step 670, Loss 0.11220324039459229\n",
            "Train step - Step 680, Loss 0.11262379586696625\n",
            "Train step - Step 690, Loss 0.11339742690324783\n",
            "Train step - Step 700, Loss 0.11990467458963394\n",
            "Train step - Step 710, Loss 0.11910267174243927\n",
            "Train epoch - Accuracy: 0.5690647482014388 Loss: 0.11774791336102451 Corrects: 3955\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.11828788369894028\n",
            "Train step - Step 730, Loss 0.11447351425886154\n",
            "Train step - Step 740, Loss 0.11143961548805237\n",
            "Train step - Step 750, Loss 0.11654426157474518\n",
            "Train step - Step 760, Loss 0.11778689920902252\n",
            "Train epoch - Accuracy: 0.580431654676259 Loss: 0.1167866430994418 Corrects: 4034\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.11234434694051743\n",
            "Train step - Step 780, Loss 0.1203087866306305\n",
            "Train step - Step 790, Loss 0.11108214408159256\n",
            "Train step - Step 800, Loss 0.12047819793224335\n",
            "Train step - Step 810, Loss 0.11651421338319778\n",
            "Train step - Step 820, Loss 0.11406409740447998\n",
            "Train epoch - Accuracy: 0.5900719424460432 Loss: 0.11634239227866097 Corrects: 4101\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.10956402122974396\n",
            "Train step - Step 840, Loss 0.12370248138904572\n",
            "Train step - Step 850, Loss 0.11142187565565109\n",
            "Train step - Step 860, Loss 0.11119963973760605\n",
            "Train step - Step 870, Loss 0.11238374561071396\n",
            "Train epoch - Accuracy: 0.600863309352518 Loss: 0.11541984294815887 Corrects: 4176\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.12441620230674744\n",
            "Train step - Step 890, Loss 0.11537349969148636\n",
            "Train step - Step 900, Loss 0.12187738716602325\n",
            "Train step - Step 910, Loss 0.1127222403883934\n",
            "Train step - Step 920, Loss 0.11301564425230026\n",
            "Train step - Step 930, Loss 0.10796594619750977\n",
            "Train epoch - Accuracy: 0.6077697841726619 Loss: 0.11546101209499852 Corrects: 4224\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.11975414305925369\n",
            "Train step - Step 950, Loss 0.11142728477716446\n",
            "Train step - Step 960, Loss 0.11611302942037582\n",
            "Train step - Step 970, Loss 0.11620455235242844\n",
            "Train step - Step 980, Loss 0.11393871903419495\n",
            "Train epoch - Accuracy: 0.616546762589928 Loss: 0.11458913725485904 Corrects: 4285\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.1151873841881752\n",
            "Train step - Step 1000, Loss 0.11061416566371918\n",
            "Train step - Step 1010, Loss 0.11603337526321411\n",
            "Train step - Step 1020, Loss 0.11562288552522659\n",
            "Train step - Step 1030, Loss 0.1101132407784462\n",
            "Train step - Step 1040, Loss 0.1143350824713707\n",
            "Train epoch - Accuracy: 0.6256115107913669 Loss: 0.11357011159118131 Corrects: 4348\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.12210863828659058\n",
            "Train step - Step 1060, Loss 0.11662346869707108\n",
            "Train step - Step 1070, Loss 0.10965602099895477\n",
            "Train step - Step 1080, Loss 0.12036556750535965\n",
            "Train step - Step 1090, Loss 0.10955817252397537\n",
            "Train epoch - Accuracy: 0.6293525179856115 Loss: 0.11329416221851925 Corrects: 4374\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10959599167108536\n",
            "Train step - Step 1110, Loss 0.11496999859809875\n",
            "Train step - Step 1120, Loss 0.10640256106853485\n",
            "Train step - Step 1130, Loss 0.11019971966743469\n",
            "Train step - Step 1140, Loss 0.11604924499988556\n",
            "Train step - Step 1150, Loss 0.11663652211427689\n",
            "Train epoch - Accuracy: 0.6306474820143885 Loss: 0.11300133368523001 Corrects: 4383\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11551743000745773\n",
            "Train step - Step 1170, Loss 0.10719206184148788\n",
            "Train step - Step 1180, Loss 0.10755189508199692\n",
            "Train step - Step 1190, Loss 0.11932254582643509\n",
            "Train step - Step 1200, Loss 0.1114882305264473\n",
            "Train epoch - Accuracy: 0.64 Loss: 0.11222561635130601 Corrects: 4448\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.1079682856798172\n",
            "Train step - Step 1220, Loss 0.11136788874864578\n",
            "Train step - Step 1230, Loss 0.1151793822646141\n",
            "Train step - Step 1240, Loss 0.11348618566989899\n",
            "Train step - Step 1250, Loss 0.10884450376033783\n",
            "Train step - Step 1260, Loss 0.1090959832072258\n",
            "Train epoch - Accuracy: 0.6398561151079136 Loss: 0.11198789124437374 Corrects: 4447\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.11507175117731094\n",
            "Train step - Step 1280, Loss 0.11044136434793472\n",
            "Train step - Step 1290, Loss 0.11430521309375763\n",
            "Train step - Step 1300, Loss 0.11137877404689789\n",
            "Train step - Step 1310, Loss 0.11391347646713257\n",
            "Train epoch - Accuracy: 0.6474820143884892 Loss: 0.11177508497195278 Corrects: 4500\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.11320953071117401\n",
            "Train step - Step 1330, Loss 0.11313249915838242\n",
            "Train step - Step 1340, Loss 0.1164611354470253\n",
            "Train step - Step 1350, Loss 0.10757860541343689\n",
            "Train step - Step 1360, Loss 0.11313685029745102\n",
            "Train step - Step 1370, Loss 0.11071215569972992\n",
            "Train epoch - Accuracy: 0.6529496402877698 Loss: 0.11156048629781325 Corrects: 4538\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.11577314138412476\n",
            "Train step - Step 1390, Loss 0.10633199661970139\n",
            "Train step - Step 1400, Loss 0.10361448675394058\n",
            "Train step - Step 1410, Loss 0.11252877861261368\n",
            "Train step - Step 1420, Loss 0.11140028387308121\n",
            "Train epoch - Accuracy: 0.6643165467625899 Loss: 0.1110255654981668 Corrects: 4617\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10570134222507477\n",
            "Train step - Step 1440, Loss 0.10516642779111862\n",
            "Train step - Step 1450, Loss 0.10991362482309341\n",
            "Train step - Step 1460, Loss 0.1143183782696724\n",
            "Train step - Step 1470, Loss 0.11285479366779327\n",
            "Train step - Step 1480, Loss 0.10772858560085297\n",
            "Train epoch - Accuracy: 0.6633093525179856 Loss: 0.1106449867538411 Corrects: 4610\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10986935347318649\n",
            "Train step - Step 1500, Loss 0.11013036221265793\n",
            "Train step - Step 1510, Loss 0.10719344019889832\n",
            "Train step - Step 1520, Loss 0.11504130810499191\n",
            "Train step - Step 1530, Loss 0.1067916676402092\n",
            "Train epoch - Accuracy: 0.6748201438848921 Loss: 0.11013193506774285 Corrects: 4690\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.11610985547304153\n",
            "Train step - Step 1550, Loss 0.11095112562179565\n",
            "Train step - Step 1560, Loss 0.11517788469791412\n",
            "Train step - Step 1570, Loss 0.09718933701515198\n",
            "Train step - Step 1580, Loss 0.10518322885036469\n",
            "Train step - Step 1590, Loss 0.10932865738868713\n",
            "Train epoch - Accuracy: 0.6732374100719425 Loss: 0.10945331677687253 Corrects: 4679\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10146982222795486\n",
            "Train step - Step 1610, Loss 0.10507726669311523\n",
            "Train step - Step 1620, Loss 0.11155758798122406\n",
            "Train step - Step 1630, Loss 0.10460841655731201\n",
            "Train step - Step 1640, Loss 0.11298738420009613\n",
            "Train epoch - Accuracy: 0.6802877697841727 Loss: 0.10906883762465965 Corrects: 4728\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.11098413914442062\n",
            "Train step - Step 1660, Loss 0.11132965981960297\n",
            "Train step - Step 1670, Loss 0.11349757760763168\n",
            "Train step - Step 1680, Loss 0.10957077890634537\n",
            "Train step - Step 1690, Loss 0.10969220101833344\n",
            "Train step - Step 1700, Loss 0.10983728617429733\n",
            "Train epoch - Accuracy: 0.683021582733813 Loss: 0.10856480518262163 Corrects: 4747\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.11299720406532288\n",
            "Train step - Step 1720, Loss 0.10600317269563675\n",
            "Train step - Step 1730, Loss 0.10747048258781433\n",
            "Train step - Step 1740, Loss 0.10668185353279114\n",
            "Train step - Step 1750, Loss 0.11152215301990509\n",
            "Train epoch - Accuracy: 0.6853237410071943 Loss: 0.1086153993182045 Corrects: 4763\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.10987480729818344\n",
            "Train step - Step 1770, Loss 0.1136472299695015\n",
            "Train step - Step 1780, Loss 0.11207246780395508\n",
            "Train step - Step 1790, Loss 0.10557850450277328\n",
            "Train step - Step 1800, Loss 0.11224737018346786\n",
            "Train step - Step 1810, Loss 0.11298762261867523\n",
            "Train epoch - Accuracy: 0.6949640287769784 Loss: 0.1078899314656532 Corrects: 4830\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.10669362545013428\n",
            "Train step - Step 1830, Loss 0.10581847280263901\n",
            "Train step - Step 1840, Loss 0.10237786173820496\n",
            "Train step - Step 1850, Loss 0.10413643717765808\n",
            "Train step - Step 1860, Loss 0.10610350221395493\n",
            "Train epoch - Accuracy: 0.6976978417266188 Loss: 0.10809375505010001 Corrects: 4849\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10816224664449692\n",
            "Train step - Step 1880, Loss 0.1046910360455513\n",
            "Train step - Step 1890, Loss 0.1053982824087143\n",
            "Train step - Step 1900, Loss 0.10766034573316574\n",
            "Train step - Step 1910, Loss 0.10328668355941772\n",
            "Train step - Step 1920, Loss 0.10466285049915314\n",
            "Train epoch - Accuracy: 0.6997122302158273 Loss: 0.10779209415260836 Corrects: 4863\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10716687887907028\n",
            "Train step - Step 1940, Loss 0.11573513597249985\n",
            "Train step - Step 1950, Loss 0.10457360744476318\n",
            "Train step - Step 1960, Loss 0.10353691130876541\n",
            "Train step - Step 1970, Loss 0.1150939092040062\n",
            "Train epoch - Accuracy: 0.701294964028777 Loss: 0.1075056403918232 Corrects: 4874\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.1088370531797409\n",
            "Train step - Step 1990, Loss 0.10164417326450348\n",
            "Train step - Step 2000, Loss 0.10830727964639664\n",
            "Train step - Step 2010, Loss 0.10282333940267563\n",
            "Train step - Step 2020, Loss 0.11061824858188629\n",
            "Train step - Step 2030, Loss 0.1074906438589096\n",
            "Train epoch - Accuracy: 0.7046043165467626 Loss: 0.10715239231535 Corrects: 4897\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10962529480457306\n",
            "Train step - Step 2050, Loss 0.1048966497182846\n",
            "Train step - Step 2060, Loss 0.11029750108718872\n",
            "Train step - Step 2070, Loss 0.10880666226148605\n",
            "Train step - Step 2080, Loss 0.11102449893951416\n",
            "Train epoch - Accuracy: 0.7116546762589928 Loss: 0.10669640501197293 Corrects: 4946\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10891172289848328\n",
            "Train step - Step 2100, Loss 0.10750042647123337\n",
            "Train step - Step 2110, Loss 0.10989420115947723\n",
            "Train step - Step 2120, Loss 0.10779491066932678\n",
            "Train step - Step 2130, Loss 0.09948611259460449\n",
            "Train step - Step 2140, Loss 0.11223625391721725\n",
            "Train epoch - Accuracy: 0.7125179856115108 Loss: 0.10625364127776606 Corrects: 4952\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.105385422706604\n",
            "Train step - Step 2160, Loss 0.10713827610015869\n",
            "Train step - Step 2170, Loss 0.10520454496145248\n",
            "Train step - Step 2180, Loss 0.10314392298460007\n",
            "Train step - Step 2190, Loss 0.10803297907114029\n",
            "Train epoch - Accuracy: 0.7153956834532375 Loss: 0.10603703737902127 Corrects: 4972\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.10090494900941849\n",
            "Train step - Step 2210, Loss 0.1073610931634903\n",
            "Train step - Step 2220, Loss 0.10334109514951706\n",
            "Train step - Step 2230, Loss 0.10448446869850159\n",
            "Train step - Step 2240, Loss 0.10308729112148285\n",
            "Train step - Step 2250, Loss 0.10772451013326645\n",
            "Train epoch - Accuracy: 0.722158273381295 Loss: 0.10563421039272555 Corrects: 5019\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10616530478000641\n",
            "Train step - Step 2270, Loss 0.10629305243492126\n",
            "Train step - Step 2280, Loss 0.10014507174491882\n",
            "Train step - Step 2290, Loss 0.10791797190904617\n",
            "Train step - Step 2300, Loss 0.10866905003786087\n",
            "Train epoch - Accuracy: 0.723453237410072 Loss: 0.10543374668994396 Corrects: 5028\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10427233576774597\n",
            "Train step - Step 2320, Loss 0.11314691603183746\n",
            "Train step - Step 2330, Loss 0.10089792311191559\n",
            "Train step - Step 2340, Loss 0.11273730546236038\n",
            "Train step - Step 2350, Loss 0.10528241842985153\n",
            "Train step - Step 2360, Loss 0.10524945706129074\n",
            "Train epoch - Accuracy: 0.7332374100719424 Loss: 0.10558045626115456 Corrects: 5096\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.0999395102262497\n",
            "Train step - Step 2380, Loss 0.10771283507347107\n",
            "Train step - Step 2390, Loss 0.10631313920021057\n",
            "Train step - Step 2400, Loss 0.10142719745635986\n",
            "Train step - Step 2410, Loss 0.10735132545232773\n",
            "Train epoch - Accuracy: 0.7287769784172662 Loss: 0.10534800722873468 Corrects: 5065\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.10310443490743637\n",
            "Train step - Step 2430, Loss 0.1002759337425232\n",
            "Train step - Step 2440, Loss 0.11424548178911209\n",
            "Train step - Step 2450, Loss 0.10394559800624847\n",
            "Train step - Step 2460, Loss 0.1139259859919548\n",
            "Train step - Step 2470, Loss 0.10418585687875748\n",
            "Train epoch - Accuracy: 0.7349640287769784 Loss: 0.10461331038166292 Corrects: 5108\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10112997889518738\n",
            "Train step - Step 2490, Loss 0.10548678040504456\n",
            "Train step - Step 2500, Loss 0.1073804497718811\n",
            "Train step - Step 2510, Loss 0.10358192771673203\n",
            "Train step - Step 2520, Loss 0.103092260658741\n",
            "Train epoch - Accuracy: 0.739136690647482 Loss: 0.1047191700532282 Corrects: 5137\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10279278457164764\n",
            "Train step - Step 2540, Loss 0.10677757859230042\n",
            "Train step - Step 2550, Loss 0.10089900344610214\n",
            "Train step - Step 2560, Loss 0.09956776350736618\n",
            "Train step - Step 2570, Loss 0.10015831887722015\n",
            "Train step - Step 2580, Loss 0.11075562238693237\n",
            "Train epoch - Accuracy: 0.740431654676259 Loss: 0.10384633767947876 Corrects: 5146\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.09976667165756226\n",
            "Train step - Step 2600, Loss 0.10295665264129639\n",
            "Train step - Step 2610, Loss 0.10820329189300537\n",
            "Train step - Step 2620, Loss 0.09914509207010269\n",
            "Train step - Step 2630, Loss 0.09931566566228867\n",
            "Train epoch - Accuracy: 0.7492086330935251 Loss: 0.10331691752020404 Corrects: 5207\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10980131477117538\n",
            "Train step - Step 2650, Loss 0.10224924981594086\n",
            "Train step - Step 2660, Loss 0.10720089823007584\n",
            "Train step - Step 2670, Loss 0.10518961399793625\n",
            "Train step - Step 2680, Loss 0.10047493875026703\n",
            "Train step - Step 2690, Loss 0.09956187009811401\n",
            "Train epoch - Accuracy: 0.7437410071942446 Loss: 0.10352891958231548 Corrects: 5169\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10738793015480042\n",
            "Train step - Step 2710, Loss 0.10386954993009567\n",
            "Train step - Step 2720, Loss 0.09992076456546783\n",
            "Train step - Step 2730, Loss 0.1023741066455841\n",
            "Train step - Step 2740, Loss 0.09974868595600128\n",
            "Train epoch - Accuracy: 0.7529496402877698 Loss: 0.10153759793411914 Corrects: 5233\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10489058494567871\n",
            "Train step - Step 2760, Loss 0.09336348623037338\n",
            "Train step - Step 2770, Loss 0.0886065661907196\n",
            "Train step - Step 2780, Loss 0.09643127769231796\n",
            "Train step - Step 2790, Loss 0.09939119964838028\n",
            "Train step - Step 2800, Loss 0.10515463352203369\n",
            "Train epoch - Accuracy: 0.7699280575539569 Loss: 0.10036380977296143 Corrects: 5351\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10190935432910919\n",
            "Train step - Step 2820, Loss 0.10587047785520554\n",
            "Train step - Step 2830, Loss 0.09957822412252426\n",
            "Train step - Step 2840, Loss 0.09934282302856445\n",
            "Train step - Step 2850, Loss 0.09628023952245712\n",
            "Train epoch - Accuracy: 0.7690647482014389 Loss: 0.10012309769932315 Corrects: 5345\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.09729007631540298\n",
            "Train step - Step 2870, Loss 0.10099661350250244\n",
            "Train step - Step 2880, Loss 0.10415887087583542\n",
            "Train step - Step 2890, Loss 0.10605449974536896\n",
            "Train step - Step 2900, Loss 0.10334962606430054\n",
            "Train step - Step 2910, Loss 0.10082828998565674\n",
            "Train epoch - Accuracy: 0.7633093525179856 Loss: 0.09985925994759841 Corrects: 5305\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10397826135158539\n",
            "Train step - Step 2930, Loss 0.10333339124917984\n",
            "Train step - Step 2940, Loss 0.09893093258142471\n",
            "Train step - Step 2950, Loss 0.10041692852973938\n",
            "Train step - Step 2960, Loss 0.09420004487037659\n",
            "Train epoch - Accuracy: 0.7717985611510791 Loss: 0.10022592838290784 Corrects: 5364\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09329701215028763\n",
            "Train step - Step 2980, Loss 0.0893590971827507\n",
            "Train step - Step 2990, Loss 0.1034405305981636\n",
            "Train step - Step 3000, Loss 0.09864820539951324\n",
            "Train step - Step 3010, Loss 0.10375697165727615\n",
            "Train step - Step 3020, Loss 0.09993855655193329\n",
            "Train epoch - Accuracy: 0.7702158273381295 Loss: 0.09963443934703045 Corrects: 5353\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.09491588920354843\n",
            "Train step - Step 3040, Loss 0.10364164412021637\n",
            "Train step - Step 3050, Loss 0.1011698916554451\n",
            "Train step - Step 3060, Loss 0.09777399152517319\n",
            "Train step - Step 3070, Loss 0.10132687538862228\n",
            "Train epoch - Accuracy: 0.7709352517985611 Loss: 0.0997439993178244 Corrects: 5358\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.10370088368654251\n",
            "Train step - Step 3090, Loss 0.09778168052434921\n",
            "Train step - Step 3100, Loss 0.09710471332073212\n",
            "Train step - Step 3110, Loss 0.09583525359630585\n",
            "Train step - Step 3120, Loss 0.10356089472770691\n",
            "Train step - Step 3130, Loss 0.10120053589344025\n",
            "Train epoch - Accuracy: 0.7728057553956834 Loss: 0.09940043372430389 Corrects: 5371\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.09951986372470856\n",
            "Train step - Step 3150, Loss 0.10023099929094315\n",
            "Train step - Step 3160, Loss 0.1036066859960556\n",
            "Train step - Step 3170, Loss 0.09634515643119812\n",
            "Train step - Step 3180, Loss 0.10059727728366852\n",
            "Train epoch - Accuracy: 0.7756834532374101 Loss: 0.09971806976434996 Corrects: 5391\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10218194872140884\n",
            "Train step - Step 3200, Loss 0.0983160063624382\n",
            "Train step - Step 3210, Loss 0.10174357146024704\n",
            "Train step - Step 3220, Loss 0.09816589206457138\n",
            "Train step - Step 3230, Loss 0.10416977107524872\n",
            "Train step - Step 3240, Loss 0.09536773711442947\n",
            "Train epoch - Accuracy: 0.7733812949640287 Loss: 0.09979265213870316 Corrects: 5375\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09934157133102417\n",
            "Train step - Step 3260, Loss 0.10157483071088791\n",
            "Train step - Step 3270, Loss 0.10490518063306808\n",
            "Train step - Step 3280, Loss 0.09836847335100174\n",
            "Train step - Step 3290, Loss 0.09739158302545547\n",
            "Train epoch - Accuracy: 0.7702158273381295 Loss: 0.09987191274011735 Corrects: 5353\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.10150850564241409\n",
            "Train step - Step 3310, Loss 0.10214176774024963\n",
            "Train step - Step 3320, Loss 0.0997081771492958\n",
            "Train step - Step 3330, Loss 0.10403221845626831\n",
            "Train step - Step 3340, Loss 0.09901001304388046\n",
            "Train step - Step 3350, Loss 0.1019619032740593\n",
            "Train epoch - Accuracy: 0.7741007194244605 Loss: 0.09908896967661467 Corrects: 5380\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.09754486382007599\n",
            "Train step - Step 3370, Loss 0.094015933573246\n",
            "Train step - Step 3380, Loss 0.0995519608259201\n",
            "Train step - Step 3390, Loss 0.09739621728658676\n",
            "Train step - Step 3400, Loss 0.09565258771181107\n",
            "Train epoch - Accuracy: 0.7758273381294964 Loss: 0.09929690891461407 Corrects: 5392\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09688430279493332\n",
            "Train step - Step 3420, Loss 0.09475652873516083\n",
            "Train step - Step 3430, Loss 0.09658613801002502\n",
            "Train step - Step 3440, Loss 0.09741640836000443\n",
            "Train step - Step 3450, Loss 0.0918760821223259\n",
            "Train step - Step 3460, Loss 0.09889302402734756\n",
            "Train epoch - Accuracy: 0.777841726618705 Loss: 0.09902837590991165 Corrects: 5406\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.09928037971258163\n",
            "Train step - Step 3480, Loss 0.09278423339128494\n",
            "Train step - Step 3490, Loss 0.09707727283239365\n",
            "Train step - Step 3500, Loss 0.10695211589336395\n",
            "Train step - Step 3510, Loss 0.09194247424602509\n",
            "Train epoch - Accuracy: 0.7789928057553956 Loss: 0.09909402017970736 Corrects: 5414\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.0887599065899849\n",
            "Train step - Step 3530, Loss 0.09830811619758606\n",
            "Train step - Step 3540, Loss 0.09940675646066666\n",
            "Train step - Step 3550, Loss 0.09974713623523712\n",
            "Train step - Step 3560, Loss 0.10306502133607864\n",
            "Train step - Step 3570, Loss 0.10128816962242126\n",
            "Train epoch - Accuracy: 0.7719424460431654 Loss: 0.0987182547098441 Corrects: 5365\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.10132936388254166\n",
            "Train step - Step 3590, Loss 0.100516676902771\n",
            "Train step - Step 3600, Loss 0.09558834135532379\n",
            "Train step - Step 3610, Loss 0.10378025472164154\n",
            "Train step - Step 3620, Loss 0.0988910123705864\n",
            "Train epoch - Accuracy: 0.7838848920863309 Loss: 0.09874315857458457 Corrects: 5448\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.10502766072750092\n",
            "Train step - Step 3640, Loss 0.09298082441091537\n",
            "Train step - Step 3650, Loss 0.0958656370639801\n",
            "Train step - Step 3660, Loss 0.09395921230316162\n",
            "Train step - Step 3670, Loss 0.09964311122894287\n",
            "Train step - Step 3680, Loss 0.10216367244720459\n",
            "Train epoch - Accuracy: 0.7906474820143885 Loss: 0.09850741676503806 Corrects: 5495\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.09837251156568527\n",
            "Train step - Step 3700, Loss 0.10199204087257385\n",
            "Train step - Step 3710, Loss 0.10144399851560593\n",
            "Train step - Step 3720, Loss 0.10155561566352844\n",
            "Train step - Step 3730, Loss 0.10093602538108826\n",
            "Train epoch - Accuracy: 0.7848920863309352 Loss: 0.09850719637579197 Corrects: 5455\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.1007729172706604\n",
            "Train step - Step 3750, Loss 0.09610527008771896\n",
            "Train step - Step 3760, Loss 0.09785277396440506\n",
            "Train step - Step 3770, Loss 0.09799715876579285\n",
            "Train step - Step 3780, Loss 0.09842211753129959\n",
            "Train step - Step 3790, Loss 0.09591767936944962\n",
            "Train epoch - Accuracy: 0.7764028776978418 Loss: 0.09848567969293046 Corrects: 5396\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.09405970573425293\n",
            "Train step - Step 3810, Loss 0.101784847676754\n",
            "Train step - Step 3820, Loss 0.09427730739116669\n",
            "Train step - Step 3830, Loss 0.10054223984479904\n",
            "Train step - Step 3840, Loss 0.0986255630850792\n",
            "Train epoch - Accuracy: 0.7869064748201439 Loss: 0.09851720525420828 Corrects: 5469\n",
            "Training finished in 448.46139311790466 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309dfbed0>\n",
            "Constructing exemplars of class 75\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [3428, 13351, 28903, 6035, 1379, 46953, 22650, 1261, 11195, 9554, 21221, 45567, 46954, 11235, 46180, 26262, 1625, 20377, 38388, 42583, 28861, 25908, 1261, 6363, 23038, 15393, 39669, 777, 13330, 15509, 32982, 29717, 46804, 12227, 13130, 1086, 13065, 49521, 41198, 7182, 43165, 41838, 34141, 38077, 22887, 33964, 1589, 47170, 33104, 27965, 5354, 15204, 31392, 12399, 30477, 46006, 30086, 24237, 12374, 14281, 44017, 15533, 15616, 27445, 44935, 24704]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309dea590>\n",
            "Constructing exemplars of class 23\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [15823, 48313, 37155, 14756, 10627, 26570, 31329, 13078, 44880, 41940, 41211, 19953, 44277, 38841, 16680, 40523, 494, 13816, 38646, 275, 7456, 12403, 23635, 7780, 28100, 3288, 14525, 37610, 29809, 24932, 30257, 3543, 8246, 16694, 31916, 42676, 45498, 42015, 11755, 13802, 31095, 7456, 8469, 46614, 34917, 13472, 16703, 26168, 12315, 35753, 14234, 20791, 18055, 39836, 43889, 2428, 31673, 31679, 39197, 7494, 25468, 43498, 39696, 19803, 28589, 47380]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1f9590>\n",
            "Constructing exemplars of class 90\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [25299, 10842, 5638, 31956, 26382, 10174, 6428, 9241, 39210, 46977, 34152, 11358, 40811, 40209, 39995, 36565, 1115, 23637, 4025, 7934, 16389, 32886, 44956, 49279, 34463, 1573, 39121, 231, 17425, 33909, 25505, 49937, 45349, 21114, 33897, 1115, 25837, 26282, 16872, 23500, 47333, 3442, 13374, 6428, 9524, 23792, 15551, 44538, 42620, 15913, 1649, 45716, 32694, 46623, 30867, 39540, 39524, 44146, 26196, 9687, 39315, 5222, 49099, 30027, 15590, 30870]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a142390>\n",
            "Constructing exemplars of class 10\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [34064, 8456, 40788, 49857, 35787, 18383, 45526, 34374, 25426, 12547, 40883, 6426, 5696, 24793, 41600, 28084, 6210, 15741, 1587, 14719, 7878, 30791, 7459, 33663, 6042, 29099, 9183, 26298, 37823, 27275, 7006, 6426, 23295, 44165, 20793, 30083, 7179, 4026, 24302, 41389, 17344, 35081, 27969, 4776, 7443, 16560, 29045, 49428, 42380, 4956, 40286, 47052, 27581, 4026, 23651, 31075, 34647, 22400, 45216, 12266, 41600, 41325, 48223, 46802, 20052, 16202]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a2088d0>\n",
            "Constructing exemplars of class 61\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [32207, 39044, 43995, 6864, 2833, 3154, 41122, 1742, 104, 27140, 27372, 35348, 38809, 34106, 45323, 17676, 22886, 9613, 30414, 20212, 7575, 37874, 48354, 40328, 1552, 32360, 43826, 6043, 183, 12700, 1806, 15467, 19893, 30613, 43031, 49230, 7488, 2513, 15189, 7187, 17221, 12700, 13110, 32286, 48659, 26641, 11965, 22364, 26859, 30676, 38311, 44144, 43995, 45987, 32375, 749, 17532, 39247, 1742, 19405, 8150, 26660, 5473, 4619, 45110, 27680]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a22e490>\n",
            "Constructing exemplars of class 76\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [18298, 38555, 608, 11846, 6063, 13467, 30071, 47839, 3075, 29987, 26318, 20993, 12422, 35830, 4629, 33981, 8131, 14244, 7168, 20258, 41197, 24200, 23667, 40623, 30892, 13182, 25394, 5817, 1572, 29249, 3233, 10135, 25175, 10456, 26047, 34394, 8930, 45539, 49828, 40173, 34295, 7694, 31337, 48541, 15375, 24480, 40506, 42923, 28994, 4072, 32042, 26669, 27027, 14176, 43845, 28799, 2770, 49028, 8826, 32529, 44302, 46893, 36014, 41637, 21990, 19983]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a209550>\n",
            "Constructing exemplars of class 64\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [6879, 27733, 4665, 45275, 21170, 32898, 37239, 7257, 23192, 32926, 9416, 16312, 41783, 15622, 3968, 1459, 48280, 15372, 8571, 11339, 29974, 14718, 26735, 2550, 3215, 11049, 44078, 45768, 16496, 28887, 1537, 38302, 39846, 26148, 26083, 9273, 2305, 39317, 5044, 31078, 13847, 22931, 34495, 47856, 40711, 32457, 1810, 46473, 11000, 17871, 8905, 32279, 2286, 38894, 38378, 41292, 8869, 32457, 2305, 43327, 1537, 11047, 30548, 13590, 37867, 13456]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a2088d0>\n",
            "Constructing exemplars of class 32\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [33341, 6947, 30464, 29839, 22098, 5059, 25345, 43191, 11332, 48706, 48725, 24589, 15096, 35074, 33507, 24589, 43613, 43479, 5509, 42432, 4811, 15096, 11696, 7872, 4345, 29140, 20519, 23846, 25345, 32382, 46944, 20963, 9077, 20974, 33507, 6392, 15446, 26386, 24510, 2977, 8155, 18782, 7444, 2566, 1732, 3886, 17884, 39382, 20799, 26534, 49253, 30294, 27992, 27892, 21743, 19249, 38389, 25731, 42076, 15059, 43419, 16551, 35635, 23193, 38548, 19236]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f26d10>\n",
            "Constructing exemplars of class 24\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [12982, 35239, 12752, 29828, 15821, 26596, 46924, 7460, 20844, 38564, 37375, 21828, 11171, 11015, 39839, 16435, 23249, 23696, 40945, 34856, 35808, 1458, 6050, 46362, 27710, 5926, 22828, 15594, 28260, 37839, 33616, 35139, 7288, 35385, 45066, 24634, 17740, 957, 28757, 18612, 9944, 46172, 42655, 37108, 23696, 45368, 18816, 30473, 47833, 21318, 15775, 26398, 902, 21978, 27264, 7558, 39192, 44835, 48817, 5274, 5546, 41177, 41965, 27816, 30096, 29667]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1f0150>\n",
            "Constructing exemplars of class 0\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [13194, 41754, 4344, 13181, 29187, 48469, 32197, 45616, 44180, 29275, 24889, 35963, 21725, 40598, 41172, 33376, 43363, 13252, 19051, 31600, 32447, 33145, 17390, 4767, 32714, 4344, 30631, 33773, 18746, 42660, 7498, 4726, 9665, 36863, 1979, 30241, 35653, 3757, 38163, 24889, 26115, 28316, 4480, 38482, 12946, 11264, 23278, 31007, 3007, 15990, 29275, 44725, 38525, 13622, 18064, 13971, 41259, 27355, 45940, 4691, 48715, 34110, 34042, 26604, 3708, 11349]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.1654127538204193\n",
            "Train step - Step 0, Loss 0.19052910804748535\n",
            "Train step - Step 0, Loss 0.1641233116388321\n",
            "Train step - Step 0, Loss 0.14056630432605743\n",
            "Train step - Step 0, Loss 0.12481825053691864\n",
            "Train step - Step 0, Loss 0.1467900276184082\n",
            "Train step - Step 0, Loss 0.13782377541065216\n",
            "Train step - Step 0, Loss 0.16012990474700928\n",
            "Train step - Step 0, Loss 0.14229075610637665\n",
            "Train step - Step 0, Loss 0.14187490940093994\n",
            "Train step - Step 0, Loss 0.13007088005542755\n",
            "Train step - Step 0, Loss 0.12594324350357056\n",
            "Train step - Step 0, Loss 0.12517613172531128\n",
            "Train step - Step 0, Loss 0.13537733256816864\n",
            "Train step - Step 0, Loss 0.14350393414497375\n",
            "Train step - Step 0, Loss 0.10676154494285583\n",
            "Train epoch - Accuracy: 0.4994107744107744 Loss: 0.1438044507696171 Corrects: 5933\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.13764096796512604\n",
            "Train step - Step 0, Loss 0.1376468688249588\n",
            "Train step - Step 0, Loss 0.13521656394004822\n",
            "Train step - Step 0, Loss 0.1590208262205124\n",
            "Train step - Step 0, Loss 0.1354624330997467\n",
            "Train step - Step 0, Loss 0.12051589041948318\n",
            "Train step - Step 0, Loss 0.12894150614738464\n",
            "Train step - Step 0, Loss 0.11896544694900513\n",
            "Train step - Step 0, Loss 0.13268892467021942\n",
            "Train step - Step 0, Loss 0.12810544669628143\n",
            "Train step - Step 0, Loss 0.11616206169128418\n",
            "Train step - Step 0, Loss 0.12917283177375793\n",
            "Train step - Step 0, Loss 0.13091889023780823\n",
            "Train step - Step 0, Loss 0.13928547501564026\n",
            "Train step - Step 0, Loss 0.12566252052783966\n",
            "Train step - Step 0, Loss 0.14027635753154755\n",
            "Train epoch - Accuracy: 0.4957912457912458 Loss: 0.13195385514485716 Corrects: 5890\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.11966072022914886\n",
            "Train step - Step 0, Loss 0.13767094910144806\n",
            "Train step - Step 0, Loss 0.13656824827194214\n",
            "Train step - Step 0, Loss 0.1284221112728119\n",
            "Train step - Step 0, Loss 0.14727036654949188\n",
            "Train step - Step 0, Loss 0.1179002895951271\n",
            "Train step - Step 0, Loss 0.12561723589897156\n",
            "Train step - Step 0, Loss 0.13176771998405457\n",
            "Train step - Step 0, Loss 0.11484364420175552\n",
            "Train step - Step 0, Loss 0.13069705665111542\n",
            "Train step - Step 0, Loss 0.11756816506385803\n",
            "Train step - Step 0, Loss 0.12312928587198257\n",
            "Train step - Step 0, Loss 0.12174441665410995\n",
            "Train step - Step 0, Loss 0.12940023839473724\n",
            "Train step - Step 0, Loss 0.11314918845891953\n",
            "Train step - Step 0, Loss 0.11629637330770493\n",
            "Train epoch - Accuracy: 0.4871212121212121 Loss: 0.12605566456161363 Corrects: 5787\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.12716668844223022\n",
            "Train step - Step 0, Loss 0.11847548931837082\n",
            "Train step - Step 0, Loss 0.11878012120723724\n",
            "Train step - Step 0, Loss 0.11852453649044037\n",
            "Train step - Step 0, Loss 0.11508990824222565\n",
            "Train step - Step 0, Loss 0.12153352051973343\n",
            "Train step - Step 0, Loss 0.1264238953590393\n",
            "Train step - Step 0, Loss 0.12178964912891388\n",
            "Train step - Step 0, Loss 0.1299213469028473\n",
            "Train step - Step 0, Loss 0.11214754730463028\n",
            "Train step - Step 0, Loss 0.12430845946073532\n",
            "Train step - Step 0, Loss 0.12654179334640503\n",
            "Train step - Step 0, Loss 0.12392184138298035\n",
            "Train step - Step 0, Loss 0.12194402515888214\n",
            "Train step - Step 0, Loss 0.12877364456653595\n",
            "Train step - Step 0, Loss 0.1388380080461502\n",
            "Train epoch - Accuracy: 0.49427609427609426 Loss: 0.12285561426119371 Corrects: 5872\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.11873216181993484\n",
            "Train step - Step 0, Loss 0.1266118437051773\n",
            "Train step - Step 0, Loss 0.11500054597854614\n",
            "Train step - Step 0, Loss 0.1264462023973465\n",
            "Train step - Step 0, Loss 0.11187401413917542\n",
            "Train step - Step 0, Loss 0.12301048636436462\n",
            "Train step - Step 0, Loss 0.12337392568588257\n",
            "Train step - Step 0, Loss 0.1372687816619873\n",
            "Train step - Step 0, Loss 0.11889171600341797\n",
            "Train step - Step 0, Loss 0.10819903761148453\n",
            "Train step - Step 0, Loss 0.11817716062068939\n",
            "Train step - Step 0, Loss 0.12943875789642334\n",
            "Train step - Step 0, Loss 0.11611396074295044\n",
            "Train step - Step 0, Loss 0.11911246180534363\n",
            "Train step - Step 0, Loss 0.1115504577755928\n",
            "Train step - Step 0, Loss 0.12825284898281097\n",
            "Train epoch - Accuracy: 0.4845959595959596 Loss: 0.12049584078668343 Corrects: 5757\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.12236898392438889\n",
            "Train step - Step 0, Loss 0.11964444071054459\n",
            "Train step - Step 0, Loss 0.12609049677848816\n",
            "Train step - Step 0, Loss 0.11348309367895126\n",
            "Train step - Step 0, Loss 0.11121441423892975\n",
            "Train step - Step 0, Loss 0.12404891103506088\n",
            "Train step - Step 0, Loss 0.13405410945415497\n",
            "Train step - Step 0, Loss 0.11271333694458008\n",
            "Train step - Step 0, Loss 0.1232684925198555\n",
            "Train step - Step 0, Loss 0.1252155303955078\n",
            "Train step - Step 0, Loss 0.11236953735351562\n",
            "Train step - Step 0, Loss 0.11232642084360123\n",
            "Train step - Step 0, Loss 0.10888300091028214\n",
            "Train step - Step 0, Loss 0.10781977325677872\n",
            "Train step - Step 0, Loss 0.11364075541496277\n",
            "Train step - Step 0, Loss 0.11560334265232086\n",
            "Train epoch - Accuracy: 0.48787878787878786 Loss: 0.11774256900705472 Corrects: 5796\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.1231115385890007\n",
            "Train step - Step 0, Loss 0.1271308958530426\n",
            "Train step - Step 0, Loss 0.11867201328277588\n",
            "Train step - Step 0, Loss 0.11194024980068207\n",
            "Train step - Step 0, Loss 0.11171048879623413\n",
            "Train step - Step 0, Loss 0.10750963538885117\n",
            "Train step - Step 0, Loss 0.12340660393238068\n",
            "Train step - Step 0, Loss 0.1190275028347969\n",
            "Train step - Step 0, Loss 0.12012189626693726\n",
            "Train step - Step 0, Loss 0.12351067364215851\n",
            "Train step - Step 0, Loss 0.12319785356521606\n",
            "Train step - Step 0, Loss 0.11217986792325974\n",
            "Train step - Step 0, Loss 0.10930502414703369\n",
            "Train step - Step 0, Loss 0.1114787682890892\n",
            "Train step - Step 0, Loss 0.1092071682214737\n",
            "Train step - Step 0, Loss 0.1248515397310257\n",
            "Train epoch - Accuracy: 0.4815656565656566 Loss: 0.11701232095559438 Corrects: 5721\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.1250661164522171\n",
            "Train step - Step 0, Loss 0.09989605098962784\n",
            "Train step - Step 0, Loss 0.12133115530014038\n",
            "Train step - Step 0, Loss 0.11591915786266327\n",
            "Train step - Step 0, Loss 0.12002125382423401\n",
            "Train step - Step 0, Loss 0.10776225477457047\n",
            "Train step - Step 0, Loss 0.1251954734325409\n",
            "Train step - Step 0, Loss 0.10824906080961227\n",
            "Train step - Step 0, Loss 0.1171494796872139\n",
            "Train step - Step 0, Loss 0.12066193670034409\n",
            "Train step - Step 0, Loss 0.11952140182256699\n",
            "Train step - Step 0, Loss 0.10933614522218704\n",
            "Train step - Step 0, Loss 0.11181876063346863\n",
            "Train step - Step 0, Loss 0.1225641593337059\n",
            "Train step - Step 0, Loss 0.12323326617479324\n",
            "Train step - Step 0, Loss 0.10094082355499268\n",
            "Train epoch - Accuracy: 0.4920875420875421 Loss: 0.11604309876759847 Corrects: 5846\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.11290571838617325\n",
            "Train step - Step 0, Loss 0.11466950923204422\n",
            "Train step - Step 0, Loss 0.1074633076786995\n",
            "Train step - Step 0, Loss 0.13356013596057892\n",
            "Train step - Step 0, Loss 0.11516708880662918\n",
            "Train step - Step 0, Loss 0.11487504094839096\n",
            "Train step - Step 0, Loss 0.10279460996389389\n",
            "Train step - Step 0, Loss 0.11329758167266846\n",
            "Train step - Step 0, Loss 0.1148369088768959\n",
            "Train step - Step 0, Loss 0.11572960019111633\n",
            "Train step - Step 0, Loss 0.1243385523557663\n",
            "Train step - Step 0, Loss 0.10809754580259323\n",
            "Train step - Step 0, Loss 0.10365753620862961\n",
            "Train step - Step 0, Loss 0.10575633496046066\n",
            "Train step - Step 0, Loss 0.10791795700788498\n",
            "Train step - Step 0, Loss 0.1295027732849121\n",
            "Train epoch - Accuracy: 0.4941919191919192 Loss: 0.11350444302414403 Corrects: 5871\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.10157853364944458\n",
            "Train step - Step 0, Loss 0.11162478476762772\n",
            "Train step - Step 0, Loss 0.11458858102560043\n",
            "Train step - Step 0, Loss 0.11218300461769104\n",
            "Train step - Step 0, Loss 0.12212461978197098\n",
            "Train step - Step 0, Loss 0.11197385936975479\n",
            "Train step - Step 0, Loss 0.1072830855846405\n",
            "Train step - Step 0, Loss 0.10518753528594971\n",
            "Train step - Step 0, Loss 0.11361118406057358\n",
            "Train step - Step 0, Loss 0.11213832348585129\n",
            "Train step - Step 0, Loss 0.11077285557985306\n",
            "Train step - Step 0, Loss 0.12645716965198517\n",
            "Train step - Step 0, Loss 0.1100304126739502\n",
            "Train step - Step 0, Loss 0.1158965453505516\n",
            "Train step - Step 0, Loss 0.12230762839317322\n",
            "Train step - Step 0, Loss 0.1228160485625267\n",
            "Train epoch - Accuracy: 0.4845959595959596 Loss: 0.11347575893606802 Corrects: 5757\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.10864613205194473\n",
            "Train step - Step 0, Loss 0.1255553662776947\n",
            "Train step - Step 0, Loss 0.10898037254810333\n",
            "Train step - Step 0, Loss 0.10861681401729584\n",
            "Train step - Step 0, Loss 0.11297818273305893\n",
            "Train step - Step 0, Loss 0.11366414278745651\n",
            "Train step - Step 0, Loss 0.11581290513277054\n",
            "Train step - Step 0, Loss 0.12222521007061005\n",
            "Train step - Step 0, Loss 0.11986171454191208\n",
            "Train step - Step 0, Loss 0.10558163374662399\n",
            "Train step - Step 0, Loss 0.11257009953260422\n",
            "Train step - Step 0, Loss 0.10609924048185349\n",
            "Train step - Step 0, Loss 0.11511894315481186\n",
            "Train step - Step 0, Loss 0.10693863779306412\n",
            "Train step - Step 0, Loss 0.1134355366230011\n",
            "Train step - Step 0, Loss 0.10853133350610733\n",
            "Train epoch - Accuracy: 0.48964646464646466 Loss: 0.11293472284921492 Corrects: 5817\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.11116611212491989\n",
            "Train step - Step 0, Loss 0.12015695124864578\n",
            "Train step - Step 0, Loss 0.10093535482883453\n",
            "Train step - Step 0, Loss 0.1008656844496727\n",
            "Train step - Step 0, Loss 0.1153208464384079\n",
            "Train step - Step 0, Loss 0.11911288648843765\n",
            "Train step - Step 0, Loss 0.10608192533254623\n",
            "Train step - Step 0, Loss 0.12065418064594269\n",
            "Train step - Step 0, Loss 0.10809434205293655\n",
            "Train step - Step 0, Loss 0.11767665296792984\n",
            "Train step - Step 0, Loss 0.09519009292125702\n",
            "Train step - Step 0, Loss 0.117348812520504\n",
            "Train step - Step 0, Loss 0.11522623151540756\n",
            "Train step - Step 0, Loss 0.0991939976811409\n",
            "Train step - Step 0, Loss 0.10939855873584747\n",
            "Train step - Step 0, Loss 0.10601683706045151\n",
            "Train epoch - Accuracy: 0.48678451178451176 Loss: 0.1102944984128981 Corrects: 5783\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.11376480758190155\n",
            "Train step - Step 0, Loss 0.10510175675153732\n",
            "Train step - Step 0, Loss 0.10956801474094391\n",
            "Train step - Step 0, Loss 0.11508162319660187\n",
            "Train step - Step 0, Loss 0.1078299880027771\n",
            "Train step - Step 0, Loss 0.11228522658348083\n",
            "Train step - Step 0, Loss 0.11059652268886566\n",
            "Train step - Step 0, Loss 0.1090625673532486\n",
            "Train step - Step 0, Loss 0.12009748071432114\n",
            "Train step - Step 0, Loss 0.11577602475881577\n",
            "Train step - Step 0, Loss 0.10078095644712448\n",
            "Train step - Step 0, Loss 0.1010131984949112\n",
            "Train step - Step 0, Loss 0.10742266476154327\n",
            "Train step - Step 0, Loss 0.10828790068626404\n",
            "Train step - Step 0, Loss 0.11419250071048737\n",
            "Train step - Step 0, Loss 0.11131177842617035\n",
            "Train epoch - Accuracy: 0.4893939393939394 Loss: 0.11009542656065238 Corrects: 5814\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.12064122408628464\n",
            "Train step - Step 0, Loss 0.11014646291732788\n",
            "Train step - Step 0, Loss 0.1151612177491188\n",
            "Train step - Step 0, Loss 0.11060494929552078\n",
            "Train step - Step 0, Loss 0.10795976221561432\n",
            "Train step - Step 0, Loss 0.11189459264278412\n",
            "Train step - Step 0, Loss 0.10307587683200836\n",
            "Train step - Step 0, Loss 0.11251873522996902\n",
            "Train step - Step 0, Loss 0.11507254838943481\n",
            "Train step - Step 0, Loss 0.109779953956604\n",
            "Train step - Step 0, Loss 0.10276161879301071\n",
            "Train step - Step 0, Loss 0.11132388561964035\n",
            "Train step - Step 0, Loss 0.10977556556463242\n",
            "Train step - Step 0, Loss 0.11366277188062668\n",
            "Train step - Step 0, Loss 0.11473151296377182\n",
            "Train step - Step 0, Loss 0.10468628257513046\n",
            "Train epoch - Accuracy: 0.49646464646464644 Loss: 0.11107441603836388 Corrects: 5898\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.10620088130235672\n",
            "Train step - Step 0, Loss 0.1044987142086029\n",
            "Train step - Step 0, Loss 0.1024484634399414\n",
            "Train step - Step 0, Loss 0.10824905335903168\n",
            "Train step - Step 0, Loss 0.1089298278093338\n",
            "Train step - Step 0, Loss 0.10577704012393951\n",
            "Train step - Step 0, Loss 0.1061875969171524\n",
            "Train step - Step 0, Loss 0.11131659150123596\n",
            "Train step - Step 0, Loss 0.10737815499305725\n",
            "Train step - Step 0, Loss 0.11485028266906738\n",
            "Train step - Step 0, Loss 0.10893625766038895\n",
            "Train step - Step 0, Loss 0.1147836297750473\n",
            "Train step - Step 0, Loss 0.11254686862230301\n",
            "Train step - Step 0, Loss 0.11135808378458023\n",
            "Train step - Step 0, Loss 0.1073550283908844\n",
            "Train step - Step 0, Loss 0.09463237971067429\n",
            "Train epoch - Accuracy: 0.4890572390572391 Loss: 0.10829416743733666 Corrects: 5810\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.11170351505279541\n",
            "Train step - Step 0, Loss 0.10891018062829971\n",
            "Train step - Step 0, Loss 0.10728931427001953\n",
            "Train step - Step 0, Loss 0.11100858449935913\n",
            "Train step - Step 0, Loss 0.10339789092540741\n",
            "Train step - Step 0, Loss 0.11193930357694626\n",
            "Train step - Step 0, Loss 0.10358240455389023\n",
            "Train step - Step 0, Loss 0.1146140843629837\n",
            "Train step - Step 0, Loss 0.10692000389099121\n",
            "Train step - Step 0, Loss 0.106234110891819\n",
            "Train step - Step 0, Loss 0.11285422742366791\n",
            "Train step - Step 0, Loss 0.10874305665493011\n",
            "Train step - Step 0, Loss 0.1114916279911995\n",
            "Train step - Step 0, Loss 0.104143887758255\n",
            "Train step - Step 0, Loss 0.10348112881183624\n",
            "Train step - Step 0, Loss 0.1032605916261673\n",
            "Train epoch - Accuracy: 0.49107744107744106 Loss: 0.10826451546616024 Corrects: 5834\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.10578910261392593\n",
            "Train step - Step 0, Loss 0.11470647901296616\n",
            "Train step - Step 0, Loss 0.10109984129667282\n",
            "Train step - Step 0, Loss 0.1098875179886818\n",
            "Train step - Step 0, Loss 0.11457357555627823\n",
            "Train step - Step 0, Loss 0.10255201160907745\n",
            "Train step - Step 0, Loss 0.10463149100542068\n",
            "Train step - Step 0, Loss 0.11255577951669693\n",
            "Train step - Step 0, Loss 0.10354249179363251\n",
            "Train step - Step 0, Loss 0.10235663503408432\n",
            "Train step - Step 0, Loss 0.1030300185084343\n",
            "Train step - Step 0, Loss 0.11161376535892487\n",
            "Train step - Step 0, Loss 0.09748733788728714\n",
            "Train step - Step 0, Loss 0.11136440932750702\n",
            "Train step - Step 0, Loss 0.10549615323543549\n",
            "Train step - Step 0, Loss 0.1072303056716919\n",
            "Train epoch - Accuracy: 0.4872895622895623 Loss: 0.10672813352912364 Corrects: 5789\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.10437808930873871\n",
            "Train step - Step 0, Loss 0.1114301085472107\n",
            "Train step - Step 0, Loss 0.10765697807073593\n",
            "Train step - Step 0, Loss 0.10961601883172989\n",
            "Train step - Step 0, Loss 0.10678963363170624\n",
            "Train step - Step 0, Loss 0.10899230092763901\n",
            "Train step - Step 0, Loss 0.10798222571611404\n",
            "Train step - Step 0, Loss 0.11256759613752365\n",
            "Train step - Step 0, Loss 0.10508546233177185\n",
            "Train step - Step 0, Loss 0.1057201400399208\n",
            "Train step - Step 0, Loss 0.10706810653209686\n",
            "Train step - Step 0, Loss 0.11020785570144653\n",
            "Train step - Step 0, Loss 0.113747738301754\n",
            "Train step - Step 0, Loss 0.10843902081251144\n",
            "Train step - Step 0, Loss 0.10360516607761383\n",
            "Train step - Step 0, Loss 0.10375778377056122\n",
            "Train epoch - Accuracy: 0.49242424242424243 Loss: 0.108083904782931 Corrects: 5850\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.10603482276201248\n",
            "Train step - Step 0, Loss 0.10766934603452682\n",
            "Train step - Step 0, Loss 0.10284611582756042\n",
            "Train step - Step 0, Loss 0.10918397456407547\n",
            "Train step - Step 0, Loss 0.0995284840464592\n",
            "Train step - Step 0, Loss 0.1081547960639\n",
            "Train step - Step 0, Loss 0.10335778445005417\n",
            "Train step - Step 0, Loss 0.10398846119642258\n",
            "Train step - Step 0, Loss 0.10773877054452896\n",
            "Train step - Step 0, Loss 0.10403601825237274\n",
            "Train step - Step 0, Loss 0.11156951636075974\n",
            "Train step - Step 0, Loss 0.1040903776884079\n",
            "Train step - Step 0, Loss 0.11122509092092514\n",
            "Train step - Step 0, Loss 0.10958036035299301\n",
            "Train step - Step 0, Loss 0.1053326204419136\n",
            "Train step - Step 0, Loss 0.11037396639585495\n",
            "Train epoch - Accuracy: 0.4845959595959596 Loss: 0.10641288638415963 Corrects: 5757\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.10442949831485748\n",
            "Train step - Step 0, Loss 0.10925436019897461\n",
            "Train step - Step 0, Loss 0.1052437499165535\n",
            "Train step - Step 0, Loss 0.10767805576324463\n",
            "Train step - Step 0, Loss 0.11349508911371231\n",
            "Train step - Step 0, Loss 0.10518854111433029\n",
            "Train step - Step 0, Loss 0.10993696749210358\n",
            "Train step - Step 0, Loss 0.10206636786460876\n",
            "Train step - Step 0, Loss 0.10095798224210739\n",
            "Train step - Step 0, Loss 0.10670746117830276\n",
            "Train step - Step 0, Loss 0.10871120542287827\n",
            "Train step - Step 0, Loss 0.10903359949588776\n",
            "Train step - Step 0, Loss 0.10261618345975876\n",
            "Train step - Step 0, Loss 0.11037217825651169\n",
            "Train step - Step 0, Loss 0.10732778161764145\n",
            "Train step - Step 0, Loss 0.10086556524038315\n",
            "Train epoch - Accuracy: 0.48653198653198654 Loss: 0.10668604477788463 Corrects: 5780\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.10164579004049301\n",
            "Train step - Step 0, Loss 0.1085948795080185\n",
            "Train step - Step 0, Loss 0.10279422253370285\n",
            "Train step - Step 0, Loss 0.11106495559215546\n",
            "Train step - Step 0, Loss 0.10663820803165436\n",
            "Train step - Step 0, Loss 0.10388938337564468\n",
            "Train step - Step 0, Loss 0.1032036691904068\n",
            "Train step - Step 0, Loss 0.10700461268424988\n",
            "Train step - Step 0, Loss 0.11001978069543839\n",
            "Train step - Step 0, Loss 0.10338563472032547\n",
            "Train step - Step 0, Loss 0.10334180295467377\n",
            "Train step - Step 0, Loss 0.0999232605099678\n",
            "Train step - Step 0, Loss 0.10357432812452316\n",
            "Train step - Step 0, Loss 0.10925226658582687\n",
            "Train step - Step 0, Loss 0.10660348832607269\n",
            "Train step - Step 0, Loss 0.10032236576080322\n",
            "Train epoch - Accuracy: 0.4882996632996633 Loss: 0.10524201320879387 Corrects: 5801\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.10333261638879776\n",
            "Train step - Step 0, Loss 0.11358282715082169\n",
            "Train step - Step 0, Loss 0.11075687408447266\n",
            "Train step - Step 0, Loss 0.09823758900165558\n",
            "Train step - Step 0, Loss 0.10567495971918106\n",
            "Train step - Step 0, Loss 0.1059492975473404\n",
            "Train step - Step 0, Loss 0.09435134381055832\n",
            "Train step - Step 0, Loss 0.10426126420497894\n",
            "Train step - Step 0, Loss 0.10184591263532639\n",
            "Train step - Step 0, Loss 0.10665032267570496\n",
            "Train step - Step 0, Loss 0.10135452449321747\n",
            "Train step - Step 0, Loss 0.11226073652505875\n",
            "Train step - Step 0, Loss 0.11027975380420685\n",
            "Train step - Step 0, Loss 0.10137221217155457\n",
            "Train step - Step 0, Loss 0.114370197057724\n",
            "Train step - Step 0, Loss 0.1116243377327919\n",
            "Train epoch - Accuracy: 0.49486531986531984 Loss: 0.10580068457909304 Corrects: 5879\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.1081618219614029\n",
            "Train step - Step 0, Loss 0.1077466532588005\n",
            "Train step - Step 0, Loss 0.1085028275847435\n",
            "Train step - Step 0, Loss 0.10697722434997559\n",
            "Train step - Step 0, Loss 0.11183921247720718\n",
            "Train step - Step 0, Loss 0.11032505333423615\n",
            "Train step - Step 0, Loss 0.10271997004747391\n",
            "Train step - Step 0, Loss 0.1070631667971611\n",
            "Train step - Step 0, Loss 0.10057005286216736\n",
            "Train step - Step 0, Loss 0.10580732673406601\n",
            "Train step - Step 0, Loss 0.10353847593069077\n",
            "Train step - Step 0, Loss 0.10800546407699585\n",
            "Train step - Step 0, Loss 0.10289645940065384\n",
            "Train step - Step 0, Loss 0.10233715921640396\n",
            "Train step - Step 0, Loss 0.10273268073797226\n",
            "Train step - Step 0, Loss 0.10321587324142456\n",
            "Train epoch - Accuracy: 0.48577441077441075 Loss: 0.10586543769547434 Corrects: 5771\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.10678288340568542\n",
            "Train step - Step 0, Loss 0.10396231710910797\n",
            "Train step - Step 0, Loss 0.09839380532503128\n",
            "Train step - Step 0, Loss 0.10401804745197296\n",
            "Train step - Step 0, Loss 0.10079450905323029\n",
            "Train step - Step 0, Loss 0.1110195592045784\n",
            "Train step - Step 0, Loss 0.10299012809991837\n",
            "Train step - Step 0, Loss 0.10331138968467712\n",
            "Train step - Step 0, Loss 0.10811830312013626\n",
            "Train step - Step 0, Loss 0.10458000004291534\n",
            "Train step - Step 0, Loss 0.10205235332250595\n",
            "Train step - Step 0, Loss 0.11239229142665863\n",
            "Train step - Step 0, Loss 0.1052958220243454\n",
            "Train step - Step 0, Loss 0.10891366004943848\n",
            "Train step - Step 0, Loss 0.11174871772527695\n",
            "Train step - Step 0, Loss 0.10449879616498947\n",
            "Train epoch - Accuracy: 0.4890572390572391 Loss: 0.10559079419783872 Corrects: 5810\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.11261442303657532\n",
            "Train step - Step 0, Loss 0.10034660995006561\n",
            "Train step - Step 0, Loss 0.10993010550737381\n",
            "Train step - Step 0, Loss 0.10270078480243683\n",
            "Train step - Step 0, Loss 0.09123164415359497\n",
            "Train step - Step 0, Loss 0.10427383333444595\n",
            "Train step - Step 0, Loss 0.10773154348134995\n",
            "Train step - Step 0, Loss 0.10618361830711365\n",
            "Train step - Step 0, Loss 0.11196599900722504\n",
            "Train step - Step 0, Loss 0.09949317574501038\n",
            "Train step - Step 0, Loss 0.10731737315654755\n",
            "Train step - Step 0, Loss 0.09960418194532394\n",
            "Train step - Step 0, Loss 0.09837636351585388\n",
            "Train step - Step 0, Loss 0.1014263927936554\n",
            "Train step - Step 0, Loss 0.1057245209813118\n",
            "Train step - Step 0, Loss 0.10841476172208786\n",
            "Train epoch - Accuracy: 0.48754208754208755 Loss: 0.10406399930667395 Corrects: 5792\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.10365872085094452\n",
            "Train step - Step 0, Loss 0.09794803708791733\n",
            "Train step - Step 0, Loss 0.11084681749343872\n",
            "Train step - Step 0, Loss 0.09777164459228516\n",
            "Train step - Step 0, Loss 0.10254083573818207\n",
            "Train step - Step 0, Loss 0.105716772377491\n",
            "Train step - Step 0, Loss 0.10425211489200592\n",
            "Train step - Step 0, Loss 0.10371509194374084\n",
            "Train step - Step 0, Loss 0.1035749688744545\n",
            "Train step - Step 0, Loss 0.09542941302061081\n",
            "Train step - Step 0, Loss 0.10915730148553848\n",
            "Train step - Step 0, Loss 0.10848928987979889\n",
            "Train step - Step 0, Loss 0.10948579758405685\n",
            "Train step - Step 0, Loss 0.10721250623464584\n",
            "Train step - Step 0, Loss 0.09847258776426315\n",
            "Train step - Step 0, Loss 0.09607858210802078\n",
            "Train epoch - Accuracy: 0.49158249158249157 Loss: 0.10364824146634401 Corrects: 5840\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.11062081903219223\n",
            "Train step - Step 0, Loss 0.10618890076875687\n",
            "Train step - Step 0, Loss 0.10652769356966019\n",
            "Train step - Step 0, Loss 0.10751412063837051\n",
            "Train step - Step 0, Loss 0.10381221026182175\n",
            "Train step - Step 0, Loss 0.11275562644004822\n",
            "Train step - Step 0, Loss 0.10069736838340759\n",
            "Train step - Step 0, Loss 0.10744955390691757\n",
            "Train step - Step 0, Loss 0.0983053520321846\n",
            "Train step - Step 0, Loss 0.09057104587554932\n",
            "Train step - Step 0, Loss 0.10088274627923965\n",
            "Train step - Step 0, Loss 0.10794368386268616\n",
            "Train step - Step 0, Loss 0.10368983447551727\n",
            "Train step - Step 0, Loss 0.10793007910251617\n",
            "Train step - Step 0, Loss 0.10212312638759613\n",
            "Train step - Step 0, Loss 0.09574830532073975\n",
            "Train epoch - Accuracy: 0.4919191919191919 Loss: 0.10420326006532919 Corrects: 5844\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.10016348212957382\n",
            "Train step - Step 0, Loss 0.10601698607206345\n",
            "Train step - Step 0, Loss 0.09687754511833191\n",
            "Train step - Step 0, Loss 0.10347557067871094\n",
            "Train step - Step 0, Loss 0.10236160457134247\n",
            "Train step - Step 0, Loss 0.10685575753450394\n",
            "Train step - Step 0, Loss 0.10897541046142578\n",
            "Train step - Step 0, Loss 0.10603050887584686\n",
            "Train step - Step 0, Loss 0.09779733419418335\n",
            "Train step - Step 0, Loss 0.11061504483222961\n",
            "Train step - Step 0, Loss 0.10822094231843948\n",
            "Train step - Step 0, Loss 0.1072281002998352\n",
            "Train step - Step 0, Loss 0.1066243126988411\n",
            "Train step - Step 0, Loss 0.09982141852378845\n",
            "Train step - Step 0, Loss 0.09872224926948547\n",
            "Train step - Step 0, Loss 0.09108234196901321\n",
            "Train epoch - Accuracy: 0.4855218855218855 Loss: 0.1035947387718191 Corrects: 5768\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.10010302066802979\n",
            "Train step - Step 0, Loss 0.1073106899857521\n",
            "Train step - Step 0, Loss 0.10654765367507935\n",
            "Train step - Step 0, Loss 0.10401277989149094\n",
            "Train step - Step 0, Loss 0.10026679933071136\n",
            "Train step - Step 0, Loss 0.10038632899522781\n",
            "Train step - Step 0, Loss 0.1084899753332138\n",
            "Train step - Step 0, Loss 0.11553964018821716\n",
            "Train step - Step 0, Loss 0.09717097878456116\n",
            "Train step - Step 0, Loss 0.10154446959495544\n",
            "Train step - Step 0, Loss 0.10985313355922699\n",
            "Train step - Step 0, Loss 0.10618405044078827\n",
            "Train step - Step 0, Loss 0.09855934232473373\n",
            "Train step - Step 0, Loss 0.10142996162176132\n",
            "Train step - Step 0, Loss 0.1042184829711914\n",
            "Train step - Step 0, Loss 0.10542330890893936\n",
            "Train epoch - Accuracy: 0.4861111111111111 Loss: 0.10414768377638826 Corrects: 5775\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.10242913663387299\n",
            "Train step - Step 0, Loss 0.10652092844247818\n",
            "Train step - Step 0, Loss 0.09681380540132523\n",
            "Train step - Step 0, Loss 0.10473614186048508\n",
            "Train step - Step 0, Loss 0.10135546326637268\n",
            "Train step - Step 0, Loss 0.1030016615986824\n",
            "Train step - Step 0, Loss 0.1023007184267044\n",
            "Train step - Step 0, Loss 0.1028372049331665\n",
            "Train step - Step 0, Loss 0.10472104698419571\n",
            "Train step - Step 0, Loss 0.10562758892774582\n",
            "Train step - Step 0, Loss 0.09761235862970352\n",
            "Train step - Step 0, Loss 0.10538451373577118\n",
            "Train step - Step 0, Loss 0.09519403427839279\n",
            "Train step - Step 0, Loss 0.1134137287735939\n",
            "Train step - Step 0, Loss 0.11155679821968079\n",
            "Train step - Step 0, Loss 0.10172796994447708\n",
            "Train epoch - Accuracy: 0.490993265993266 Loss: 0.10351128022779119 Corrects: 5833\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.1025729551911354\n",
            "Train step - Step 0, Loss 0.10569696873426437\n",
            "Train step - Step 0, Loss 0.1037595123052597\n",
            "Train step - Step 0, Loss 0.10724438726902008\n",
            "Train step - Step 0, Loss 0.10297822952270508\n",
            "Train step - Step 0, Loss 0.10230252146720886\n",
            "Train step - Step 0, Loss 0.10425807535648346\n",
            "Train step - Step 0, Loss 0.10872957855463028\n",
            "Train step - Step 0, Loss 0.0979892835021019\n",
            "Train step - Step 0, Loss 0.11112238466739655\n",
            "Train step - Step 0, Loss 0.1082296296954155\n",
            "Train step - Step 0, Loss 0.09770874679088593\n",
            "Train step - Step 0, Loss 0.10132154077291489\n",
            "Train step - Step 0, Loss 0.10896511375904083\n",
            "Train step - Step 0, Loss 0.09814330190420151\n",
            "Train step - Step 0, Loss 0.09854347258806229\n",
            "Train epoch - Accuracy: 0.4877104377104377 Loss: 0.10390073420724484 Corrects: 5794\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.1114158034324646\n",
            "Train step - Step 0, Loss 0.0951772928237915\n",
            "Train step - Step 0, Loss 0.10354457795619965\n",
            "Train step - Step 0, Loss 0.1006331592798233\n",
            "Train step - Step 0, Loss 0.10303937643766403\n",
            "Train step - Step 0, Loss 0.09864994138479233\n",
            "Train step - Step 0, Loss 0.10182353109121323\n",
            "Train step - Step 0, Loss 0.10820238292217255\n",
            "Train step - Step 0, Loss 0.1134832426905632\n",
            "Train step - Step 0, Loss 0.1040412187576294\n",
            "Train step - Step 0, Loss 0.10267192125320435\n",
            "Train step - Step 0, Loss 0.0991610586643219\n",
            "Train step - Step 0, Loss 0.1032763198018074\n",
            "Train step - Step 0, Loss 0.09630724042654037\n",
            "Train step - Step 0, Loss 0.1085435077548027\n",
            "Train step - Step 0, Loss 0.08920907229185104\n",
            "Train epoch - Accuracy: 0.4904882154882155 Loss: 0.10290342317988174 Corrects: 5827\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.0913400873541832\n",
            "Train step - Step 0, Loss 0.10497553646564484\n",
            "Train step - Step 0, Loss 0.09192439168691635\n",
            "Train step - Step 0, Loss 0.10566402226686478\n",
            "Train step - Step 0, Loss 0.09992703795433044\n",
            "Train step - Step 0, Loss 0.10423363745212555\n",
            "Train step - Step 0, Loss 0.11057381331920624\n",
            "Train step - Step 0, Loss 0.10691572725772858\n",
            "Train step - Step 0, Loss 0.1034243106842041\n",
            "Train step - Step 0, Loss 0.10562023520469666\n",
            "Train step - Step 0, Loss 0.10263831168413162\n",
            "Train step - Step 0, Loss 0.09515274316072464\n",
            "Train step - Step 0, Loss 0.09556476771831512\n",
            "Train step - Step 0, Loss 0.10252071917057037\n",
            "Train step - Step 0, Loss 0.10706572979688644\n",
            "Train step - Step 0, Loss 0.09958665817975998\n",
            "Train epoch - Accuracy: 0.4856060606060606 Loss: 0.101767907374435 Corrects: 5769\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.10208045691251755\n",
            "Train step - Step 0, Loss 0.10376667976379395\n",
            "Train step - Step 0, Loss 0.10792409628629684\n",
            "Train step - Step 0, Loss 0.09723005443811417\n",
            "Train step - Step 0, Loss 0.10269366949796677\n",
            "Train step - Step 0, Loss 0.10450291633605957\n",
            "Train step - Step 0, Loss 0.10443802177906036\n",
            "Train step - Step 0, Loss 0.09966066479682922\n",
            "Train step - Step 0, Loss 0.10279843956232071\n",
            "Train step - Step 0, Loss 0.10416111350059509\n",
            "Train step - Step 0, Loss 0.10591728985309601\n",
            "Train step - Step 0, Loss 0.10455773025751114\n",
            "Train step - Step 0, Loss 0.10025335848331451\n",
            "Train step - Step 0, Loss 0.09535346925258636\n",
            "Train step - Step 0, Loss 0.10697093605995178\n",
            "Train step - Step 0, Loss 0.10779567807912827\n",
            "Train epoch - Accuracy: 0.48383838383838385 Loss: 0.10297135326898459 Corrects: 5748\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.10263263434171677\n",
            "Train step - Step 0, Loss 0.10892902314662933\n",
            "Train step - Step 0, Loss 0.10508240759372711\n",
            "Train step - Step 0, Loss 0.09813889861106873\n",
            "Train step - Step 0, Loss 0.09885313361883163\n",
            "Train step - Step 0, Loss 0.09838984161615372\n",
            "Train step - Step 0, Loss 0.10595143586397171\n",
            "Train step - Step 0, Loss 0.10445374995470047\n",
            "Train step - Step 0, Loss 0.09555484354496002\n",
            "Train step - Step 0, Loss 0.10447032004594803\n",
            "Train step - Step 0, Loss 0.1052519902586937\n",
            "Train step - Step 0, Loss 0.10309336334466934\n",
            "Train step - Step 0, Loss 0.10422246903181076\n",
            "Train step - Step 0, Loss 0.10332059115171432\n",
            "Train step - Step 0, Loss 0.09778013825416565\n",
            "Train step - Step 0, Loss 0.10535745322704315\n",
            "Train epoch - Accuracy: 0.490993265993266 Loss: 0.10249769028389093 Corrects: 5833\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.10811799764633179\n",
            "Train step - Step 0, Loss 0.09685496240854263\n",
            "Train step - Step 0, Loss 0.10800677537918091\n",
            "Train step - Step 0, Loss 0.10006188601255417\n",
            "Train step - Step 0, Loss 0.10058962553739548\n",
            "Train step - Step 0, Loss 0.10665707290172577\n",
            "Train step - Step 0, Loss 0.09850972890853882\n",
            "Train step - Step 0, Loss 0.1007298082113266\n",
            "Train step - Step 0, Loss 0.10637987405061722\n",
            "Train step - Step 0, Loss 0.09685464948415756\n",
            "Train step - Step 0, Loss 0.09549015760421753\n",
            "Train step - Step 0, Loss 0.100914366543293\n",
            "Train step - Step 0, Loss 0.1115085706114769\n",
            "Train step - Step 0, Loss 0.10843777656555176\n",
            "Train step - Step 0, Loss 0.10049726814031601\n",
            "Train step - Step 0, Loss 0.09914758801460266\n",
            "Train epoch - Accuracy: 0.5 Loss: 0.10253484941492177 Corrects: 5940\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.10302623361349106\n",
            "Train step - Step 0, Loss 0.10383522510528564\n",
            "Train step - Step 0, Loss 0.09979134798049927\n",
            "Train step - Step 0, Loss 0.10845182836055756\n",
            "Train step - Step 0, Loss 0.10043268650770187\n",
            "Train step - Step 0, Loss 0.09946167469024658\n",
            "Train step - Step 0, Loss 0.10399740189313889\n",
            "Train step - Step 0, Loss 0.10735499113798141\n",
            "Train step - Step 0, Loss 0.09816297143697739\n",
            "Train step - Step 0, Loss 0.09882582724094391\n",
            "Train step - Step 0, Loss 0.09673034399747849\n",
            "Train step - Step 0, Loss 0.10378670692443848\n",
            "Train step - Step 0, Loss 0.10585896670818329\n",
            "Train step - Step 0, Loss 0.10154122859239578\n",
            "Train step - Step 0, Loss 0.1107291579246521\n",
            "Train step - Step 0, Loss 0.09486540406942368\n",
            "Train epoch - Accuracy: 0.48282828282828283 Loss: 0.10255869092664334 Corrects: 5736\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.10100587457418442\n",
            "Train step - Step 0, Loss 0.10353107005357742\n",
            "Train step - Step 0, Loss 0.0971846729516983\n",
            "Train step - Step 0, Loss 0.09882856905460358\n",
            "Train step - Step 0, Loss 0.10327986627817154\n",
            "Train step - Step 0, Loss 0.09981435537338257\n",
            "Train step - Step 0, Loss 0.09956499934196472\n",
            "Train step - Step 0, Loss 0.1003681868314743\n",
            "Train step - Step 0, Loss 0.10028387606143951\n",
            "Train step - Step 0, Loss 0.1088535338640213\n",
            "Train step - Step 0, Loss 0.1042790412902832\n",
            "Train step - Step 0, Loss 0.10236848145723343\n",
            "Train step - Step 0, Loss 0.10491375625133514\n",
            "Train step - Step 0, Loss 0.1007717028260231\n",
            "Train step - Step 0, Loss 0.10064379870891571\n",
            "Train step - Step 0, Loss 0.1052599847316742\n",
            "Train epoch - Accuracy: 0.4951178451178451 Loss: 0.10182027654214339 Corrects: 5882\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.10071983933448792\n",
            "Train step - Step 0, Loss 0.10862530767917633\n",
            "Train step - Step 0, Loss 0.10175322741270065\n",
            "Train step - Step 0, Loss 0.1005924642086029\n",
            "Train step - Step 0, Loss 0.10296260565519333\n",
            "Train step - Step 0, Loss 0.10300036519765854\n",
            "Train step - Step 0, Loss 0.10509739071130753\n",
            "Train step - Step 0, Loss 0.10109898447990417\n",
            "Train step - Step 0, Loss 0.10368985682725906\n",
            "Train step - Step 0, Loss 0.10690311342477798\n",
            "Train step - Step 0, Loss 0.09914007782936096\n",
            "Train step - Step 0, Loss 0.10547444224357605\n",
            "Train step - Step 0, Loss 0.09666126221418381\n",
            "Train step - Step 0, Loss 0.10167074203491211\n",
            "Train step - Step 0, Loss 0.10004804283380508\n",
            "Train step - Step 0, Loss 0.09455837309360504\n",
            "Train epoch - Accuracy: 0.4887205387205387 Loss: 0.10225531859229309 Corrects: 5806\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.10359653830528259\n",
            "Train step - Step 0, Loss 0.10880796611309052\n",
            "Train step - Step 0, Loss 0.0995233803987503\n",
            "Train step - Step 0, Loss 0.1032155379652977\n",
            "Train step - Step 0, Loss 0.10462920367717743\n",
            "Train step - Step 0, Loss 0.10360892117023468\n",
            "Train step - Step 0, Loss 0.10647699981927872\n",
            "Train step - Step 0, Loss 0.10311302542686462\n",
            "Train step - Step 0, Loss 0.1040039211511612\n",
            "Train step - Step 0, Loss 0.09900044649839401\n",
            "Train step - Step 0, Loss 0.09556546062231064\n",
            "Train step - Step 0, Loss 0.1035977378487587\n",
            "Train step - Step 0, Loss 0.09803891181945801\n",
            "Train step - Step 0, Loss 0.09883774816989899\n",
            "Train step - Step 0, Loss 0.1012248769402504\n",
            "Train step - Step 0, Loss 0.10682889819145203\n",
            "Train epoch - Accuracy: 0.49082491582491583 Loss: 0.1023558284899201 Corrects: 5831\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.092557393014431\n",
            "Train step - Step 0, Loss 0.09761815518140793\n",
            "Train step - Step 0, Loss 0.10471055656671524\n",
            "Train step - Step 0, Loss 0.10515333712100983\n",
            "Train step - Step 0, Loss 0.10100188851356506\n",
            "Train step - Step 0, Loss 0.10523368418216705\n",
            "Train step - Step 0, Loss 0.10310754179954529\n",
            "Train step - Step 0, Loss 0.10170087963342667\n",
            "Train step - Step 0, Loss 0.09942328184843063\n",
            "Train step - Step 0, Loss 0.10014533996582031\n",
            "Train step - Step 0, Loss 0.09986542910337448\n",
            "Train step - Step 0, Loss 0.09693177789449692\n",
            "Train step - Step 0, Loss 0.1051635667681694\n",
            "Train step - Step 0, Loss 0.10289088636636734\n",
            "Train step - Step 0, Loss 0.10462944209575653\n",
            "Train step - Step 0, Loss 0.10230814665555954\n",
            "Train epoch - Accuracy: 0.49924242424242427 Loss: 0.10137148145774398 Corrects: 5931\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.10207942873239517\n",
            "Train step - Step 0, Loss 0.09846639633178711\n",
            "Train step - Step 0, Loss 0.09780807793140411\n",
            "Train step - Step 0, Loss 0.10658378899097443\n",
            "Train step - Step 0, Loss 0.09892453253269196\n",
            "Train step - Step 0, Loss 0.09958784282207489\n",
            "Train step - Step 0, Loss 0.10358140617609024\n",
            "Train step - Step 0, Loss 0.104567751288414\n",
            "Train step - Step 0, Loss 0.09485392272472382\n",
            "Train step - Step 0, Loss 0.09836527705192566\n",
            "Train step - Step 0, Loss 0.09684333205223083\n",
            "Train step - Step 0, Loss 0.09874051809310913\n",
            "Train step - Step 0, Loss 0.09455467760562897\n",
            "Train step - Step 0, Loss 0.10462235659360886\n",
            "Train step - Step 0, Loss 0.10578737407922745\n",
            "Train step - Step 0, Loss 0.10719436407089233\n",
            "Train epoch - Accuracy: 0.48914141414141415 Loss: 0.10056494811568598 Corrects: 5811\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.1004752367734909\n",
            "Train step - Step 0, Loss 0.10067615658044815\n",
            "Train step - Step 0, Loss 0.1118297427892685\n",
            "Train step - Step 0, Loss 0.09990844875574112\n",
            "Train step - Step 0, Loss 0.09317881613969803\n",
            "Train step - Step 0, Loss 0.10478197783231735\n",
            "Train step - Step 0, Loss 0.10560472309589386\n",
            "Train step - Step 0, Loss 0.10190893709659576\n",
            "Train step - Step 0, Loss 0.09931157529354095\n",
            "Train step - Step 0, Loss 0.09757714718580246\n",
            "Train step - Step 0, Loss 0.09758894145488739\n",
            "Train step - Step 0, Loss 0.10146975517272949\n",
            "Train step - Step 0, Loss 0.09806660562753677\n",
            "Train step - Step 0, Loss 0.10090609639883041\n",
            "Train step - Step 0, Loss 0.10188192129135132\n",
            "Train step - Step 0, Loss 0.10547944158315659\n",
            "Train epoch - Accuracy: 0.49713804713804716 Loss: 0.10114647723508603 Corrects: 5906\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.10416729748249054\n",
            "Train step - Step 0, Loss 0.09472229331731796\n",
            "Train step - Step 0, Loss 0.10654577612876892\n",
            "Train step - Step 0, Loss 0.10038109123706818\n",
            "Train step - Step 0, Loss 0.097153440117836\n",
            "Train step - Step 0, Loss 0.10058064013719559\n",
            "Train step - Step 0, Loss 0.10153096914291382\n",
            "Train step - Step 0, Loss 0.1000346913933754\n",
            "Train step - Step 0, Loss 0.10005995631217957\n",
            "Train step - Step 0, Loss 0.09488039463758469\n",
            "Train step - Step 0, Loss 0.10144778341054916\n",
            "Train step - Step 0, Loss 0.09671596437692642\n",
            "Train step - Step 0, Loss 0.09956643730401993\n",
            "Train step - Step 0, Loss 0.10883331298828125\n",
            "Train step - Step 0, Loss 0.10611681640148163\n",
            "Train step - Step 0, Loss 0.10841003060340881\n",
            "Train epoch - Accuracy: 0.49132996632996634 Loss: 0.10107824266558946 Corrects: 5837\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.09685295075178146\n",
            "Train step - Step 0, Loss 0.10685195028781891\n",
            "Train step - Step 0, Loss 0.10095153748989105\n",
            "Train step - Step 0, Loss 0.10231518745422363\n",
            "Train step - Step 0, Loss 0.10082753747701645\n",
            "Train step - Step 0, Loss 0.0955168604850769\n",
            "Train step - Step 0, Loss 0.1007351279258728\n",
            "Train step - Step 0, Loss 0.10466504842042923\n",
            "Train step - Step 0, Loss 0.09722985327243805\n",
            "Train step - Step 0, Loss 0.10700732469558716\n",
            "Train step - Step 0, Loss 0.0992637425661087\n",
            "Train step - Step 0, Loss 0.10573042184114456\n",
            "Train step - Step 0, Loss 0.11118955165147781\n",
            "Train step - Step 0, Loss 0.090535968542099\n",
            "Train step - Step 0, Loss 0.10222112387418747\n",
            "Train step - Step 0, Loss 0.09988965839147568\n",
            "Train epoch - Accuracy: 0.4941077441077441 Loss: 0.10141203808363038 Corrects: 5870\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.09591378271579742\n",
            "Train step - Step 0, Loss 0.1013476699590683\n",
            "Train step - Step 0, Loss 0.10416226089000702\n",
            "Train step - Step 0, Loss 0.09622953087091446\n",
            "Train step - Step 0, Loss 0.10363070666790009\n",
            "Train step - Step 0, Loss 0.09938257187604904\n",
            "Train step - Step 0, Loss 0.09939361363649368\n",
            "Train step - Step 0, Loss 0.10004346072673798\n",
            "Train step - Step 0, Loss 0.09913314133882523\n",
            "Train step - Step 0, Loss 0.10334167629480362\n",
            "Train step - Step 0, Loss 0.10680647939443588\n",
            "Train step - Step 0, Loss 0.1002860739827156\n",
            "Train step - Step 0, Loss 0.10218813270330429\n",
            "Train step - Step 0, Loss 0.10034841299057007\n",
            "Train step - Step 0, Loss 0.1089794933795929\n",
            "Train step - Step 0, Loss 0.09352395683526993\n",
            "Train epoch - Accuracy: 0.4935185185185185 Loss: 0.10117342139434332 Corrects: 5863\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.10649029910564423\n",
            "Train step - Step 0, Loss 0.09886665642261505\n",
            "Train step - Step 0, Loss 0.09974361211061478\n",
            "Train step - Step 0, Loss 0.10096431523561478\n",
            "Train step - Step 0, Loss 0.1081257238984108\n",
            "Train step - Step 0, Loss 0.0906810387969017\n",
            "Train step - Step 0, Loss 0.10054942220449448\n",
            "Train step - Step 0, Loss 0.1018223762512207\n",
            "Train step - Step 0, Loss 0.10162760317325592\n",
            "Train step - Step 0, Loss 0.10479113459587097\n",
            "Train step - Step 0, Loss 0.0998174250125885\n",
            "Train step - Step 0, Loss 0.10808002948760986\n",
            "Train step - Step 0, Loss 0.09976308792829514\n",
            "Train step - Step 0, Loss 0.0959538146853447\n",
            "Train step - Step 0, Loss 0.09357427060604095\n",
            "Train step - Step 0, Loss 0.09668672829866409\n",
            "Train epoch - Accuracy: 0.4911616161616162 Loss: 0.10060106430089835 Corrects: 5835\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.10581881552934647\n",
            "Train step - Step 0, Loss 0.10520115494728088\n",
            "Train step - Step 0, Loss 0.0994824469089508\n",
            "Train step - Step 0, Loss 0.10054147988557816\n",
            "Train step - Step 0, Loss 0.10392554104328156\n",
            "Train step - Step 0, Loss 0.1084466427564621\n",
            "Train step - Step 0, Loss 0.0992293730378151\n",
            "Train step - Step 0, Loss 0.09791484475135803\n",
            "Train step - Step 0, Loss 0.10556802153587341\n",
            "Train step - Step 0, Loss 0.10320525616407394\n",
            "Train step - Step 0, Loss 0.09794862568378448\n",
            "Train step - Step 0, Loss 0.09742654114961624\n",
            "Train step - Step 0, Loss 0.09638821333646774\n",
            "Train step - Step 0, Loss 0.0966903567314148\n",
            "Train step - Step 0, Loss 0.09996195882558823\n",
            "Train step - Step 0, Loss 0.09647338837385178\n",
            "Train epoch - Accuracy: 0.49747474747474746 Loss: 0.10104056068442084 Corrects: 5910\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.10763148218393326\n",
            "Train step - Step 0, Loss 0.10112860053777695\n",
            "Train step - Step 0, Loss 0.10049498826265335\n",
            "Train step - Step 0, Loss 0.09977162629365921\n",
            "Train step - Step 0, Loss 0.10347428172826767\n",
            "Train step - Step 0, Loss 0.09818034619092941\n",
            "Train step - Step 0, Loss 0.09834634512662888\n",
            "Train step - Step 0, Loss 0.1006297692656517\n",
            "Train step - Step 0, Loss 0.10167732834815979\n",
            "Train step - Step 0, Loss 0.09518598020076752\n",
            "Train step - Step 0, Loss 0.09463043510913849\n",
            "Train step - Step 0, Loss 0.10533685982227325\n",
            "Train step - Step 0, Loss 0.09226010739803314\n",
            "Train step - Step 0, Loss 0.10386203229427338\n",
            "Train step - Step 0, Loss 0.10048627853393555\n",
            "Train step - Step 0, Loss 0.10405325144529343\n",
            "Train epoch - Accuracy: 0.49175084175084177 Loss: 0.10032300107707881 Corrects: 5842\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.10400136560201645\n",
            "Train step - Step 0, Loss 0.09656287729740143\n",
            "Train step - Step 0, Loss 0.09982266277074814\n",
            "Train step - Step 0, Loss 0.09900625050067902\n",
            "Train step - Step 0, Loss 0.09820365905761719\n",
            "Train step - Step 0, Loss 0.0964846983551979\n",
            "Train step - Step 0, Loss 0.09387615323066711\n",
            "Train step - Step 0, Loss 0.10738082975149155\n",
            "Train step - Step 0, Loss 0.10101621598005295\n",
            "Train step - Step 0, Loss 0.10218154639005661\n",
            "Train step - Step 0, Loss 0.1013362780213356\n",
            "Train step - Step 0, Loss 0.09840904921293259\n",
            "Train step - Step 0, Loss 0.10371270030736923\n",
            "Train step - Step 0, Loss 0.09588703513145447\n",
            "Train step - Step 0, Loss 0.0909198448061943\n",
            "Train step - Step 0, Loss 0.10412873327732086\n",
            "Train epoch - Accuracy: 0.4911616161616162 Loss: 0.09940114813019531 Corrects: 5835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.56 0.12090732902288437\n",
            "TEST GROUP:  0.587\n",
            "TEST ALL:  0.6433333333333333\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  4000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [97, 95, 68, 64, 56, 42, 36, 34, 32, 30, 24, 22, 20, 18, 16, 10, 6, 4, 2, 72, 76, 80, 61, 83, 81, 79, 75, 67, 65, 63, 59, 82, 49, 47, 39, 23, 21, 7, 90, 0]\n",
            "TRAIN_SET CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "VALIDATION CLASSES:  [63, 42, 36, 97, 95, 30, 83, 72, 6, 2]\n",
            "GROUP:  4\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  40\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.27104392647743225\n",
            "Train step - Step 10, Loss 0.15608878433704376\n",
            "Train step - Step 20, Loss 0.1412857323884964\n",
            "Train step - Step 30, Loss 0.137394979596138\n",
            "Train step - Step 40, Loss 0.13113842904567719\n",
            "Train step - Step 50, Loss 0.132715106010437\n",
            "Train epoch - Accuracy: 0.23116883116883116 Loss: 0.15121370451618926 Corrects: 1602\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.12849323451519012\n",
            "Train step - Step 70, Loss 0.13137739896774292\n",
            "Train step - Step 80, Loss 0.12553651630878448\n",
            "Train step - Step 90, Loss 0.1266622394323349\n",
            "Train step - Step 100, Loss 0.12371938675642014\n",
            "Train epoch - Accuracy: 0.27936507936507937 Loss: 0.12686303927096798 Corrects: 1936\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.12536972761154175\n",
            "Train step - Step 120, Loss 0.11982672661542892\n",
            "Train step - Step 130, Loss 0.12111399322748184\n",
            "Train step - Step 140, Loss 0.1267518252134323\n",
            "Train step - Step 150, Loss 0.12251835316419601\n",
            "Train step - Step 160, Loss 0.12562040984630585\n",
            "Train epoch - Accuracy: 0.31284271284271287 Loss: 0.12308012453938631 Corrects: 2168\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.12795524299144745\n",
            "Train step - Step 180, Loss 0.12514325976371765\n",
            "Train step - Step 190, Loss 0.12368743866682053\n",
            "Train step - Step 200, Loss 0.1223849281668663\n",
            "Train step - Step 210, Loss 0.12050073593854904\n",
            "Train epoch - Accuracy: 0.3512265512265512 Loss: 0.12123770079700462 Corrects: 2434\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.11993461102247238\n",
            "Train step - Step 230, Loss 0.12628372013568878\n",
            "Train step - Step 240, Loss 0.11477722227573395\n",
            "Train step - Step 250, Loss 0.1179899200797081\n",
            "Train step - Step 260, Loss 0.11490609496831894\n",
            "Train step - Step 270, Loss 0.12038766592741013\n",
            "Train epoch - Accuracy: 0.3704184704184704 Loss: 0.11996948819655877 Corrects: 2567\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.116268090903759\n",
            "Train step - Step 290, Loss 0.12255840748548508\n",
            "Train step - Step 300, Loss 0.12030110508203506\n",
            "Train step - Step 310, Loss 0.1171637773513794\n",
            "Train step - Step 320, Loss 0.1216668114066124\n",
            "Train epoch - Accuracy: 0.3935064935064935 Loss: 0.11906384312659286 Corrects: 2727\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.1200694590806961\n",
            "Train step - Step 340, Loss 0.1131356731057167\n",
            "Train step - Step 350, Loss 0.11453612893819809\n",
            "Train step - Step 360, Loss 0.12127017974853516\n",
            "Train step - Step 370, Loss 0.11514774709939957\n",
            "Train step - Step 380, Loss 0.12047334015369415\n",
            "Train epoch - Accuracy: 0.413997113997114 Loss: 0.11801425307817101 Corrects: 2869\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11338579654693604\n",
            "Train step - Step 400, Loss 0.12080025672912598\n",
            "Train step - Step 410, Loss 0.1173001304268837\n",
            "Train step - Step 420, Loss 0.11678647994995117\n",
            "Train step - Step 430, Loss 0.11592104285955429\n",
            "Train epoch - Accuracy: 0.4236652236652237 Loss: 0.11733451212553407 Corrects: 2936\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.11583735793828964\n",
            "Train step - Step 450, Loss 0.11755430698394775\n",
            "Train step - Step 460, Loss 0.11573611944913864\n",
            "Train step - Step 470, Loss 0.12065499275922775\n",
            "Train step - Step 480, Loss 0.1178225502371788\n",
            "Train step - Step 490, Loss 0.11420255154371262\n",
            "Train epoch - Accuracy: 0.44083694083694086 Loss: 0.11693277029162018 Corrects: 3055\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.11617765575647354\n",
            "Train step - Step 510, Loss 0.11362774670124054\n",
            "Train step - Step 520, Loss 0.11905514448881149\n",
            "Train step - Step 530, Loss 0.11942072212696075\n",
            "Train step - Step 540, Loss 0.11538437753915787\n",
            "Train epoch - Accuracy: 0.4458874458874459 Loss: 0.11630238918170957 Corrects: 3090\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.11010005325078964\n",
            "Train step - Step 560, Loss 0.11298193782567978\n",
            "Train step - Step 570, Loss 0.11773087084293365\n",
            "Train step - Step 580, Loss 0.11761223524808884\n",
            "Train step - Step 590, Loss 0.11583280563354492\n",
            "Train step - Step 600, Loss 0.1199633851647377\n",
            "Train epoch - Accuracy: 0.4658008658008658 Loss: 0.11604718819239095 Corrects: 3228\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.11208216100931168\n",
            "Train step - Step 620, Loss 0.11117470264434814\n",
            "Train step - Step 630, Loss 0.11038427799940109\n",
            "Train step - Step 640, Loss 0.11706526577472687\n",
            "Train step - Step 650, Loss 0.1137852594256401\n",
            "Train epoch - Accuracy: 0.4652236652236652 Loss: 0.1156575471162796 Corrects: 3224\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.1122342124581337\n",
            "Train step - Step 670, Loss 0.1155657097697258\n",
            "Train step - Step 680, Loss 0.11753944307565689\n",
            "Train step - Step 690, Loss 0.11572469770908356\n",
            "Train step - Step 700, Loss 0.11477050930261612\n",
            "Train step - Step 710, Loss 0.11770863831043243\n",
            "Train epoch - Accuracy: 0.481962481962482 Loss: 0.1148594584923458 Corrects: 3340\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.1182151809334755\n",
            "Train step - Step 730, Loss 0.12181484699249268\n",
            "Train step - Step 740, Loss 0.11615407466888428\n",
            "Train step - Step 750, Loss 0.11132019758224487\n",
            "Train step - Step 760, Loss 0.10968047380447388\n",
            "Train epoch - Accuracy: 0.48744588744588746 Loss: 0.11426237278858477 Corrects: 3378\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.112046979367733\n",
            "Train step - Step 780, Loss 0.11258204281330109\n",
            "Train step - Step 790, Loss 0.1133345514535904\n",
            "Train step - Step 800, Loss 0.11493077129125595\n",
            "Train step - Step 810, Loss 0.11485973745584488\n",
            "Train step - Step 820, Loss 0.11024262011051178\n",
            "Train epoch - Accuracy: 0.49134199134199136 Loss: 0.11460460840279578 Corrects: 3405\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.11729466170072556\n",
            "Train step - Step 840, Loss 0.11446785926818848\n",
            "Train step - Step 850, Loss 0.114474356174469\n",
            "Train step - Step 860, Loss 0.11160603910684586\n",
            "Train step - Step 870, Loss 0.1124824658036232\n",
            "Train epoch - Accuracy: 0.49956709956709955 Loss: 0.11427238116532693 Corrects: 3462\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.11798494309186935\n",
            "Train step - Step 890, Loss 0.10777430981397629\n",
            "Train step - Step 900, Loss 0.10979034006595612\n",
            "Train step - Step 910, Loss 0.10629899799823761\n",
            "Train step - Step 920, Loss 0.10999446362257004\n",
            "Train step - Step 930, Loss 0.1170726791024208\n",
            "Train epoch - Accuracy: 0.501010101010101 Loss: 0.11336369729489303 Corrects: 3472\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.113150954246521\n",
            "Train step - Step 950, Loss 0.1070767194032669\n",
            "Train step - Step 960, Loss 0.10690388828516006\n",
            "Train step - Step 970, Loss 0.11466043442487717\n",
            "Train step - Step 980, Loss 0.11422785371541977\n",
            "Train epoch - Accuracy: 0.5135642135642136 Loss: 0.11309839244958814 Corrects: 3559\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.11167361587285995\n",
            "Train step - Step 1000, Loss 0.11451005190610886\n",
            "Train step - Step 1010, Loss 0.10775623470544815\n",
            "Train step - Step 1020, Loss 0.11375148594379425\n",
            "Train step - Step 1030, Loss 0.10961587727069855\n",
            "Train step - Step 1040, Loss 0.11097393184900284\n",
            "Train epoch - Accuracy: 0.5163059163059163 Loss: 0.11253063809045981 Corrects: 3578\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10620417445898056\n",
            "Train step - Step 1060, Loss 0.11644585430622101\n",
            "Train step - Step 1070, Loss 0.11734515428543091\n",
            "Train step - Step 1080, Loss 0.10868018865585327\n",
            "Train step - Step 1090, Loss 0.1065589189529419\n",
            "Train epoch - Accuracy: 0.5209235209235209 Loss: 0.11297520019791343 Corrects: 3610\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.11845862865447998\n",
            "Train step - Step 1110, Loss 0.10798349231481552\n",
            "Train step - Step 1120, Loss 0.11332274973392487\n",
            "Train step - Step 1130, Loss 0.1128445491194725\n",
            "Train step - Step 1140, Loss 0.10798295587301254\n",
            "Train step - Step 1150, Loss 0.11552270501852036\n",
            "Train epoch - Accuracy: 0.5380952380952381 Loss: 0.11238608940640225 Corrects: 3729\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11472933739423752\n",
            "Train step - Step 1170, Loss 0.10669989883899689\n",
            "Train step - Step 1180, Loss 0.1187811866402626\n",
            "Train step - Step 1190, Loss 0.11069478839635849\n",
            "Train step - Step 1200, Loss 0.11056504398584366\n",
            "Train epoch - Accuracy: 0.5402597402597402 Loss: 0.11238664613141643 Corrects: 3744\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.11694636195898056\n",
            "Train step - Step 1220, Loss 0.11475005000829697\n",
            "Train step - Step 1230, Loss 0.11359152942895889\n",
            "Train step - Step 1240, Loss 0.11223985999822617\n",
            "Train step - Step 1250, Loss 0.11212711781263351\n",
            "Train step - Step 1260, Loss 0.10685151070356369\n",
            "Train epoch - Accuracy: 0.5458874458874459 Loss: 0.11210424213268368 Corrects: 3783\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.11606772243976593\n",
            "Train step - Step 1280, Loss 0.1077202782034874\n",
            "Train step - Step 1290, Loss 0.10684412717819214\n",
            "Train step - Step 1300, Loss 0.11385359615087509\n",
            "Train step - Step 1310, Loss 0.11129369586706161\n",
            "Train epoch - Accuracy: 0.5453102453102453 Loss: 0.11153948124697026 Corrects: 3779\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.1175394058227539\n",
            "Train step - Step 1330, Loss 0.10923121124505997\n",
            "Train step - Step 1340, Loss 0.11076299101114273\n",
            "Train step - Step 1350, Loss 0.10691504925489426\n",
            "Train step - Step 1360, Loss 0.10743539780378342\n",
            "Train step - Step 1370, Loss 0.10753075033426285\n",
            "Train epoch - Accuracy: 0.5451659451659452 Loss: 0.11146395384061217 Corrects: 3778\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10357172787189484\n",
            "Train step - Step 1390, Loss 0.11004316806793213\n",
            "Train step - Step 1400, Loss 0.11101561039686203\n",
            "Train step - Step 1410, Loss 0.10368654876947403\n",
            "Train step - Step 1420, Loss 0.1083623394370079\n",
            "Train epoch - Accuracy: 0.5564213564213564 Loss: 0.11100010307664307 Corrects: 3856\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.1049104705452919\n",
            "Train step - Step 1440, Loss 0.11049788445234299\n",
            "Train step - Step 1450, Loss 0.1059141680598259\n",
            "Train step - Step 1460, Loss 0.10933675616979599\n",
            "Train step - Step 1470, Loss 0.11381693184375763\n",
            "Train step - Step 1480, Loss 0.10909094661474228\n",
            "Train epoch - Accuracy: 0.5633477633477634 Loss: 0.11086422179383461 Corrects: 3904\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10579244047403336\n",
            "Train step - Step 1500, Loss 0.11324746906757355\n",
            "Train step - Step 1510, Loss 0.116368368268013\n",
            "Train step - Step 1520, Loss 0.10762137174606323\n",
            "Train step - Step 1530, Loss 0.10914500802755356\n",
            "Train epoch - Accuracy: 0.5757575757575758 Loss: 0.1099949867049337 Corrects: 3990\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.10839271545410156\n",
            "Train step - Step 1550, Loss 0.11031029373407364\n",
            "Train step - Step 1560, Loss 0.10606582462787628\n",
            "Train step - Step 1570, Loss 0.11021178215742111\n",
            "Train step - Step 1580, Loss 0.10684054344892502\n",
            "Train step - Step 1590, Loss 0.10933931916952133\n",
            "Train epoch - Accuracy: 0.5705627705627706 Loss: 0.11010379367662543 Corrects: 3954\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.11139136552810669\n",
            "Train step - Step 1610, Loss 0.10899609327316284\n",
            "Train step - Step 1620, Loss 0.11172640323638916\n",
            "Train step - Step 1630, Loss 0.10753355175256729\n",
            "Train step - Step 1640, Loss 0.11125283688306808\n",
            "Train epoch - Accuracy: 0.5753246753246753 Loss: 0.11006340670035171 Corrects: 3987\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.11037319153547287\n",
            "Train step - Step 1660, Loss 0.11161525547504425\n",
            "Train step - Step 1670, Loss 0.11564864963293076\n",
            "Train step - Step 1680, Loss 0.11288910359144211\n",
            "Train step - Step 1690, Loss 0.11319243162870407\n",
            "Train step - Step 1700, Loss 0.10653986781835556\n",
            "Train epoch - Accuracy: 0.5808080808080808 Loss: 0.1097767502435014 Corrects: 4025\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.11352284252643585\n",
            "Train step - Step 1720, Loss 0.11214073747396469\n",
            "Train step - Step 1730, Loss 0.10947835445404053\n",
            "Train step - Step 1740, Loss 0.10708260536193848\n",
            "Train step - Step 1750, Loss 0.1031435877084732\n",
            "Train epoch - Accuracy: 0.5803751803751803 Loss: 0.1095359394367123 Corrects: 4022\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.1041855588555336\n",
            "Train step - Step 1770, Loss 0.10590004920959473\n",
            "Train step - Step 1780, Loss 0.10619281977415085\n",
            "Train step - Step 1790, Loss 0.10887753218412399\n",
            "Train step - Step 1800, Loss 0.11353099346160889\n",
            "Train step - Step 1810, Loss 0.10986413806676865\n",
            "Train epoch - Accuracy: 0.5836940836940837 Loss: 0.10951237469524532 Corrects: 4045\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.114026740193367\n",
            "Train step - Step 1830, Loss 0.10940814018249512\n",
            "Train step - Step 1840, Loss 0.11403629928827286\n",
            "Train step - Step 1850, Loss 0.11051791161298752\n",
            "Train step - Step 1860, Loss 0.11521921306848526\n",
            "Train epoch - Accuracy: 0.5894660894660895 Loss: 0.10940983906323776 Corrects: 4085\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.1165887713432312\n",
            "Train step - Step 1880, Loss 0.10617311298847198\n",
            "Train step - Step 1890, Loss 0.1075284481048584\n",
            "Train step - Step 1900, Loss 0.10457711666822433\n",
            "Train step - Step 1910, Loss 0.10492230951786041\n",
            "Train step - Step 1920, Loss 0.11071038246154785\n",
            "Train epoch - Accuracy: 0.5936507936507937 Loss: 0.10882724316261204 Corrects: 4114\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10929396003484726\n",
            "Train step - Step 1940, Loss 0.11671590805053711\n",
            "Train step - Step 1950, Loss 0.10615141689777374\n",
            "Train step - Step 1960, Loss 0.10887720435857773\n",
            "Train step - Step 1970, Loss 0.1071605235338211\n",
            "Train epoch - Accuracy: 0.6007215007215008 Loss: 0.10892017059253924 Corrects: 4163\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.11000459641218185\n",
            "Train step - Step 1990, Loss 0.10656855255365372\n",
            "Train step - Step 2000, Loss 0.11100637167692184\n",
            "Train step - Step 2010, Loss 0.10961013287305832\n",
            "Train step - Step 2020, Loss 0.10985050350427628\n",
            "Train step - Step 2030, Loss 0.10994942486286163\n",
            "Train epoch - Accuracy: 0.6108225108225108 Loss: 0.10847630116330596 Corrects: 4233\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10317535698413849\n",
            "Train step - Step 2050, Loss 0.10837917774915695\n",
            "Train step - Step 2060, Loss 0.10370035469532013\n",
            "Train step - Step 2070, Loss 0.11195135116577148\n",
            "Train step - Step 2080, Loss 0.1127108559012413\n",
            "Train epoch - Accuracy: 0.6109668109668109 Loss: 0.10792630713266384 Corrects: 4234\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.11320102214813232\n",
            "Train step - Step 2100, Loss 0.101641945540905\n",
            "Train step - Step 2110, Loss 0.1064830794930458\n",
            "Train step - Step 2120, Loss 0.10982701927423477\n",
            "Train step - Step 2130, Loss 0.11228080838918686\n",
            "Train step - Step 2140, Loss 0.10792344808578491\n",
            "Train epoch - Accuracy: 0.604040404040404 Loss: 0.10851754414355771 Corrects: 4186\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.10310915857553482\n",
            "Train step - Step 2160, Loss 0.10228049010038376\n",
            "Train step - Step 2170, Loss 0.10967733711004257\n",
            "Train step - Step 2180, Loss 0.10953541845083237\n",
            "Train step - Step 2190, Loss 0.11106906086206436\n",
            "Train epoch - Accuracy: 0.6121212121212121 Loss: 0.1081861051001074 Corrects: 4242\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.11372983455657959\n",
            "Train step - Step 2210, Loss 0.10886066406965256\n",
            "Train step - Step 2220, Loss 0.10732879489660263\n",
            "Train step - Step 2230, Loss 0.11306591331958771\n",
            "Train step - Step 2240, Loss 0.11203863471746445\n",
            "Train step - Step 2250, Loss 0.11066430062055588\n",
            "Train epoch - Accuracy: 0.6212121212121212 Loss: 0.1075781075512348 Corrects: 4305\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10357141494750977\n",
            "Train step - Step 2270, Loss 0.10507416725158691\n",
            "Train step - Step 2280, Loss 0.10648792237043381\n",
            "Train step - Step 2290, Loss 0.1037742868065834\n",
            "Train step - Step 2300, Loss 0.09851666539907455\n",
            "Train epoch - Accuracy: 0.6212121212121212 Loss: 0.10763943255979777 Corrects: 4305\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.1082448959350586\n",
            "Train step - Step 2320, Loss 0.10844137519598007\n",
            "Train step - Step 2330, Loss 0.10931988060474396\n",
            "Train step - Step 2340, Loss 0.10601546615362167\n",
            "Train step - Step 2350, Loss 0.11131035536527634\n",
            "Train step - Step 2360, Loss 0.10639909654855728\n",
            "Train epoch - Accuracy: 0.6291486291486291 Loss: 0.10708611119232136 Corrects: 4360\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.10760229825973511\n",
            "Train step - Step 2380, Loss 0.10271506756544113\n",
            "Train step - Step 2390, Loss 0.10841353237628937\n",
            "Train step - Step 2400, Loss 0.10817787796258926\n",
            "Train step - Step 2410, Loss 0.10687383264303207\n",
            "Train epoch - Accuracy: 0.6329004329004329 Loss: 0.10689467678510438 Corrects: 4386\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.11006384342908859\n",
            "Train step - Step 2430, Loss 0.10974431037902832\n",
            "Train step - Step 2440, Loss 0.10737492889165878\n",
            "Train step - Step 2450, Loss 0.1120491549372673\n",
            "Train step - Step 2460, Loss 0.10299402475357056\n",
            "Train step - Step 2470, Loss 0.10632403939962387\n",
            "Train epoch - Accuracy: 0.6256854256854257 Loss: 0.10682309585130231 Corrects: 4336\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.11002307385206223\n",
            "Train step - Step 2490, Loss 0.1036837249994278\n",
            "Train step - Step 2500, Loss 0.10604455322027206\n",
            "Train step - Step 2510, Loss 0.10651390999555588\n",
            "Train step - Step 2520, Loss 0.11097166687250137\n",
            "Train epoch - Accuracy: 0.6343434343434343 Loss: 0.10667127087002709 Corrects: 4396\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10958540439605713\n",
            "Train step - Step 2540, Loss 0.10542743653059006\n",
            "Train step - Step 2550, Loss 0.1094154641032219\n",
            "Train step - Step 2560, Loss 0.10919719189405441\n",
            "Train step - Step 2570, Loss 0.10474977642297745\n",
            "Train step - Step 2580, Loss 0.10918938368558884\n",
            "Train epoch - Accuracy: 0.6339105339105339 Loss: 0.10650059614131634 Corrects: 4393\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.11336340755224228\n",
            "Train step - Step 2600, Loss 0.10861455649137497\n",
            "Train step - Step 2610, Loss 0.1068694218993187\n",
            "Train step - Step 2620, Loss 0.10185866802930832\n",
            "Train step - Step 2630, Loss 0.1091616153717041\n",
            "Train epoch - Accuracy: 0.6405483405483405 Loss: 0.10635470681075238 Corrects: 4439\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10575832426548004\n",
            "Train step - Step 2650, Loss 0.10499017685651779\n",
            "Train step - Step 2660, Loss 0.10644068568944931\n",
            "Train step - Step 2670, Loss 0.10287237167358398\n",
            "Train step - Step 2680, Loss 0.11346836388111115\n",
            "Train step - Step 2690, Loss 0.10601164400577545\n",
            "Train epoch - Accuracy: 0.6509379509379509 Loss: 0.10596062758182206 Corrects: 4511\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10818209499120712\n",
            "Train step - Step 2710, Loss 0.09912236034870148\n",
            "Train step - Step 2720, Loss 0.10687599331140518\n",
            "Train step - Step 2730, Loss 0.1034243255853653\n",
            "Train step - Step 2740, Loss 0.10589080303907394\n",
            "Train epoch - Accuracy: 0.6476190476190476 Loss: 0.10436828569287346 Corrects: 4488\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.09810882806777954\n",
            "Train step - Step 2760, Loss 0.10393276065587997\n",
            "Train step - Step 2770, Loss 0.09497060626745224\n",
            "Train step - Step 2780, Loss 0.10382845252752304\n",
            "Train step - Step 2790, Loss 0.10063979774713516\n",
            "Train step - Step 2800, Loss 0.10028965771198273\n",
            "Train epoch - Accuracy: 0.6607503607503608 Loss: 0.10369445833808932 Corrects: 4579\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10350926220417023\n",
            "Train step - Step 2820, Loss 0.10361900180578232\n",
            "Train step - Step 2830, Loss 0.1037338376045227\n",
            "Train step - Step 2840, Loss 0.09867972135543823\n",
            "Train step - Step 2850, Loss 0.10661448538303375\n",
            "Train epoch - Accuracy: 0.6626262626262627 Loss: 0.1035868516194528 Corrects: 4592\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.10344939678907394\n",
            "Train step - Step 2870, Loss 0.10477013885974884\n",
            "Train step - Step 2880, Loss 0.1036943718791008\n",
            "Train step - Step 2890, Loss 0.10246949642896652\n",
            "Train step - Step 2900, Loss 0.09867670387029648\n",
            "Train step - Step 2910, Loss 0.09980849921703339\n",
            "Train epoch - Accuracy: 0.6633477633477634 Loss: 0.10372520857215099 Corrects: 4597\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10381962358951569\n",
            "Train step - Step 2930, Loss 0.1076519712805748\n",
            "Train step - Step 2940, Loss 0.09971115738153458\n",
            "Train step - Step 2950, Loss 0.1059868335723877\n",
            "Train step - Step 2960, Loss 0.10509438812732697\n",
            "Train epoch - Accuracy: 0.6653679653679654 Loss: 0.10369113769495127 Corrects: 4611\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.10631924122571945\n",
            "Train step - Step 2980, Loss 0.10521640628576279\n",
            "Train step - Step 2990, Loss 0.10125606507062912\n",
            "Train step - Step 3000, Loss 0.10639574378728867\n",
            "Train step - Step 3010, Loss 0.10337606817483902\n",
            "Train step - Step 3020, Loss 0.10142075270414352\n",
            "Train epoch - Accuracy: 0.6655122655122655 Loss: 0.10306272702815729 Corrects: 4612\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.1038265973329544\n",
            "Train step - Step 3040, Loss 0.10225718468427658\n",
            "Train step - Step 3050, Loss 0.09813843667507172\n",
            "Train step - Step 3060, Loss 0.1037178784608841\n",
            "Train step - Step 3070, Loss 0.10532629489898682\n",
            "Train epoch - Accuracy: 0.6626262626262627 Loss: 0.10334375151480087 Corrects: 4592\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.10378604382276535\n",
            "Train step - Step 3090, Loss 0.10045633465051651\n",
            "Train step - Step 3100, Loss 0.10148024559020996\n",
            "Train step - Step 3110, Loss 0.10349547117948532\n",
            "Train step - Step 3120, Loss 0.10769066959619522\n",
            "Train step - Step 3130, Loss 0.10710418224334717\n",
            "Train epoch - Accuracy: 0.6676767676767676 Loss: 0.10293200722590497 Corrects: 4627\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10445423424243927\n",
            "Train step - Step 3150, Loss 0.1027141809463501\n",
            "Train step - Step 3160, Loss 0.10315390676259995\n",
            "Train step - Step 3170, Loss 0.09909512102603912\n",
            "Train step - Step 3180, Loss 0.10718613117933273\n",
            "Train epoch - Accuracy: 0.6666666666666666 Loss: 0.10300427837160242 Corrects: 4620\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10167999565601349\n",
            "Train step - Step 3200, Loss 0.10274553298950195\n",
            "Train step - Step 3210, Loss 0.09911390393972397\n",
            "Train step - Step 3220, Loss 0.1017790362238884\n",
            "Train step - Step 3230, Loss 0.1060214638710022\n",
            "Train step - Step 3240, Loss 0.10338395088911057\n",
            "Train epoch - Accuracy: 0.6611832611832612 Loss: 0.10344345712601537 Corrects: 4582\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.10857035219669342\n",
            "Train step - Step 3260, Loss 0.10579223930835724\n",
            "Train step - Step 3270, Loss 0.10629858821630478\n",
            "Train step - Step 3280, Loss 0.10540368407964706\n",
            "Train step - Step 3290, Loss 0.10337119549512863\n",
            "Train epoch - Accuracy: 0.6683982683982684 Loss: 0.10350171993305157 Corrects: 4632\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.09916434437036514\n",
            "Train step - Step 3310, Loss 0.10660376399755478\n",
            "Train step - Step 3320, Loss 0.10753891617059708\n",
            "Train step - Step 3330, Loss 0.10315727442502975\n",
            "Train step - Step 3340, Loss 0.10331525653600693\n",
            "Train step - Step 3350, Loss 0.10612686723470688\n",
            "Train epoch - Accuracy: 0.66998556998557 Loss: 0.10308882310061916 Corrects: 4643\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.10818996280431747\n",
            "Train step - Step 3370, Loss 0.10182256996631622\n",
            "Train step - Step 3380, Loss 0.10364687442779541\n",
            "Train step - Step 3390, Loss 0.1018802672624588\n",
            "Train step - Step 3400, Loss 0.10414077341556549\n",
            "Train epoch - Accuracy: 0.6766233766233766 Loss: 0.10294028092686404 Corrects: 4689\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.1031670793890953\n",
            "Train step - Step 3420, Loss 0.10195793956518173\n",
            "Train step - Step 3430, Loss 0.10165121406316757\n",
            "Train step - Step 3440, Loss 0.10091135650873184\n",
            "Train step - Step 3450, Loss 0.09881007671356201\n",
            "Train step - Step 3460, Loss 0.10719098895788193\n",
            "Train epoch - Accuracy: 0.6707070707070707 Loss: 0.10309210975061764 Corrects: 4648\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.10226690769195557\n",
            "Train step - Step 3480, Loss 0.10209832340478897\n",
            "Train step - Step 3490, Loss 0.1019236370921135\n",
            "Train step - Step 3500, Loss 0.1003236174583435\n",
            "Train step - Step 3510, Loss 0.09954090416431427\n",
            "Train epoch - Accuracy: 0.6673881673881674 Loss: 0.10275256147374322 Corrects: 4625\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.10441070050001144\n",
            "Train step - Step 3530, Loss 0.10219456255435944\n",
            "Train step - Step 3540, Loss 0.09547946602106094\n",
            "Train step - Step 3550, Loss 0.09738423675298691\n",
            "Train step - Step 3560, Loss 0.09969061613082886\n",
            "Train step - Step 3570, Loss 0.10444078594446182\n",
            "Train epoch - Accuracy: 0.6705627705627706 Loss: 0.10275614665012167 Corrects: 4647\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.10107731074094772\n",
            "Train step - Step 3590, Loss 0.09695769846439362\n",
            "Train step - Step 3600, Loss 0.10112794488668442\n",
            "Train step - Step 3610, Loss 0.1048516035079956\n",
            "Train step - Step 3620, Loss 0.10295325517654419\n",
            "Train epoch - Accuracy: 0.6813852813852814 Loss: 0.102270335253613 Corrects: 4722\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09927041828632355\n",
            "Train step - Step 3640, Loss 0.10423123091459274\n",
            "Train step - Step 3650, Loss 0.0983852744102478\n",
            "Train step - Step 3660, Loss 0.09631817787885666\n",
            "Train step - Step 3670, Loss 0.10372652858495712\n",
            "Train step - Step 3680, Loss 0.10017044842243195\n",
            "Train epoch - Accuracy: 0.6761904761904762 Loss: 0.10237655133266986 Corrects: 4686\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.10136139392852783\n",
            "Train step - Step 3700, Loss 0.10243790596723557\n",
            "Train step - Step 3710, Loss 0.10879296064376831\n",
            "Train step - Step 3720, Loss 0.10489685833454132\n",
            "Train step - Step 3730, Loss 0.1025003120303154\n",
            "Train epoch - Accuracy: 0.6712842712842713 Loss: 0.10307903067030087 Corrects: 4652\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.10369076579809189\n",
            "Train step - Step 3750, Loss 0.10232429951429367\n",
            "Train step - Step 3760, Loss 0.10647517442703247\n",
            "Train step - Step 3770, Loss 0.09917130321264267\n",
            "Train step - Step 3780, Loss 0.10256019979715347\n",
            "Train step - Step 3790, Loss 0.10503280162811279\n",
            "Train epoch - Accuracy: 0.676046176046176 Loss: 0.10267707938368702 Corrects: 4685\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.09865116328001022\n",
            "Train step - Step 3810, Loss 0.10620154440402985\n",
            "Train step - Step 3820, Loss 0.10405852645635605\n",
            "Train step - Step 3830, Loss 0.10013014078140259\n",
            "Train step - Step 3840, Loss 0.10046090930700302\n",
            "Train epoch - Accuracy: 0.6746031746031746 Loss: 0.10241278311691931 Corrects: 4675\n",
            "Training finished in 451.59893441200256 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a243750>\n",
            "Constructing exemplars of class 95\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [6147, 43375, 29194, 28003, 3547, 14016, 25851, 894, 33499, 19816, 14626, 33380, 45887, 32805, 18669, 27078, 16623, 41176, 38447, 48204, 14203, 13170, 46459, 15787, 5579, 16769, 37254, 9851, 28170, 25851, 2899, 1498, 34789, 29358, 13640, 36621, 40704, 9249, 36539, 43178, 34558, 16337, 17792, 37946, 17150, 27842, 42289, 15850, 18560, 48605]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a2524d0>\n",
            "Constructing exemplars of class 83\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [47975, 22890, 19412, 4939, 26530, 43390, 32425, 12226, 27459, 27248, 44340, 43544, 31308, 3884, 17556, 47666, 38622, 7196, 32654, 11028, 48781, 11700, 32654, 27927, 31728, 19809, 49397, 2863, 32070, 16176, 36184, 31605, 20359, 26721, 3069, 20945, 36721, 19184, 26089, 8606, 45906, 21256, 2666, 29421, 34265, 14665, 35468, 27409, 41124, 16296]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a218e90>\n",
            "Constructing exemplars of class 63\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [44395, 27386, 3567, 37516, 13230, 33750, 1008, 35809, 25606, 6267, 35945, 37951, 49011, 30039, 49389, 11237, 49120, 23409, 28946, 33462, 22518, 37951, 3508, 34902, 12138, 31986, 39180, 7776, 16172, 49120, 45813, 6787, 25916, 42504, 44665, 972, 38830, 26222, 16004, 21242, 21607, 14497, 10107, 35945, 45586, 39207, 4432, 33580, 18476, 30385]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a523f50>\n",
            "Constructing exemplars of class 42\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [37261, 13681, 3828, 21430, 33794, 30492, 46592, 10030, 43810, 15505, 7004, 36608, 4258, 14849, 987, 6757, 32818, 9000, 10580, 30353, 28667, 44694, 23764, 8064, 36294, 29610, 32656, 35072, 35973, 44038, 1515, 32313, 45963, 16060, 35924, 32237, 14603, 35561, 4182, 34838, 21647, 8188, 17562, 1013, 23115, 22536, 15884, 28659, 20825, 18046]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a222d90>\n",
            "Constructing exemplars of class 30\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [2541, 39110, 3761, 27245, 17858, 14108, 20163, 14466, 28423, 1214, 40798, 43818, 36881, 13868, 19962, 33504, 30536, 6936, 15018, 40666, 29238, 32684, 33053, 27269, 20853, 22882, 20394, 39413, 1612, 25962, 36293, 8243, 6215, 6343, 3794, 20823, 23642, 9692, 43838, 26915, 28039, 14516, 41010, 25962, 12343, 17370, 10434, 23337, 24036, 35489]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a25e550>\n",
            "Constructing exemplars of class 6\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [16771, 37581, 35217, 6910, 25543, 3919, 28507, 1762, 17735, 33259, 21415, 30252, 44592, 20916, 30138, 5535, 34061, 39127, 35141, 47426, 6237, 14373, 40425, 10250, 21415, 24832, 12432, 12164, 7096, 36903, 46636, 36968, 11088, 40401, 10231, 44477, 27766, 19264, 16460, 45507, 28104, 43921, 32885, 22055, 5877, 34768, 33259, 42630, 25414, 25210]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a220790>\n",
            "Constructing exemplars of class 2\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [42080, 46707, 12114, 32270, 33878, 48224, 6923, 30511, 47725, 37926, 41812, 36119, 23185, 48579, 28641, 18300, 41725, 39700, 36345, 38437, 40643, 38518, 46946, 22572, 44202, 31106, 30919, 39828, 32906, 41812, 48645, 36874, 14048, 26051, 9773, 20458, 34266, 33986, 5921, 11911, 3821, 20468, 37530, 2902, 46050, 44051, 9321, 36345, 18548, 29817]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a51f250>\n",
            "Constructing exemplars of class 97\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [18982, 13865, 26085, 2976, 491, 32519, 19133, 5300, 24013, 48860, 41097, 18406, 41773, 46539, 31281, 31763, 42903, 39014, 34609, 31763, 26637, 20723, 20507, 302, 2197, 30807, 9325, 26085, 44541, 36695, 17021, 4697, 9712, 46512, 27978, 14228, 19425, 27738, 40303, 2258, 14465, 23025, 47988, 45262, 25821, 40860, 26290, 38928, 19113, 22369]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a217310>\n",
            "Constructing exemplars of class 72\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [40880, 23304, 14519, 13768, 2574, 46511, 4003, 7687, 36106, 2629, 38107, 45018, 23858, 8705, 48053, 33989, 8495, 6370, 10966, 28495, 30298, 40125, 33487, 11779, 22923, 43386, 22333, 42759, 6061, 10594, 35222, 49268, 9496, 27946, 15650, 23383, 13975, 8629, 15163, 44206, 34724, 49124, 12060, 15309, 41216, 43888, 39178, 21899, 19314, 6808]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a25a190>\n",
            "Constructing exemplars of class 36\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [46597, 34257, 20070, 27828, 31117, 14508, 10005, 36048, 37010, 3985, 32402, 15231, 27537, 14457, 17494, 19019, 33779, 29292, 16209, 48387, 21513, 47376, 26728, 14164, 21836, 38828, 23384, 49056, 12841, 28130, 36328, 30457, 16019, 4967, 25775, 34592, 19764, 14113, 5822, 43983, 356, 12207, 3180, 40437, 48424, 24857, 39301, 45214, 13153, 9134]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.1641889065504074\n",
            "Train step - Step 0, Loss 0.12134683132171631\n",
            "Train step - Step 0, Loss 0.10994089394807816\n",
            "Train step - Step 0, Loss 0.12556776404380798\n",
            "Train step - Step 0, Loss 0.1318332850933075\n",
            "Train step - Step 0, Loss 0.10731955617666245\n",
            "Train step - Step 0, Loss 0.118475541472435\n",
            "Train step - Step 0, Loss 0.12674164772033691\n",
            "Train step - Step 0, Loss 0.11117327213287354\n",
            "Train step - Step 0, Loss 0.11467698961496353\n",
            "Train step - Step 0, Loss 0.1071346178650856\n",
            "Train step - Step 0, Loss 0.10614325851202011\n",
            "Train step - Step 0, Loss 0.10557599365711212\n",
            "Train step - Step 0, Loss 0.11655095964670181\n",
            "Train step - Step 0, Loss 0.11704086512327194\n",
            "Train step - Step 0, Loss 0.12033583968877792\n",
            "Train epoch - Accuracy: 0.4410833333333333 Loss: 0.11897089809179306 Corrects: 5293\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.10856271535158157\n",
            "Train step - Step 0, Loss 0.10807007551193237\n",
            "Train step - Step 0, Loss 0.11590538173913956\n",
            "Train step - Step 0, Loss 0.12525612115859985\n",
            "Train step - Step 0, Loss 0.11362851411104202\n",
            "Train step - Step 0, Loss 0.10849244147539139\n",
            "Train step - Step 0, Loss 0.1054762601852417\n",
            "Train step - Step 0, Loss 0.10288034379482269\n",
            "Train step - Step 0, Loss 0.11243456602096558\n",
            "Train step - Step 0, Loss 0.10921536386013031\n",
            "Train step - Step 0, Loss 0.10782934725284576\n",
            "Train step - Step 0, Loss 0.11101335287094116\n",
            "Train step - Step 0, Loss 0.09889493137598038\n",
            "Train step - Step 0, Loss 0.1161503940820694\n",
            "Train step - Step 0, Loss 0.09424793720245361\n",
            "Train step - Step 0, Loss 0.10256263613700867\n",
            "Train epoch - Accuracy: 0.43183333333333335 Loss: 0.10893820118904114 Corrects: 5182\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.1073855608701706\n",
            "Train step - Step 0, Loss 0.10689513385295868\n",
            "Train step - Step 0, Loss 0.11516530066728592\n",
            "Train step - Step 0, Loss 0.10825427621603012\n",
            "Train step - Step 0, Loss 0.10681308060884476\n",
            "Train step - Step 0, Loss 0.10048636049032211\n",
            "Train step - Step 0, Loss 0.1080654039978981\n",
            "Train step - Step 0, Loss 0.10389138758182526\n",
            "Train step - Step 0, Loss 0.10483251512050629\n",
            "Train step - Step 0, Loss 0.10057593137025833\n",
            "Train step - Step 0, Loss 0.10845860093832016\n",
            "Train step - Step 0, Loss 0.11281667649745941\n",
            "Train step - Step 0, Loss 0.10414295643568039\n",
            "Train step - Step 0, Loss 0.10928462445735931\n",
            "Train step - Step 0, Loss 0.11334552615880966\n",
            "Train step - Step 0, Loss 0.10595234483480453\n",
            "Train epoch - Accuracy: 0.4221666666666667 Loss: 0.10730454725027085 Corrects: 5066\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.0986001119017601\n",
            "Train step - Step 0, Loss 0.11353529989719391\n",
            "Train step - Step 0, Loss 0.11086142808198929\n",
            "Train step - Step 0, Loss 0.11123238503932953\n",
            "Train step - Step 0, Loss 0.10720022767782211\n",
            "Train step - Step 0, Loss 0.10604947805404663\n",
            "Train step - Step 0, Loss 0.11082400381565094\n",
            "Train step - Step 0, Loss 0.09558447450399399\n",
            "Train step - Step 0, Loss 0.10489443689584732\n",
            "Train step - Step 0, Loss 0.10489200800657272\n",
            "Train step - Step 0, Loss 0.09811404347419739\n",
            "Train step - Step 0, Loss 0.10666687786579132\n",
            "Train step - Step 0, Loss 0.1014644056558609\n",
            "Train step - Step 0, Loss 0.11024696379899979\n",
            "Train step - Step 0, Loss 0.1057928279042244\n",
            "Train step - Step 0, Loss 0.1021067202091217\n",
            "Train epoch - Accuracy: 0.43116666666666664 Loss: 0.1055856430530548 Corrects: 5174\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.10574867576360703\n",
            "Train step - Step 0, Loss 0.11957922577857971\n",
            "Train step - Step 0, Loss 0.1108163446187973\n",
            "Train step - Step 0, Loss 0.09981770813465118\n",
            "Train step - Step 0, Loss 0.10496097058057785\n",
            "Train step - Step 0, Loss 0.10400888323783875\n",
            "Train step - Step 0, Loss 0.10009659826755524\n",
            "Train step - Step 0, Loss 0.10901041328907013\n",
            "Train step - Step 0, Loss 0.11327969282865524\n",
            "Train step - Step 0, Loss 0.09301809966564178\n",
            "Train step - Step 0, Loss 0.09531336277723312\n",
            "Train step - Step 0, Loss 0.1075557991862297\n",
            "Train step - Step 0, Loss 0.10094267874956131\n",
            "Train step - Step 0, Loss 0.10430435836315155\n",
            "Train step - Step 0, Loss 0.09792274236679077\n",
            "Train step - Step 0, Loss 0.09887731075286865\n",
            "Train epoch - Accuracy: 0.43116666666666664 Loss: 0.10420312786102295 Corrects: 5174\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.10991156846284866\n",
            "Train step - Step 0, Loss 0.10927008837461472\n",
            "Train step - Step 0, Loss 0.10712990164756775\n",
            "Train step - Step 0, Loss 0.10405734926462173\n",
            "Train step - Step 0, Loss 0.09669215232133865\n",
            "Train step - Step 0, Loss 0.10575064271688461\n",
            "Train step - Step 0, Loss 0.10164424777030945\n",
            "Train step - Step 0, Loss 0.10589254647493362\n",
            "Train step - Step 0, Loss 0.10670483112335205\n",
            "Train step - Step 0, Loss 0.10331973433494568\n",
            "Train step - Step 0, Loss 0.10568203032016754\n",
            "Train step - Step 0, Loss 0.10623656213283539\n",
            "Train step - Step 0, Loss 0.10015542060136795\n",
            "Train step - Step 0, Loss 0.09955872595310211\n",
            "Train step - Step 0, Loss 0.10578840970993042\n",
            "Train step - Step 0, Loss 0.09614917635917664\n",
            "Train epoch - Accuracy: 0.4334166666666667 Loss: 0.10418479657173156 Corrects: 5201\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.10511069744825363\n",
            "Train step - Step 0, Loss 0.09649302810430527\n",
            "Train step - Step 0, Loss 0.10088923573493958\n",
            "Train step - Step 0, Loss 0.10965616255998611\n",
            "Train step - Step 0, Loss 0.10026843100786209\n",
            "Train step - Step 0, Loss 0.10491199791431427\n",
            "Train step - Step 0, Loss 0.10183835029602051\n",
            "Train step - Step 0, Loss 0.10147331655025482\n",
            "Train step - Step 0, Loss 0.09635498374700546\n",
            "Train step - Step 0, Loss 0.103487528860569\n",
            "Train step - Step 0, Loss 0.09404736012220383\n",
            "Train step - Step 0, Loss 0.11238168179988861\n",
            "Train step - Step 0, Loss 0.1006975769996643\n",
            "Train step - Step 0, Loss 0.10305816680192947\n",
            "Train step - Step 0, Loss 0.10688768327236176\n",
            "Train step - Step 0, Loss 0.10730044543743134\n",
            "Train epoch - Accuracy: 0.4170833333333333 Loss: 0.10269561469554901 Corrects: 5005\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.09696727246046066\n",
            "Train step - Step 0, Loss 0.10346350073814392\n",
            "Train step - Step 0, Loss 0.10878174006938934\n",
            "Train step - Step 0, Loss 0.10175896435976028\n",
            "Train step - Step 0, Loss 0.10467792302370071\n",
            "Train step - Step 0, Loss 0.10413778573274612\n",
            "Train step - Step 0, Loss 0.10552536696195602\n",
            "Train step - Step 0, Loss 0.10891958326101303\n",
            "Train step - Step 0, Loss 0.09807223826646805\n",
            "Train step - Step 0, Loss 0.10107888281345367\n",
            "Train step - Step 0, Loss 0.09922964125871658\n",
            "Train step - Step 0, Loss 0.10671190172433853\n",
            "Train step - Step 0, Loss 0.10267262905836105\n",
            "Train step - Step 0, Loss 0.09428580850362778\n",
            "Train step - Step 0, Loss 0.09240912646055222\n",
            "Train step - Step 0, Loss 0.09404128044843674\n",
            "Train epoch - Accuracy: 0.42725 Loss: 0.1015979625582695 Corrects: 5127\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.10029629617929459\n",
            "Train step - Step 0, Loss 0.10783833265304565\n",
            "Train step - Step 0, Loss 0.0952020138502121\n",
            "Train step - Step 0, Loss 0.1031566858291626\n",
            "Train step - Step 0, Loss 0.10146171599626541\n",
            "Train step - Step 0, Loss 0.10145548731088638\n",
            "Train step - Step 0, Loss 0.09988411515951157\n",
            "Train step - Step 0, Loss 0.09363175928592682\n",
            "Train step - Step 0, Loss 0.09685346484184265\n",
            "Train step - Step 0, Loss 0.11282390356063843\n",
            "Train step - Step 0, Loss 0.10122987627983093\n",
            "Train step - Step 0, Loss 0.0964457094669342\n",
            "Train step - Step 0, Loss 0.107060007750988\n",
            "Train step - Step 0, Loss 0.10193252563476562\n",
            "Train step - Step 0, Loss 0.10159797221422195\n",
            "Train step - Step 0, Loss 0.09889405965805054\n",
            "Train epoch - Accuracy: 0.4315 Loss: 0.10129143381118774 Corrects: 5178\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.1017293855547905\n",
            "Train step - Step 0, Loss 0.09506756067276001\n",
            "Train step - Step 0, Loss 0.10813742130994797\n",
            "Train step - Step 0, Loss 0.10772150754928589\n",
            "Train step - Step 0, Loss 0.10241471230983734\n",
            "Train step - Step 0, Loss 0.09878253191709518\n",
            "Train step - Step 0, Loss 0.10491454601287842\n",
            "Train step - Step 0, Loss 0.10808177292346954\n",
            "Train step - Step 0, Loss 0.09664895385503769\n",
            "Train step - Step 0, Loss 0.09664469212293625\n",
            "Train step - Step 0, Loss 0.10887426882982254\n",
            "Train step - Step 0, Loss 0.09785258769989014\n",
            "Train step - Step 0, Loss 0.10683317482471466\n",
            "Train step - Step 0, Loss 0.0976102277636528\n",
            "Train step - Step 0, Loss 0.11058202385902405\n",
            "Train step - Step 0, Loss 0.10437234491109848\n",
            "Train epoch - Accuracy: 0.4280833333333333 Loss: 0.10285619729757309 Corrects: 5137\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.1025812178850174\n",
            "Train step - Step 0, Loss 0.09490910172462463\n",
            "Train step - Step 0, Loss 0.09817477315664291\n",
            "Train step - Step 0, Loss 0.09674470126628876\n",
            "Train step - Step 0, Loss 0.09571470320224762\n",
            "Train step - Step 0, Loss 0.10921575129032135\n",
            "Train step - Step 0, Loss 0.09396998584270477\n",
            "Train step - Step 0, Loss 0.10200650244951248\n",
            "Train step - Step 0, Loss 0.10449879616498947\n",
            "Train step - Step 0, Loss 0.09251822531223297\n",
            "Train step - Step 0, Loss 0.10228100419044495\n",
            "Train step - Step 0, Loss 0.09760764241218567\n",
            "Train step - Step 0, Loss 0.10776262730360031\n",
            "Train step - Step 0, Loss 0.10642191767692566\n",
            "Train step - Step 0, Loss 0.10427633672952652\n",
            "Train step - Step 0, Loss 0.09521714597940445\n",
            "Train epoch - Accuracy: 0.42075 Loss: 0.10036441618204117 Corrects: 5049\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.10121847689151764\n",
            "Train step - Step 0, Loss 0.09822085499763489\n",
            "Train step - Step 0, Loss 0.10445055365562439\n",
            "Train step - Step 0, Loss 0.0952727422118187\n",
            "Train step - Step 0, Loss 0.08598692715167999\n",
            "Train step - Step 0, Loss 0.10438688844442368\n",
            "Train step - Step 0, Loss 0.09927976131439209\n",
            "Train step - Step 0, Loss 0.09497036784887314\n",
            "Train step - Step 0, Loss 0.10937236994504929\n",
            "Train step - Step 0, Loss 0.10301034152507782\n",
            "Train step - Step 0, Loss 0.10448335856199265\n",
            "Train step - Step 0, Loss 0.09915392100811005\n",
            "Train step - Step 0, Loss 0.09772691130638123\n",
            "Train step - Step 0, Loss 0.11271941661834717\n",
            "Train step - Step 0, Loss 0.1035144180059433\n",
            "Train step - Step 0, Loss 0.08619114011526108\n",
            "Train epoch - Accuracy: 0.42725 Loss: 0.10032875341176986 Corrects: 5127\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.10063331574201584\n",
            "Train step - Step 0, Loss 0.10653156042098999\n",
            "Train step - Step 0, Loss 0.09426292032003403\n",
            "Train step - Step 0, Loss 0.09682726114988327\n",
            "Train step - Step 0, Loss 0.09989599138498306\n",
            "Train step - Step 0, Loss 0.09850066900253296\n",
            "Train step - Step 0, Loss 0.09980874508619308\n",
            "Train step - Step 0, Loss 0.10021194070577621\n",
            "Train step - Step 0, Loss 0.10067121684551239\n",
            "Train step - Step 0, Loss 0.10381641983985901\n",
            "Train step - Step 0, Loss 0.09590613096952438\n",
            "Train step - Step 0, Loss 0.09427480399608612\n",
            "Train step - Step 0, Loss 0.10567522794008255\n",
            "Train step - Step 0, Loss 0.10563322901725769\n",
            "Train step - Step 0, Loss 0.10027095675468445\n",
            "Train step - Step 0, Loss 0.10556701570749283\n",
            "Train epoch - Accuracy: 0.42883333333333334 Loss: 0.10040958553552627 Corrects: 5146\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.0975235179066658\n",
            "Train step - Step 0, Loss 0.105064257979393\n",
            "Train step - Step 0, Loss 0.10009055584669113\n",
            "Train step - Step 0, Loss 0.09983175247907639\n",
            "Train step - Step 0, Loss 0.1031833216547966\n",
            "Train step - Step 0, Loss 0.10021555423736572\n",
            "Train step - Step 0, Loss 0.10367433726787567\n",
            "Train step - Step 0, Loss 0.08951187133789062\n",
            "Train step - Step 0, Loss 0.10228968411684036\n",
            "Train step - Step 0, Loss 0.10757584869861603\n",
            "Train step - Step 0, Loss 0.09795773029327393\n",
            "Train step - Step 0, Loss 0.09300060570240021\n",
            "Train step - Step 0, Loss 0.09627051651477814\n",
            "Train step - Step 0, Loss 0.10683771967887878\n",
            "Train step - Step 0, Loss 0.09905017912387848\n",
            "Train step - Step 0, Loss 0.10022834688425064\n",
            "Train epoch - Accuracy: 0.4250833333333333 Loss: 0.10014209085702896 Corrects: 5101\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.09907010942697525\n",
            "Train step - Step 0, Loss 0.09122290462255478\n",
            "Train step - Step 0, Loss 0.09279575943946838\n",
            "Train step - Step 0, Loss 0.10384226590394974\n",
            "Train step - Step 0, Loss 0.10121703892946243\n",
            "Train step - Step 0, Loss 0.10425246506929398\n",
            "Train step - Step 0, Loss 0.10036645829677582\n",
            "Train step - Step 0, Loss 0.09650159627199173\n",
            "Train step - Step 0, Loss 0.10498007386922836\n",
            "Train step - Step 0, Loss 0.10105964541435242\n",
            "Train step - Step 0, Loss 0.10037901252508163\n",
            "Train step - Step 0, Loss 0.10001727193593979\n",
            "Train step - Step 0, Loss 0.09965397417545319\n",
            "Train step - Step 0, Loss 0.1042780876159668\n",
            "Train step - Step 0, Loss 0.09508998692035675\n",
            "Train step - Step 0, Loss 0.10492546856403351\n",
            "Train epoch - Accuracy: 0.42891666666666667 Loss: 0.09985952436923981 Corrects: 5147\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.09798767417669296\n",
            "Train step - Step 0, Loss 0.10898509621620178\n",
            "Train step - Step 0, Loss 0.10050398856401443\n",
            "Train step - Step 0, Loss 0.09709420800209045\n",
            "Train step - Step 0, Loss 0.09940660744905472\n",
            "Train step - Step 0, Loss 0.09230238944292068\n",
            "Train step - Step 0, Loss 0.09603312611579895\n",
            "Train step - Step 0, Loss 0.10204652696847916\n",
            "Train step - Step 0, Loss 0.10333942621946335\n",
            "Train step - Step 0, Loss 0.10014668852090836\n",
            "Train step - Step 0, Loss 0.09789662808179855\n",
            "Train step - Step 0, Loss 0.09904766827821732\n",
            "Train step - Step 0, Loss 0.10222148895263672\n",
            "Train step - Step 0, Loss 0.09931207448244095\n",
            "Train step - Step 0, Loss 0.10288082808256149\n",
            "Train step - Step 0, Loss 0.09704697877168655\n",
            "Train epoch - Accuracy: 0.4285 Loss: 0.09983096200227737 Corrects: 5142\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.10460523515939713\n",
            "Train step - Step 0, Loss 0.09701428562402725\n",
            "Train step - Step 0, Loss 0.10306823998689651\n",
            "Train step - Step 0, Loss 0.10178966820240021\n",
            "Train step - Step 0, Loss 0.09886548668146133\n",
            "Train step - Step 0, Loss 0.10358186066150665\n",
            "Train step - Step 0, Loss 0.10011439770460129\n",
            "Train step - Step 0, Loss 0.09924490004777908\n",
            "Train step - Step 0, Loss 0.10344533622264862\n",
            "Train step - Step 0, Loss 0.09258753806352615\n",
            "Train step - Step 0, Loss 0.09360941499471664\n",
            "Train step - Step 0, Loss 0.10602056980133057\n",
            "Train step - Step 0, Loss 0.09686298668384552\n",
            "Train step - Step 0, Loss 0.09731729328632355\n",
            "Train step - Step 0, Loss 0.09652441740036011\n",
            "Train step - Step 0, Loss 0.09262057393789291\n",
            "Train epoch - Accuracy: 0.4290833333333333 Loss: 0.09936252731084824 Corrects: 5149\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.09885060787200928\n",
            "Train step - Step 0, Loss 0.09908154606819153\n",
            "Train step - Step 0, Loss 0.10133921355009079\n",
            "Train step - Step 0, Loss 0.10544624924659729\n",
            "Train step - Step 0, Loss 0.09992238879203796\n",
            "Train step - Step 0, Loss 0.09554014354944229\n",
            "Train step - Step 0, Loss 0.10098902881145477\n",
            "Train step - Step 0, Loss 0.103690966963768\n",
            "Train step - Step 0, Loss 0.10335038602352142\n",
            "Train step - Step 0, Loss 0.09645847231149673\n",
            "Train step - Step 0, Loss 0.1043444499373436\n",
            "Train step - Step 0, Loss 0.09295190125703812\n",
            "Train step - Step 0, Loss 0.09726925939321518\n",
            "Train step - Step 0, Loss 0.09611332416534424\n",
            "Train step - Step 0, Loss 0.0998074933886528\n",
            "Train step - Step 0, Loss 0.09367796033620834\n",
            "Train epoch - Accuracy: 0.427 Loss: 0.09943706601858139 Corrects: 5124\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.10049125552177429\n",
            "Train step - Step 0, Loss 0.09812121838331223\n",
            "Train step - Step 0, Loss 0.09484776109457016\n",
            "Train step - Step 0, Loss 0.08928774297237396\n",
            "Train step - Step 0, Loss 0.0994633212685585\n",
            "Train step - Step 0, Loss 0.09865594655275345\n",
            "Train step - Step 0, Loss 0.10141299664974213\n",
            "Train step - Step 0, Loss 0.0988103523850441\n",
            "Train step - Step 0, Loss 0.10636342316865921\n",
            "Train step - Step 0, Loss 0.09113921225070953\n",
            "Train step - Step 0, Loss 0.0955432802438736\n",
            "Train step - Step 0, Loss 0.09652239829301834\n",
            "Train step - Step 0, Loss 0.0987207442522049\n",
            "Train step - Step 0, Loss 0.10210469365119934\n",
            "Train step - Step 0, Loss 0.10350170731544495\n",
            "Train step - Step 0, Loss 0.10704578459262848\n",
            "Train epoch - Accuracy: 0.42175 Loss: 0.09868093883991241 Corrects: 5061\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.08902402222156525\n",
            "Train step - Step 0, Loss 0.09961117804050446\n",
            "Train step - Step 0, Loss 0.0991513803601265\n",
            "Train step - Step 0, Loss 0.09656092524528503\n",
            "Train step - Step 0, Loss 0.10802878439426422\n",
            "Train step - Step 0, Loss 0.10201477259397507\n",
            "Train step - Step 0, Loss 0.09805256873369217\n",
            "Train step - Step 0, Loss 0.09989015012979507\n",
            "Train step - Step 0, Loss 0.09475842118263245\n",
            "Train step - Step 0, Loss 0.10441102832555771\n",
            "Train step - Step 0, Loss 0.09797916561365128\n",
            "Train step - Step 0, Loss 0.09301453828811646\n",
            "Train step - Step 0, Loss 0.0946812555193901\n",
            "Train step - Step 0, Loss 0.099466472864151\n",
            "Train step - Step 0, Loss 0.09390445053577423\n",
            "Train step - Step 0, Loss 0.09744066745042801\n",
            "Train epoch - Accuracy: 0.43016666666666664 Loss: 0.0980127699971199 Corrects: 5162\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.10104946792125702\n",
            "Train step - Step 0, Loss 0.09637941420078278\n",
            "Train step - Step 0, Loss 0.10216974467039108\n",
            "Train step - Step 0, Loss 0.097568579018116\n",
            "Train step - Step 0, Loss 0.10100528597831726\n",
            "Train step - Step 0, Loss 0.10164458304643631\n",
            "Train step - Step 0, Loss 0.10273420065641403\n",
            "Train step - Step 0, Loss 0.10148907452821732\n",
            "Train step - Step 0, Loss 0.09215109050273895\n",
            "Train step - Step 0, Loss 0.09730155020952225\n",
            "Train step - Step 0, Loss 0.10053230822086334\n",
            "Train step - Step 0, Loss 0.09266197681427002\n",
            "Train step - Step 0, Loss 0.09489496797323227\n",
            "Train step - Step 0, Loss 0.09607097506523132\n",
            "Train step - Step 0, Loss 0.09336952120065689\n",
            "Train step - Step 0, Loss 0.09823159128427505\n",
            "Train epoch - Accuracy: 0.42525 Loss: 0.0980747190117836 Corrects: 5103\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.09522709995508194\n",
            "Train step - Step 0, Loss 0.09510520845651627\n",
            "Train step - Step 0, Loss 0.09540731459856033\n",
            "Train step - Step 0, Loss 0.09539330750703812\n",
            "Train step - Step 0, Loss 0.09180706739425659\n",
            "Train step - Step 0, Loss 0.10432401299476624\n",
            "Train step - Step 0, Loss 0.0955880880355835\n",
            "Train step - Step 0, Loss 0.09763341397047043\n",
            "Train step - Step 0, Loss 0.09799426794052124\n",
            "Train step - Step 0, Loss 0.09478811919689178\n",
            "Train step - Step 0, Loss 0.09760376811027527\n",
            "Train step - Step 0, Loss 0.09414858371019363\n",
            "Train step - Step 0, Loss 0.09627785533666611\n",
            "Train step - Step 0, Loss 0.10050798207521439\n",
            "Train step - Step 0, Loss 0.09326297789812088\n",
            "Train step - Step 0, Loss 0.09679761528968811\n",
            "Train epoch - Accuracy: 0.4290833333333333 Loss: 0.09635632491111755 Corrects: 5149\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.09768375009298325\n",
            "Train step - Step 0, Loss 0.09372618794441223\n",
            "Train step - Step 0, Loss 0.097807377576828\n",
            "Train step - Step 0, Loss 0.1057584211230278\n",
            "Train step - Step 0, Loss 0.09606882929801941\n",
            "Train step - Step 0, Loss 0.09663411974906921\n",
            "Train step - Step 0, Loss 0.09933413565158844\n",
            "Train step - Step 0, Loss 0.09413811564445496\n",
            "Train step - Step 0, Loss 0.09856162220239639\n",
            "Train step - Step 0, Loss 0.09908752143383026\n",
            "Train step - Step 0, Loss 0.09468667209148407\n",
            "Train step - Step 0, Loss 0.09594660252332687\n",
            "Train step - Step 0, Loss 0.09354647994041443\n",
            "Train step - Step 0, Loss 0.10369808226823807\n",
            "Train step - Step 0, Loss 0.10198657959699631\n",
            "Train step - Step 0, Loss 0.10293573886156082\n",
            "Train epoch - Accuracy: 0.43233333333333335 Loss: 0.09811195737123489 Corrects: 5188\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.09612235426902771\n",
            "Train step - Step 0, Loss 0.09695400297641754\n",
            "Train step - Step 0, Loss 0.10149352997541428\n",
            "Train step - Step 0, Loss 0.09472908079624176\n",
            "Train step - Step 0, Loss 0.09618732333183289\n",
            "Train step - Step 0, Loss 0.09424189478158951\n",
            "Train step - Step 0, Loss 0.09546386450529099\n",
            "Train step - Step 0, Loss 0.10119753330945969\n",
            "Train step - Step 0, Loss 0.0953558161854744\n",
            "Train step - Step 0, Loss 0.10713069885969162\n",
            "Train step - Step 0, Loss 0.095843106508255\n",
            "Train step - Step 0, Loss 0.10506529361009598\n",
            "Train step - Step 0, Loss 0.09533384442329407\n",
            "Train step - Step 0, Loss 0.09785860776901245\n",
            "Train step - Step 0, Loss 0.1041417196393013\n",
            "Train step - Step 0, Loss 0.10023854672908783\n",
            "Train epoch - Accuracy: 0.4261666666666667 Loss: 0.09854513680934907 Corrects: 5114\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.09369875490665436\n",
            "Train step - Step 0, Loss 0.0944359228014946\n",
            "Train step - Step 0, Loss 0.091038279235363\n",
            "Train step - Step 0, Loss 0.09332479536533356\n",
            "Train step - Step 0, Loss 0.09245109558105469\n",
            "Train step - Step 0, Loss 0.09822256118059158\n",
            "Train step - Step 0, Loss 0.10431016236543655\n",
            "Train step - Step 0, Loss 0.1038970798254013\n",
            "Train step - Step 0, Loss 0.09473218023777008\n",
            "Train step - Step 0, Loss 0.09454935789108276\n",
            "Train step - Step 0, Loss 0.09992262721061707\n",
            "Train step - Step 0, Loss 0.09650559723377228\n",
            "Train step - Step 0, Loss 0.094297856092453\n",
            "Train step - Step 0, Loss 0.10067564249038696\n",
            "Train step - Step 0, Loss 0.10298699140548706\n",
            "Train step - Step 0, Loss 0.08680439740419388\n",
            "Train epoch - Accuracy: 0.4225 Loss: 0.09659530574083328 Corrects: 5070\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.09673923254013062\n",
            "Train step - Step 0, Loss 0.09966199845075607\n",
            "Train step - Step 0, Loss 0.09706771373748779\n",
            "Train step - Step 0, Loss 0.09113345295190811\n",
            "Train step - Step 0, Loss 0.09720173478126526\n",
            "Train step - Step 0, Loss 0.09286252409219742\n",
            "Train step - Step 0, Loss 0.10392742604017258\n",
            "Train step - Step 0, Loss 0.09765614569187164\n",
            "Train step - Step 0, Loss 0.10022095590829849\n",
            "Train step - Step 0, Loss 0.09606234729290009\n",
            "Train step - Step 0, Loss 0.09802507609128952\n",
            "Train step - Step 0, Loss 0.08754417300224304\n",
            "Train step - Step 0, Loss 0.1000313088297844\n",
            "Train step - Step 0, Loss 0.09388507902622223\n",
            "Train step - Step 0, Loss 0.09994605928659439\n",
            "Train step - Step 0, Loss 0.10075203329324722\n",
            "Train epoch - Accuracy: 0.42733333333333334 Loss: 0.09695585590600968 Corrects: 5128\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.08998224139213562\n",
            "Train step - Step 0, Loss 0.09809970110654831\n",
            "Train step - Step 0, Loss 0.09503083676099777\n",
            "Train step - Step 0, Loss 0.09804224222898483\n",
            "Train step - Step 0, Loss 0.09536359459161758\n",
            "Train step - Step 0, Loss 0.0951429009437561\n",
            "Train step - Step 0, Loss 0.09997493028640747\n",
            "Train step - Step 0, Loss 0.0931268259882927\n",
            "Train step - Step 0, Loss 0.09983345866203308\n",
            "Train step - Step 0, Loss 0.09859801083803177\n",
            "Train step - Step 0, Loss 0.10028105974197388\n",
            "Train step - Step 0, Loss 0.08964173495769501\n",
            "Train step - Step 0, Loss 0.09498261660337448\n",
            "Train step - Step 0, Loss 0.09703013300895691\n",
            "Train step - Step 0, Loss 0.10084258019924164\n",
            "Train step - Step 0, Loss 0.10114140808582306\n",
            "Train epoch - Accuracy: 0.42441666666666666 Loss: 0.09658791983127595 Corrects: 5093\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.09440892189741135\n",
            "Train step - Step 0, Loss 0.08986709266901016\n",
            "Train step - Step 0, Loss 0.09174761921167374\n",
            "Train step - Step 0, Loss 0.09980321675539017\n",
            "Train step - Step 0, Loss 0.09375758469104767\n",
            "Train step - Step 0, Loss 0.09158220142126083\n",
            "Train step - Step 0, Loss 0.09790313243865967\n",
            "Train step - Step 0, Loss 0.09648624807596207\n",
            "Train step - Step 0, Loss 0.08955061435699463\n",
            "Train step - Step 0, Loss 0.10466022789478302\n",
            "Train step - Step 0, Loss 0.09626379609107971\n",
            "Train step - Step 0, Loss 0.10023338347673416\n",
            "Train step - Step 0, Loss 0.1023116409778595\n",
            "Train step - Step 0, Loss 0.1005743071436882\n",
            "Train step - Step 0, Loss 0.09674618393182755\n",
            "Train step - Step 0, Loss 0.10164982080459595\n",
            "Train epoch - Accuracy: 0.4265833333333333 Loss: 0.09660334777832032 Corrects: 5119\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.08973086625337601\n",
            "Train step - Step 0, Loss 0.08994090557098389\n",
            "Train step - Step 0, Loss 0.0961272120475769\n",
            "Train step - Step 0, Loss 0.10165786743164062\n",
            "Train step - Step 0, Loss 0.09221756458282471\n",
            "Train step - Step 0, Loss 0.09731034934520721\n",
            "Train step - Step 0, Loss 0.09909465163946152\n",
            "Train step - Step 0, Loss 0.10043220967054367\n",
            "Train step - Step 0, Loss 0.10213075578212738\n",
            "Train step - Step 0, Loss 0.10022033005952835\n",
            "Train step - Step 0, Loss 0.09889879077672958\n",
            "Train step - Step 0, Loss 0.09211566299200058\n",
            "Train step - Step 0, Loss 0.0976291224360466\n",
            "Train step - Step 0, Loss 0.09846235066652298\n",
            "Train step - Step 0, Loss 0.09538377821445465\n",
            "Train step - Step 0, Loss 0.09342391043901443\n",
            "Train epoch - Accuracy: 0.4320833333333333 Loss: 0.09662351113557816 Corrects: 5185\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.09810015559196472\n",
            "Train step - Step 0, Loss 0.09825652837753296\n",
            "Train step - Step 0, Loss 0.09772969037294388\n",
            "Train step - Step 0, Loss 0.09775350242853165\n",
            "Train step - Step 0, Loss 0.10006165504455566\n",
            "Train step - Step 0, Loss 0.10232137888669968\n",
            "Train step - Step 0, Loss 0.09407051652669907\n",
            "Train step - Step 0, Loss 0.0960790142416954\n",
            "Train step - Step 0, Loss 0.0998007133603096\n",
            "Train step - Step 0, Loss 0.09592103213071823\n",
            "Train step - Step 0, Loss 0.08986688405275345\n",
            "Train step - Step 0, Loss 0.09407009929418564\n",
            "Train step - Step 0, Loss 0.09231138229370117\n",
            "Train step - Step 0, Loss 0.09992114454507828\n",
            "Train step - Step 0, Loss 0.09680339694023132\n",
            "Train step - Step 0, Loss 0.0910213440656662\n",
            "Train epoch - Accuracy: 0.4185 Loss: 0.09663714778423309 Corrects: 5022\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.10347981750965118\n",
            "Train step - Step 0, Loss 0.093179851770401\n",
            "Train step - Step 0, Loss 0.09348402172327042\n",
            "Train step - Step 0, Loss 0.09941192716360092\n",
            "Train step - Step 0, Loss 0.09716010093688965\n",
            "Train step - Step 0, Loss 0.09180701524019241\n",
            "Train step - Step 0, Loss 0.09566399455070496\n",
            "Train step - Step 0, Loss 0.09746059030294418\n",
            "Train step - Step 0, Loss 0.09115483611822128\n",
            "Train step - Step 0, Loss 0.09817071259021759\n",
            "Train step - Step 0, Loss 0.10171791911125183\n",
            "Train step - Step 0, Loss 0.08897846937179565\n",
            "Train step - Step 0, Loss 0.09692782163619995\n",
            "Train step - Step 0, Loss 0.09638143330812454\n",
            "Train step - Step 0, Loss 0.09966561943292618\n",
            "Train step - Step 0, Loss 0.10139816254377365\n",
            "Train epoch - Accuracy: 0.41983333333333334 Loss: 0.09651315087080002 Corrects: 5038\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.08991764485836029\n",
            "Train step - Step 0, Loss 0.0946410670876503\n",
            "Train step - Step 0, Loss 0.09412553906440735\n",
            "Train step - Step 0, Loss 0.09548966586589813\n",
            "Train step - Step 0, Loss 0.0958532840013504\n",
            "Train step - Step 0, Loss 0.10016380995512009\n",
            "Train step - Step 0, Loss 0.09453196823596954\n",
            "Train step - Step 0, Loss 0.1005815714597702\n",
            "Train step - Step 0, Loss 0.10001692175865173\n",
            "Train step - Step 0, Loss 0.09566708654165268\n",
            "Train step - Step 0, Loss 0.10257405042648315\n",
            "Train step - Step 0, Loss 0.09393331408500671\n",
            "Train step - Step 0, Loss 0.09122731536626816\n",
            "Train step - Step 0, Loss 0.10307537764310837\n",
            "Train step - Step 0, Loss 0.09805169701576233\n",
            "Train step - Step 0, Loss 0.09543197602033615\n",
            "Train epoch - Accuracy: 0.42483333333333334 Loss: 0.09660769909620286 Corrects: 5098\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.10407298058271408\n",
            "Train step - Step 0, Loss 0.08844022452831268\n",
            "Train step - Step 0, Loss 0.10247603058815002\n",
            "Train step - Step 0, Loss 0.09875659644603729\n",
            "Train step - Step 0, Loss 0.09505864977836609\n",
            "Train step - Step 0, Loss 0.09985563904047012\n",
            "Train step - Step 0, Loss 0.09393113851547241\n",
            "Train step - Step 0, Loss 0.09616360068321228\n",
            "Train step - Step 0, Loss 0.10248462855815887\n",
            "Train step - Step 0, Loss 0.08896933495998383\n",
            "Train step - Step 0, Loss 0.09684277325868607\n",
            "Train step - Step 0, Loss 0.09472937881946564\n",
            "Train step - Step 0, Loss 0.09311679750680923\n",
            "Train step - Step 0, Loss 0.0994831845164299\n",
            "Train step - Step 0, Loss 0.09746193885803223\n",
            "Train step - Step 0, Loss 0.09437686949968338\n",
            "Train epoch - Accuracy: 0.42425 Loss: 0.09669302016496659 Corrects: 5091\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.09931544959545135\n",
            "Train step - Step 0, Loss 0.10201916098594666\n",
            "Train step - Step 0, Loss 0.0982896089553833\n",
            "Train step - Step 0, Loss 0.09822370111942291\n",
            "Train step - Step 0, Loss 0.09169072657823563\n",
            "Train step - Step 0, Loss 0.09646859765052795\n",
            "Train step - Step 0, Loss 0.09917546808719635\n",
            "Train step - Step 0, Loss 0.09514743089675903\n",
            "Train step - Step 0, Loss 0.08869990706443787\n",
            "Train step - Step 0, Loss 0.09621214121580124\n",
            "Train step - Step 0, Loss 0.09981030225753784\n",
            "Train step - Step 0, Loss 0.09357369691133499\n",
            "Train step - Step 0, Loss 0.0873086005449295\n",
            "Train step - Step 0, Loss 0.09116034209728241\n",
            "Train step - Step 0, Loss 0.09782645106315613\n",
            "Train step - Step 0, Loss 0.09266821295022964\n",
            "Train epoch - Accuracy: 0.42391666666666666 Loss: 0.09554170995950699 Corrects: 5087\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.09792905300855637\n",
            "Train step - Step 0, Loss 0.092860147356987\n",
            "Train step - Step 0, Loss 0.09184914082288742\n",
            "Train step - Step 0, Loss 0.09429650753736496\n",
            "Train step - Step 0, Loss 0.10083086043596268\n",
            "Train step - Step 0, Loss 0.09320683777332306\n",
            "Train step - Step 0, Loss 0.09954666346311569\n",
            "Train step - Step 0, Loss 0.0919579491019249\n",
            "Train step - Step 0, Loss 0.10096538811922073\n",
            "Train step - Step 0, Loss 0.10420490056276321\n",
            "Train step - Step 0, Loss 0.09833568334579468\n",
            "Train step - Step 0, Loss 0.10264074802398682\n",
            "Train step - Step 0, Loss 0.09350129961967468\n",
            "Train step - Step 0, Loss 0.09412103146314621\n",
            "Train step - Step 0, Loss 0.08824361860752106\n",
            "Train step - Step 0, Loss 0.08948715776205063\n",
            "Train epoch - Accuracy: 0.43241666666666667 Loss: 0.09602683538198471 Corrects: 5189\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.09276745468378067\n",
            "Train step - Step 0, Loss 0.09304790198802948\n",
            "Train step - Step 0, Loss 0.09914101660251617\n",
            "Train step - Step 0, Loss 0.10592420399188995\n",
            "Train step - Step 0, Loss 0.08931247889995575\n",
            "Train step - Step 0, Loss 0.09367445856332779\n",
            "Train step - Step 0, Loss 0.09240312874317169\n",
            "Train step - Step 0, Loss 0.09809607267379761\n",
            "Train step - Step 0, Loss 0.09313912689685822\n",
            "Train step - Step 0, Loss 0.09898722916841507\n",
            "Train step - Step 0, Loss 0.10032790154218674\n",
            "Train step - Step 0, Loss 0.0966414287686348\n",
            "Train step - Step 0, Loss 0.08895057439804077\n",
            "Train step - Step 0, Loss 0.0967504158616066\n",
            "Train step - Step 0, Loss 0.0950281023979187\n",
            "Train step - Step 0, Loss 0.09668692201375961\n",
            "Train epoch - Accuracy: 0.4230833333333333 Loss: 0.09565573257207871 Corrects: 5077\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.09388359636068344\n",
            "Train step - Step 0, Loss 0.10011518001556396\n",
            "Train step - Step 0, Loss 0.09400878101587296\n",
            "Train step - Step 0, Loss 0.09337504208087921\n",
            "Train step - Step 0, Loss 0.09568627923727036\n",
            "Train step - Step 0, Loss 0.0954226553440094\n",
            "Train step - Step 0, Loss 0.0962507426738739\n",
            "Train step - Step 0, Loss 0.09194250404834747\n",
            "Train step - Step 0, Loss 0.10009147226810455\n",
            "Train step - Step 0, Loss 0.08677808940410614\n",
            "Train step - Step 0, Loss 0.09534361213445663\n",
            "Train step - Step 0, Loss 0.09960243105888367\n",
            "Train step - Step 0, Loss 0.10206466168165207\n",
            "Train step - Step 0, Loss 0.10085947066545486\n",
            "Train step - Step 0, Loss 0.09860041737556458\n",
            "Train step - Step 0, Loss 0.09686115384101868\n",
            "Train epoch - Accuracy: 0.4196666666666667 Loss: 0.09629204201698303 Corrects: 5036\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.0976657122373581\n",
            "Train step - Step 0, Loss 0.08996549993753433\n",
            "Train step - Step 0, Loss 0.0961860790848732\n",
            "Train step - Step 0, Loss 0.09038494527339935\n",
            "Train step - Step 0, Loss 0.10320927947759628\n",
            "Train step - Step 0, Loss 0.09526527673006058\n",
            "Train step - Step 0, Loss 0.0907902643084526\n",
            "Train step - Step 0, Loss 0.09353271126747131\n",
            "Train step - Step 0, Loss 0.09415829181671143\n",
            "Train step - Step 0, Loss 0.09676191210746765\n",
            "Train step - Step 0, Loss 0.09528440982103348\n",
            "Train step - Step 0, Loss 0.09897346049547195\n",
            "Train step - Step 0, Loss 0.10133769363164902\n",
            "Train step - Step 0, Loss 0.09723740071058273\n",
            "Train step - Step 0, Loss 0.1007814109325409\n",
            "Train step - Step 0, Loss 0.09671945124864578\n",
            "Train epoch - Accuracy: 0.42591666666666667 Loss: 0.09612697631120681 Corrects: 5111\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.08924482017755508\n",
            "Train step - Step 0, Loss 0.10059192031621933\n",
            "Train step - Step 0, Loss 0.09507419914007187\n",
            "Train step - Step 0, Loss 0.09184937179088593\n",
            "Train step - Step 0, Loss 0.09826262295246124\n",
            "Train step - Step 0, Loss 0.09545791149139404\n",
            "Train step - Step 0, Loss 0.09022030979394913\n",
            "Train step - Step 0, Loss 0.09959323704242706\n",
            "Train step - Step 0, Loss 0.09417568892240524\n",
            "Train step - Step 0, Loss 0.09106263518333435\n",
            "Train step - Step 0, Loss 0.09876970201730728\n",
            "Train step - Step 0, Loss 0.09081020951271057\n",
            "Train step - Step 0, Loss 0.10294856131076813\n",
            "Train step - Step 0, Loss 0.09715218096971512\n",
            "Train step - Step 0, Loss 0.09555346518754959\n",
            "Train step - Step 0, Loss 0.08511850237846375\n",
            "Train epoch - Accuracy: 0.42916666666666664 Loss: 0.09497381758689881 Corrects: 5150\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.09178777039051056\n",
            "Train step - Step 0, Loss 0.0921914130449295\n",
            "Train step - Step 0, Loss 0.09586705267429352\n",
            "Train step - Step 0, Loss 0.09690835326910019\n",
            "Train step - Step 0, Loss 0.09755643457174301\n",
            "Train step - Step 0, Loss 0.0961926206946373\n",
            "Train step - Step 0, Loss 0.09547416120767593\n",
            "Train step - Step 0, Loss 0.09590017050504684\n",
            "Train step - Step 0, Loss 0.09704194217920303\n",
            "Train step - Step 0, Loss 0.09741158783435822\n",
            "Train step - Step 0, Loss 0.09399262815713882\n",
            "Train step - Step 0, Loss 0.09659531712532043\n",
            "Train step - Step 0, Loss 0.09506681561470032\n",
            "Train step - Step 0, Loss 0.09644690155982971\n",
            "Train step - Step 0, Loss 0.0969882383942604\n",
            "Train step - Step 0, Loss 0.09508820623159409\n",
            "Train epoch - Accuracy: 0.42591666666666667 Loss: 0.09567049831151962 Corrects: 5111\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.09978576004505157\n",
            "Train step - Step 0, Loss 0.0925464853644371\n",
            "Train step - Step 0, Loss 0.09472060203552246\n",
            "Train step - Step 0, Loss 0.09143593162298203\n",
            "Train step - Step 0, Loss 0.09303682297468185\n",
            "Train step - Step 0, Loss 0.09298919886350632\n",
            "Train step - Step 0, Loss 0.09259191155433655\n",
            "Train step - Step 0, Loss 0.09876475483179092\n",
            "Train step - Step 0, Loss 0.0937257781624794\n",
            "Train step - Step 0, Loss 0.09670007228851318\n",
            "Train step - Step 0, Loss 0.09851961582899094\n",
            "Train step - Step 0, Loss 0.09802151471376419\n",
            "Train step - Step 0, Loss 0.09540636092424393\n",
            "Train step - Step 0, Loss 0.09965278953313828\n",
            "Train step - Step 0, Loss 0.09755369275808334\n",
            "Train step - Step 0, Loss 0.09678994119167328\n",
            "Train epoch - Accuracy: 0.424 Loss: 0.09574048030376435 Corrects: 5088\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.09470928460359573\n",
            "Train step - Step 0, Loss 0.10094321519136429\n",
            "Train step - Step 0, Loss 0.09629415720701218\n",
            "Train step - Step 0, Loss 0.08999421447515488\n",
            "Train step - Step 0, Loss 0.08915701508522034\n",
            "Train step - Step 0, Loss 0.09381281584501266\n",
            "Train step - Step 0, Loss 0.09324086457490921\n",
            "Train step - Step 0, Loss 0.09418975561857224\n",
            "Train step - Step 0, Loss 0.09954480826854706\n",
            "Train step - Step 0, Loss 0.09161550551652908\n",
            "Train step - Step 0, Loss 0.10174532234668732\n",
            "Train step - Step 0, Loss 0.09515349566936493\n",
            "Train step - Step 0, Loss 0.10182029753923416\n",
            "Train step - Step 0, Loss 0.09497039765119553\n",
            "Train step - Step 0, Loss 0.09831263870000839\n",
            "Train step - Step 0, Loss 0.09335528314113617\n",
            "Train epoch - Accuracy: 0.42866666666666664 Loss: 0.09560645377635955 Corrects: 5144\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.09385307878255844\n",
            "Train step - Step 0, Loss 0.1033882424235344\n",
            "Train step - Step 0, Loss 0.09188713133335114\n",
            "Train step - Step 0, Loss 0.0993477925658226\n",
            "Train step - Step 0, Loss 0.0993046760559082\n",
            "Train step - Step 0, Loss 0.09418154507875443\n",
            "Train step - Step 0, Loss 0.09301108121871948\n",
            "Train step - Step 0, Loss 0.09729045629501343\n",
            "Train step - Step 0, Loss 0.10060807317495346\n",
            "Train step - Step 0, Loss 0.09200841188430786\n",
            "Train step - Step 0, Loss 0.09508983045816422\n",
            "Train step - Step 0, Loss 0.09589261561632156\n",
            "Train step - Step 0, Loss 0.09844914078712463\n",
            "Train step - Step 0, Loss 0.08806715160608292\n",
            "Train step - Step 0, Loss 0.08874280005693436\n",
            "Train step - Step 0, Loss 0.10394633561372757\n",
            "Train epoch - Accuracy: 0.42083333333333334 Loss: 0.09574966317415237 Corrects: 5050\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.09493644535541534\n",
            "Train step - Step 0, Loss 0.09892304986715317\n",
            "Train step - Step 0, Loss 0.09563731402158737\n",
            "Train step - Step 0, Loss 0.09624245017766953\n",
            "Train step - Step 0, Loss 0.09376347064971924\n",
            "Train step - Step 0, Loss 0.09856966882944107\n",
            "Train step - Step 0, Loss 0.0915905237197876\n",
            "Train step - Step 0, Loss 0.09059698134660721\n",
            "Train step - Step 0, Loss 0.09763789921998978\n",
            "Train step - Step 0, Loss 0.09491484612226486\n",
            "Train step - Step 0, Loss 0.09485865384340286\n",
            "Train step - Step 0, Loss 0.09523935616016388\n",
            "Train step - Step 0, Loss 0.09148310869932175\n",
            "Train step - Step 0, Loss 0.08984558284282684\n",
            "Train step - Step 0, Loss 0.09080024063587189\n",
            "Train step - Step 0, Loss 0.09734116494655609\n",
            "Train epoch - Accuracy: 0.42633333333333334 Loss: 0.09445618045330048 Corrects: 5116\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.09687408804893494\n",
            "Train step - Step 0, Loss 0.09040505439043045\n",
            "Train step - Step 0, Loss 0.09760723263025284\n",
            "Train step - Step 0, Loss 0.09022574871778488\n",
            "Train step - Step 0, Loss 0.09406597167253494\n",
            "Train step - Step 0, Loss 0.09121730178594589\n",
            "Train step - Step 0, Loss 0.09843439608812332\n",
            "Train step - Step 0, Loss 0.09007973223924637\n",
            "Train step - Step 0, Loss 0.0998794287443161\n",
            "Train step - Step 0, Loss 0.09726736694574356\n",
            "Train step - Step 0, Loss 0.09510643035173416\n",
            "Train step - Step 0, Loss 0.10168780386447906\n",
            "Train step - Step 0, Loss 0.09471648931503296\n",
            "Train step - Step 0, Loss 0.09001602232456207\n",
            "Train step - Step 0, Loss 0.09301988035440445\n",
            "Train step - Step 0, Loss 0.09682077914476395\n",
            "Train epoch - Accuracy: 0.42525 Loss: 0.09479141980409622 Corrects: 5103\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.08949530124664307\n",
            "Train step - Step 0, Loss 0.09344888478517532\n",
            "Train step - Step 0, Loss 0.1018858402967453\n",
            "Train step - Step 0, Loss 0.09162475913763046\n",
            "Train step - Step 0, Loss 0.10137707740068436\n",
            "Train step - Step 0, Loss 0.09157285839319229\n",
            "Train step - Step 0, Loss 0.09109989553689957\n",
            "Train step - Step 0, Loss 0.09538426995277405\n",
            "Train step - Step 0, Loss 0.09578109532594681\n",
            "Train step - Step 0, Loss 0.09091731160879135\n",
            "Train step - Step 0, Loss 0.09976303577423096\n",
            "Train step - Step 0, Loss 0.09545368701219559\n",
            "Train step - Step 0, Loss 0.08952690660953522\n",
            "Train step - Step 0, Loss 0.09526754915714264\n",
            "Train step - Step 0, Loss 0.09430932998657227\n",
            "Train step - Step 0, Loss 0.1026969850063324\n",
            "Train epoch - Accuracy: 0.42541666666666667 Loss: 0.09478997874259949 Corrects: 5105\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.09334520995616913\n",
            "Train step - Step 0, Loss 0.0932101309299469\n",
            "Train step - Step 0, Loss 0.098392553627491\n",
            "Train step - Step 0, Loss 0.0927666425704956\n",
            "Train step - Step 0, Loss 0.10224568843841553\n",
            "Train step - Step 0, Loss 0.09743344783782959\n",
            "Train step - Step 0, Loss 0.10012000799179077\n",
            "Train step - Step 0, Loss 0.09561936557292938\n",
            "Train step - Step 0, Loss 0.09529203921556473\n",
            "Train step - Step 0, Loss 0.09089609980583191\n",
            "Train step - Step 0, Loss 0.09825964272022247\n",
            "Train step - Step 0, Loss 0.08741986751556396\n",
            "Train step - Step 0, Loss 0.0911768227815628\n",
            "Train step - Step 0, Loss 0.09854608029127121\n",
            "Train step - Step 0, Loss 0.09696336090564728\n",
            "Train step - Step 0, Loss 0.09159441292285919\n",
            "Train epoch - Accuracy: 0.427 Loss: 0.09529174196720124 Corrects: 5124\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.09313291311264038\n",
            "Train step - Step 0, Loss 0.09222172945737839\n",
            "Train step - Step 0, Loss 0.09257188439369202\n",
            "Train step - Step 0, Loss 0.09828611463308334\n",
            "Train step - Step 0, Loss 0.09331513196229935\n",
            "Train step - Step 0, Loss 0.0966789498925209\n",
            "Train step - Step 0, Loss 0.09182552248239517\n",
            "Train step - Step 0, Loss 0.0945812463760376\n",
            "Train step - Step 0, Loss 0.09129807353019714\n",
            "Train step - Step 0, Loss 0.09633877128362656\n",
            "Train step - Step 0, Loss 0.0897400975227356\n",
            "Train step - Step 0, Loss 0.09900086373090744\n",
            "Train step - Step 0, Loss 0.09355055540800095\n",
            "Train step - Step 0, Loss 0.09635401517152786\n",
            "Train step - Step 0, Loss 0.09336981922388077\n",
            "Train step - Step 0, Loss 0.09603245556354523\n",
            "Train epoch - Accuracy: 0.428 Loss: 0.09422630226612091 Corrects: 5136\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.09672136604785919\n",
            "Train step - Step 0, Loss 0.09042537957429886\n",
            "Train step - Step 0, Loss 0.09724204242229462\n",
            "Train step - Step 0, Loss 0.09561899304389954\n",
            "Train step - Step 0, Loss 0.09088350087404251\n",
            "Train step - Step 0, Loss 0.09382638335227966\n",
            "Train step - Step 0, Loss 0.09225961565971375\n",
            "Train step - Step 0, Loss 0.09273677319288254\n",
            "Train step - Step 0, Loss 0.09312419593334198\n",
            "Train step - Step 0, Loss 0.09463953226804733\n",
            "Train step - Step 0, Loss 0.10564960539340973\n",
            "Train step - Step 0, Loss 0.09605153650045395\n",
            "Train step - Step 0, Loss 0.09096825867891312\n",
            "Train step - Step 0, Loss 0.09203590452671051\n",
            "Train step - Step 0, Loss 0.0973457470536232\n",
            "Train step - Step 0, Loss 0.09496019780635834\n",
            "Train epoch - Accuracy: 0.42483333333333334 Loss: 0.09464825332164764 Corrects: 5098\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.10095974802970886\n",
            "Train step - Step 0, Loss 0.09876338392496109\n",
            "Train step - Step 0, Loss 0.09516897797584534\n",
            "Train step - Step 0, Loss 0.09266693890094757\n",
            "Train step - Step 0, Loss 0.09256052225828171\n",
            "Train step - Step 0, Loss 0.09553813934326172\n",
            "Train step - Step 0, Loss 0.09368128329515457\n",
            "Train step - Step 0, Loss 0.10034246742725372\n",
            "Train step - Step 0, Loss 0.09216013550758362\n",
            "Train step - Step 0, Loss 0.10135055333375931\n",
            "Train step - Step 0, Loss 0.0940200537443161\n",
            "Train step - Step 0, Loss 0.09487879276275635\n",
            "Train step - Step 0, Loss 0.09276294708251953\n",
            "Train step - Step 0, Loss 0.08986896276473999\n",
            "Train step - Step 0, Loss 0.09916406124830246\n",
            "Train step - Step 0, Loss 0.09782198071479797\n",
            "Train epoch - Accuracy: 0.4235833333333333 Loss: 0.095681645154953 Corrects: 5083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.48 0.09552721679210663\n",
            "TEST GROUP:  0.427\n",
            "TEST ALL:  0.563\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  5000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 80, 97, 93, 85, 81, 65, 61, 49, 21, 9, 96, 76, 83, 72, 68, 64, 56, 36, 32, 24, 20, 16, 4, 2, 6, 10, 18, 79, 75, 67, 63, 59, 55, 47, 39, 31, 23, 19, 7, 98, 94, 90, 82, 54, 42, 34, 30, 22, 0]\n",
            "TRAIN_SET CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "VALIDATION CLASSES:  [55, 54, 98, 96, 31, 94, 93, 85, 19, 9]\n",
            "GROUP:  5\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  50\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.25998884439468384\n",
            "Train step - Step 10, Loss 0.14335153996944427\n",
            "Train step - Step 20, Loss 0.13750776648521423\n",
            "Train step - Step 30, Loss 0.12334831058979034\n",
            "Train step - Step 40, Loss 0.11664299666881561\n",
            "Train step - Step 50, Loss 0.11873897165060043\n",
            "Train epoch - Accuracy: 0.21136690647482015 Loss: 0.14173941593375994 Corrects: 1469\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.11721021682024002\n",
            "Train step - Step 70, Loss 0.12059339880943298\n",
            "Train step - Step 80, Loss 0.1090506911277771\n",
            "Train step - Step 90, Loss 0.11778222769498825\n",
            "Train step - Step 100, Loss 0.11852949857711792\n",
            "Train epoch - Accuracy: 0.2880575539568345 Loss: 0.11772399028856978 Corrects: 2002\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.11273353546857834\n",
            "Train step - Step 120, Loss 0.12059475481510162\n",
            "Train step - Step 130, Loss 0.11240719258785248\n",
            "Train step - Step 140, Loss 0.11538445949554443\n",
            "Train step - Step 150, Loss 0.11541826277971268\n",
            "Train step - Step 160, Loss 0.11325372755527496\n",
            "Train epoch - Accuracy: 0.3315107913669065 Loss: 0.11449245661068305 Corrects: 2304\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11600460112094879\n",
            "Train step - Step 180, Loss 0.11510822176933289\n",
            "Train step - Step 190, Loss 0.1118939220905304\n",
            "Train step - Step 200, Loss 0.10988505184650421\n",
            "Train step - Step 210, Loss 0.11938123404979706\n",
            "Train epoch - Accuracy: 0.37453237410071943 Loss: 0.11329194782877998 Corrects: 2603\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.10665210336446762\n",
            "Train step - Step 230, Loss 0.11099714040756226\n",
            "Train step - Step 240, Loss 0.11599981784820557\n",
            "Train step - Step 250, Loss 0.11678420007228851\n",
            "Train step - Step 260, Loss 0.11012942343950272\n",
            "Train step - Step 270, Loss 0.10833138972520828\n",
            "Train epoch - Accuracy: 0.4037410071942446 Loss: 0.11228095094505831 Corrects: 2806\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.11233116686344147\n",
            "Train step - Step 290, Loss 0.11387990415096283\n",
            "Train step - Step 300, Loss 0.11107829213142395\n",
            "Train step - Step 310, Loss 0.11662522703409195\n",
            "Train step - Step 320, Loss 0.11343225091695786\n",
            "Train epoch - Accuracy: 0.41697841726618706 Loss: 0.11139665950545304 Corrects: 2898\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.11155026406049728\n",
            "Train step - Step 340, Loss 0.11225172132253647\n",
            "Train step - Step 350, Loss 0.10730484127998352\n",
            "Train step - Step 360, Loss 0.11010314524173737\n",
            "Train step - Step 370, Loss 0.10873308032751083\n",
            "Train step - Step 380, Loss 0.1106947660446167\n",
            "Train epoch - Accuracy: 0.4352517985611511 Loss: 0.11032748319905439 Corrects: 3025\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.1137951985001564\n",
            "Train step - Step 400, Loss 0.108163982629776\n",
            "Train step - Step 410, Loss 0.11081083863973618\n",
            "Train step - Step 420, Loss 0.10807328671216965\n",
            "Train step - Step 430, Loss 0.10439489036798477\n",
            "Train epoch - Accuracy: 0.4454676258992806 Loss: 0.10998145769397132 Corrects: 3096\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.10493779182434082\n",
            "Train step - Step 450, Loss 0.11206962168216705\n",
            "Train step - Step 460, Loss 0.11055383086204529\n",
            "Train step - Step 470, Loss 0.11052224785089493\n",
            "Train step - Step 480, Loss 0.1120474711060524\n",
            "Train step - Step 490, Loss 0.10880344361066818\n",
            "Train epoch - Accuracy: 0.45870503597122303 Loss: 0.10949679112262863 Corrects: 3188\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.1071496307849884\n",
            "Train step - Step 510, Loss 0.10986416786909103\n",
            "Train step - Step 520, Loss 0.11066966503858566\n",
            "Train step - Step 530, Loss 0.10950883477926254\n",
            "Train step - Step 540, Loss 0.11221285909414291\n",
            "Train epoch - Accuracy: 0.4788489208633094 Loss: 0.1090356317998694 Corrects: 3328\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.11483518034219742\n",
            "Train step - Step 560, Loss 0.10463470220565796\n",
            "Train step - Step 570, Loss 0.11002860963344574\n",
            "Train step - Step 580, Loss 0.10987918823957443\n",
            "Train step - Step 590, Loss 0.10427065938711166\n",
            "Train step - Step 600, Loss 0.1092761978507042\n",
            "Train epoch - Accuracy: 0.48388489208633095 Loss: 0.10867884470618885 Corrects: 3363\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.10797923058271408\n",
            "Train step - Step 620, Loss 0.11322204023599625\n",
            "Train step - Step 630, Loss 0.10511357337236404\n",
            "Train step - Step 640, Loss 0.1088559702038765\n",
            "Train step - Step 650, Loss 0.10945568978786469\n",
            "Train epoch - Accuracy: 0.5004316546762589 Loss: 0.10809660375975877 Corrects: 3478\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.11227414757013321\n",
            "Train step - Step 670, Loss 0.10167773813009262\n",
            "Train step - Step 680, Loss 0.10709341615438461\n",
            "Train step - Step 690, Loss 0.10909944027662277\n",
            "Train step - Step 700, Loss 0.10266639292240143\n",
            "Train step - Step 710, Loss 0.10569308698177338\n",
            "Train epoch - Accuracy: 0.5041726618705036 Loss: 0.10808393979672905 Corrects: 3504\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.10595159232616425\n",
            "Train step - Step 730, Loss 0.11000596731901169\n",
            "Train step - Step 740, Loss 0.1068287268280983\n",
            "Train step - Step 750, Loss 0.1076158657670021\n",
            "Train step - Step 760, Loss 0.11232233047485352\n",
            "Train epoch - Accuracy: 0.5056115107913669 Loss: 0.10775846629691639 Corrects: 3514\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.10801061987876892\n",
            "Train step - Step 780, Loss 0.10558377206325531\n",
            "Train step - Step 790, Loss 0.10531483590602875\n",
            "Train step - Step 800, Loss 0.10753566771745682\n",
            "Train step - Step 810, Loss 0.10516059398651123\n",
            "Train step - Step 820, Loss 0.1107826977968216\n",
            "Train epoch - Accuracy: 0.5194244604316547 Loss: 0.10768899120872827 Corrects: 3610\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.10682712495326996\n",
            "Train step - Step 840, Loss 0.1064615249633789\n",
            "Train step - Step 850, Loss 0.10799520462751389\n",
            "Train step - Step 860, Loss 0.1099885031580925\n",
            "Train step - Step 870, Loss 0.10772761702537537\n",
            "Train epoch - Accuracy: 0.5202877697841727 Loss: 0.1073890424718102 Corrects: 3616\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.10901100188493729\n",
            "Train step - Step 890, Loss 0.10743112117052078\n",
            "Train step - Step 900, Loss 0.10489204525947571\n",
            "Train step - Step 910, Loss 0.10969915241003036\n",
            "Train step - Step 920, Loss 0.09901265799999237\n",
            "Train step - Step 930, Loss 0.11039496958255768\n",
            "Train epoch - Accuracy: 0.5264748201438849 Loss: 0.10692303142959265 Corrects: 3659\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.1004272997379303\n",
            "Train step - Step 950, Loss 0.11192928999662399\n",
            "Train step - Step 960, Loss 0.10446299612522125\n",
            "Train step - Step 970, Loss 0.10671113431453705\n",
            "Train step - Step 980, Loss 0.1019933670759201\n",
            "Train epoch - Accuracy: 0.5345323741007194 Loss: 0.10694095804322538 Corrects: 3715\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10646415501832962\n",
            "Train step - Step 1000, Loss 0.105631522834301\n",
            "Train step - Step 1010, Loss 0.10391471534967422\n",
            "Train step - Step 1020, Loss 0.10629492253065109\n",
            "Train step - Step 1030, Loss 0.10605953633785248\n",
            "Train step - Step 1040, Loss 0.10513310879468918\n",
            "Train epoch - Accuracy: 0.5385611510791367 Loss: 0.10671349452768299 Corrects: 3743\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10638204216957092\n",
            "Train step - Step 1060, Loss 0.10538056492805481\n",
            "Train step - Step 1070, Loss 0.10304734855890274\n",
            "Train step - Step 1080, Loss 0.10932127386331558\n",
            "Train step - Step 1090, Loss 0.10590186715126038\n",
            "Train epoch - Accuracy: 0.542158273381295 Loss: 0.10666532789631714 Corrects: 3768\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.1038842499256134\n",
            "Train step - Step 1110, Loss 0.10666045546531677\n",
            "Train step - Step 1120, Loss 0.10415511578321457\n",
            "Train step - Step 1130, Loss 0.10798724740743637\n",
            "Train step - Step 1140, Loss 0.10983321815729141\n",
            "Train step - Step 1150, Loss 0.10665334761142731\n",
            "Train epoch - Accuracy: 0.5494964028776979 Loss: 0.10608968512831832 Corrects: 3819\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11015589535236359\n",
            "Train step - Step 1170, Loss 0.1071852296590805\n",
            "Train step - Step 1180, Loss 0.10440555959939957\n",
            "Train step - Step 1190, Loss 0.10950110107660294\n",
            "Train step - Step 1200, Loss 0.10417388379573822\n",
            "Train epoch - Accuracy: 0.56 Loss: 0.10615424486372968 Corrects: 3892\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.10120689123868942\n",
            "Train step - Step 1220, Loss 0.09975143522024155\n",
            "Train step - Step 1230, Loss 0.10484712570905685\n",
            "Train step - Step 1240, Loss 0.10602502524852753\n",
            "Train step - Step 1250, Loss 0.10772629827260971\n",
            "Train step - Step 1260, Loss 0.10612539201974869\n",
            "Train epoch - Accuracy: 0.5556834532374101 Loss: 0.10573073444392184 Corrects: 3862\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10568675398826599\n",
            "Train step - Step 1280, Loss 0.10352075099945068\n",
            "Train step - Step 1290, Loss 0.10333631187677383\n",
            "Train step - Step 1300, Loss 0.10481613129377365\n",
            "Train step - Step 1310, Loss 0.10329080373048782\n",
            "Train epoch - Accuracy: 0.5686330935251799 Loss: 0.10573485447777262 Corrects: 3952\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.10427874326705933\n",
            "Train step - Step 1330, Loss 0.10425221174955368\n",
            "Train step - Step 1340, Loss 0.09986499696969986\n",
            "Train step - Step 1350, Loss 0.1021249070763588\n",
            "Train step - Step 1360, Loss 0.09905652701854706\n",
            "Train step - Step 1370, Loss 0.1068815365433693\n",
            "Train epoch - Accuracy: 0.5676258992805755 Loss: 0.10548305794275065 Corrects: 3945\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10311999917030334\n",
            "Train step - Step 1390, Loss 0.10685937851667404\n",
            "Train step - Step 1400, Loss 0.10416381806135178\n",
            "Train step - Step 1410, Loss 0.11074064671993256\n",
            "Train step - Step 1420, Loss 0.10671941190958023\n",
            "Train epoch - Accuracy: 0.5746762589928057 Loss: 0.10499684518189739 Corrects: 3994\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10690239816904068\n",
            "Train step - Step 1440, Loss 0.10376869887113571\n",
            "Train step - Step 1450, Loss 0.10421788692474365\n",
            "Train step - Step 1460, Loss 0.10400016605854034\n",
            "Train step - Step 1470, Loss 0.1041475236415863\n",
            "Train step - Step 1480, Loss 0.10502582043409348\n",
            "Train epoch - Accuracy: 0.5815827338129497 Loss: 0.10507487690062832 Corrects: 4042\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10225309431552887\n",
            "Train step - Step 1500, Loss 0.11115352064371109\n",
            "Train step - Step 1510, Loss 0.10468442738056183\n",
            "Train step - Step 1520, Loss 0.10332878679037094\n",
            "Train step - Step 1530, Loss 0.10514748096466064\n",
            "Train epoch - Accuracy: 0.581294964028777 Loss: 0.10493674427485294 Corrects: 4040\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.10289914906024933\n",
            "Train step - Step 1550, Loss 0.10945173352956772\n",
            "Train step - Step 1560, Loss 0.10359128564596176\n",
            "Train step - Step 1570, Loss 0.1116684153676033\n",
            "Train step - Step 1580, Loss 0.103600412607193\n",
            "Train step - Step 1590, Loss 0.10699497163295746\n",
            "Train epoch - Accuracy: 0.5840287769784173 Loss: 0.10499618393482922 Corrects: 4059\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10422448068857193\n",
            "Train step - Step 1610, Loss 0.10255252569913864\n",
            "Train step - Step 1620, Loss 0.10355041176080704\n",
            "Train step - Step 1630, Loss 0.10162505507469177\n",
            "Train step - Step 1640, Loss 0.10572604089975357\n",
            "Train epoch - Accuracy: 0.5863309352517986 Loss: 0.10452422370584749 Corrects: 4075\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.10557201504707336\n",
            "Train step - Step 1660, Loss 0.09889540821313858\n",
            "Train step - Step 1670, Loss 0.10578662902116776\n",
            "Train step - Step 1680, Loss 0.10610461980104446\n",
            "Train step - Step 1690, Loss 0.10732095688581467\n",
            "Train step - Step 1700, Loss 0.11132176965475082\n",
            "Train epoch - Accuracy: 0.5887769784172662 Loss: 0.104268076447703 Corrects: 4092\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.10160093009471893\n",
            "Train step - Step 1720, Loss 0.11227187514305115\n",
            "Train step - Step 1730, Loss 0.10415218025445938\n",
            "Train step - Step 1740, Loss 0.10997816175222397\n",
            "Train step - Step 1750, Loss 0.10418735444545746\n",
            "Train epoch - Accuracy: 0.5946762589928057 Loss: 0.10407131984508294 Corrects: 4133\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.10166776180267334\n",
            "Train step - Step 1770, Loss 0.1059165745973587\n",
            "Train step - Step 1780, Loss 0.10845813155174255\n",
            "Train step - Step 1790, Loss 0.10189453512430191\n",
            "Train step - Step 1800, Loss 0.10354989767074585\n",
            "Train step - Step 1810, Loss 0.10690145194530487\n",
            "Train epoch - Accuracy: 0.602589928057554 Loss: 0.10386761936138002 Corrects: 4188\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.09888008236885071\n",
            "Train step - Step 1830, Loss 0.10480610281229019\n",
            "Train step - Step 1840, Loss 0.10300777107477188\n",
            "Train step - Step 1850, Loss 0.11178675293922424\n",
            "Train step - Step 1860, Loss 0.10573669523000717\n",
            "Train epoch - Accuracy: 0.6037410071942446 Loss: 0.10409807093923898 Corrects: 4196\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10654450953006744\n",
            "Train step - Step 1880, Loss 0.10018140822649002\n",
            "Train step - Step 1890, Loss 0.10413934290409088\n",
            "Train step - Step 1900, Loss 0.09887412935495377\n",
            "Train step - Step 1910, Loss 0.10407721996307373\n",
            "Train step - Step 1920, Loss 0.10986676812171936\n",
            "Train epoch - Accuracy: 0.6110791366906475 Loss: 0.10369619802176523 Corrects: 4247\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10216203331947327\n",
            "Train step - Step 1940, Loss 0.10748457908630371\n",
            "Train step - Step 1950, Loss 0.10392826050519943\n",
            "Train step - Step 1960, Loss 0.1029193177819252\n",
            "Train step - Step 1970, Loss 0.10323995351791382\n",
            "Train epoch - Accuracy: 0.6184172661870504 Loss: 0.10377873784132141 Corrects: 4298\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.09739423543214798\n",
            "Train step - Step 1990, Loss 0.10552625358104706\n",
            "Train step - Step 2000, Loss 0.10293325781822205\n",
            "Train step - Step 2010, Loss 0.1008903831243515\n",
            "Train step - Step 2020, Loss 0.10404045879840851\n",
            "Train step - Step 2030, Loss 0.10196731984615326\n",
            "Train epoch - Accuracy: 0.6221582733812949 Loss: 0.10347144599012334 Corrects: 4324\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10015710443258286\n",
            "Train step - Step 2050, Loss 0.10278953611850739\n",
            "Train step - Step 2060, Loss 0.10070649534463882\n",
            "Train step - Step 2070, Loss 0.10370072722434998\n",
            "Train step - Step 2080, Loss 0.10139414668083191\n",
            "Train epoch - Accuracy: 0.6215827338129496 Loss: 0.10336541171768586 Corrects: 4320\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10245726257562637\n",
            "Train step - Step 2100, Loss 0.1074281632900238\n",
            "Train step - Step 2110, Loss 0.10266326367855072\n",
            "Train step - Step 2120, Loss 0.10404683649539948\n",
            "Train step - Step 2130, Loss 0.10840611904859543\n",
            "Train step - Step 2140, Loss 0.10103348642587662\n",
            "Train epoch - Accuracy: 0.6212949640287769 Loss: 0.10309262701290117 Corrects: 4318\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.09737572818994522\n",
            "Train step - Step 2160, Loss 0.10664138197898865\n",
            "Train step - Step 2170, Loss 0.10539756715297699\n",
            "Train step - Step 2180, Loss 0.10172266513109207\n",
            "Train step - Step 2190, Loss 0.10046496987342834\n",
            "Train epoch - Accuracy: 0.6244604316546762 Loss: 0.10324994621516989 Corrects: 4340\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09823819249868393\n",
            "Train step - Step 2210, Loss 0.10346075147390366\n",
            "Train step - Step 2220, Loss 0.0947587639093399\n",
            "Train step - Step 2230, Loss 0.10959884524345398\n",
            "Train step - Step 2240, Loss 0.10041350871324539\n",
            "Train step - Step 2250, Loss 0.09907007217407227\n",
            "Train epoch - Accuracy: 0.6250359712230216 Loss: 0.1030784741730141 Corrects: 4344\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.09868680685758591\n",
            "Train step - Step 2270, Loss 0.10826388746500015\n",
            "Train step - Step 2280, Loss 0.10397067666053772\n",
            "Train step - Step 2290, Loss 0.10441573709249496\n",
            "Train step - Step 2300, Loss 0.09954553097486496\n",
            "Train epoch - Accuracy: 0.6257553956834533 Loss: 0.10297667076690592 Corrects: 4349\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10603853315114975\n",
            "Train step - Step 2320, Loss 0.10061398148536682\n",
            "Train step - Step 2330, Loss 0.10119735449552536\n",
            "Train step - Step 2340, Loss 0.10626313090324402\n",
            "Train step - Step 2350, Loss 0.0976211205124855\n",
            "Train step - Step 2360, Loss 0.1048789918422699\n",
            "Train epoch - Accuracy: 0.6385611510791367 Loss: 0.10260377180662086 Corrects: 4438\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.1069168820977211\n",
            "Train step - Step 2380, Loss 0.10447341948747635\n",
            "Train step - Step 2390, Loss 0.10806918889284134\n",
            "Train step - Step 2400, Loss 0.10457572340965271\n",
            "Train step - Step 2410, Loss 0.10571994632482529\n",
            "Train epoch - Accuracy: 0.6319424460431655 Loss: 0.1025540132895648 Corrects: 4392\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.0977485254406929\n",
            "Train step - Step 2430, Loss 0.10645493119955063\n",
            "Train step - Step 2440, Loss 0.1042899489402771\n",
            "Train step - Step 2450, Loss 0.0944012999534607\n",
            "Train step - Step 2460, Loss 0.10291633009910583\n",
            "Train step - Step 2470, Loss 0.10551242530345917\n",
            "Train epoch - Accuracy: 0.6440287769784173 Loss: 0.10231852720324085 Corrects: 4476\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10068333148956299\n",
            "Train step - Step 2490, Loss 0.1000434085726738\n",
            "Train step - Step 2500, Loss 0.10058515518903732\n",
            "Train step - Step 2510, Loss 0.10200528800487518\n",
            "Train step - Step 2520, Loss 0.1004316657781601\n",
            "Train epoch - Accuracy: 0.638273381294964 Loss: 0.10223335438709465 Corrects: 4436\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10627157986164093\n",
            "Train step - Step 2540, Loss 0.09619247168302536\n",
            "Train step - Step 2550, Loss 0.10131987929344177\n",
            "Train step - Step 2560, Loss 0.1028377115726471\n",
            "Train step - Step 2570, Loss 0.0979137048125267\n",
            "Train step - Step 2580, Loss 0.10003402829170227\n",
            "Train epoch - Accuracy: 0.6548201438848921 Loss: 0.10204299410898908 Corrects: 4551\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.10512104630470276\n",
            "Train step - Step 2600, Loss 0.09939669072628021\n",
            "Train step - Step 2610, Loss 0.09994378685951233\n",
            "Train step - Step 2620, Loss 0.09938032180070877\n",
            "Train step - Step 2630, Loss 0.09528246521949768\n",
            "Train epoch - Accuracy: 0.6444604316546763 Loss: 0.1020446837784575 Corrects: 4479\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10518351942300797\n",
            "Train step - Step 2650, Loss 0.1053038164973259\n",
            "Train step - Step 2660, Loss 0.10033036768436432\n",
            "Train step - Step 2670, Loss 0.1065661609172821\n",
            "Train step - Step 2680, Loss 0.10282838344573975\n",
            "Train step - Step 2690, Loss 0.10072749853134155\n",
            "Train epoch - Accuracy: 0.6494964028776978 Loss: 0.10158424660670672 Corrects: 4514\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10232371836900711\n",
            "Train step - Step 2710, Loss 0.09731202572584152\n",
            "Train step - Step 2720, Loss 0.09169609844684601\n",
            "Train step - Step 2730, Loss 0.0979781523346901\n",
            "Train step - Step 2740, Loss 0.10095895826816559\n",
            "Train epoch - Accuracy: 0.6605755395683454 Loss: 0.100950225651693 Corrects: 4591\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.0976797491312027\n",
            "Train step - Step 2760, Loss 0.09652554988861084\n",
            "Train step - Step 2770, Loss 0.10170495510101318\n",
            "Train step - Step 2780, Loss 0.10027400404214859\n",
            "Train step - Step 2790, Loss 0.10211160778999329\n",
            "Train step - Step 2800, Loss 0.09839873015880585\n",
            "Train epoch - Accuracy: 0.6677697841726619 Loss: 0.10029810377376543 Corrects: 4641\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10130062699317932\n",
            "Train step - Step 2820, Loss 0.1015116348862648\n",
            "Train step - Step 2830, Loss 0.1006765216588974\n",
            "Train step - Step 2840, Loss 0.09906338155269623\n",
            "Train step - Step 2850, Loss 0.10058362036943436\n",
            "Train epoch - Accuracy: 0.6635971223021583 Loss: 0.1007500603066074 Corrects: 4612\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.0975629985332489\n",
            "Train step - Step 2870, Loss 0.10098335146903992\n",
            "Train step - Step 2880, Loss 0.09776091575622559\n",
            "Train step - Step 2890, Loss 0.09617458283901215\n",
            "Train step - Step 2900, Loss 0.10015324503183365\n",
            "Train step - Step 2910, Loss 0.10337983816862106\n",
            "Train epoch - Accuracy: 0.6647482014388489 Loss: 0.10018715405421291 Corrects: 4620\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10158117115497589\n",
            "Train step - Step 2930, Loss 0.10086975991725922\n",
            "Train step - Step 2940, Loss 0.10118444263935089\n",
            "Train step - Step 2950, Loss 0.10363902896642685\n",
            "Train step - Step 2960, Loss 0.10137607157230377\n",
            "Train epoch - Accuracy: 0.6643165467625899 Loss: 0.10039461735341189 Corrects: 4617\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09770827740430832\n",
            "Train step - Step 2980, Loss 0.09970702975988388\n",
            "Train step - Step 2990, Loss 0.09889934211969376\n",
            "Train step - Step 3000, Loss 0.10693403333425522\n",
            "Train step - Step 3010, Loss 0.10014188289642334\n",
            "Train step - Step 3020, Loss 0.09934834390878677\n",
            "Train epoch - Accuracy: 0.6644604316546763 Loss: 0.10022997572910872 Corrects: 4618\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.09985535591840744\n",
            "Train step - Step 3040, Loss 0.10282792896032333\n",
            "Train step - Step 3050, Loss 0.10294442623853683\n",
            "Train step - Step 3060, Loss 0.09826567769050598\n",
            "Train step - Step 3070, Loss 0.10122320801019669\n",
            "Train epoch - Accuracy: 0.6643165467625899 Loss: 0.10033565208208647 Corrects: 4617\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.09945530444383621\n",
            "Train step - Step 3090, Loss 0.10205858200788498\n",
            "Train step - Step 3100, Loss 0.09998437017202377\n",
            "Train step - Step 3110, Loss 0.09438249468803406\n",
            "Train step - Step 3120, Loss 0.10504475980997086\n",
            "Train step - Step 3130, Loss 0.10403984785079956\n",
            "Train epoch - Accuracy: 0.661726618705036 Loss: 0.09995923281359158 Corrects: 4599\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10185477137565613\n",
            "Train step - Step 3150, Loss 0.10315219312906265\n",
            "Train step - Step 3160, Loss 0.1001734808087349\n",
            "Train step - Step 3170, Loss 0.09943139553070068\n",
            "Train step - Step 3180, Loss 0.09728988260030746\n",
            "Train epoch - Accuracy: 0.6699280575539568 Loss: 0.10034202625425599 Corrects: 4656\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09659872204065323\n",
            "Train step - Step 3200, Loss 0.10118839889764786\n",
            "Train step - Step 3210, Loss 0.10133487731218338\n",
            "Train step - Step 3220, Loss 0.09824419021606445\n",
            "Train step - Step 3230, Loss 0.10314969718456268\n",
            "Train step - Step 3240, Loss 0.09910314530134201\n",
            "Train epoch - Accuracy: 0.6673381294964029 Loss: 0.10038248756806628 Corrects: 4638\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.10269135236740112\n",
            "Train step - Step 3260, Loss 0.10279452800750732\n",
            "Train step - Step 3270, Loss 0.10779275000095367\n",
            "Train step - Step 3280, Loss 0.1009887307882309\n",
            "Train step - Step 3290, Loss 0.09582482278347015\n",
            "Train epoch - Accuracy: 0.6709352517985612 Loss: 0.1002268995183835 Corrects: 4663\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.10044486820697784\n",
            "Train step - Step 3310, Loss 0.09911774098873138\n",
            "Train step - Step 3320, Loss 0.10192962735891342\n",
            "Train step - Step 3330, Loss 0.10348573327064514\n",
            "Train step - Step 3340, Loss 0.10436660796403885\n",
            "Train step - Step 3350, Loss 0.09908892214298248\n",
            "Train epoch - Accuracy: 0.6722302158273381 Loss: 0.10008785306978568 Corrects: 4672\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.10071074962615967\n",
            "Train step - Step 3370, Loss 0.09592563658952713\n",
            "Train step - Step 3380, Loss 0.10006015747785568\n",
            "Train step - Step 3390, Loss 0.10150232911109924\n",
            "Train step - Step 3400, Loss 0.0998561754822731\n",
            "Train epoch - Accuracy: 0.663884892086331 Loss: 0.10034043995596523 Corrects: 4614\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09389646351337433\n",
            "Train step - Step 3420, Loss 0.09396643191576004\n",
            "Train step - Step 3430, Loss 0.1024492159485817\n",
            "Train step - Step 3440, Loss 0.09925527125597\n",
            "Train step - Step 3450, Loss 0.09547138214111328\n",
            "Train step - Step 3460, Loss 0.09636706858873367\n",
            "Train epoch - Accuracy: 0.6713669064748201 Loss: 0.0997825131999503 Corrects: 4666\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.09687259793281555\n",
            "Train step - Step 3480, Loss 0.10074473917484283\n",
            "Train step - Step 3490, Loss 0.1017361730337143\n",
            "Train step - Step 3500, Loss 0.10454168170690536\n",
            "Train step - Step 3510, Loss 0.10069306194782257\n",
            "Train epoch - Accuracy: 0.6716546762589928 Loss: 0.10025302364457425 Corrects: 4668\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.10002538561820984\n",
            "Train step - Step 3530, Loss 0.10505983233451843\n",
            "Train step - Step 3540, Loss 0.10521535575389862\n",
            "Train step - Step 3550, Loss 0.10071244835853577\n",
            "Train step - Step 3560, Loss 0.10024753212928772\n",
            "Train step - Step 3570, Loss 0.0984974354505539\n",
            "Train epoch - Accuracy: 0.6741007194244605 Loss: 0.10015843985964068 Corrects: 4685\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.09811220318078995\n",
            "Train step - Step 3590, Loss 0.10128390789031982\n",
            "Train step - Step 3600, Loss 0.10174170881509781\n",
            "Train step - Step 3610, Loss 0.09898711740970612\n",
            "Train step - Step 3620, Loss 0.09495633840560913\n",
            "Train epoch - Accuracy: 0.6729496402877698 Loss: 0.09999617337537327 Corrects: 4677\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.1032341867685318\n",
            "Train step - Step 3640, Loss 0.10412666201591492\n",
            "Train step - Step 3650, Loss 0.09909550100564957\n",
            "Train step - Step 3660, Loss 0.10115758329629898\n",
            "Train step - Step 3670, Loss 0.09623628109693527\n",
            "Train step - Step 3680, Loss 0.09900134801864624\n",
            "Train epoch - Accuracy: 0.679136690647482 Loss: 0.0996441507318037 Corrects: 4720\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.09922801703214645\n",
            "Train step - Step 3700, Loss 0.09967648983001709\n",
            "Train step - Step 3710, Loss 0.0989600196480751\n",
            "Train step - Step 3720, Loss 0.10308577120304108\n",
            "Train step - Step 3730, Loss 0.09880492091178894\n",
            "Train epoch - Accuracy: 0.6759712230215827 Loss: 0.09980148054927374 Corrects: 4698\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.1005866602063179\n",
            "Train step - Step 3750, Loss 0.09899596869945526\n",
            "Train step - Step 3760, Loss 0.10129427909851074\n",
            "Train step - Step 3770, Loss 0.10114704072475433\n",
            "Train step - Step 3780, Loss 0.10624385625123978\n",
            "Train step - Step 3790, Loss 0.09867900609970093\n",
            "Train epoch - Accuracy: 0.6764028776978417 Loss: 0.0998771595954895 Corrects: 4701\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.10214013606309891\n",
            "Train step - Step 3810, Loss 0.10044039785861969\n",
            "Train step - Step 3820, Loss 0.10007785260677338\n",
            "Train step - Step 3830, Loss 0.09735782444477081\n",
            "Train step - Step 3840, Loss 0.09834538400173187\n",
            "Train epoch - Accuracy: 0.6736690647482014 Loss: 0.09952829911125649 Corrects: 4682\n",
            "Training finished in 447.97895193099976 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee59ff90>\n",
            "Constructing exemplars of class 55\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [32703, 4672, 34624, 12117, 2929, 3777, 22876, 13377, 42657, 36515, 25445, 2417, 11003, 45731, 46844, 24406, 17986, 12723, 24083, 49779, 10455, 23866, 9576, 18373, 46308, 36424, 15195, 25943, 12947, 8437, 47849, 39153, 10647, 38665, 15739, 16177, 10913, 18546, 41712, 40039]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a207990>\n",
            "Constructing exemplars of class 31\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [42428, 593, 42873, 12848, 38882, 23234, 16631, 14639, 39763, 31902, 31380, 31136, 26579, 37584, 31798, 19230, 44679, 3305, 46805, 29007, 23690, 31762, 35687, 31661, 26056, 16298, 14566, 36654, 25592, 39980, 1697, 27076, 44558, 29260, 47501, 30231, 32309, 44715, 4549, 1163]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee578290>\n",
            "Constructing exemplars of class 19\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [1850, 49450, 23073, 46468, 36580, 3611, 18220, 39853, 15735, 8924, 13498, 4038, 18457, 23503, 11148, 42771, 7698, 22153, 15065, 37207, 17741, 38897, 22964, 48802, 31229, 39096, 10705, 46563, 44475, 49450, 25953, 20607, 39074, 48193, 9027, 38897, 19008, 8252, 41367, 41897]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a617210>\n",
            "Constructing exemplars of class 98\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [33552, 15118, 3624, 42474, 19101, 24936, 12689, 17733, 1772, 36191, 21310, 1267, 23474, 31514, 18109, 2106, 6326, 42553, 29937, 14675, 32462, 7526, 22231, 11547, 36246, 45361, 29008, 20685, 38365, 8983, 12163, 14930, 5455, 48054, 28915, 8983, 28640, 5299, 9787, 1146]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a207990>\n",
            "Constructing exemplars of class 94\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [48187, 30557, 11129, 12486, 1305, 20693, 14944, 32473, 21313, 29414, 11066, 47292, 49982, 3005, 2133, 18675, 9741, 34822, 18935, 48146, 45955, 22009, 14943, 4253, 31897, 9056, 18234, 46168, 1435, 40458, 24209, 40568, 2494, 14944, 19426, 6106, 24402, 19237, 20398, 18234]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee583c50>\n",
            "Constructing exemplars of class 54\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [5336, 27923, 1295, 36722, 22330, 40397, 26834, 10925, 37341, 26088, 5128, 16464, 8053, 11459, 31898, 11584, 22412, 28881, 14184, 4192, 31296, 7847, 27040, 18056, 28026, 48933, 13574, 26088, 17111, 14325, 7642, 37113, 10857, 39664, 15687, 35633, 18311, 12883, 20957, 18291]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a25e2d0>\n",
            "Constructing exemplars of class 93\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [38617, 6732, 8311, 20630, 47762, 11099, 35277, 16641, 21285, 25470, 39470, 27623, 35101, 7737, 27315, 29109, 6906, 23613, 32379, 17547, 35559, 20940, 10409, 35143, 5015, 22741, 32753, 34365, 10560, 16077, 27566, 9888, 43965, 25452, 10663, 24576, 4715, 38574, 47581, 43507]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a527b90>\n",
            "Constructing exemplars of class 85\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [16156, 18907, 28211, 9875, 2115, 3028, 2202, 28019, 2195, 19930, 20358, 35958, 31286, 27860, 2766, 17670, 35358, 36380, 42142, 47858, 23049, 5553, 27901, 23434, 26533, 33442, 30815, 25082, 18414, 34490, 4524, 45294, 47723, 9820, 25623, 26833, 26242, 3862, 1866, 19523]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee56b310>\n",
            "Constructing exemplars of class 9\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [44039, 15525, 14040, 17153, 22462, 23769, 47729, 2921, 31703, 28458, 38621, 41258, 20582, 33547, 9016, 15658, 45207, 47382, 11776, 28874, 46018, 14040, 1876, 46945, 9805, 36594, 4795, 45332, 16470, 48638, 39886, 9109, 34293, 48470, 23303, 8374, 34658, 25570, 5670, 28458]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1f93d0>\n",
            "Constructing exemplars of class 96\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [5854, 29327, 18213, 27077, 28807, 23257, 1823, 17948, 36653, 35249, 39112, 39740, 43485, 39082, 10063, 23665, 28195, 48166, 41191, 14915, 16165, 9286, 7748, 47624, 830, 40534, 15523, 23542, 34709, 40534, 34422, 16426, 18099, 13450, 31207, 31615, 9088, 48487, 28717, 48858]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.10607156157493591\n",
            "Train step - Step 0, Loss 0.1035681813955307\n",
            "Train step - Step 0, Loss 0.10815918445587158\n",
            "Train step - Step 0, Loss 0.09791847318410873\n",
            "Train step - Step 0, Loss 0.09862463921308517\n",
            "Train step - Step 0, Loss 0.1047155037522316\n",
            "Train step - Step 0, Loss 0.10493407398462296\n",
            "Train step - Step 0, Loss 0.10390643030405045\n",
            "Train step - Step 0, Loss 0.09633177518844604\n",
            "Train step - Step 0, Loss 0.09903714805841446\n",
            "Train step - Step 0, Loss 0.09748034179210663\n",
            "Train step - Step 0, Loss 0.09978223592042923\n",
            "Train step - Step 0, Loss 0.09379123151302338\n",
            "Train step - Step 0, Loss 0.09697898477315903\n",
            "Train step - Step 0, Loss 0.09374602138996124\n",
            "Train step - Step 0, Loss 0.09066788852214813\n",
            "Train epoch - Accuracy: 0.38866666666666666 Loss: 0.09994964587688446 Corrects: 4664\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.09475086629390717\n",
            "Train step - Step 0, Loss 0.0983809307217598\n",
            "Train step - Step 0, Loss 0.10238810628652573\n",
            "Train step - Step 0, Loss 0.09677112102508545\n",
            "Train step - Step 0, Loss 0.0909501314163208\n",
            "Train step - Step 0, Loss 0.08733826875686646\n",
            "Train step - Step 0, Loss 0.09136513620615005\n",
            "Train step - Step 0, Loss 0.1021774411201477\n",
            "Train step - Step 0, Loss 0.10284379124641418\n",
            "Train step - Step 0, Loss 0.09435397386550903\n",
            "Train step - Step 0, Loss 0.09671808034181595\n",
            "Train step - Step 0, Loss 0.0984552800655365\n",
            "Train step - Step 0, Loss 0.0986027792096138\n",
            "Train step - Step 0, Loss 0.10639834403991699\n",
            "Train step - Step 0, Loss 0.10393000394105911\n",
            "Train step - Step 0, Loss 0.1051890030503273\n",
            "Train epoch - Accuracy: 0.38558333333333333 Loss: 0.09799471241235733 Corrects: 4627\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.09704402834177017\n",
            "Train step - Step 0, Loss 0.09229501336812973\n",
            "Train step - Step 0, Loss 0.09369771927595139\n",
            "Train step - Step 0, Loss 0.09302464872598648\n",
            "Train step - Step 0, Loss 0.10050889849662781\n",
            "Train step - Step 0, Loss 0.08798599243164062\n",
            "Train step - Step 0, Loss 0.09509604424238205\n",
            "Train step - Step 0, Loss 0.10242314636707306\n",
            "Train step - Step 0, Loss 0.09658057242631912\n",
            "Train step - Step 0, Loss 0.09587880969047546\n",
            "Train step - Step 0, Loss 0.09899673610925674\n",
            "Train step - Step 0, Loss 0.10216516256332397\n",
            "Train step - Step 0, Loss 0.09155071526765823\n",
            "Train step - Step 0, Loss 0.09623593837022781\n",
            "Train step - Step 0, Loss 0.09780889749526978\n",
            "Train step - Step 0, Loss 0.09323117136955261\n",
            "Train epoch - Accuracy: 0.38825 Loss: 0.09597195553779601 Corrects: 4659\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.09045387804508209\n",
            "Train step - Step 0, Loss 0.09383200854063034\n",
            "Train step - Step 0, Loss 0.09972433000802994\n",
            "Train step - Step 0, Loss 0.10194272547960281\n",
            "Train step - Step 0, Loss 0.09570004045963287\n",
            "Train step - Step 0, Loss 0.0899905115365982\n",
            "Train step - Step 0, Loss 0.09574529528617859\n",
            "Train step - Step 0, Loss 0.09540034085512161\n",
            "Train step - Step 0, Loss 0.09049881249666214\n",
            "Train step - Step 0, Loss 0.0946914553642273\n",
            "Train step - Step 0, Loss 0.0946168527007103\n",
            "Train step - Step 0, Loss 0.08753933012485504\n",
            "Train step - Step 0, Loss 0.09586810320615768\n",
            "Train step - Step 0, Loss 0.09270548820495605\n",
            "Train step - Step 0, Loss 0.09620305895805359\n",
            "Train step - Step 0, Loss 0.0876823142170906\n",
            "Train epoch - Accuracy: 0.3869166666666667 Loss: 0.09406167536973953 Corrects: 4643\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.09592602401971817\n",
            "Train step - Step 0, Loss 0.09102414548397064\n",
            "Train step - Step 0, Loss 0.08987339586019516\n",
            "Train step - Step 0, Loss 0.09223410487174988\n",
            "Train step - Step 0, Loss 0.09478223323822021\n",
            "Train step - Step 0, Loss 0.09058050811290741\n",
            "Train step - Step 0, Loss 0.09218831360340118\n",
            "Train step - Step 0, Loss 0.0976279005408287\n",
            "Train step - Step 0, Loss 0.09618885070085526\n",
            "Train step - Step 0, Loss 0.09041067212820053\n",
            "Train step - Step 0, Loss 0.09214158356189728\n",
            "Train step - Step 0, Loss 0.09163496643304825\n",
            "Train step - Step 0, Loss 0.09658704698085785\n",
            "Train step - Step 0, Loss 0.09461285918951035\n",
            "Train step - Step 0, Loss 0.09740475565195084\n",
            "Train step - Step 0, Loss 0.10148883610963821\n",
            "Train epoch - Accuracy: 0.3879166666666667 Loss: 0.09386546450853347 Corrects: 4655\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.09222918748855591\n",
            "Train step - Step 0, Loss 0.09025529026985168\n",
            "Train step - Step 0, Loss 0.09112448245286942\n",
            "Train step - Step 0, Loss 0.08836643397808075\n",
            "Train step - Step 0, Loss 0.09832557290792465\n",
            "Train step - Step 0, Loss 0.09455198794603348\n",
            "Train step - Step 0, Loss 0.0943177342414856\n",
            "Train step - Step 0, Loss 0.09823616594076157\n",
            "Train step - Step 0, Loss 0.09524749964475632\n",
            "Train step - Step 0, Loss 0.10242246091365814\n",
            "Train step - Step 0, Loss 0.08653534203767776\n",
            "Train step - Step 0, Loss 0.10146325081586838\n",
            "Train step - Step 0, Loss 0.09805860370397568\n",
            "Train step - Step 0, Loss 0.08675996214151382\n",
            "Train step - Step 0, Loss 0.09181278198957443\n",
            "Train step - Step 0, Loss 0.10433033853769302\n",
            "Train epoch - Accuracy: 0.38008333333333333 Loss: 0.09439444595575333 Corrects: 4561\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.09518774598836899\n",
            "Train step - Step 0, Loss 0.0860556811094284\n",
            "Train step - Step 0, Loss 0.09469782561063766\n",
            "Train step - Step 0, Loss 0.09301357716321945\n",
            "Train step - Step 0, Loss 0.08876492083072662\n",
            "Train step - Step 0, Loss 0.09263268113136292\n",
            "Train step - Step 0, Loss 0.09156382828950882\n",
            "Train step - Step 0, Loss 0.09450165182352066\n",
            "Train step - Step 0, Loss 0.09728002548217773\n",
            "Train step - Step 0, Loss 0.09164973348379135\n",
            "Train step - Step 0, Loss 0.09737098217010498\n",
            "Train step - Step 0, Loss 0.09695522487163544\n",
            "Train step - Step 0, Loss 0.09440872073173523\n",
            "Train step - Step 0, Loss 0.09962838888168335\n",
            "Train step - Step 0, Loss 0.09487541764974594\n",
            "Train step - Step 0, Loss 0.08773940056562424\n",
            "Train epoch - Accuracy: 0.3873333333333333 Loss: 0.09365910595655441 Corrects: 4648\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.09353507310152054\n",
            "Train step - Step 0, Loss 0.09072700887918472\n",
            "Train step - Step 0, Loss 0.09197013825178146\n",
            "Train step - Step 0, Loss 0.09576883167028427\n",
            "Train step - Step 0, Loss 0.0925048366189003\n",
            "Train step - Step 0, Loss 0.09329577535390854\n",
            "Train step - Step 0, Loss 0.09724950045347214\n",
            "Train step - Step 0, Loss 0.08905131369829178\n",
            "Train step - Step 0, Loss 0.09178397804498672\n",
            "Train step - Step 0, Loss 0.09325901418924332\n",
            "Train step - Step 0, Loss 0.09115713834762573\n",
            "Train step - Step 0, Loss 0.09913906455039978\n",
            "Train step - Step 0, Loss 0.09663502126932144\n",
            "Train step - Step 0, Loss 0.10010843724012375\n",
            "Train step - Step 0, Loss 0.08910252153873444\n",
            "Train step - Step 0, Loss 0.09605519473552704\n",
            "Train epoch - Accuracy: 0.3814166666666667 Loss: 0.09378061759471894 Corrects: 4577\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.09699435532093048\n",
            "Train step - Step 0, Loss 0.09996591508388519\n",
            "Train step - Step 0, Loss 0.09560121595859528\n",
            "Train step - Step 0, Loss 0.09965728223323822\n",
            "Train step - Step 0, Loss 0.08779379725456238\n",
            "Train step - Step 0, Loss 0.09200998395681381\n",
            "Train step - Step 0, Loss 0.0908491313457489\n",
            "Train step - Step 0, Loss 0.0891157016158104\n",
            "Train step - Step 0, Loss 0.0950329378247261\n",
            "Train step - Step 0, Loss 0.09218770265579224\n",
            "Train step - Step 0, Loss 0.0927821472287178\n",
            "Train step - Step 0, Loss 0.09318947792053223\n",
            "Train step - Step 0, Loss 0.08997858315706253\n",
            "Train step - Step 0, Loss 0.09429922699928284\n",
            "Train step - Step 0, Loss 0.09569357335567474\n",
            "Train step - Step 0, Loss 0.09167356044054031\n",
            "Train epoch - Accuracy: 0.386 Loss: 0.09359660845994949 Corrects: 4632\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.09277516603469849\n",
            "Train step - Step 0, Loss 0.09236755967140198\n",
            "Train step - Step 0, Loss 0.09077592194080353\n",
            "Train step - Step 0, Loss 0.08910684287548065\n",
            "Train step - Step 0, Loss 0.09585565328598022\n",
            "Train step - Step 0, Loss 0.09242209047079086\n",
            "Train step - Step 0, Loss 0.10127132385969162\n",
            "Train step - Step 0, Loss 0.08779537677764893\n",
            "Train step - Step 0, Loss 0.0927080288529396\n",
            "Train step - Step 0, Loss 0.0976383313536644\n",
            "Train step - Step 0, Loss 0.09976028650999069\n",
            "Train step - Step 0, Loss 0.09175293892621994\n",
            "Train step - Step 0, Loss 0.09296276420354843\n",
            "Train step - Step 0, Loss 0.09492012113332748\n",
            "Train step - Step 0, Loss 0.0912616103887558\n",
            "Train step - Step 0, Loss 0.0829104408621788\n",
            "Train epoch - Accuracy: 0.39375 Loss: 0.09313235467672348 Corrects: 4725\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.08733245730400085\n",
            "Train step - Step 0, Loss 0.09630192071199417\n",
            "Train step - Step 0, Loss 0.09099961072206497\n",
            "Train step - Step 0, Loss 0.09423621743917465\n",
            "Train step - Step 0, Loss 0.09674383699893951\n",
            "Train step - Step 0, Loss 0.09449152648448944\n",
            "Train step - Step 0, Loss 0.08464084565639496\n",
            "Train step - Step 0, Loss 0.09328529983758926\n",
            "Train step - Step 0, Loss 0.09244433045387268\n",
            "Train step - Step 0, Loss 0.09570066630840302\n",
            "Train step - Step 0, Loss 0.09170389920473099\n",
            "Train step - Step 0, Loss 0.09278816729784012\n",
            "Train step - Step 0, Loss 0.09501106292009354\n",
            "Train step - Step 0, Loss 0.08299102634191513\n",
            "Train step - Step 0, Loss 0.09212429821491241\n",
            "Train step - Step 0, Loss 0.09753556549549103\n",
            "Train epoch - Accuracy: 0.38716666666666666 Loss: 0.09227231323719025 Corrects: 4646\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.09373971819877625\n",
            "Train step - Step 0, Loss 0.09138057380914688\n",
            "Train step - Step 0, Loss 0.09859023988246918\n",
            "Train step - Step 0, Loss 0.09634793549776077\n",
            "Train step - Step 0, Loss 0.08988013863563538\n",
            "Train step - Step 0, Loss 0.09386175125837326\n",
            "Train step - Step 0, Loss 0.0916985347867012\n",
            "Train step - Step 0, Loss 0.08834579586982727\n",
            "Train step - Step 0, Loss 0.0889621153473854\n",
            "Train step - Step 0, Loss 0.0941905677318573\n",
            "Train step - Step 0, Loss 0.09226568788290024\n",
            "Train step - Step 0, Loss 0.09227951616048813\n",
            "Train step - Step 0, Loss 0.10003574937582016\n",
            "Train step - Step 0, Loss 0.08977048844099045\n",
            "Train step - Step 0, Loss 0.09404675662517548\n",
            "Train step - Step 0, Loss 0.08584116399288177\n",
            "Train epoch - Accuracy: 0.37983333333333336 Loss: 0.09273896300792694 Corrects: 4558\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.09330829977989197\n",
            "Train step - Step 0, Loss 0.09825722128152847\n",
            "Train step - Step 0, Loss 0.09092442691326141\n",
            "Train step - Step 0, Loss 0.09161467105150223\n",
            "Train step - Step 0, Loss 0.08971478790044785\n",
            "Train step - Step 0, Loss 0.09071885794401169\n",
            "Train step - Step 0, Loss 0.09134473651647568\n",
            "Train step - Step 0, Loss 0.09451618790626526\n",
            "Train step - Step 0, Loss 0.09495815634727478\n",
            "Train step - Step 0, Loss 0.09007394313812256\n",
            "Train step - Step 0, Loss 0.08785685151815414\n",
            "Train step - Step 0, Loss 0.08713981509208679\n",
            "Train step - Step 0, Loss 0.09237981587648392\n",
            "Train step - Step 0, Loss 0.09601917862892151\n",
            "Train step - Step 0, Loss 0.09277992695569992\n",
            "Train step - Step 0, Loss 0.08822537213563919\n",
            "Train epoch - Accuracy: 0.38716666666666666 Loss: 0.09195185500383377 Corrects: 4646\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.10221762955188751\n",
            "Train step - Step 0, Loss 0.0960291177034378\n",
            "Train step - Step 0, Loss 0.09213505685329437\n",
            "Train step - Step 0, Loss 0.08971317112445831\n",
            "Train step - Step 0, Loss 0.08484557271003723\n",
            "Train step - Step 0, Loss 0.08700870722532272\n",
            "Train step - Step 0, Loss 0.08958274126052856\n",
            "Train step - Step 0, Loss 0.0994366705417633\n",
            "Train step - Step 0, Loss 0.09481953829526901\n",
            "Train step - Step 0, Loss 0.08786556124687195\n",
            "Train step - Step 0, Loss 0.09482954442501068\n",
            "Train step - Step 0, Loss 0.08914800733327866\n",
            "Train step - Step 0, Loss 0.08541012555360794\n",
            "Train step - Step 0, Loss 0.09635433554649353\n",
            "Train step - Step 0, Loss 0.09227202087640762\n",
            "Train step - Step 0, Loss 0.09217695146799088\n",
            "Train epoch - Accuracy: 0.3864166666666667 Loss: 0.09211381727457046 Corrects: 4637\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.09182348847389221\n",
            "Train step - Step 0, Loss 0.09693185985088348\n",
            "Train step - Step 0, Loss 0.0964498221874237\n",
            "Train step - Step 0, Loss 0.08586868643760681\n",
            "Train step - Step 0, Loss 0.0857125073671341\n",
            "Train step - Step 0, Loss 0.08813479542732239\n",
            "Train step - Step 0, Loss 0.09403449296951294\n",
            "Train step - Step 0, Loss 0.09722723811864853\n",
            "Train step - Step 0, Loss 0.09547481685876846\n",
            "Train step - Step 0, Loss 0.09705830365419388\n",
            "Train step - Step 0, Loss 0.08691953122615814\n",
            "Train step - Step 0, Loss 0.09111291170120239\n",
            "Train step - Step 0, Loss 0.09591854363679886\n",
            "Train step - Step 0, Loss 0.08913446217775345\n",
            "Train step - Step 0, Loss 0.08940579742193222\n",
            "Train step - Step 0, Loss 0.0882561206817627\n",
            "Train epoch - Accuracy: 0.38483333333333336 Loss: 0.09192750930786132 Corrects: 4618\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.09147487580776215\n",
            "Train step - Step 0, Loss 0.09097978472709656\n",
            "Train step - Step 0, Loss 0.09476097673177719\n",
            "Train step - Step 0, Loss 0.09582389146089554\n",
            "Train step - Step 0, Loss 0.08617071807384491\n",
            "Train step - Step 0, Loss 0.0907994732260704\n",
            "Train step - Step 0, Loss 0.08657624572515488\n",
            "Train step - Step 0, Loss 0.08769086003303528\n",
            "Train step - Step 0, Loss 0.09038686752319336\n",
            "Train step - Step 0, Loss 0.08751456439495087\n",
            "Train step - Step 0, Loss 0.09223808348178864\n",
            "Train step - Step 0, Loss 0.09456547349691391\n",
            "Train step - Step 0, Loss 0.08899182081222534\n",
            "Train step - Step 0, Loss 0.10190651565790176\n",
            "Train step - Step 0, Loss 0.09932053834199905\n",
            "Train step - Step 0, Loss 0.10045253485441208\n",
            "Train epoch - Accuracy: 0.3859166666666667 Loss: 0.09228694552183152 Corrects: 4631\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.0968221053481102\n",
            "Train step - Step 0, Loss 0.0958113893866539\n",
            "Train step - Step 0, Loss 0.09004414826631546\n",
            "Train step - Step 0, Loss 0.09050072729587555\n",
            "Train step - Step 0, Loss 0.09462405741214752\n",
            "Train step - Step 0, Loss 0.09064438939094543\n",
            "Train step - Step 0, Loss 0.09369686245918274\n",
            "Train step - Step 0, Loss 0.09606920182704926\n",
            "Train step - Step 0, Loss 0.09283731132745743\n",
            "Train step - Step 0, Loss 0.09192721545696259\n",
            "Train step - Step 0, Loss 0.09374638646841049\n",
            "Train step - Step 0, Loss 0.09124584496021271\n",
            "Train step - Step 0, Loss 0.09197796136140823\n",
            "Train step - Step 0, Loss 0.08183182030916214\n",
            "Train step - Step 0, Loss 0.09130629152059555\n",
            "Train step - Step 0, Loss 0.08456961810588837\n",
            "Train epoch - Accuracy: 0.3868333333333333 Loss: 0.09190027034282684 Corrects: 4642\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.09699488431215286\n",
            "Train step - Step 0, Loss 0.0972929298877716\n",
            "Train step - Step 0, Loss 0.10242106020450592\n",
            "Train step - Step 0, Loss 0.09069178253412247\n",
            "Train step - Step 0, Loss 0.09542537480592728\n",
            "Train step - Step 0, Loss 0.09033707529306412\n",
            "Train step - Step 0, Loss 0.08925794810056686\n",
            "Train step - Step 0, Loss 0.08462987840175629\n",
            "Train step - Step 0, Loss 0.09194483608007431\n",
            "Train step - Step 0, Loss 0.0917823314666748\n",
            "Train step - Step 0, Loss 0.08215641230344772\n",
            "Train step - Step 0, Loss 0.09741111099720001\n",
            "Train step - Step 0, Loss 0.09113655984401703\n",
            "Train step - Step 0, Loss 0.08783936500549316\n",
            "Train step - Step 0, Loss 0.09074027091264725\n",
            "Train step - Step 0, Loss 0.08749792724847794\n",
            "Train epoch - Accuracy: 0.3913333333333333 Loss: 0.0918238735795021 Corrects: 4696\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.09985815733671188\n",
            "Train step - Step 0, Loss 0.08903761208057404\n",
            "Train step - Step 0, Loss 0.09137603640556335\n",
            "Train step - Step 0, Loss 0.09049501270055771\n",
            "Train step - Step 0, Loss 0.08576294034719467\n",
            "Train step - Step 0, Loss 0.09100104868412018\n",
            "Train step - Step 0, Loss 0.09042953699827194\n",
            "Train step - Step 0, Loss 0.08847815543413162\n",
            "Train step - Step 0, Loss 0.09105278551578522\n",
            "Train step - Step 0, Loss 0.09089838713407516\n",
            "Train step - Step 0, Loss 0.08928095549345016\n",
            "Train step - Step 0, Loss 0.09149110317230225\n",
            "Train step - Step 0, Loss 0.0870848223567009\n",
            "Train step - Step 0, Loss 0.0895874947309494\n",
            "Train step - Step 0, Loss 0.09688004851341248\n",
            "Train step - Step 0, Loss 0.08845636248588562\n",
            "Train epoch - Accuracy: 0.38175 Loss: 0.09075195670127868 Corrects: 4581\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.08607667684555054\n",
            "Train step - Step 0, Loss 0.09751828759908676\n",
            "Train step - Step 0, Loss 0.08526048064231873\n",
            "Train step - Step 0, Loss 0.0957433432340622\n",
            "Train step - Step 0, Loss 0.09168612211942673\n",
            "Train step - Step 0, Loss 0.08827759325504303\n",
            "Train step - Step 0, Loss 0.09073792397975922\n",
            "Train step - Step 0, Loss 0.09319403767585754\n",
            "Train step - Step 0, Loss 0.08352605253458023\n",
            "Train step - Step 0, Loss 0.08870626986026764\n",
            "Train step - Step 0, Loss 0.0923316702246666\n",
            "Train step - Step 0, Loss 0.09230785071849823\n",
            "Train step - Step 0, Loss 0.09231578558683395\n",
            "Train step - Step 0, Loss 0.09089044481515884\n",
            "Train step - Step 0, Loss 0.09764815121889114\n",
            "Train step - Step 0, Loss 0.08520542085170746\n",
            "Train epoch - Accuracy: 0.38416666666666666 Loss: 0.09084634101390839 Corrects: 4610\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.08804310113191605\n",
            "Train step - Step 0, Loss 0.08742911368608475\n",
            "Train step - Step 0, Loss 0.09214874356985092\n",
            "Train step - Step 0, Loss 0.0859750360250473\n",
            "Train step - Step 0, Loss 0.09272295236587524\n",
            "Train step - Step 0, Loss 0.09876252710819244\n",
            "Train step - Step 0, Loss 0.09441474825143814\n",
            "Train step - Step 0, Loss 0.08543795347213745\n",
            "Train step - Step 0, Loss 0.08837903290987015\n",
            "Train step - Step 0, Loss 0.09604252874851227\n",
            "Train step - Step 0, Loss 0.09342620521783829\n",
            "Train step - Step 0, Loss 0.08929455280303955\n",
            "Train step - Step 0, Loss 0.0969996526837349\n",
            "Train step - Step 0, Loss 0.08540786802768707\n",
            "Train step - Step 0, Loss 0.08965558558702469\n",
            "Train step - Step 0, Loss 0.09067697823047638\n",
            "Train epoch - Accuracy: 0.38908333333333334 Loss: 0.090932013630867 Corrects: 4669\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.08869065344333649\n",
            "Train step - Step 0, Loss 0.09157054871320724\n",
            "Train step - Step 0, Loss 0.09100010246038437\n",
            "Train step - Step 0, Loss 0.09140060842037201\n",
            "Train step - Step 0, Loss 0.08790870755910873\n",
            "Train step - Step 0, Loss 0.09067320823669434\n",
            "Train step - Step 0, Loss 0.08579424768686295\n",
            "Train step - Step 0, Loss 0.0946391299366951\n",
            "Train step - Step 0, Loss 0.09324340522289276\n",
            "Train step - Step 0, Loss 0.09114901721477509\n",
            "Train step - Step 0, Loss 0.08668987452983856\n",
            "Train step - Step 0, Loss 0.09619095921516418\n",
            "Train step - Step 0, Loss 0.09847687929868698\n",
            "Train step - Step 0, Loss 0.08678529411554337\n",
            "Train step - Step 0, Loss 0.08909975737333298\n",
            "Train step - Step 0, Loss 0.08394552767276764\n",
            "Train epoch - Accuracy: 0.38766666666666666 Loss: 0.090609814286232 Corrects: 4652\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.09058579057455063\n",
            "Train step - Step 0, Loss 0.08829004317522049\n",
            "Train step - Step 0, Loss 0.09024415910243988\n",
            "Train step - Step 0, Loss 0.08987642824649811\n",
            "Train step - Step 0, Loss 0.08725640922784805\n",
            "Train step - Step 0, Loss 0.08448684960603714\n",
            "Train step - Step 0, Loss 0.08784470707178116\n",
            "Train step - Step 0, Loss 0.08914545178413391\n",
            "Train step - Step 0, Loss 0.09077435731887817\n",
            "Train step - Step 0, Loss 0.09006399661302567\n",
            "Train step - Step 0, Loss 0.08697081357240677\n",
            "Train step - Step 0, Loss 0.09543002396821976\n",
            "Train step - Step 0, Loss 0.09877800196409225\n",
            "Train step - Step 0, Loss 0.09186762571334839\n",
            "Train step - Step 0, Loss 0.09166160970926285\n",
            "Train step - Step 0, Loss 0.09061349183320999\n",
            "Train epoch - Accuracy: 0.39108333333333334 Loss: 0.09023422080278397 Corrects: 4693\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.0895497277379036\n",
            "Train step - Step 0, Loss 0.0933782309293747\n",
            "Train step - Step 0, Loss 0.09052853286266327\n",
            "Train step - Step 0, Loss 0.09525541216135025\n",
            "Train step - Step 0, Loss 0.09085870534181595\n",
            "Train step - Step 0, Loss 0.0949445441365242\n",
            "Train step - Step 0, Loss 0.0876709446310997\n",
            "Train step - Step 0, Loss 0.09448020160198212\n",
            "Train step - Step 0, Loss 0.09522849321365356\n",
            "Train step - Step 0, Loss 0.09005524218082428\n",
            "Train step - Step 0, Loss 0.08382316678762436\n",
            "Train step - Step 0, Loss 0.09050043672323227\n",
            "Train step - Step 0, Loss 0.08960483223199844\n",
            "Train step - Step 0, Loss 0.09160067141056061\n",
            "Train step - Step 0, Loss 0.08892510831356049\n",
            "Train step - Step 0, Loss 0.09259296208620071\n",
            "Train epoch - Accuracy: 0.3824166666666667 Loss: 0.09115359050035476 Corrects: 4589\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.08978447318077087\n",
            "Train step - Step 0, Loss 0.08721862733364105\n",
            "Train step - Step 0, Loss 0.09638945758342743\n",
            "Train step - Step 0, Loss 0.09281105548143387\n",
            "Train step - Step 0, Loss 0.09313908219337463\n",
            "Train step - Step 0, Loss 0.09547726809978485\n",
            "Train step - Step 0, Loss 0.08984246104955673\n",
            "Train step - Step 0, Loss 0.09206317365169525\n",
            "Train step - Step 0, Loss 0.0888502225279808\n",
            "Train step - Step 0, Loss 0.0932566449046135\n",
            "Train step - Step 0, Loss 0.0915692001581192\n",
            "Train step - Step 0, Loss 0.08475411683320999\n",
            "Train step - Step 0, Loss 0.09251603484153748\n",
            "Train step - Step 0, Loss 0.09303148835897446\n",
            "Train step - Step 0, Loss 0.08189941942691803\n",
            "Train step - Step 0, Loss 0.09325353801250458\n",
            "Train epoch - Accuracy: 0.38475 Loss: 0.09093671596050262 Corrects: 4617\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.0889909416437149\n",
            "Train step - Step 0, Loss 0.08935276418924332\n",
            "Train step - Step 0, Loss 0.08860643953084946\n",
            "Train step - Step 0, Loss 0.08625020831823349\n",
            "Train step - Step 0, Loss 0.09251941740512848\n",
            "Train step - Step 0, Loss 0.08780946582555771\n",
            "Train step - Step 0, Loss 0.0884382426738739\n",
            "Train step - Step 0, Loss 0.08555835485458374\n",
            "Train step - Step 0, Loss 0.09144779294729233\n",
            "Train step - Step 0, Loss 0.09749257564544678\n",
            "Train step - Step 0, Loss 0.09280704706907272\n",
            "Train step - Step 0, Loss 0.09391197562217712\n",
            "Train step - Step 0, Loss 0.08588952571153641\n",
            "Train step - Step 0, Loss 0.09520164877176285\n",
            "Train step - Step 0, Loss 0.08765766024589539\n",
            "Train step - Step 0, Loss 0.09301981329917908\n",
            "Train epoch - Accuracy: 0.387 Loss: 0.09024457240104675 Corrects: 4644\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.09509117156267166\n",
            "Train step - Step 0, Loss 0.09197281301021576\n",
            "Train step - Step 0, Loss 0.0912657082080841\n",
            "Train step - Step 0, Loss 0.08424953371286392\n",
            "Train step - Step 0, Loss 0.09496480226516724\n",
            "Train step - Step 0, Loss 0.08240616321563721\n",
            "Train step - Step 0, Loss 0.08621802181005478\n",
            "Train step - Step 0, Loss 0.0936477854847908\n",
            "Train step - Step 0, Loss 0.09023449569940567\n",
            "Train step - Step 0, Loss 0.08665325492620468\n",
            "Train step - Step 0, Loss 0.09457379579544067\n",
            "Train step - Step 0, Loss 0.09111442416906357\n",
            "Train step - Step 0, Loss 0.09149546176195145\n",
            "Train step - Step 0, Loss 0.09150248765945435\n",
            "Train step - Step 0, Loss 0.08993195742368698\n",
            "Train step - Step 0, Loss 0.09286433458328247\n",
            "Train epoch - Accuracy: 0.39691666666666664 Loss: 0.09045517349243164 Corrects: 4763\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.0940055251121521\n",
            "Train step - Step 0, Loss 0.09325671195983887\n",
            "Train step - Step 0, Loss 0.08554425090551376\n",
            "Train step - Step 0, Loss 0.08649711310863495\n",
            "Train step - Step 0, Loss 0.09106288850307465\n",
            "Train step - Step 0, Loss 0.083897665143013\n",
            "Train step - Step 0, Loss 0.08944212645292282\n",
            "Train step - Step 0, Loss 0.08790040016174316\n",
            "Train step - Step 0, Loss 0.08405852317810059\n",
            "Train step - Step 0, Loss 0.08984853327274323\n",
            "Train step - Step 0, Loss 0.08987589925527573\n",
            "Train step - Step 0, Loss 0.0957082062959671\n",
            "Train step - Step 0, Loss 0.08856178820133209\n",
            "Train step - Step 0, Loss 0.09103696048259735\n",
            "Train step - Step 0, Loss 0.0915515273809433\n",
            "Train step - Step 0, Loss 0.09385168552398682\n",
            "Train epoch - Accuracy: 0.3884166666666667 Loss: 0.08965794706344604 Corrects: 4661\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.0943150594830513\n",
            "Train step - Step 0, Loss 0.08870630711317062\n",
            "Train step - Step 0, Loss 0.09149914979934692\n",
            "Train step - Step 0, Loss 0.09323836863040924\n",
            "Train step - Step 0, Loss 0.09136251360177994\n",
            "Train step - Step 0, Loss 0.08837083727121353\n",
            "Train step - Step 0, Loss 0.09189378470182419\n",
            "Train step - Step 0, Loss 0.08927973359823227\n",
            "Train step - Step 0, Loss 0.10163076967000961\n",
            "Train step - Step 0, Loss 0.09021944552659988\n",
            "Train step - Step 0, Loss 0.08980196714401245\n",
            "Train step - Step 0, Loss 0.08902142196893692\n",
            "Train step - Step 0, Loss 0.08642353862524033\n",
            "Train step - Step 0, Loss 0.08798213303089142\n",
            "Train step - Step 0, Loss 0.0991276353597641\n",
            "Train step - Step 0, Loss 0.08188623934984207\n",
            "Train epoch - Accuracy: 0.3905 Loss: 0.09113930016756058 Corrects: 4686\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.09470117837190628\n",
            "Train step - Step 0, Loss 0.0896141529083252\n",
            "Train step - Step 0, Loss 0.09177077561616898\n",
            "Train step - Step 0, Loss 0.09276186674833298\n",
            "Train step - Step 0, Loss 0.08591099083423615\n",
            "Train step - Step 0, Loss 0.08619999140501022\n",
            "Train step - Step 0, Loss 0.09429119527339935\n",
            "Train step - Step 0, Loss 0.08939038962125778\n",
            "Train step - Step 0, Loss 0.08896198123693466\n",
            "Train step - Step 0, Loss 0.08747491240501404\n",
            "Train step - Step 0, Loss 0.09261472523212433\n",
            "Train step - Step 0, Loss 0.09556174278259277\n",
            "Train step - Step 0, Loss 0.08605986833572388\n",
            "Train step - Step 0, Loss 0.0863831639289856\n",
            "Train step - Step 0, Loss 0.09174510836601257\n",
            "Train step - Step 0, Loss 0.09450656920671463\n",
            "Train epoch - Accuracy: 0.39008333333333334 Loss: 0.09040055352449416 Corrects: 4681\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.0955233946442604\n",
            "Train step - Step 0, Loss 0.0941004827618599\n",
            "Train step - Step 0, Loss 0.09324353188276291\n",
            "Train step - Step 0, Loss 0.09129545092582703\n",
            "Train step - Step 0, Loss 0.0880855992436409\n",
            "Train step - Step 0, Loss 0.08858705312013626\n",
            "Train step - Step 0, Loss 0.09424921125173569\n",
            "Train step - Step 0, Loss 0.08819590508937836\n",
            "Train step - Step 0, Loss 0.09418190270662308\n",
            "Train step - Step 0, Loss 0.08926261216402054\n",
            "Train step - Step 0, Loss 0.08636901527643204\n",
            "Train step - Step 0, Loss 0.08604235202074051\n",
            "Train step - Step 0, Loss 0.09148935973644257\n",
            "Train step - Step 0, Loss 0.0885939970612526\n",
            "Train step - Step 0, Loss 0.09088627994060516\n",
            "Train step - Step 0, Loss 0.09140224009752274\n",
            "Train epoch - Accuracy: 0.3804166666666667 Loss: 0.09070288306474686 Corrects: 4565\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.09021861106157303\n",
            "Train step - Step 0, Loss 0.09219510108232498\n",
            "Train step - Step 0, Loss 0.08635708689689636\n",
            "Train step - Step 0, Loss 0.08893980830907822\n",
            "Train step - Step 0, Loss 0.08956079930067062\n",
            "Train step - Step 0, Loss 0.09303169697523117\n",
            "Train step - Step 0, Loss 0.09068597108125687\n",
            "Train step - Step 0, Loss 0.09228619188070297\n",
            "Train step - Step 0, Loss 0.0908631980419159\n",
            "Train step - Step 0, Loss 0.08974528312683105\n",
            "Train step - Step 0, Loss 0.08665487170219421\n",
            "Train step - Step 0, Loss 0.08937257528305054\n",
            "Train step - Step 0, Loss 0.08830524235963821\n",
            "Train step - Step 0, Loss 0.08972075581550598\n",
            "Train step - Step 0, Loss 0.0941692367196083\n",
            "Train step - Step 0, Loss 0.0829731673002243\n",
            "Train epoch - Accuracy: 0.3938333333333333 Loss: 0.08985373818874359 Corrects: 4726\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.08814331889152527\n",
            "Train step - Step 0, Loss 0.09819861501455307\n",
            "Train step - Step 0, Loss 0.0874609425663948\n",
            "Train step - Step 0, Loss 0.08887431025505066\n",
            "Train step - Step 0, Loss 0.0875050276517868\n",
            "Train step - Step 0, Loss 0.0940418466925621\n",
            "Train step - Step 0, Loss 0.09438008815050125\n",
            "Train step - Step 0, Loss 0.08398942649364471\n",
            "Train step - Step 0, Loss 0.09229854494333267\n",
            "Train step - Step 0, Loss 0.08713218569755554\n",
            "Train step - Step 0, Loss 0.09501173347234726\n",
            "Train step - Step 0, Loss 0.09303775429725647\n",
            "Train step - Step 0, Loss 0.0931662991642952\n",
            "Train step - Step 0, Loss 0.08699269592761993\n",
            "Train step - Step 0, Loss 0.09034741669893265\n",
            "Train step - Step 0, Loss 0.08340328186750412\n",
            "Train epoch - Accuracy: 0.38816666666666666 Loss: 0.09041326445341111 Corrects: 4658\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.08750109374523163\n",
            "Train step - Step 0, Loss 0.08995295315980911\n",
            "Train step - Step 0, Loss 0.0863751769065857\n",
            "Train step - Step 0, Loss 0.08939528465270996\n",
            "Train step - Step 0, Loss 0.08435221016407013\n",
            "Train step - Step 0, Loss 0.08922645449638367\n",
            "Train step - Step 0, Loss 0.09292132407426834\n",
            "Train step - Step 0, Loss 0.09369558840990067\n",
            "Train step - Step 0, Loss 0.10074631869792938\n",
            "Train step - Step 0, Loss 0.0907551571726799\n",
            "Train step - Step 0, Loss 0.08329859375953674\n",
            "Train step - Step 0, Loss 0.08938056975603104\n",
            "Train step - Step 0, Loss 0.09195201098918915\n",
            "Train step - Step 0, Loss 0.09173224121332169\n",
            "Train step - Step 0, Loss 0.0941135585308075\n",
            "Train step - Step 0, Loss 0.09675464034080505\n",
            "Train epoch - Accuracy: 0.38858333333333334 Loss: 0.0906156919002533 Corrects: 4663\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.08939436823129654\n",
            "Train step - Step 0, Loss 0.0911385715007782\n",
            "Train step - Step 0, Loss 0.08732916414737701\n",
            "Train step - Step 0, Loss 0.09471441060304642\n",
            "Train step - Step 0, Loss 0.09376954287290573\n",
            "Train step - Step 0, Loss 0.0916954055428505\n",
            "Train step - Step 0, Loss 0.0898357480764389\n",
            "Train step - Step 0, Loss 0.09019026905298233\n",
            "Train step - Step 0, Loss 0.08647464215755463\n",
            "Train step - Step 0, Loss 0.0891856700181961\n",
            "Train step - Step 0, Loss 0.08957425504922867\n",
            "Train step - Step 0, Loss 0.08965586870908737\n",
            "Train step - Step 0, Loss 0.08338961005210876\n",
            "Train step - Step 0, Loss 0.08591930568218231\n",
            "Train step - Step 0, Loss 0.09345259517431259\n",
            "Train step - Step 0, Loss 0.09627876430749893\n",
            "Train epoch - Accuracy: 0.3844166666666667 Loss: 0.08997719389200211 Corrects: 4613\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.08906270563602448\n",
            "Train step - Step 0, Loss 0.08348007500171661\n",
            "Train step - Step 0, Loss 0.08946391195058823\n",
            "Train step - Step 0, Loss 0.08896028250455856\n",
            "Train step - Step 0, Loss 0.08895169943571091\n",
            "Train step - Step 0, Loss 0.09617248922586441\n",
            "Train step - Step 0, Loss 0.08851061761379242\n",
            "Train step - Step 0, Loss 0.09280087798833847\n",
            "Train step - Step 0, Loss 0.09411013871431351\n",
            "Train step - Step 0, Loss 0.0908626988530159\n",
            "Train step - Step 0, Loss 0.0849316269159317\n",
            "Train step - Step 0, Loss 0.09193779528141022\n",
            "Train step - Step 0, Loss 0.08840800076723099\n",
            "Train step - Step 0, Loss 0.0865013599395752\n",
            "Train step - Step 0, Loss 0.08773517608642578\n",
            "Train step - Step 0, Loss 0.09382322430610657\n",
            "Train epoch - Accuracy: 0.38875 Loss: 0.08963385415077209 Corrects: 4665\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.08939069509506226\n",
            "Train step - Step 0, Loss 0.08922374993562698\n",
            "Train step - Step 0, Loss 0.09135251492261887\n",
            "Train step - Step 0, Loss 0.08721178025007248\n",
            "Train step - Step 0, Loss 0.08834844082593918\n",
            "Train step - Step 0, Loss 0.09410816431045532\n",
            "Train step - Step 0, Loss 0.0881371796131134\n",
            "Train step - Step 0, Loss 0.08949900418519974\n",
            "Train step - Step 0, Loss 0.08709343522787094\n",
            "Train step - Step 0, Loss 0.09181130677461624\n",
            "Train step - Step 0, Loss 0.09428088366985321\n",
            "Train step - Step 0, Loss 0.08838405460119247\n",
            "Train step - Step 0, Loss 0.08813397586345673\n",
            "Train step - Step 0, Loss 0.08917868882417679\n",
            "Train step - Step 0, Loss 0.08469973504543304\n",
            "Train step - Step 0, Loss 0.09795524179935455\n",
            "Train epoch - Accuracy: 0.3844166666666667 Loss: 0.08973284065723419 Corrects: 4613\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.08952268213033676\n",
            "Train step - Step 0, Loss 0.08519859611988068\n",
            "Train step - Step 0, Loss 0.09007924795150757\n",
            "Train step - Step 0, Loss 0.09372025728225708\n",
            "Train step - Step 0, Loss 0.08645039051771164\n",
            "Train step - Step 0, Loss 0.09842722862958908\n",
            "Train step - Step 0, Loss 0.08782873302698135\n",
            "Train step - Step 0, Loss 0.08253299444913864\n",
            "Train step - Step 0, Loss 0.08793284744024277\n",
            "Train step - Step 0, Loss 0.08872906863689423\n",
            "Train step - Step 0, Loss 0.08935301005840302\n",
            "Train step - Step 0, Loss 0.09987630695104599\n",
            "Train step - Step 0, Loss 0.09462035447359085\n",
            "Train step - Step 0, Loss 0.09632803499698639\n",
            "Train step - Step 0, Loss 0.08599276095628738\n",
            "Train step - Step 0, Loss 0.09077256172895432\n",
            "Train epoch - Accuracy: 0.38216666666666665 Loss: 0.09045282334089279 Corrects: 4586\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.09169556200504303\n",
            "Train step - Step 0, Loss 0.08724170923233032\n",
            "Train step - Step 0, Loss 0.09227491170167923\n",
            "Train step - Step 0, Loss 0.08695058524608612\n",
            "Train step - Step 0, Loss 0.09058775007724762\n",
            "Train step - Step 0, Loss 0.08429587632417679\n",
            "Train step - Step 0, Loss 0.09159014374017715\n",
            "Train step - Step 0, Loss 0.0874934047460556\n",
            "Train step - Step 0, Loss 0.09488065540790558\n",
            "Train step - Step 0, Loss 0.08474321663379669\n",
            "Train step - Step 0, Loss 0.09632544219493866\n",
            "Train step - Step 0, Loss 0.08619283884763718\n",
            "Train step - Step 0, Loss 0.08477004617452621\n",
            "Train step - Step 0, Loss 0.09328917413949966\n",
            "Train step - Step 0, Loss 0.0848013162612915\n",
            "Train step - Step 0, Loss 0.0900268480181694\n",
            "Train epoch - Accuracy: 0.3924166666666667 Loss: 0.08917756241559982 Corrects: 4709\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.09164769947528839\n",
            "Train step - Step 0, Loss 0.09018005430698395\n",
            "Train step - Step 0, Loss 0.0898623839020729\n",
            "Train step - Step 0, Loss 0.08895950764417648\n",
            "Train step - Step 0, Loss 0.09162019938230515\n",
            "Train step - Step 0, Loss 0.08616635948419571\n",
            "Train step - Step 0, Loss 0.09177190065383911\n",
            "Train step - Step 0, Loss 0.0936608761548996\n",
            "Train step - Step 0, Loss 0.08953328430652618\n",
            "Train step - Step 0, Loss 0.08775649219751358\n",
            "Train step - Step 0, Loss 0.08409955352544785\n",
            "Train step - Step 0, Loss 0.08147946745157242\n",
            "Train step - Step 0, Loss 0.09588038176298141\n",
            "Train step - Step 0, Loss 0.08949417620897293\n",
            "Train step - Step 0, Loss 0.08733512461185455\n",
            "Train step - Step 0, Loss 0.09097178280353546\n",
            "Train epoch - Accuracy: 0.3878333333333333 Loss: 0.08936350882053375 Corrects: 4654\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.08800871670246124\n",
            "Train step - Step 0, Loss 0.09185866266489029\n",
            "Train step - Step 0, Loss 0.08126373589038849\n",
            "Train step - Step 0, Loss 0.09576918929815292\n",
            "Train step - Step 0, Loss 0.0911417305469513\n",
            "Train step - Step 0, Loss 0.0912175104022026\n",
            "Train step - Step 0, Loss 0.09046658873558044\n",
            "Train step - Step 0, Loss 0.09101971983909607\n",
            "Train step - Step 0, Loss 0.09331310540437698\n",
            "Train step - Step 0, Loss 0.08748160302639008\n",
            "Train step - Step 0, Loss 0.08832337707281113\n",
            "Train step - Step 0, Loss 0.09083399921655655\n",
            "Train step - Step 0, Loss 0.08208614587783813\n",
            "Train step - Step 0, Loss 0.08885113149881363\n",
            "Train step - Step 0, Loss 0.0917043387889862\n",
            "Train step - Step 0, Loss 0.08366226404905319\n",
            "Train epoch - Accuracy: 0.39216666666666666 Loss: 0.08932022207975387 Corrects: 4706\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.0849902406334877\n",
            "Train step - Step 0, Loss 0.0942608192563057\n",
            "Train step - Step 0, Loss 0.09218656271696091\n",
            "Train step - Step 0, Loss 0.08592753112316132\n",
            "Train step - Step 0, Loss 0.09374944865703583\n",
            "Train step - Step 0, Loss 0.08747386187314987\n",
            "Train step - Step 0, Loss 0.09312107414007187\n",
            "Train step - Step 0, Loss 0.08837354183197021\n",
            "Train step - Step 0, Loss 0.0879901647567749\n",
            "Train step - Step 0, Loss 0.0891881212592125\n",
            "Train step - Step 0, Loss 0.08736422657966614\n",
            "Train step - Step 0, Loss 0.09081035107374191\n",
            "Train step - Step 0, Loss 0.09008330851793289\n",
            "Train step - Step 0, Loss 0.09199211001396179\n",
            "Train step - Step 0, Loss 0.09084959328174591\n",
            "Train step - Step 0, Loss 0.08991346508264542\n",
            "Train epoch - Accuracy: 0.38566666666666666 Loss: 0.0898916397690773 Corrects: 4628\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.08595793694257736\n",
            "Train step - Step 0, Loss 0.08900731801986694\n",
            "Train step - Step 0, Loss 0.09029235690832138\n",
            "Train step - Step 0, Loss 0.09234259277582169\n",
            "Train step - Step 0, Loss 0.08741108328104019\n",
            "Train step - Step 0, Loss 0.08790821582078934\n",
            "Train step - Step 0, Loss 0.0878901258111\n",
            "Train step - Step 0, Loss 0.09418967366218567\n",
            "Train step - Step 0, Loss 0.08965045213699341\n",
            "Train step - Step 0, Loss 0.08582593500614166\n",
            "Train step - Step 0, Loss 0.08694787323474884\n",
            "Train step - Step 0, Loss 0.08936024457216263\n",
            "Train step - Step 0, Loss 0.09133144468069077\n",
            "Train step - Step 0, Loss 0.09213555604219437\n",
            "Train step - Step 0, Loss 0.0889233872294426\n",
            "Train step - Step 0, Loss 0.08586268872022629\n",
            "Train epoch - Accuracy: 0.3905 Loss: 0.08914165610074996 Corrects: 4686\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.09463158994913101\n",
            "Train step - Step 0, Loss 0.09239017963409424\n",
            "Train step - Step 0, Loss 0.08842183649539948\n",
            "Train step - Step 0, Loss 0.08839326351881027\n",
            "Train step - Step 0, Loss 0.089266337454319\n",
            "Train step - Step 0, Loss 0.08558732271194458\n",
            "Train step - Step 0, Loss 0.09191560000181198\n",
            "Train step - Step 0, Loss 0.08523497730493546\n",
            "Train step - Step 0, Loss 0.09058638662099838\n",
            "Train step - Step 0, Loss 0.08700432628393173\n",
            "Train step - Step 0, Loss 0.09009824693202972\n",
            "Train step - Step 0, Loss 0.08871636539697647\n",
            "Train step - Step 0, Loss 0.08733777701854706\n",
            "Train step - Step 0, Loss 0.09264051169157028\n",
            "Train step - Step 0, Loss 0.08556870371103287\n",
            "Train step - Step 0, Loss 0.08567801862955093\n",
            "Train epoch - Accuracy: 0.38516666666666666 Loss: 0.08904589992761612 Corrects: 4622\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.09032105654478073\n",
            "Train step - Step 0, Loss 0.08391513675451279\n",
            "Train step - Step 0, Loss 0.09392043203115463\n",
            "Train step - Step 0, Loss 0.08287958055734634\n",
            "Train step - Step 0, Loss 0.09273770451545715\n",
            "Train step - Step 0, Loss 0.08740612864494324\n",
            "Train step - Step 0, Loss 0.0855797603726387\n",
            "Train step - Step 0, Loss 0.09043584764003754\n",
            "Train step - Step 0, Loss 0.0923454686999321\n",
            "Train step - Step 0, Loss 0.0880703404545784\n",
            "Train step - Step 0, Loss 0.08624543249607086\n",
            "Train step - Step 0, Loss 0.09103713184595108\n",
            "Train step - Step 0, Loss 0.08996791392564774\n",
            "Train step - Step 0, Loss 0.09313240647315979\n",
            "Train step - Step 0, Loss 0.08917534351348877\n",
            "Train step - Step 0, Loss 0.09085742384195328\n",
            "Train epoch - Accuracy: 0.3834166666666667 Loss: 0.08921315675973893 Corrects: 4601\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.0916890799999237\n",
            "Train step - Step 0, Loss 0.0857740193605423\n",
            "Train step - Step 0, Loss 0.08566251397132874\n",
            "Train step - Step 0, Loss 0.08230477571487427\n",
            "Train step - Step 0, Loss 0.09340284019708633\n",
            "Train step - Step 0, Loss 0.0874127671122551\n",
            "Train step - Step 0, Loss 0.09141556173563004\n",
            "Train step - Step 0, Loss 0.08887442201375961\n",
            "Train step - Step 0, Loss 0.09146945178508759\n",
            "Train step - Step 0, Loss 0.09447512775659561\n",
            "Train step - Step 0, Loss 0.08706974238157272\n",
            "Train step - Step 0, Loss 0.09091571718454361\n",
            "Train step - Step 0, Loss 0.08816004544496536\n",
            "Train step - Step 0, Loss 0.09041478484869003\n",
            "Train step - Step 0, Loss 0.08602014183998108\n",
            "Train step - Step 0, Loss 0.0840969905257225\n",
            "Train epoch - Accuracy: 0.385 Loss: 0.0888077830672264 Corrects: 4620\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.08728525042533875\n",
            "Train step - Step 0, Loss 0.08731754869222641\n",
            "Train step - Step 0, Loss 0.0881481021642685\n",
            "Train step - Step 0, Loss 0.08523301035165787\n",
            "Train step - Step 0, Loss 0.09551934152841568\n",
            "Train step - Step 0, Loss 0.09093626588582993\n",
            "Train step - Step 0, Loss 0.08790323883295059\n",
            "Train step - Step 0, Loss 0.08798108994960785\n",
            "Train step - Step 0, Loss 0.08844700455665588\n",
            "Train step - Step 0, Loss 0.09170746058225632\n",
            "Train step - Step 0, Loss 0.0892973467707634\n",
            "Train step - Step 0, Loss 0.08653310686349869\n",
            "Train step - Step 0, Loss 0.08792762458324432\n",
            "Train step - Step 0, Loss 0.08984927088022232\n",
            "Train step - Step 0, Loss 0.09500054270029068\n",
            "Train step - Step 0, Loss 0.08820633590221405\n",
            "Train epoch - Accuracy: 0.37875 Loss: 0.0892297705411911 Corrects: 4545\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.08869224786758423\n",
            "Train step - Step 0, Loss 0.0889819860458374\n",
            "Train step - Step 0, Loss 0.09092118591070175\n",
            "Train step - Step 0, Loss 0.09151320159435272\n",
            "Train step - Step 0, Loss 0.08696535229682922\n",
            "Train step - Step 0, Loss 0.08976057916879654\n",
            "Train step - Step 0, Loss 0.08723818510770798\n",
            "Train step - Step 0, Loss 0.08873212337493896\n",
            "Train step - Step 0, Loss 0.08837222307920456\n",
            "Train step - Step 0, Loss 0.08915112167596817\n",
            "Train step - Step 0, Loss 0.0932721197605133\n",
            "Train step - Step 0, Loss 0.08686760812997818\n",
            "Train step - Step 0, Loss 0.08367174863815308\n",
            "Train step - Step 0, Loss 0.08462581783533096\n",
            "Train step - Step 0, Loss 0.09364984184503555\n",
            "Train step - Step 0, Loss 0.0939878523349762\n",
            "Train epoch - Accuracy: 0.38616666666666666 Loss: 0.08903409600257874 Corrects: 4634\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.09412778168916702\n",
            "Train step - Step 0, Loss 0.09011861681938171\n",
            "Train step - Step 0, Loss 0.09034185111522675\n",
            "Train step - Step 0, Loss 0.09055259823799133\n",
            "Train step - Step 0, Loss 0.0841587632894516\n",
            "Train step - Step 0, Loss 0.08898843079805374\n",
            "Train step - Step 0, Loss 0.09013094753026962\n",
            "Train step - Step 0, Loss 0.08420778810977936\n",
            "Train step - Step 0, Loss 0.08843959122896194\n",
            "Train step - Step 0, Loss 0.09012322872877121\n",
            "Train step - Step 0, Loss 0.08627317100763321\n",
            "Train step - Step 0, Loss 0.09048646688461304\n",
            "Train step - Step 0, Loss 0.0879971981048584\n",
            "Train step - Step 0, Loss 0.08895188570022583\n",
            "Train step - Step 0, Loss 0.0901966392993927\n",
            "Train step - Step 0, Loss 0.09006302058696747\n",
            "Train epoch - Accuracy: 0.38375 Loss: 0.08904859817028046 Corrects: 4605\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.08909149467945099\n",
            "Train step - Step 0, Loss 0.09047438204288483\n",
            "Train step - Step 0, Loss 0.09524378925561905\n",
            "Train step - Step 0, Loss 0.09240733832120895\n",
            "Train step - Step 0, Loss 0.08822742104530334\n",
            "Train step - Step 0, Loss 0.09068429470062256\n",
            "Train step - Step 0, Loss 0.09006838500499725\n",
            "Train step - Step 0, Loss 0.09211330860853195\n",
            "Train step - Step 0, Loss 0.08765434473752975\n",
            "Train step - Step 0, Loss 0.092912957072258\n",
            "Train step - Step 0, Loss 0.08333296328783035\n",
            "Train step - Step 0, Loss 0.0848148912191391\n",
            "Train step - Step 0, Loss 0.08582192659378052\n",
            "Train step - Step 0, Loss 0.08537954837083817\n",
            "Train step - Step 0, Loss 0.09251566976308823\n",
            "Train step - Step 0, Loss 0.08846969157457352\n",
            "Train epoch - Accuracy: 0.389 Loss: 0.08934632140398026 Corrects: 4668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.5 0.07491014897823334\n",
            "TEST GROUP:  0.442\n",
            "TEST ALL:  0.5128\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  6000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 95, 85, 81, 65, 61, 57, 49, 45, 21, 13, 9, 96, 88, 80, 76, 72, 68, 64, 60, 56, 40, 36, 32, 24, 20, 16, 8, 4, 93, 97, 2, 15, 83, 79, 75, 67, 63, 59, 55, 47, 39, 31, 23, 19, 7, 6, 98, 94, 90, 82, 54, 42, 34, 30, 22, 18, 14, 10, 0]\n",
            "TRAIN_SET CLASSES:  [99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "VALIDATION CLASSES:  [60, 57, 45, 40, 99, 88, 15, 14, 13, 8]\n",
            "GROUP:  6\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  60\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.24906323850154877\n",
            "Train step - Step 10, Loss 0.14063303172588348\n",
            "Train step - Step 20, Loss 0.1245354562997818\n",
            "Train step - Step 30, Loss 0.12189552932977676\n",
            "Train step - Step 40, Loss 0.11266627907752991\n",
            "Train step - Step 50, Loss 0.10884886234998703\n",
            "Train epoch - Accuracy: 0.18172661870503598 Loss: 0.1334558697720226 Corrects: 1263\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.10786408931016922\n",
            "Train step - Step 70, Loss 0.10790202021598816\n",
            "Train step - Step 80, Loss 0.11162833869457245\n",
            "Train step - Step 90, Loss 0.11202482879161835\n",
            "Train step - Step 100, Loss 0.10935467481613159\n",
            "Train epoch - Accuracy: 0.25050359712230214 Loss: 0.11082560828049406 Corrects: 1741\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.11221341788768768\n",
            "Train step - Step 120, Loss 0.11099618673324585\n",
            "Train step - Step 130, Loss 0.11059882491827011\n",
            "Train step - Step 140, Loss 0.10896433144807816\n",
            "Train step - Step 150, Loss 0.10804105550050735\n",
            "Train step - Step 160, Loss 0.11156900972127914\n",
            "Train epoch - Accuracy: 0.3057553956834532 Loss: 0.1079428897165566 Corrects: 2125\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.10468509793281555\n",
            "Train step - Step 180, Loss 0.10889878869056702\n",
            "Train step - Step 190, Loss 0.1074429377913475\n",
            "Train step - Step 200, Loss 0.10822580754756927\n",
            "Train step - Step 210, Loss 0.10403882712125778\n",
            "Train epoch - Accuracy: 0.34258992805755395 Loss: 0.10641737291709982 Corrects: 2381\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.10370030999183655\n",
            "Train step - Step 230, Loss 0.10487163066864014\n",
            "Train step - Step 240, Loss 0.09863639622926712\n",
            "Train step - Step 250, Loss 0.10856688022613525\n",
            "Train step - Step 260, Loss 0.10710449516773224\n",
            "Train step - Step 270, Loss 0.10064879059791565\n",
            "Train epoch - Accuracy: 0.38316546762589926 Loss: 0.10543484054237819 Corrects: 2663\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.10547240078449249\n",
            "Train step - Step 290, Loss 0.10380701720714569\n",
            "Train step - Step 300, Loss 0.10382011532783508\n",
            "Train step - Step 310, Loss 0.09853916615247726\n",
            "Train step - Step 320, Loss 0.10143519192934036\n",
            "Train epoch - Accuracy: 0.3975539568345324 Loss: 0.10437517963939434 Corrects: 2763\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.10573247820138931\n",
            "Train step - Step 340, Loss 0.11327167600393295\n",
            "Train step - Step 350, Loss 0.10633333027362823\n",
            "Train step - Step 360, Loss 0.10435236990451813\n",
            "Train step - Step 370, Loss 0.10173289477825165\n",
            "Train step - Step 380, Loss 0.1066390872001648\n",
            "Train epoch - Accuracy: 0.42805755395683454 Loss: 0.10451221298613994 Corrects: 2975\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.10590857267379761\n",
            "Train step - Step 400, Loss 0.10362128913402557\n",
            "Train step - Step 410, Loss 0.10413054376840591\n",
            "Train step - Step 420, Loss 0.10255825519561768\n",
            "Train step - Step 430, Loss 0.10388769954442978\n",
            "Train epoch - Accuracy: 0.441726618705036 Loss: 0.1032887002246843 Corrects: 3070\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.10052698850631714\n",
            "Train step - Step 450, Loss 0.10002797096967697\n",
            "Train step - Step 460, Loss 0.10323245823383331\n",
            "Train step - Step 470, Loss 0.10734841227531433\n",
            "Train step - Step 480, Loss 0.1035536676645279\n",
            "Train step - Step 490, Loss 0.10349232703447342\n",
            "Train epoch - Accuracy: 0.45870503597122303 Loss: 0.10304149241756193 Corrects: 3188\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.10120999068021774\n",
            "Train step - Step 510, Loss 0.10120794177055359\n",
            "Train step - Step 520, Loss 0.10231562703847885\n",
            "Train step - Step 530, Loss 0.09962430596351624\n",
            "Train step - Step 540, Loss 0.1031145378947258\n",
            "Train epoch - Accuracy: 0.47266187050359715 Loss: 0.10271368348341194 Corrects: 3285\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.09913195669651031\n",
            "Train step - Step 560, Loss 0.10461624711751938\n",
            "Train step - Step 570, Loss 0.09872211515903473\n",
            "Train step - Step 580, Loss 0.10022297501564026\n",
            "Train step - Step 590, Loss 0.10197145491838455\n",
            "Train step - Step 600, Loss 0.10087701678276062\n",
            "Train epoch - Accuracy: 0.4739568345323741 Loss: 0.10247458490536367 Corrects: 3294\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.10474706441164017\n",
            "Train step - Step 620, Loss 0.10406922549009323\n",
            "Train step - Step 630, Loss 0.09479233622550964\n",
            "Train step - Step 640, Loss 0.10184101015329361\n",
            "Train step - Step 650, Loss 0.09959067404270172\n",
            "Train epoch - Accuracy: 0.4925179856115108 Loss: 0.10182050499127066 Corrects: 3423\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.09913205355405807\n",
            "Train step - Step 670, Loss 0.09881024062633514\n",
            "Train step - Step 680, Loss 0.10924121737480164\n",
            "Train step - Step 690, Loss 0.10173863172531128\n",
            "Train step - Step 700, Loss 0.10111147165298462\n",
            "Train step - Step 710, Loss 0.09862878173589706\n",
            "Train epoch - Accuracy: 0.5007194244604316 Loss: 0.10177020143690726 Corrects: 3480\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.09844978153705597\n",
            "Train step - Step 730, Loss 0.10400230437517166\n",
            "Train step - Step 740, Loss 0.10343898832798004\n",
            "Train step - Step 750, Loss 0.09875622391700745\n",
            "Train step - Step 760, Loss 0.09933203458786011\n",
            "Train epoch - Accuracy: 0.5066187050359712 Loss: 0.10154304691570268 Corrects: 3521\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.10301679372787476\n",
            "Train step - Step 780, Loss 0.10299988836050034\n",
            "Train step - Step 790, Loss 0.10070344060659409\n",
            "Train step - Step 800, Loss 0.0970463752746582\n",
            "Train step - Step 810, Loss 0.10066274553537369\n",
            "Train step - Step 820, Loss 0.09840929508209229\n",
            "Train epoch - Accuracy: 0.5133812949640287 Loss: 0.10147316037750931 Corrects: 3568\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.09834731370210648\n",
            "Train step - Step 840, Loss 0.10156746208667755\n",
            "Train step - Step 850, Loss 0.09569372236728668\n",
            "Train step - Step 860, Loss 0.09697214514017105\n",
            "Train step - Step 870, Loss 0.1015438437461853\n",
            "Train epoch - Accuracy: 0.519568345323741 Loss: 0.10084435923494023 Corrects: 3611\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.10340091586112976\n",
            "Train step - Step 890, Loss 0.10737557709217072\n",
            "Train step - Step 900, Loss 0.0979330763220787\n",
            "Train step - Step 910, Loss 0.10440998524427414\n",
            "Train step - Step 920, Loss 0.09398002922534943\n",
            "Train step - Step 930, Loss 0.09491801261901855\n",
            "Train epoch - Accuracy: 0.5330935251798561 Loss: 0.10053432593457133 Corrects: 3705\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.0977482944726944\n",
            "Train step - Step 950, Loss 0.0994512289762497\n",
            "Train step - Step 960, Loss 0.09415937215089798\n",
            "Train step - Step 970, Loss 0.10432005673646927\n",
            "Train step - Step 980, Loss 0.09858006983995438\n",
            "Train epoch - Accuracy: 0.5352517985611511 Loss: 0.10059768901668864 Corrects: 3720\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10042787343263626\n",
            "Train step - Step 1000, Loss 0.1025683805346489\n",
            "Train step - Step 1010, Loss 0.09413366764783859\n",
            "Train step - Step 1020, Loss 0.10142440348863602\n",
            "Train step - Step 1030, Loss 0.1027648076415062\n",
            "Train step - Step 1040, Loss 0.10024415701627731\n",
            "Train epoch - Accuracy: 0.5434532374100719 Loss: 0.10019594983874465 Corrects: 3777\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10096918046474457\n",
            "Train step - Step 1060, Loss 0.10499412566423416\n",
            "Train step - Step 1070, Loss 0.10014690458774567\n",
            "Train step - Step 1080, Loss 0.10022547841072083\n",
            "Train step - Step 1090, Loss 0.09984061121940613\n",
            "Train epoch - Accuracy: 0.5530935251798561 Loss: 0.10041444623856235 Corrects: 3844\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10258235037326813\n",
            "Train step - Step 1110, Loss 0.09645957499742508\n",
            "Train step - Step 1120, Loss 0.10100953280925751\n",
            "Train step - Step 1130, Loss 0.10807575285434723\n",
            "Train step - Step 1140, Loss 0.09834721684455872\n",
            "Train step - Step 1150, Loss 0.10444358736276627\n",
            "Train epoch - Accuracy: 0.5571223021582734 Loss: 0.09993769019627742 Corrects: 3872\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.09949439764022827\n",
            "Train step - Step 1170, Loss 0.10254167020320892\n",
            "Train step - Step 1180, Loss 0.09732440859079361\n",
            "Train step - Step 1190, Loss 0.0986555963754654\n",
            "Train step - Step 1200, Loss 0.09883571416139603\n",
            "Train epoch - Accuracy: 0.5673381294964028 Loss: 0.09989409838220198 Corrects: 3943\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.10038589686155319\n",
            "Train step - Step 1220, Loss 0.09704587608575821\n",
            "Train step - Step 1230, Loss 0.09390749037265778\n",
            "Train step - Step 1240, Loss 0.09590025246143341\n",
            "Train step - Step 1250, Loss 0.09872701019048691\n",
            "Train step - Step 1260, Loss 0.099331796169281\n",
            "Train epoch - Accuracy: 0.5601438848920863 Loss: 0.0995948510011323 Corrects: 3893\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10003995895385742\n",
            "Train step - Step 1280, Loss 0.0947340801358223\n",
            "Train step - Step 1290, Loss 0.09865963459014893\n",
            "Train step - Step 1300, Loss 0.10270337015390396\n",
            "Train step - Step 1310, Loss 0.09785660356283188\n",
            "Train epoch - Accuracy: 0.5682014388489208 Loss: 0.09936204505481308 Corrects: 3949\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.09544546157121658\n",
            "Train step - Step 1330, Loss 0.09629480540752411\n",
            "Train step - Step 1340, Loss 0.09589432924985886\n",
            "Train step - Step 1350, Loss 0.10250432789325714\n",
            "Train step - Step 1360, Loss 0.097868911921978\n",
            "Train step - Step 1370, Loss 0.09614408761262894\n",
            "Train epoch - Accuracy: 0.5732374100719424 Loss: 0.09975267476529526 Corrects: 3984\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.0970112532377243\n",
            "Train step - Step 1390, Loss 0.09455467760562897\n",
            "Train step - Step 1400, Loss 0.10382265597581863\n",
            "Train step - Step 1410, Loss 0.10129675269126892\n",
            "Train step - Step 1420, Loss 0.09809229522943497\n",
            "Train epoch - Accuracy: 0.5713669064748201 Loss: 0.0994344823523391 Corrects: 3971\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.09884370863437653\n",
            "Train step - Step 1440, Loss 0.09973163902759552\n",
            "Train step - Step 1450, Loss 0.0997810810804367\n",
            "Train step - Step 1460, Loss 0.09788171947002411\n",
            "Train step - Step 1470, Loss 0.09724749624729156\n",
            "Train step - Step 1480, Loss 0.10126664489507675\n",
            "Train epoch - Accuracy: 0.5831654676258993 Loss: 0.0996121560819715 Corrects: 4053\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10179659724235535\n",
            "Train step - Step 1500, Loss 0.09786748886108398\n",
            "Train step - Step 1510, Loss 0.10236822813749313\n",
            "Train step - Step 1520, Loss 0.09781701117753983\n",
            "Train step - Step 1530, Loss 0.09983238577842712\n",
            "Train epoch - Accuracy: 0.5810071942446043 Loss: 0.09896058617092722 Corrects: 4038\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09814407676458359\n",
            "Train step - Step 1550, Loss 0.09938838332891464\n",
            "Train step - Step 1560, Loss 0.097144715487957\n",
            "Train step - Step 1570, Loss 0.09857559204101562\n",
            "Train step - Step 1580, Loss 0.0969138965010643\n",
            "Train step - Step 1590, Loss 0.09715534001588821\n",
            "Train epoch - Accuracy: 0.5864748201438849 Loss: 0.09870146939651571 Corrects: 4076\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.09751549363136292\n",
            "Train step - Step 1610, Loss 0.10283809155225754\n",
            "Train step - Step 1620, Loss 0.09843476861715317\n",
            "Train step - Step 1630, Loss 0.09522689133882523\n",
            "Train step - Step 1640, Loss 0.10112589597702026\n",
            "Train epoch - Accuracy: 0.5938129496402877 Loss: 0.09863926226286579 Corrects: 4127\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.0998070165514946\n",
            "Train step - Step 1660, Loss 0.096343033015728\n",
            "Train step - Step 1670, Loss 0.09462437778711319\n",
            "Train step - Step 1680, Loss 0.09635937958955765\n",
            "Train step - Step 1690, Loss 0.09665713459253311\n",
            "Train step - Step 1700, Loss 0.09569413959980011\n",
            "Train epoch - Accuracy: 0.6028776978417266 Loss: 0.09865801062300908 Corrects: 4190\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.10106555372476578\n",
            "Train step - Step 1720, Loss 0.10388515889644623\n",
            "Train step - Step 1730, Loss 0.10545801371335983\n",
            "Train step - Step 1740, Loss 0.09082785248756409\n",
            "Train step - Step 1750, Loss 0.10092966258525848\n",
            "Train epoch - Accuracy: 0.5985611510791367 Loss: 0.09854182208827932 Corrects: 4160\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.10214744508266449\n",
            "Train step - Step 1770, Loss 0.0964168906211853\n",
            "Train step - Step 1780, Loss 0.09877261519432068\n",
            "Train step - Step 1790, Loss 0.09964503347873688\n",
            "Train step - Step 1800, Loss 0.09673283249139786\n",
            "Train step - Step 1810, Loss 0.09969574958086014\n",
            "Train epoch - Accuracy: 0.6087769784172662 Loss: 0.09802547001152588 Corrects: 4231\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.09671970456838608\n",
            "Train step - Step 1830, Loss 0.09603769332170486\n",
            "Train step - Step 1840, Loss 0.09589330852031708\n",
            "Train step - Step 1850, Loss 0.10119812190532684\n",
            "Train step - Step 1860, Loss 0.09943932294845581\n",
            "Train epoch - Accuracy: 0.6169784172661871 Loss: 0.09797724344104314 Corrects: 4288\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10268258303403854\n",
            "Train step - Step 1880, Loss 0.10404177010059357\n",
            "Train step - Step 1890, Loss 0.09949652850627899\n",
            "Train step - Step 1900, Loss 0.09738635271787643\n",
            "Train step - Step 1910, Loss 0.09747735410928726\n",
            "Train step - Step 1920, Loss 0.10075303912162781\n",
            "Train epoch - Accuracy: 0.6185611510791367 Loss: 0.09782436767928035 Corrects: 4299\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.0981113389134407\n",
            "Train step - Step 1940, Loss 0.09927356243133545\n",
            "Train step - Step 1950, Loss 0.0965208113193512\n",
            "Train step - Step 1960, Loss 0.09889433532953262\n",
            "Train step - Step 1970, Loss 0.09407410770654678\n",
            "Train epoch - Accuracy: 0.6172661870503597 Loss: 0.09789028695161395 Corrects: 4290\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.10011351108551025\n",
            "Train step - Step 1990, Loss 0.09806205332279205\n",
            "Train step - Step 2000, Loss 0.10077646374702454\n",
            "Train step - Step 2010, Loss 0.0996926948428154\n",
            "Train step - Step 2020, Loss 0.1036861315369606\n",
            "Train step - Step 2030, Loss 0.09800244122743607\n",
            "Train epoch - Accuracy: 0.618273381294964 Loss: 0.09787904093591429 Corrects: 4297\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.09469635784626007\n",
            "Train step - Step 2050, Loss 0.10305770486593246\n",
            "Train step - Step 2060, Loss 0.09488993138074875\n",
            "Train step - Step 2070, Loss 0.09982439875602722\n",
            "Train step - Step 2080, Loss 0.10067660361528397\n",
            "Train epoch - Accuracy: 0.623453237410072 Loss: 0.09759124200978725 Corrects: 4333\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.09749914705753326\n",
            "Train step - Step 2100, Loss 0.09801246970891953\n",
            "Train step - Step 2110, Loss 0.0996331125497818\n",
            "Train step - Step 2120, Loss 0.09401258081197739\n",
            "Train step - Step 2130, Loss 0.09566374123096466\n",
            "Train step - Step 2140, Loss 0.09536956995725632\n",
            "Train epoch - Accuracy: 0.6235971223021582 Loss: 0.09780696098753017 Corrects: 4334\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.09367202967405319\n",
            "Train step - Step 2160, Loss 0.10032449662685394\n",
            "Train step - Step 2170, Loss 0.0978379175066948\n",
            "Train step - Step 2180, Loss 0.09892912209033966\n",
            "Train step - Step 2190, Loss 0.09776868671178818\n",
            "Train epoch - Accuracy: 0.6297841726618705 Loss: 0.09793996288193216 Corrects: 4377\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09584391117095947\n",
            "Train step - Step 2210, Loss 0.09692277014255524\n",
            "Train step - Step 2220, Loss 0.099250927567482\n",
            "Train step - Step 2230, Loss 0.09675929695367813\n",
            "Train step - Step 2240, Loss 0.0976993665099144\n",
            "Train step - Step 2250, Loss 0.09782831370830536\n",
            "Train epoch - Accuracy: 0.6359712230215827 Loss: 0.09745359047282513 Corrects: 4420\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.09745916724205017\n",
            "Train step - Step 2270, Loss 0.09593639522790909\n",
            "Train step - Step 2280, Loss 0.09615353494882584\n",
            "Train step - Step 2290, Loss 0.09747852385044098\n",
            "Train step - Step 2300, Loss 0.10098195821046829\n",
            "Train epoch - Accuracy: 0.6307913669064749 Loss: 0.09728420000496528 Corrects: 4384\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.09667646884918213\n",
            "Train step - Step 2320, Loss 0.09901410341262817\n",
            "Train step - Step 2330, Loss 0.0978594496846199\n",
            "Train step - Step 2340, Loss 0.10294616967439651\n",
            "Train step - Step 2350, Loss 0.10360802710056305\n",
            "Train step - Step 2360, Loss 0.10235211253166199\n",
            "Train epoch - Accuracy: 0.638273381294964 Loss: 0.09717511141042916 Corrects: 4436\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.09508726000785828\n",
            "Train step - Step 2380, Loss 0.0925179272890091\n",
            "Train step - Step 2390, Loss 0.09797463566064835\n",
            "Train step - Step 2400, Loss 0.09600522369146347\n",
            "Train step - Step 2410, Loss 0.09685015678405762\n",
            "Train epoch - Accuracy: 0.643453237410072 Loss: 0.09693354289523132 Corrects: 4472\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.09447558969259262\n",
            "Train step - Step 2430, Loss 0.09914741665124893\n",
            "Train step - Step 2440, Loss 0.09413623809814453\n",
            "Train step - Step 2450, Loss 0.09751635789871216\n",
            "Train step - Step 2460, Loss 0.09457363188266754\n",
            "Train step - Step 2470, Loss 0.09664905816316605\n",
            "Train epoch - Accuracy: 0.6424460431654676 Loss: 0.09704702878384282 Corrects: 4465\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.09977517277002335\n",
            "Train step - Step 2490, Loss 0.0964980497956276\n",
            "Train step - Step 2500, Loss 0.09743978828191757\n",
            "Train step - Step 2510, Loss 0.09837029129266739\n",
            "Train step - Step 2520, Loss 0.099519744515419\n",
            "Train epoch - Accuracy: 0.6310791366906475 Loss: 0.09705121859586496 Corrects: 4386\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.09057342261075974\n",
            "Train step - Step 2540, Loss 0.09499583393335342\n",
            "Train step - Step 2550, Loss 0.09376062452793121\n",
            "Train step - Step 2560, Loss 0.09762495756149292\n",
            "Train step - Step 2570, Loss 0.10111924260854721\n",
            "Train step - Step 2580, Loss 0.09682448208332062\n",
            "Train epoch - Accuracy: 0.6484892086330936 Loss: 0.09682474230047611 Corrects: 4507\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.09752221405506134\n",
            "Train step - Step 2600, Loss 0.09543445706367493\n",
            "Train step - Step 2610, Loss 0.093418188393116\n",
            "Train step - Step 2620, Loss 0.09951002150774002\n",
            "Train step - Step 2630, Loss 0.09545739740133286\n",
            "Train epoch - Accuracy: 0.6441726618705036 Loss: 0.09670405372012433 Corrects: 4477\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10131960362195969\n",
            "Train step - Step 2650, Loss 0.09527172148227692\n",
            "Train step - Step 2660, Loss 0.09962368756532669\n",
            "Train step - Step 2670, Loss 0.09341203421354294\n",
            "Train step - Step 2680, Loss 0.0956864058971405\n",
            "Train step - Step 2690, Loss 0.09484825283288956\n",
            "Train epoch - Accuracy: 0.6585611510791367 Loss: 0.09639934121490383 Corrects: 4577\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.09870784729719162\n",
            "Train step - Step 2710, Loss 0.09636229276657104\n",
            "Train step - Step 2720, Loss 0.09062683582305908\n",
            "Train step - Step 2730, Loss 0.09703589230775833\n",
            "Train step - Step 2740, Loss 0.09649667143821716\n",
            "Train epoch - Accuracy: 0.66 Loss: 0.09579363093101721 Corrects: 4587\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10066484659910202\n",
            "Train step - Step 2760, Loss 0.09602773189544678\n",
            "Train step - Step 2770, Loss 0.09976702183485031\n",
            "Train step - Step 2780, Loss 0.09473643451929092\n",
            "Train step - Step 2790, Loss 0.09389197826385498\n",
            "Train step - Step 2800, Loss 0.09591241180896759\n",
            "Train epoch - Accuracy: 0.661726618705036 Loss: 0.09574967869751745 Corrects: 4599\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.09367518872022629\n",
            "Train step - Step 2820, Loss 0.09907270222902298\n",
            "Train step - Step 2830, Loss 0.09603152424097061\n",
            "Train step - Step 2840, Loss 0.0967090055346489\n",
            "Train step - Step 2850, Loss 0.09913443773984909\n",
            "Train epoch - Accuracy: 0.6687769784172661 Loss: 0.0954377204394169 Corrects: 4648\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.09941614419221878\n",
            "Train step - Step 2870, Loss 0.09645228832960129\n",
            "Train step - Step 2880, Loss 0.09273824840784073\n",
            "Train step - Step 2890, Loss 0.09744605422019958\n",
            "Train step - Step 2900, Loss 0.10148657113313675\n",
            "Train step - Step 2910, Loss 0.09944978356361389\n",
            "Train epoch - Accuracy: 0.6634532374100719 Loss: 0.09566874120089648 Corrects: 4611\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.09985053539276123\n",
            "Train step - Step 2930, Loss 0.09479594975709915\n",
            "Train step - Step 2940, Loss 0.1010947972536087\n",
            "Train step - Step 2950, Loss 0.09229738265275955\n",
            "Train step - Step 2960, Loss 0.09665360301733017\n",
            "Train epoch - Accuracy: 0.6635971223021583 Loss: 0.09544772446369953 Corrects: 4612\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09803713858127594\n",
            "Train step - Step 2980, Loss 0.09874241054058075\n",
            "Train step - Step 2990, Loss 0.09329459071159363\n",
            "Train step - Step 3000, Loss 0.09778579324483871\n",
            "Train step - Step 3010, Loss 0.09580567479133606\n",
            "Train step - Step 3020, Loss 0.09528932720422745\n",
            "Train epoch - Accuracy: 0.6680575539568345 Loss: 0.09578133229943488 Corrects: 4643\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.09160850197076797\n",
            "Train step - Step 3040, Loss 0.099870964884758\n",
            "Train step - Step 3050, Loss 0.0949711725115776\n",
            "Train step - Step 3060, Loss 0.10074567049741745\n",
            "Train step - Step 3070, Loss 0.0903453379869461\n",
            "Train epoch - Accuracy: 0.6627338129496403 Loss: 0.09551788654901998 Corrects: 4606\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.09810841083526611\n",
            "Train step - Step 3090, Loss 0.0956508219242096\n",
            "Train step - Step 3100, Loss 0.09443467110395432\n",
            "Train step - Step 3110, Loss 0.09443540871143341\n",
            "Train step - Step 3120, Loss 0.10050147026777267\n",
            "Train step - Step 3130, Loss 0.0960921049118042\n",
            "Train epoch - Accuracy: 0.6598561151079136 Loss: 0.09540704754187906 Corrects: 4586\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.09556665271520615\n",
            "Train step - Step 3150, Loss 0.09020107984542847\n",
            "Train step - Step 3160, Loss 0.09250891208648682\n",
            "Train step - Step 3170, Loss 0.09800758957862854\n",
            "Train step - Step 3180, Loss 0.0967470183968544\n",
            "Train epoch - Accuracy: 0.6624460431654676 Loss: 0.09539372299214918 Corrects: 4604\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09622984379529953\n",
            "Train step - Step 3200, Loss 0.09701795876026154\n",
            "Train step - Step 3210, Loss 0.09203871339559555\n",
            "Train step - Step 3220, Loss 0.09761232137680054\n",
            "Train step - Step 3230, Loss 0.08836417645215988\n",
            "Train step - Step 3240, Loss 0.09477823227643967\n",
            "Train epoch - Accuracy: 0.6690647482014388 Loss: 0.09557021592589592 Corrects: 4650\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09576356410980225\n",
            "Train step - Step 3260, Loss 0.09052583575248718\n",
            "Train step - Step 3270, Loss 0.0957801565527916\n",
            "Train step - Step 3280, Loss 0.08943017572164536\n",
            "Train step - Step 3290, Loss 0.0911540538072586\n",
            "Train epoch - Accuracy: 0.6690647482014388 Loss: 0.09501521703579444 Corrects: 4650\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.09946372359991074\n",
            "Train step - Step 3310, Loss 0.09814963489770889\n",
            "Train step - Step 3320, Loss 0.0958455428481102\n",
            "Train step - Step 3330, Loss 0.09747334569692612\n",
            "Train step - Step 3340, Loss 0.08969268947839737\n",
            "Train step - Step 3350, Loss 0.09398401528596878\n",
            "Train epoch - Accuracy: 0.6648920863309352 Loss: 0.09534222538737085 Corrects: 4621\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.09118638187646866\n",
            "Train step - Step 3370, Loss 0.09294674545526505\n",
            "Train step - Step 3380, Loss 0.09471441805362701\n",
            "Train step - Step 3390, Loss 0.09317584335803986\n",
            "Train step - Step 3400, Loss 0.09072709828615189\n",
            "Train epoch - Accuracy: 0.6690647482014388 Loss: 0.09531063716617419 Corrects: 4650\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09644310176372528\n",
            "Train step - Step 3420, Loss 0.10189668834209442\n",
            "Train step - Step 3430, Loss 0.0913575291633606\n",
            "Train step - Step 3440, Loss 0.0944618359208107\n",
            "Train step - Step 3450, Loss 0.09821411222219467\n",
            "Train step - Step 3460, Loss 0.09791191667318344\n",
            "Train epoch - Accuracy: 0.6728057553956834 Loss: 0.09548639374671222 Corrects: 4676\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.09426586329936981\n",
            "Train step - Step 3480, Loss 0.09421934187412262\n",
            "Train step - Step 3490, Loss 0.09871608018875122\n",
            "Train step - Step 3500, Loss 0.09169609844684601\n",
            "Train step - Step 3510, Loss 0.09776641428470612\n",
            "Train epoch - Accuracy: 0.6713669064748201 Loss: 0.09513283447610389 Corrects: 4666\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.0917489230632782\n",
            "Train step - Step 3530, Loss 0.09430072456598282\n",
            "Train step - Step 3540, Loss 0.095969557762146\n",
            "Train step - Step 3550, Loss 0.09190239012241364\n",
            "Train step - Step 3560, Loss 0.09538023918867111\n",
            "Train step - Step 3570, Loss 0.0929182916879654\n",
            "Train epoch - Accuracy: 0.6700719424460432 Loss: 0.09517290297172053 Corrects: 4657\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.0917646586894989\n",
            "Train step - Step 3590, Loss 0.09133115410804749\n",
            "Train step - Step 3600, Loss 0.09288328886032104\n",
            "Train step - Step 3610, Loss 0.09398047626018524\n",
            "Train step - Step 3620, Loss 0.09419996291399002\n",
            "Train epoch - Accuracy: 0.6666187050359712 Loss: 0.09505002174874862 Corrects: 4633\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09680397063493729\n",
            "Train step - Step 3640, Loss 0.09627369046211243\n",
            "Train step - Step 3650, Loss 0.09589266031980515\n",
            "Train step - Step 3660, Loss 0.09575647115707397\n",
            "Train step - Step 3670, Loss 0.09269785135984421\n",
            "Train step - Step 3680, Loss 0.0979984775185585\n",
            "Train epoch - Accuracy: 0.6748201438848921 Loss: 0.0950341275034191 Corrects: 4690\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.09497765451669693\n",
            "Train step - Step 3700, Loss 0.09835647791624069\n",
            "Train step - Step 3710, Loss 0.09001490473747253\n",
            "Train step - Step 3720, Loss 0.0989793986082077\n",
            "Train step - Step 3730, Loss 0.09810160845518112\n",
            "Train epoch - Accuracy: 0.6729496402877698 Loss: 0.09514647580951238 Corrects: 4677\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.09443368762731552\n",
            "Train step - Step 3750, Loss 0.09886886179447174\n",
            "Train step - Step 3760, Loss 0.09774904698133469\n",
            "Train step - Step 3770, Loss 0.0974862277507782\n",
            "Train step - Step 3780, Loss 0.09466153383255005\n",
            "Train step - Step 3790, Loss 0.0934714749455452\n",
            "Train epoch - Accuracy: 0.6735251798561152 Loss: 0.09519240712733577 Corrects: 4681\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.09169049561023712\n",
            "Train step - Step 3810, Loss 0.09151382744312286\n",
            "Train step - Step 3820, Loss 0.09856224805116653\n",
            "Train step - Step 3830, Loss 0.097913458943367\n",
            "Train step - Step 3840, Loss 0.09300343692302704\n",
            "Train epoch - Accuracy: 0.6682014388489209 Loss: 0.09514925902267155 Corrects: 4644\n",
            "Training finished in 452.90734481811523 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee4cef90>\n",
            "Constructing exemplars of class 99\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [39138, 8620, 39231, 38537, 16719, 45464, 28945, 40593, 17713, 24374, 23750, 33087, 49112, 11795, 15736, 14757, 40739, 25635, 31907, 4548, 16508, 17180, 14663, 97, 16474, 32510, 43060, 27855, 7111, 30479, 20300, 34216, 47529]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a222a50>\n",
            "Constructing exemplars of class 15\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [23531, 37496, 28422, 40863, 45104, 72, 20368, 47865, 34688, 5495, 376, 5318, 45908, 9543, 9213, 1676, 10932, 876, 32594, 7622, 9859, 47815, 46668, 32785, 36105, 42921, 5431, 10874, 34037, 31187, 726, 22550, 46317]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a252a90>\n",
            "Constructing exemplars of class 14\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [2167, 27582, 15827, 26753, 39837, 7947, 5733, 18499, 27539, 24040, 41179, 9316, 49366, 5733, 33688, 21882, 44181, 18856, 24094, 7528, 17211, 33757, 39636, 48283, 507, 22682, 7534, 5733, 44242, 6263, 30899, 42593, 24247]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a252910>\n",
            "Constructing exemplars of class 57\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [28370, 47604, 24636, 30384, 43288, 34969, 16512, 42029, 30107, 6981, 4200, 33137, 10165, 12757, 41810, 30607, 39552, 38372, 2087, 11497, 8773, 9924, 43288, 16422, 23047, 28635, 43288, 36321, 30187, 45830, 32388, 23751, 21462]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a030e10>\n",
            "Constructing exemplars of class 45\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [28638, 48281, 32223, 47099, 14590, 24579, 10918, 3664, 2663, 8369, 11346, 36460, 34048, 39566, 15817, 11545, 7620, 7254, 6920, 4479, 46994, 34521, 30292, 7407, 8233, 18615, 19126, 28149, 21039, 21079, 4139, 1998, 4933]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee43ee90>\n",
            "Constructing exemplars of class 13\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [39808, 43019, 8932, 26667, 31561, 41936, 49822, 33485, 5763, 42506, 45834, 10130, 27555, 48838, 45869, 43019, 34191, 35201, 27663, 33060, 723, 41744, 24313, 21193, 19445, 5612, 26059, 20524, 49052, 27002, 24353, 10362, 28353]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30baffa90>\n",
            "Constructing exemplars of class 88\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [11930, 24776, 47259, 26396, 39431, 18469, 32238, 37604, 42908, 7300, 7180, 32448, 32562, 20254, 49537, 410, 36198, 13231, 45548, 18281, 31608, 49540, 23488, 9786, 32702, 16158, 41745, 17700, 22270, 24266, 16340, 11543, 28390]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a05cf50>\n",
            "Constructing exemplars of class 60\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [7271, 3748, 41753, 10917, 18047, 26102, 25086, 39293, 18379, 25434, 30485, 33308, 39140, 17869, 23484, 42054, 17327, 31189, 25950, 8805, 38662, 49427, 42865, 17054, 23267, 26295, 3088, 9015, 38714, 17201, 45351, 29132, 6772]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a51fe90>\n",
            "Constructing exemplars of class 40\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [24265, 41377, 28133, 23375, 24708, 45420, 31786, 37266, 39520, 11134, 18086, 34512, 17059, 43913, 3867, 33209, 38770, 39166, 13635, 3108, 31077, 13899, 18925, 5948, 27905, 39257, 20499, 26795, 49336, 11156, 18370, 30337, 31335]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f9b290>\n",
            "Constructing exemplars of class 8\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [9657, 22005, 15385, 19933, 29988, 23669, 28559, 27526, 32023, 8545, 40156, 34945, 13692, 19154, 40537, 16271, 5375, 23763, 17049, 38391, 9439, 13809, 16015, 1290, 13582, 26173, 27008, 34719, 22173, 7715, 31779, 35094, 26228]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.11945590376853943\n",
            "Train step - Step 0, Loss 0.10710126161575317\n",
            "Train step - Step 0, Loss 0.0981469675898552\n",
            "Train step - Step 0, Loss 0.09463071078062057\n",
            "Train step - Step 0, Loss 0.09006615728139877\n",
            "Train step - Step 0, Loss 0.08739236742258072\n",
            "Train step - Step 0, Loss 0.0824262872338295\n",
            "Train step - Step 0, Loss 0.08333513885736465\n",
            "Train step - Step 0, Loss 0.08353935927152634\n",
            "Train step - Step 0, Loss 0.08921253681182861\n",
            "Train step - Step 0, Loss 0.08383435010910034\n",
            "Train step - Step 0, Loss 0.09018591046333313\n",
            "Train step - Step 0, Loss 0.0870354026556015\n",
            "Train step - Step 0, Loss 0.0909767672419548\n",
            "Train step - Step 0, Loss 0.08438258618116379\n",
            "Train step - Step 0, Loss 0.08301147073507309\n",
            "Train epoch - Accuracy: 0.3525252525252525 Loss: 0.09119245796793639 Corrects: 4188\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.08088633418083191\n",
            "Train step - Step 0, Loss 0.0870901569724083\n",
            "Train step - Step 0, Loss 0.09070461988449097\n",
            "Train step - Step 0, Loss 0.09193770587444305\n",
            "Train step - Step 0, Loss 0.08858569711446762\n",
            "Train step - Step 0, Loss 0.08464690297842026\n",
            "Train step - Step 0, Loss 0.08689049631357193\n",
            "Train step - Step 0, Loss 0.08610817044973373\n",
            "Train step - Step 0, Loss 0.08869922906160355\n",
            "Train step - Step 0, Loss 0.09251625835895538\n",
            "Train step - Step 0, Loss 0.0857381597161293\n",
            "Train step - Step 0, Loss 0.0906575545668602\n",
            "Train step - Step 0, Loss 0.08458200842142105\n",
            "Train step - Step 0, Loss 0.08324293047189713\n",
            "Train step - Step 0, Loss 0.08562247455120087\n",
            "Train step - Step 0, Loss 0.07710596174001694\n",
            "Train epoch - Accuracy: 0.3591750841750842 Loss: 0.08688821776045694 Corrects: 4267\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.08601424098014832\n",
            "Train step - Step 0, Loss 0.08984243869781494\n",
            "Train step - Step 0, Loss 0.08564473688602448\n",
            "Train step - Step 0, Loss 0.08625669777393341\n",
            "Train step - Step 0, Loss 0.08232063055038452\n",
            "Train step - Step 0, Loss 0.08482199907302856\n",
            "Train step - Step 0, Loss 0.08137497305870056\n",
            "Train step - Step 0, Loss 0.08465716987848282\n",
            "Train step - Step 0, Loss 0.08662565052509308\n",
            "Train step - Step 0, Loss 0.08317912369966507\n",
            "Train step - Step 0, Loss 0.08413206040859222\n",
            "Train step - Step 0, Loss 0.09029797464609146\n",
            "Train step - Step 0, Loss 0.0857255831360817\n",
            "Train step - Step 0, Loss 0.08332987874746323\n",
            "Train step - Step 0, Loss 0.08965978026390076\n",
            "Train step - Step 0, Loss 0.08530635386705399\n",
            "Train epoch - Accuracy: 0.3548821548821549 Loss: 0.08558353400892682 Corrects: 4216\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.08990804851055145\n",
            "Train step - Step 0, Loss 0.0837114155292511\n",
            "Train step - Step 0, Loss 0.08249545097351074\n",
            "Train step - Step 0, Loss 0.0866401270031929\n",
            "Train step - Step 0, Loss 0.08036543428897858\n",
            "Train step - Step 0, Loss 0.08695562928915024\n",
            "Train step - Step 0, Loss 0.08186248689889908\n",
            "Train step - Step 0, Loss 0.09120731800794601\n",
            "Train step - Step 0, Loss 0.08702438324689865\n",
            "Train step - Step 0, Loss 0.08028774708509445\n",
            "Train step - Step 0, Loss 0.08193568140268326\n",
            "Train step - Step 0, Loss 0.08863145858049393\n",
            "Train step - Step 0, Loss 0.08250319957733154\n",
            "Train step - Step 0, Loss 0.08770149946212769\n",
            "Train step - Step 0, Loss 0.08684056252241135\n",
            "Train step - Step 0, Loss 0.08426555246114731\n",
            "Train epoch - Accuracy: 0.3511784511784512 Loss: 0.08517623725864622 Corrects: 4172\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.08347117155790329\n",
            "Train step - Step 0, Loss 0.08340462297201157\n",
            "Train step - Step 0, Loss 0.08886763453483582\n",
            "Train step - Step 0, Loss 0.08581192791461945\n",
            "Train step - Step 0, Loss 0.08715452998876572\n",
            "Train step - Step 0, Loss 0.08330982178449631\n",
            "Train step - Step 0, Loss 0.08752235770225525\n",
            "Train step - Step 0, Loss 0.08255553245544434\n",
            "Train step - Step 0, Loss 0.0826302021741867\n",
            "Train step - Step 0, Loss 0.08152567595243454\n",
            "Train step - Step 0, Loss 0.08499220758676529\n",
            "Train step - Step 0, Loss 0.08523372560739517\n",
            "Train step - Step 0, Loss 0.08191460371017456\n",
            "Train step - Step 0, Loss 0.08208627253770828\n",
            "Train step - Step 0, Loss 0.08815895020961761\n",
            "Train step - Step 0, Loss 0.07851070165634155\n",
            "Train epoch - Accuracy: 0.3584175084175084 Loss: 0.08439215373511266 Corrects: 4258\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.08719877153635025\n",
            "Train step - Step 0, Loss 0.0834459513425827\n",
            "Train step - Step 0, Loss 0.08550527691841125\n",
            "Train step - Step 0, Loss 0.08645782619714737\n",
            "Train step - Step 0, Loss 0.08130206167697906\n",
            "Train step - Step 0, Loss 0.08185689151287079\n",
            "Train step - Step 0, Loss 0.08314809203147888\n",
            "Train step - Step 0, Loss 0.08607842773199081\n",
            "Train step - Step 0, Loss 0.08532938361167908\n",
            "Train step - Step 0, Loss 0.08800695091485977\n",
            "Train step - Step 0, Loss 0.08651088178157806\n",
            "Train step - Step 0, Loss 0.08399739861488342\n",
            "Train step - Step 0, Loss 0.08399990200996399\n",
            "Train step - Step 0, Loss 0.08896484225988388\n",
            "Train step - Step 0, Loss 0.08856421709060669\n",
            "Train step - Step 0, Loss 0.08016549795866013\n",
            "Train epoch - Accuracy: 0.3501683501683502 Loss: 0.08520044944804124 Corrects: 4160\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.0856408029794693\n",
            "Train step - Step 0, Loss 0.0836733803153038\n",
            "Train step - Step 0, Loss 0.09084347635507584\n",
            "Train step - Step 0, Loss 0.08263394236564636\n",
            "Train step - Step 0, Loss 0.08684651553630829\n",
            "Train step - Step 0, Loss 0.07607186585664749\n",
            "Train step - Step 0, Loss 0.07770688831806183\n",
            "Train step - Step 0, Loss 0.08693888038396835\n",
            "Train step - Step 0, Loss 0.08326193690299988\n",
            "Train step - Step 0, Loss 0.08685139566659927\n",
            "Train step - Step 0, Loss 0.08331729471683502\n",
            "Train step - Step 0, Loss 0.08549466729164124\n",
            "Train step - Step 0, Loss 0.0868941992521286\n",
            "Train step - Step 0, Loss 0.08516459912061691\n",
            "Train step - Step 0, Loss 0.08715328574180603\n",
            "Train step - Step 0, Loss 0.0787944570183754\n",
            "Train epoch - Accuracy: 0.3522727272727273 Loss: 0.08439130715348504 Corrects: 4185\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.08128806203603745\n",
            "Train step - Step 0, Loss 0.08285897225141525\n",
            "Train step - Step 0, Loss 0.08964180946350098\n",
            "Train step - Step 0, Loss 0.0796613097190857\n",
            "Train step - Step 0, Loss 0.08348787575960159\n",
            "Train step - Step 0, Loss 0.08891886472702026\n",
            "Train step - Step 0, Loss 0.08661407232284546\n",
            "Train step - Step 0, Loss 0.08317296952009201\n",
            "Train step - Step 0, Loss 0.08155375719070435\n",
            "Train step - Step 0, Loss 0.0845375508069992\n",
            "Train step - Step 0, Loss 0.08490335941314697\n",
            "Train step - Step 0, Loss 0.08292922377586365\n",
            "Train step - Step 0, Loss 0.08214112371206284\n",
            "Train step - Step 0, Loss 0.08451016992330551\n",
            "Train step - Step 0, Loss 0.0811518207192421\n",
            "Train step - Step 0, Loss 0.07944577932357788\n",
            "Train epoch - Accuracy: 0.3533670033670034 Loss: 0.08369203396517821 Corrects: 4198\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.08525203168392181\n",
            "Train step - Step 0, Loss 0.08849687874317169\n",
            "Train step - Step 0, Loss 0.08872656524181366\n",
            "Train step - Step 0, Loss 0.07880336046218872\n",
            "Train step - Step 0, Loss 0.08278851211071014\n",
            "Train step - Step 0, Loss 0.0825226902961731\n",
            "Train step - Step 0, Loss 0.08088012784719467\n",
            "Train step - Step 0, Loss 0.07924437522888184\n",
            "Train step - Step 0, Loss 0.08102553337812424\n",
            "Train step - Step 0, Loss 0.08611509203910828\n",
            "Train step - Step 0, Loss 0.08668646216392517\n",
            "Train step - Step 0, Loss 0.08360395580530167\n",
            "Train step - Step 0, Loss 0.08233550935983658\n",
            "Train step - Step 0, Loss 0.08830337226390839\n",
            "Train step - Step 0, Loss 0.08071848750114441\n",
            "Train step - Step 0, Loss 0.08105950802564621\n",
            "Train epoch - Accuracy: 0.3557239057239057 Loss: 0.08362017606544976 Corrects: 4226\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.08409670740365982\n",
            "Train step - Step 0, Loss 0.08169392496347427\n",
            "Train step - Step 0, Loss 0.08385906368494034\n",
            "Train step - Step 0, Loss 0.08706360310316086\n",
            "Train step - Step 0, Loss 0.08867338299751282\n",
            "Train step - Step 0, Loss 0.08403532207012177\n",
            "Train step - Step 0, Loss 0.08378571271896362\n",
            "Train step - Step 0, Loss 0.08190029859542847\n",
            "Train step - Step 0, Loss 0.0857364758849144\n",
            "Train step - Step 0, Loss 0.08500775694847107\n",
            "Train step - Step 0, Loss 0.0852787122130394\n",
            "Train step - Step 0, Loss 0.08423768728971481\n",
            "Train step - Step 0, Loss 0.08431531488895416\n",
            "Train step - Step 0, Loss 0.0811227485537529\n",
            "Train step - Step 0, Loss 0.08471205085515976\n",
            "Train step - Step 0, Loss 0.08497852832078934\n",
            "Train epoch - Accuracy: 0.3525252525252525 Loss: 0.08438642083695441 Corrects: 4188\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.08110763877630234\n",
            "Train step - Step 0, Loss 0.08877319097518921\n",
            "Train step - Step 0, Loss 0.08813370019197464\n",
            "Train step - Step 0, Loss 0.08399326354265213\n",
            "Train step - Step 0, Loss 0.07803282141685486\n",
            "Train step - Step 0, Loss 0.08070860058069229\n",
            "Train step - Step 0, Loss 0.08218100666999817\n",
            "Train step - Step 0, Loss 0.07894046604633331\n",
            "Train step - Step 0, Loss 0.08185518532991409\n",
            "Train step - Step 0, Loss 0.08693139255046844\n",
            "Train step - Step 0, Loss 0.08792605251073837\n",
            "Train step - Step 0, Loss 0.08908500522375107\n",
            "Train step - Step 0, Loss 0.08711068332195282\n",
            "Train step - Step 0, Loss 0.08703478425741196\n",
            "Train step - Step 0, Loss 0.0853310152888298\n",
            "Train step - Step 0, Loss 0.0859060138463974\n",
            "Train epoch - Accuracy: 0.3441919191919192 Loss: 0.08451964448798786 Corrects: 4089\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.08266287297010422\n",
            "Train step - Step 0, Loss 0.0859302207827568\n",
            "Train step - Step 0, Loss 0.08512067049741745\n",
            "Train step - Step 0, Loss 0.08408261090517044\n",
            "Train step - Step 0, Loss 0.08438170701265335\n",
            "Train step - Step 0, Loss 0.08191484957933426\n",
            "Train step - Step 0, Loss 0.08641049265861511\n",
            "Train step - Step 0, Loss 0.08536433428525925\n",
            "Train step - Step 0, Loss 0.08405450731515884\n",
            "Train step - Step 0, Loss 0.08328783512115479\n",
            "Train step - Step 0, Loss 0.0812157541513443\n",
            "Train step - Step 0, Loss 0.08790192753076553\n",
            "Train step - Step 0, Loss 0.08190926909446716\n",
            "Train step - Step 0, Loss 0.088594451546669\n",
            "Train step - Step 0, Loss 0.07770615071058273\n",
            "Train step - Step 0, Loss 0.08122605085372925\n",
            "Train epoch - Accuracy: 0.3521043771043771 Loss: 0.0839506983757019 Corrects: 4183\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.08402144908905029\n",
            "Train step - Step 0, Loss 0.08422297239303589\n",
            "Train step - Step 0, Loss 0.08418762683868408\n",
            "Train step - Step 0, Loss 0.08821586519479752\n",
            "Train step - Step 0, Loss 0.08451029658317566\n",
            "Train step - Step 0, Loss 0.08513692021369934\n",
            "Train step - Step 0, Loss 0.08671742677688599\n",
            "Train step - Step 0, Loss 0.07903733104467392\n",
            "Train step - Step 0, Loss 0.07962674647569656\n",
            "Train step - Step 0, Loss 0.08065765351057053\n",
            "Train step - Step 0, Loss 0.08460765331983566\n",
            "Train step - Step 0, Loss 0.08340466767549515\n",
            "Train step - Step 0, Loss 0.08652979880571365\n",
            "Train step - Step 0, Loss 0.07976526021957397\n",
            "Train step - Step 0, Loss 0.0802602544426918\n",
            "Train step - Step 0, Loss 0.08801881223917007\n",
            "Train epoch - Accuracy: 0.3457070707070707 Loss: 0.08353362364901437 Corrects: 4107\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.08891935646533966\n",
            "Train step - Step 0, Loss 0.07871627062559128\n",
            "Train step - Step 0, Loss 0.08067405223846436\n",
            "Train step - Step 0, Loss 0.08392868936061859\n",
            "Train step - Step 0, Loss 0.08482886105775833\n",
            "Train step - Step 0, Loss 0.08494390547275543\n",
            "Train step - Step 0, Loss 0.08291417360305786\n",
            "Train step - Step 0, Loss 0.0829145535826683\n",
            "Train step - Step 0, Loss 0.0841677114367485\n",
            "Train step - Step 0, Loss 0.0858391523361206\n",
            "Train step - Step 0, Loss 0.08218508213758469\n",
            "Train step - Step 0, Loss 0.07627807557582855\n",
            "Train step - Step 0, Loss 0.0880962684750557\n",
            "Train step - Step 0, Loss 0.08072338998317719\n",
            "Train step - Step 0, Loss 0.08786696195602417\n",
            "Train step - Step 0, Loss 0.08898147195577621\n",
            "Train epoch - Accuracy: 0.3498316498316498 Loss: 0.08369820245889702 Corrects: 4156\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.08512667566537857\n",
            "Train step - Step 0, Loss 0.07873379439115524\n",
            "Train step - Step 0, Loss 0.08087144792079926\n",
            "Train step - Step 0, Loss 0.07830297201871872\n",
            "Train step - Step 0, Loss 0.0867057740688324\n",
            "Train step - Step 0, Loss 0.08521510660648346\n",
            "Train step - Step 0, Loss 0.0828077420592308\n",
            "Train step - Step 0, Loss 0.08611201494932175\n",
            "Train step - Step 0, Loss 0.08169429749250412\n",
            "Train step - Step 0, Loss 0.07990946620702744\n",
            "Train step - Step 0, Loss 0.08522528409957886\n",
            "Train step - Step 0, Loss 0.08446405082941055\n",
            "Train step - Step 0, Loss 0.08161856234073639\n",
            "Train step - Step 0, Loss 0.08719755709171295\n",
            "Train step - Step 0, Loss 0.08322878181934357\n",
            "Train step - Step 0, Loss 0.07699377834796906\n",
            "Train epoch - Accuracy: 0.3461279461279461 Loss: 0.08296109001443844 Corrects: 4112\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.08703073859214783\n",
            "Train step - Step 0, Loss 0.0831344723701477\n",
            "Train step - Step 0, Loss 0.08508344739675522\n",
            "Train step - Step 0, Loss 0.08532259613275528\n",
            "Train step - Step 0, Loss 0.07952290028333664\n",
            "Train step - Step 0, Loss 0.08107305318117142\n",
            "Train step - Step 0, Loss 0.08290411531925201\n",
            "Train step - Step 0, Loss 0.08604992181062698\n",
            "Train step - Step 0, Loss 0.0870223194360733\n",
            "Train step - Step 0, Loss 0.08191458880901337\n",
            "Train step - Step 0, Loss 0.08823006600141525\n",
            "Train step - Step 0, Loss 0.08498363196849823\n",
            "Train step - Step 0, Loss 0.08318425714969635\n",
            "Train step - Step 0, Loss 0.08393514901399612\n",
            "Train step - Step 0, Loss 0.0835530012845993\n",
            "Train step - Step 0, Loss 0.08270255476236343\n",
            "Train epoch - Accuracy: 0.34814814814814815 Loss: 0.084151019396806 Corrects: 4136\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.07934504747390747\n",
            "Train step - Step 0, Loss 0.0824437066912651\n",
            "Train step - Step 0, Loss 0.0828884020447731\n",
            "Train step - Step 0, Loss 0.0837903618812561\n",
            "Train step - Step 0, Loss 0.08217103779315948\n",
            "Train step - Step 0, Loss 0.08855331689119339\n",
            "Train step - Step 0, Loss 0.0836847722530365\n",
            "Train step - Step 0, Loss 0.08258210122585297\n",
            "Train step - Step 0, Loss 0.07584922760725021\n",
            "Train step - Step 0, Loss 0.08323462307453156\n",
            "Train step - Step 0, Loss 0.08347692340612411\n",
            "Train step - Step 0, Loss 0.08312933146953583\n",
            "Train step - Step 0, Loss 0.08206653594970703\n",
            "Train step - Step 0, Loss 0.08186791092157364\n",
            "Train step - Step 0, Loss 0.08681938052177429\n",
            "Train step - Step 0, Loss 0.07462827861309052\n",
            "Train epoch - Accuracy: 0.3543771043771044 Loss: 0.0825460806338474 Corrects: 4210\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.08108702301979065\n",
            "Train step - Step 0, Loss 0.08698099851608276\n",
            "Train step - Step 0, Loss 0.08299072831869125\n",
            "Train step - Step 0, Loss 0.08784384280443192\n",
            "Train step - Step 0, Loss 0.0842515304684639\n",
            "Train step - Step 0, Loss 0.08353381603956223\n",
            "Train step - Step 0, Loss 0.08271639049053192\n",
            "Train step - Step 0, Loss 0.08081839233636856\n",
            "Train step - Step 0, Loss 0.0784107968211174\n",
            "Train step - Step 0, Loss 0.08429718017578125\n",
            "Train step - Step 0, Loss 0.08296476304531097\n",
            "Train step - Step 0, Loss 0.08440600335597992\n",
            "Train step - Step 0, Loss 0.08187742531299591\n",
            "Train step - Step 0, Loss 0.08272013068199158\n",
            "Train step - Step 0, Loss 0.07847224920988083\n",
            "Train step - Step 0, Loss 0.08327799290418625\n",
            "Train epoch - Accuracy: 0.3558080808080808 Loss: 0.08290313242962866 Corrects: 4227\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.07719199359416962\n",
            "Train step - Step 0, Loss 0.08232416957616806\n",
            "Train step - Step 0, Loss 0.08359474688768387\n",
            "Train step - Step 0, Loss 0.08036422729492188\n",
            "Train step - Step 0, Loss 0.08324889093637466\n",
            "Train step - Step 0, Loss 0.08393432945013046\n",
            "Train step - Step 0, Loss 0.08520087599754333\n",
            "Train step - Step 0, Loss 0.08091762661933899\n",
            "Train step - Step 0, Loss 0.08373753726482391\n",
            "Train step - Step 0, Loss 0.08220371603965759\n",
            "Train step - Step 0, Loss 0.08545967936515808\n",
            "Train step - Step 0, Loss 0.08402213454246521\n",
            "Train step - Step 0, Loss 0.08076249063014984\n",
            "Train step - Step 0, Loss 0.08246481418609619\n",
            "Train step - Step 0, Loss 0.08893857896327972\n",
            "Train step - Step 0, Loss 0.08500251173973083\n",
            "Train epoch - Accuracy: 0.34915824915824917 Loss: 0.08301968411965803 Corrects: 4148\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.08241686969995499\n",
            "Train step - Step 0, Loss 0.08366644382476807\n",
            "Train step - Step 0, Loss 0.08719900995492935\n",
            "Train step - Step 0, Loss 0.08356871455907822\n",
            "Train step - Step 0, Loss 0.08815688639879227\n",
            "Train step - Step 0, Loss 0.08775394409894943\n",
            "Train step - Step 0, Loss 0.08065508306026459\n",
            "Train step - Step 0, Loss 0.08440486341714859\n",
            "Train step - Step 0, Loss 0.08275077491998672\n",
            "Train step - Step 0, Loss 0.08423395454883575\n",
            "Train step - Step 0, Loss 0.08080798387527466\n",
            "Train step - Step 0, Loss 0.08383757621049881\n",
            "Train step - Step 0, Loss 0.08614404499530792\n",
            "Train step - Step 0, Loss 0.07913484424352646\n",
            "Train step - Step 0, Loss 0.08345271646976471\n",
            "Train step - Step 0, Loss 0.07609131187200546\n",
            "Train epoch - Accuracy: 0.3595959595959596 Loss: 0.08364292607463972 Corrects: 4272\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.08560879528522491\n",
            "Train step - Step 0, Loss 0.07869669049978256\n",
            "Train step - Step 0, Loss 0.08368553966283798\n",
            "Train step - Step 0, Loss 0.08678663522005081\n",
            "Train step - Step 0, Loss 0.08610543608665466\n",
            "Train step - Step 0, Loss 0.07976526021957397\n",
            "Train step - Step 0, Loss 0.08184283971786499\n",
            "Train step - Step 0, Loss 0.08179505169391632\n",
            "Train step - Step 0, Loss 0.08653347939252853\n",
            "Train step - Step 0, Loss 0.08110713213682175\n",
            "Train step - Step 0, Loss 0.07986196130514145\n",
            "Train step - Step 0, Loss 0.07966429740190506\n",
            "Train step - Step 0, Loss 0.08063387870788574\n",
            "Train step - Step 0, Loss 0.08337820321321487\n",
            "Train step - Step 0, Loss 0.0865207090973854\n",
            "Train step - Step 0, Loss 0.09012852609157562\n",
            "Train epoch - Accuracy: 0.3548821548821549 Loss: 0.08302116565632098 Corrects: 4216\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.07979031652212143\n",
            "Train step - Step 0, Loss 0.08207251131534576\n",
            "Train step - Step 0, Loss 0.08144037425518036\n",
            "Train step - Step 0, Loss 0.0843740925192833\n",
            "Train step - Step 0, Loss 0.0817938894033432\n",
            "Train step - Step 0, Loss 0.08734048157930374\n",
            "Train step - Step 0, Loss 0.0864388644695282\n",
            "Train step - Step 0, Loss 0.08491446077823639\n",
            "Train step - Step 0, Loss 0.0821695625782013\n",
            "Train step - Step 0, Loss 0.07693308591842651\n",
            "Train step - Step 0, Loss 0.0796646997332573\n",
            "Train step - Step 0, Loss 0.0872792974114418\n",
            "Train step - Step 0, Loss 0.08123166114091873\n",
            "Train step - Step 0, Loss 0.0845736712217331\n",
            "Train step - Step 0, Loss 0.0849296823143959\n",
            "Train step - Step 0, Loss 0.07486218959093094\n",
            "Train epoch - Accuracy: 0.3495791245791246 Loss: 0.08274995087072103 Corrects: 4153\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.08442918211221695\n",
            "Train step - Step 0, Loss 0.0846698135137558\n",
            "Train step - Step 0, Loss 0.0817338079214096\n",
            "Train step - Step 0, Loss 0.08689891546964645\n",
            "Train step - Step 0, Loss 0.08278907090425491\n",
            "Train step - Step 0, Loss 0.08397670090198517\n",
            "Train step - Step 0, Loss 0.08098110556602478\n",
            "Train step - Step 0, Loss 0.07710249722003937\n",
            "Train step - Step 0, Loss 0.08705410361289978\n",
            "Train step - Step 0, Loss 0.0788494348526001\n",
            "Train step - Step 0, Loss 0.08261731266975403\n",
            "Train step - Step 0, Loss 0.08047468215227127\n",
            "Train step - Step 0, Loss 0.08983241766691208\n",
            "Train step - Step 0, Loss 0.0813186764717102\n",
            "Train step - Step 0, Loss 0.082373708486557\n",
            "Train step - Step 0, Loss 0.08707313984632492\n",
            "Train epoch - Accuracy: 0.3531144781144781 Loss: 0.08312998554020216 Corrects: 4195\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.08457966893911362\n",
            "Train step - Step 0, Loss 0.08069250732660294\n",
            "Train step - Step 0, Loss 0.08605613559484482\n",
            "Train step - Step 0, Loss 0.08161396533250809\n",
            "Train step - Step 0, Loss 0.07894814759492874\n",
            "Train step - Step 0, Loss 0.08008742332458496\n",
            "Train step - Step 0, Loss 0.08513680845499039\n",
            "Train step - Step 0, Loss 0.08219815790653229\n",
            "Train step - Step 0, Loss 0.08098985254764557\n",
            "Train step - Step 0, Loss 0.07886151224374771\n",
            "Train step - Step 0, Loss 0.07874172925949097\n",
            "Train step - Step 0, Loss 0.07997813075780869\n",
            "Train step - Step 0, Loss 0.08598051220178604\n",
            "Train step - Step 0, Loss 0.08279462903738022\n",
            "Train step - Step 0, Loss 0.08632391691207886\n",
            "Train step - Step 0, Loss 0.08672092109918594\n",
            "Train epoch - Accuracy: 0.3538720538720539 Loss: 0.08233590491793373 Corrects: 4204\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.0828603133559227\n",
            "Train step - Step 0, Loss 0.08509839326143265\n",
            "Train step - Step 0, Loss 0.08105111867189407\n",
            "Train step - Step 0, Loss 0.07802264392375946\n",
            "Train step - Step 0, Loss 0.07575999945402145\n",
            "Train step - Step 0, Loss 0.08029980212450027\n",
            "Train step - Step 0, Loss 0.0855388194322586\n",
            "Train step - Step 0, Loss 0.08040483295917511\n",
            "Train step - Step 0, Loss 0.08420433104038239\n",
            "Train step - Step 0, Loss 0.08368328213691711\n",
            "Train step - Step 0, Loss 0.0788784846663475\n",
            "Train step - Step 0, Loss 0.07951565831899643\n",
            "Train step - Step 0, Loss 0.08228502422571182\n",
            "Train step - Step 0, Loss 0.08132967352867126\n",
            "Train step - Step 0, Loss 0.08716088533401489\n",
            "Train step - Step 0, Loss 0.08499917387962341\n",
            "Train epoch - Accuracy: 0.35622895622895623 Loss: 0.08183832728501522 Corrects: 4232\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.0842670276761055\n",
            "Train step - Step 0, Loss 0.0818379744887352\n",
            "Train step - Step 0, Loss 0.08387717604637146\n",
            "Train step - Step 0, Loss 0.08464518934488297\n",
            "Train step - Step 0, Loss 0.08584431558847427\n",
            "Train step - Step 0, Loss 0.08758875727653503\n",
            "Train step - Step 0, Loss 0.07834192365407944\n",
            "Train step - Step 0, Loss 0.08599354326725006\n",
            "Train step - Step 0, Loss 0.08513285219669342\n",
            "Train step - Step 0, Loss 0.08060744404792786\n",
            "Train step - Step 0, Loss 0.08116530627012253\n",
            "Train step - Step 0, Loss 0.08265962451696396\n",
            "Train step - Step 0, Loss 0.08387763053178787\n",
            "Train step - Step 0, Loss 0.08167172968387604\n",
            "Train step - Step 0, Loss 0.08051756769418716\n",
            "Train step - Step 0, Loss 0.07806914299726486\n",
            "Train epoch - Accuracy: 0.35033670033670034 Loss: 0.08304633361221564 Corrects: 4162\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.08307674527168274\n",
            "Train step - Step 0, Loss 0.08283491432666779\n",
            "Train step - Step 0, Loss 0.07947231084108353\n",
            "Train step - Step 0, Loss 0.0789613202214241\n",
            "Train step - Step 0, Loss 0.07766101509332657\n",
            "Train step - Step 0, Loss 0.0790657177567482\n",
            "Train step - Step 0, Loss 0.08301978558301926\n",
            "Train step - Step 0, Loss 0.08153823763132095\n",
            "Train step - Step 0, Loss 0.07931068539619446\n",
            "Train step - Step 0, Loss 0.0885886549949646\n",
            "Train step - Step 0, Loss 0.08514807373285294\n",
            "Train step - Step 0, Loss 0.08502312004566193\n",
            "Train step - Step 0, Loss 0.08288570493459702\n",
            "Train step - Step 0, Loss 0.07758809626102448\n",
            "Train step - Step 0, Loss 0.08542103320360184\n",
            "Train step - Step 0, Loss 0.08619998395442963\n",
            "Train epoch - Accuracy: 0.35993265993265994 Loss: 0.08210111727016141 Corrects: 4276\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.08245376497507095\n",
            "Train step - Step 0, Loss 0.08471652120351791\n",
            "Train step - Step 0, Loss 0.08340132236480713\n",
            "Train step - Step 0, Loss 0.07845613360404968\n",
            "Train step - Step 0, Loss 0.08365670591592789\n",
            "Train step - Step 0, Loss 0.08263511210680008\n",
            "Train step - Step 0, Loss 0.08188442140817642\n",
            "Train step - Step 0, Loss 0.08232399076223373\n",
            "Train step - Step 0, Loss 0.08503028005361557\n",
            "Train step - Step 0, Loss 0.08215617388486862\n",
            "Train step - Step 0, Loss 0.08933182805776596\n",
            "Train step - Step 0, Loss 0.0784529596567154\n",
            "Train step - Step 0, Loss 0.08159297704696655\n",
            "Train step - Step 0, Loss 0.0834483876824379\n",
            "Train step - Step 0, Loss 0.07753368467092514\n",
            "Train step - Step 0, Loss 0.08585707098245621\n",
            "Train epoch - Accuracy: 0.3509259259259259 Loss: 0.08257420705725449 Corrects: 4169\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.08572400361299515\n",
            "Train step - Step 0, Loss 0.08194614946842194\n",
            "Train step - Step 0, Loss 0.08592814952135086\n",
            "Train step - Step 0, Loss 0.0810256153345108\n",
            "Train step - Step 0, Loss 0.08469625562429428\n",
            "Train step - Step 0, Loss 0.0810081958770752\n",
            "Train step - Step 0, Loss 0.08081179857254028\n",
            "Train step - Step 0, Loss 0.0758994072675705\n",
            "Train step - Step 0, Loss 0.08157233893871307\n",
            "Train step - Step 0, Loss 0.08071289956569672\n",
            "Train step - Step 0, Loss 0.08381500840187073\n",
            "Train step - Step 0, Loss 0.08613435924053192\n",
            "Train step - Step 0, Loss 0.0865296944975853\n",
            "Train step - Step 0, Loss 0.08636689186096191\n",
            "Train step - Step 0, Loss 0.07903429120779037\n",
            "Train step - Step 0, Loss 0.08289876580238342\n",
            "Train epoch - Accuracy: 0.3478114478114478 Loss: 0.08275160277732695 Corrects: 4132\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.07952072471380234\n",
            "Train step - Step 0, Loss 0.08384077250957489\n",
            "Train step - Step 0, Loss 0.08098790794610977\n",
            "Train step - Step 0, Loss 0.0846070721745491\n",
            "Train step - Step 0, Loss 0.08166204392910004\n",
            "Train step - Step 0, Loss 0.08085641264915466\n",
            "Train step - Step 0, Loss 0.08171633630990982\n",
            "Train step - Step 0, Loss 0.08603514730930328\n",
            "Train step - Step 0, Loss 0.08357920497655869\n",
            "Train step - Step 0, Loss 0.08103010058403015\n",
            "Train step - Step 0, Loss 0.08110843598842621\n",
            "Train step - Step 0, Loss 0.08739493787288666\n",
            "Train step - Step 0, Loss 0.08269365131855011\n",
            "Train step - Step 0, Loss 0.07911799103021622\n",
            "Train step - Step 0, Loss 0.08111797273159027\n",
            "Train step - Step 0, Loss 0.08030491322278976\n",
            "Train epoch - Accuracy: 0.35193602693602694 Loss: 0.08228923734089341 Corrects: 4181\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.08714169263839722\n",
            "Train step - Step 0, Loss 0.08319734036922455\n",
            "Train step - Step 0, Loss 0.0805174857378006\n",
            "Train step - Step 0, Loss 0.08388077467679977\n",
            "Train step - Step 0, Loss 0.08081290870904922\n",
            "Train step - Step 0, Loss 0.0818551629781723\n",
            "Train step - Step 0, Loss 0.08002515882253647\n",
            "Train step - Step 0, Loss 0.08352502435445786\n",
            "Train step - Step 0, Loss 0.0806560292840004\n",
            "Train step - Step 0, Loss 0.08275974541902542\n",
            "Train step - Step 0, Loss 0.08623674511909485\n",
            "Train step - Step 0, Loss 0.08234607428312302\n",
            "Train step - Step 0, Loss 0.07968656718730927\n",
            "Train step - Step 0, Loss 0.08525340259075165\n",
            "Train step - Step 0, Loss 0.07988329976797104\n",
            "Train step - Step 0, Loss 0.08076436072587967\n",
            "Train epoch - Accuracy: 0.35353535353535354 Loss: 0.0824653385715051 Corrects: 4200\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.08648089319467545\n",
            "Train step - Step 0, Loss 0.08398281037807465\n",
            "Train step - Step 0, Loss 0.08112620562314987\n",
            "Train step - Step 0, Loss 0.08087626844644547\n",
            "Train step - Step 0, Loss 0.07943833619356155\n",
            "Train step - Step 0, Loss 0.08479592949151993\n",
            "Train step - Step 0, Loss 0.07932431995868683\n",
            "Train step - Step 0, Loss 0.0820271298289299\n",
            "Train step - Step 0, Loss 0.07917797565460205\n",
            "Train step - Step 0, Loss 0.08546791225671768\n",
            "Train step - Step 0, Loss 0.08455371111631393\n",
            "Train step - Step 0, Loss 0.08206765353679657\n",
            "Train step - Step 0, Loss 0.07899856567382812\n",
            "Train step - Step 0, Loss 0.08298712223768234\n",
            "Train step - Step 0, Loss 0.08162425458431244\n",
            "Train step - Step 0, Loss 0.07707522064447403\n",
            "Train epoch - Accuracy: 0.35454545454545455 Loss: 0.08204011945712446 Corrects: 4212\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.0782989040017128\n",
            "Train step - Step 0, Loss 0.08569467067718506\n",
            "Train step - Step 0, Loss 0.08088134974241257\n",
            "Train step - Step 0, Loss 0.0834195613861084\n",
            "Train step - Step 0, Loss 0.08202937990427017\n",
            "Train step - Step 0, Loss 0.07871191203594208\n",
            "Train step - Step 0, Loss 0.08439283818006516\n",
            "Train step - Step 0, Loss 0.08279402554035187\n",
            "Train step - Step 0, Loss 0.07864678651094437\n",
            "Train step - Step 0, Loss 0.08227598667144775\n",
            "Train step - Step 0, Loss 0.0813075602054596\n",
            "Train step - Step 0, Loss 0.08688458800315857\n",
            "Train step - Step 0, Loss 0.08238884806632996\n",
            "Train step - Step 0, Loss 0.08338853716850281\n",
            "Train step - Step 0, Loss 0.08463303744792938\n",
            "Train step - Step 0, Loss 0.07758260518312454\n",
            "Train epoch - Accuracy: 0.3514309764309764 Loss: 0.08223772649512147 Corrects: 4175\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.08455751091241837\n",
            "Train step - Step 0, Loss 0.07974725216627121\n",
            "Train step - Step 0, Loss 0.07890332490205765\n",
            "Train step - Step 0, Loss 0.08506033569574356\n",
            "Train step - Step 0, Loss 0.0770239606499672\n",
            "Train step - Step 0, Loss 0.08434693515300751\n",
            "Train step - Step 0, Loss 0.08453933894634247\n",
            "Train step - Step 0, Loss 0.07989724725484848\n",
            "Train step - Step 0, Loss 0.0792497843503952\n",
            "Train step - Step 0, Loss 0.08288991451263428\n",
            "Train step - Step 0, Loss 0.0836014673113823\n",
            "Train step - Step 0, Loss 0.08308775722980499\n",
            "Train step - Step 0, Loss 0.08220077306032181\n",
            "Train step - Step 0, Loss 0.08424878120422363\n",
            "Train step - Step 0, Loss 0.08263517171144485\n",
            "Train step - Step 0, Loss 0.07941510528326035\n",
            "Train epoch - Accuracy: 0.3522727272727273 Loss: 0.0820502875579728 Corrects: 4185\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.07684969902038574\n",
            "Train step - Step 0, Loss 0.0801960825920105\n",
            "Train step - Step 0, Loss 0.07949479669332504\n",
            "Train step - Step 0, Loss 0.08527649194002151\n",
            "Train step - Step 0, Loss 0.08273228257894516\n",
            "Train step - Step 0, Loss 0.08090817183256149\n",
            "Train step - Step 0, Loss 0.07980778813362122\n",
            "Train step - Step 0, Loss 0.08059028536081314\n",
            "Train step - Step 0, Loss 0.08748500049114227\n",
            "Train step - Step 0, Loss 0.09039236605167389\n",
            "Train step - Step 0, Loss 0.08318222314119339\n",
            "Train step - Step 0, Loss 0.08987212926149368\n",
            "Train step - Step 0, Loss 0.08847629278898239\n",
            "Train step - Step 0, Loss 0.08402086794376373\n",
            "Train step - Step 0, Loss 0.07951600104570389\n",
            "Train step - Step 0, Loss 0.07470711320638657\n",
            "Train epoch - Accuracy: 0.3528619528619529 Loss: 0.08299438792346704 Corrects: 4192\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.08266624808311462\n",
            "Train step - Step 0, Loss 0.08464913815259933\n",
            "Train step - Step 0, Loss 0.08188924193382263\n",
            "Train step - Step 0, Loss 0.08074281364679337\n",
            "Train step - Step 0, Loss 0.08189123868942261\n",
            "Train step - Step 0, Loss 0.08144979923963547\n",
            "Train step - Step 0, Loss 0.0821739211678505\n",
            "Train step - Step 0, Loss 0.08484860509634018\n",
            "Train step - Step 0, Loss 0.08400022983551025\n",
            "Train step - Step 0, Loss 0.08298558741807938\n",
            "Train step - Step 0, Loss 0.08081161975860596\n",
            "Train step - Step 0, Loss 0.08323686569929123\n",
            "Train step - Step 0, Loss 0.08078943192958832\n",
            "Train step - Step 0, Loss 0.08368611335754395\n",
            "Train step - Step 0, Loss 0.08278147876262665\n",
            "Train step - Step 0, Loss 0.08026871830224991\n",
            "Train epoch - Accuracy: 0.35395622895622897 Loss: 0.08250364731959622 Corrects: 4205\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.0825844332575798\n",
            "Train step - Step 0, Loss 0.08091310411691666\n",
            "Train step - Step 0, Loss 0.0895470604300499\n",
            "Train step - Step 0, Loss 0.08216524124145508\n",
            "Train step - Step 0, Loss 0.07894860208034515\n",
            "Train step - Step 0, Loss 0.08066318184137344\n",
            "Train step - Step 0, Loss 0.08266902714967728\n",
            "Train step - Step 0, Loss 0.08093301951885223\n",
            "Train step - Step 0, Loss 0.08172769844532013\n",
            "Train step - Step 0, Loss 0.08134859800338745\n",
            "Train step - Step 0, Loss 0.07886502146720886\n",
            "Train step - Step 0, Loss 0.08378362655639648\n",
            "Train step - Step 0, Loss 0.07801520079374313\n",
            "Train step - Step 0, Loss 0.08035202324390411\n",
            "Train step - Step 0, Loss 0.08335351198911667\n",
            "Train step - Step 0, Loss 0.09271779656410217\n",
            "Train epoch - Accuracy: 0.35134680134680135 Loss: 0.08205774980362016 Corrects: 4174\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.08345971256494522\n",
            "Train step - Step 0, Loss 0.08123315125703812\n",
            "Train step - Step 0, Loss 0.08147740364074707\n",
            "Train step - Step 0, Loss 0.08034346997737885\n",
            "Train step - Step 0, Loss 0.08339869230985641\n",
            "Train step - Step 0, Loss 0.0754091739654541\n",
            "Train step - Step 0, Loss 0.08547353744506836\n",
            "Train step - Step 0, Loss 0.07947396486997604\n",
            "Train step - Step 0, Loss 0.08363748341798782\n",
            "Train step - Step 0, Loss 0.08132624626159668\n",
            "Train step - Step 0, Loss 0.08017237484455109\n",
            "Train step - Step 0, Loss 0.08415740728378296\n",
            "Train step - Step 0, Loss 0.08521470427513123\n",
            "Train step - Step 0, Loss 0.0831967145204544\n",
            "Train step - Step 0, Loss 0.07982946187257767\n",
            "Train step - Step 0, Loss 0.08919978141784668\n",
            "Train epoch - Accuracy: 0.3553030303030303 Loss: 0.08207617913833773 Corrects: 4221\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.08715734630823135\n",
            "Train step - Step 0, Loss 0.08591774851083755\n",
            "Train step - Step 0, Loss 0.08287898451089859\n",
            "Train step - Step 0, Loss 0.07703080028295517\n",
            "Train step - Step 0, Loss 0.0806952714920044\n",
            "Train step - Step 0, Loss 0.08390844613313675\n",
            "Train step - Step 0, Loss 0.08681946992874146\n",
            "Train step - Step 0, Loss 0.07515957206487656\n",
            "Train step - Step 0, Loss 0.07856205105781555\n",
            "Train step - Step 0, Loss 0.08240959793329239\n",
            "Train step - Step 0, Loss 0.08457817882299423\n",
            "Train step - Step 0, Loss 0.08361033350229263\n",
            "Train step - Step 0, Loss 0.07718402147293091\n",
            "Train step - Step 0, Loss 0.08251380175352097\n",
            "Train step - Step 0, Loss 0.08694282174110413\n",
            "Train step - Step 0, Loss 0.08596336841583252\n",
            "Train epoch - Accuracy: 0.3500841750841751 Loss: 0.08246715309643986 Corrects: 4159\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.08377276360988617\n",
            "Train step - Step 0, Loss 0.07856481522321701\n",
            "Train step - Step 0, Loss 0.0787191092967987\n",
            "Train step - Step 0, Loss 0.08332322537899017\n",
            "Train step - Step 0, Loss 0.08277330547571182\n",
            "Train step - Step 0, Loss 0.0829223096370697\n",
            "Train step - Step 0, Loss 0.08499547094106674\n",
            "Train step - Step 0, Loss 0.08588504791259766\n",
            "Train step - Step 0, Loss 0.07809141278266907\n",
            "Train step - Step 0, Loss 0.07714848965406418\n",
            "Train step - Step 0, Loss 0.08232957869768143\n",
            "Train step - Step 0, Loss 0.08436363935470581\n",
            "Train step - Step 0, Loss 0.08165581524372101\n",
            "Train step - Step 0, Loss 0.08078822493553162\n",
            "Train step - Step 0, Loss 0.08532215654850006\n",
            "Train step - Step 0, Loss 0.07757440954446793\n",
            "Train epoch - Accuracy: 0.34949494949494947 Loss: 0.08190825820872277 Corrects: 4152\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.0822252482175827\n",
            "Train step - Step 0, Loss 0.08260985463857651\n",
            "Train step - Step 0, Loss 0.08420396596193314\n",
            "Train step - Step 0, Loss 0.08164634555578232\n",
            "Train step - Step 0, Loss 0.08211240917444229\n",
            "Train step - Step 0, Loss 0.08111100643873215\n",
            "Train step - Step 0, Loss 0.08073867112398148\n",
            "Train step - Step 0, Loss 0.0818573608994484\n",
            "Train step - Step 0, Loss 0.08047318458557129\n",
            "Train step - Step 0, Loss 0.08325446397066116\n",
            "Train step - Step 0, Loss 0.08027037978172302\n",
            "Train step - Step 0, Loss 0.08312825113534927\n",
            "Train step - Step 0, Loss 0.08072004467248917\n",
            "Train step - Step 0, Loss 0.0806172788143158\n",
            "Train step - Step 0, Loss 0.08038131892681122\n",
            "Train step - Step 0, Loss 0.08695012331008911\n",
            "Train epoch - Accuracy: 0.35774410774410775 Loss: 0.08184938370579421 Corrects: 4250\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.08387914299964905\n",
            "Train step - Step 0, Loss 0.08143285661935806\n",
            "Train step - Step 0, Loss 0.08314461261034012\n",
            "Train step - Step 0, Loss 0.07966113090515137\n",
            "Train step - Step 0, Loss 0.08169395476579666\n",
            "Train step - Step 0, Loss 0.08081995695829391\n",
            "Train step - Step 0, Loss 0.07919574528932571\n",
            "Train step - Step 0, Loss 0.08636574447154999\n",
            "Train step - Step 0, Loss 0.08072678744792938\n",
            "Train step - Step 0, Loss 0.08038542419672012\n",
            "Train step - Step 0, Loss 0.08103913068771362\n",
            "Train step - Step 0, Loss 0.08487917482852936\n",
            "Train step - Step 0, Loss 0.08231717348098755\n",
            "Train step - Step 0, Loss 0.08142277598381042\n",
            "Train step - Step 0, Loss 0.08219598233699799\n",
            "Train step - Step 0, Loss 0.07393935322761536\n",
            "Train epoch - Accuracy: 0.353030303030303 Loss: 0.08170140867281442 Corrects: 4194\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.08538174629211426\n",
            "Train step - Step 0, Loss 0.0815558135509491\n",
            "Train step - Step 0, Loss 0.07766502350568771\n",
            "Train step - Step 0, Loss 0.08168020844459534\n",
            "Train step - Step 0, Loss 0.08240532875061035\n",
            "Train step - Step 0, Loss 0.07655640691518784\n",
            "Train step - Step 0, Loss 0.0817023366689682\n",
            "Train step - Step 0, Loss 0.08062169700860977\n",
            "Train step - Step 0, Loss 0.08591663092374802\n",
            "Train step - Step 0, Loss 0.08420157432556152\n",
            "Train step - Step 0, Loss 0.0770658403635025\n",
            "Train step - Step 0, Loss 0.08212769776582718\n",
            "Train step - Step 0, Loss 0.0829758271574974\n",
            "Train step - Step 0, Loss 0.08266943693161011\n",
            "Train step - Step 0, Loss 0.08069055527448654\n",
            "Train step - Step 0, Loss 0.07981444150209427\n",
            "Train epoch - Accuracy: 0.3537037037037037 Loss: 0.08149521734678385 Corrects: 4202\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.07375555485486984\n",
            "Train step - Step 0, Loss 0.0798022598028183\n",
            "Train step - Step 0, Loss 0.08227305859327316\n",
            "Train step - Step 0, Loss 0.07628575712442398\n",
            "Train step - Step 0, Loss 0.08751256763935089\n",
            "Train step - Step 0, Loss 0.07969693094491959\n",
            "Train step - Step 0, Loss 0.08218631148338318\n",
            "Train step - Step 0, Loss 0.08085689693689346\n",
            "Train step - Step 0, Loss 0.082850880920887\n",
            "Train step - Step 0, Loss 0.08459831774234772\n",
            "Train step - Step 0, Loss 0.08405166119337082\n",
            "Train step - Step 0, Loss 0.0865158662199974\n",
            "Train step - Step 0, Loss 0.0831238180398941\n",
            "Train step - Step 0, Loss 0.0793938860297203\n",
            "Train step - Step 0, Loss 0.08091504871845245\n",
            "Train step - Step 0, Loss 0.0845867320895195\n",
            "Train epoch - Accuracy: 0.3506734006734007 Loss: 0.0816787941437779 Corrects: 4166\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.07719505578279495\n",
            "Train step - Step 0, Loss 0.07921905070543289\n",
            "Train step - Step 0, Loss 0.08342155814170837\n",
            "Train step - Step 0, Loss 0.07679113745689392\n",
            "Train step - Step 0, Loss 0.0844942107796669\n",
            "Train step - Step 0, Loss 0.08388249576091766\n",
            "Train step - Step 0, Loss 0.0840507298707962\n",
            "Train step - Step 0, Loss 0.0817173644900322\n",
            "Train step - Step 0, Loss 0.08622578531503677\n",
            "Train step - Step 0, Loss 0.0846533551812172\n",
            "Train step - Step 0, Loss 0.08210922032594681\n",
            "Train step - Step 0, Loss 0.0805911049246788\n",
            "Train step - Step 0, Loss 0.08041106164455414\n",
            "Train step - Step 0, Loss 0.08334247022867203\n",
            "Train step - Step 0, Loss 0.08546768128871918\n",
            "Train step - Step 0, Loss 0.08461741358041763\n",
            "Train epoch - Accuracy: 0.3532828282828283 Loss: 0.08231025095840898 Corrects: 4197\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.08031626045703888\n",
            "Train step - Step 0, Loss 0.07955451309680939\n",
            "Train step - Step 0, Loss 0.08153560757637024\n",
            "Train step - Step 0, Loss 0.08069925755262375\n",
            "Train step - Step 0, Loss 0.0860067829489708\n",
            "Train step - Step 0, Loss 0.08275796473026276\n",
            "Train step - Step 0, Loss 0.08329866081476212\n",
            "Train step - Step 0, Loss 0.08413494378328323\n",
            "Train step - Step 0, Loss 0.07770715653896332\n",
            "Train step - Step 0, Loss 0.08387866616249084\n",
            "Train step - Step 0, Loss 0.0811828076839447\n",
            "Train step - Step 0, Loss 0.08158258348703384\n",
            "Train step - Step 0, Loss 0.08441127091646194\n",
            "Train step - Step 0, Loss 0.08252418786287308\n",
            "Train step - Step 0, Loss 0.07900284975767136\n",
            "Train step - Step 0, Loss 0.078170545399189\n",
            "Train epoch - Accuracy: 0.35462962962962963 Loss: 0.0817930315329571 Corrects: 4213\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.08052445948123932\n",
            "Train step - Step 0, Loss 0.08105943351984024\n",
            "Train step - Step 0, Loss 0.08185187727212906\n",
            "Train step - Step 0, Loss 0.0735783725976944\n",
            "Train step - Step 0, Loss 0.08223197609186172\n",
            "Train step - Step 0, Loss 0.07677818834781647\n",
            "Train step - Step 0, Loss 0.08310694247484207\n",
            "Train step - Step 0, Loss 0.08418965339660645\n",
            "Train step - Step 0, Loss 0.08551134914159775\n",
            "Train step - Step 0, Loss 0.08696897327899933\n",
            "Train step - Step 0, Loss 0.07910455018281937\n",
            "Train step - Step 0, Loss 0.08076053112745285\n",
            "Train step - Step 0, Loss 0.08242782950401306\n",
            "Train step - Step 0, Loss 0.08390120416879654\n",
            "Train step - Step 0, Loss 0.07721107453107834\n",
            "Train step - Step 0, Loss 0.08582931756973267\n",
            "Train epoch - Accuracy: 0.35774410774410775 Loss: 0.08141827282279429 Corrects: 4250\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.07903086394071579\n",
            "Train step - Step 0, Loss 0.08341803401708603\n",
            "Train step - Step 0, Loss 0.0817241445183754\n",
            "Train step - Step 0, Loss 0.07848680764436722\n",
            "Train step - Step 0, Loss 0.0771387442946434\n",
            "Train step - Step 0, Loss 0.08383996784687042\n",
            "Train step - Step 0, Loss 0.08457531780004501\n",
            "Train step - Step 0, Loss 0.07609860599040985\n",
            "Train step - Step 0, Loss 0.08295805752277374\n",
            "Train step - Step 0, Loss 0.08456824719905853\n",
            "Train step - Step 0, Loss 0.08499610424041748\n",
            "Train step - Step 0, Loss 0.0770551860332489\n",
            "Train step - Step 0, Loss 0.08270938694477081\n",
            "Train step - Step 0, Loss 0.08451736718416214\n",
            "Train step - Step 0, Loss 0.07645837962627411\n",
            "Train step - Step 0, Loss 0.08322247862815857\n",
            "Train epoch - Accuracy: 0.35218855218855216 Loss: 0.08123382636995026 Corrects: 4184\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.07989867031574249\n",
            "Train step - Step 0, Loss 0.0835314467549324\n",
            "Train step - Step 0, Loss 0.08151751756668091\n",
            "Train step - Step 0, Loss 0.07961705327033997\n",
            "Train step - Step 0, Loss 0.0758444145321846\n",
            "Train step - Step 0, Loss 0.08503963053226471\n",
            "Train step - Step 0, Loss 0.08326949924230576\n",
            "Train step - Step 0, Loss 0.0800742506980896\n",
            "Train step - Step 0, Loss 0.0841466411948204\n",
            "Train step - Step 0, Loss 0.0816827341914177\n",
            "Train step - Step 0, Loss 0.07957685738801956\n",
            "Train step - Step 0, Loss 0.08246147632598877\n",
            "Train step - Step 0, Loss 0.08599000424146652\n",
            "Train step - Step 0, Loss 0.08282558619976044\n",
            "Train step - Step 0, Loss 0.07747995853424072\n",
            "Train step - Step 0, Loss 0.08607892692089081\n",
            "Train epoch - Accuracy: 0.35235690235690237 Loss: 0.08166821740492426 Corrects: 4186\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.07743068784475327\n",
            "Train step - Step 0, Loss 0.08104542642831802\n",
            "Train step - Step 0, Loss 0.07782839983701706\n",
            "Train step - Step 0, Loss 0.08411876112222672\n",
            "Train step - Step 0, Loss 0.08085241168737411\n",
            "Train step - Step 0, Loss 0.08243729174137115\n",
            "Train step - Step 0, Loss 0.0826319009065628\n",
            "Train step - Step 0, Loss 0.08330148458480835\n",
            "Train step - Step 0, Loss 0.08642703294754028\n",
            "Train step - Step 0, Loss 0.08118937909603119\n",
            "Train step - Step 0, Loss 0.08060277253389359\n",
            "Train step - Step 0, Loss 0.08206512033939362\n",
            "Train step - Step 0, Loss 0.08270375430583954\n",
            "Train step - Step 0, Loss 0.08207688480615616\n",
            "Train step - Step 0, Loss 0.08097013831138611\n",
            "Train step - Step 0, Loss 0.074148990213871\n",
            "Train epoch - Accuracy: 0.362962962962963 Loss: 0.0814829113959062 Corrects: 4312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.44 0.07319577783346176\n",
            "TEST GROUP:  0.493\n",
            "TEST ALL:  0.4801666666666667\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  7000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 49, 96, 9, 13, 17, 21, 45, 53, 84, 57, 61, 65, 69, 81, 85, 88, 80, 95, 36, 4, 8, 16, 20, 24, 32, 40, 76, 52, 56, 60, 64, 68, 72, 93, 97, 2, 47, 19, 23, 27, 31, 35, 39, 55, 6, 59, 63, 67, 75, 79, 83, 15, 7, 98, 94, 90, 86, 82, 70, 54, 50, 42, 34, 30, 22, 18, 14, 10, 0]\n",
            "TRAIN_SET CLASSES:  [35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "VALIDATION CLASSES:  [53, 52, 50, 35, 27, 86, 84, 17, 70, 69]\n",
            "GROUP:  7\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  70\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.22782158851623535\n",
            "Train step - Step 10, Loss 0.1259160190820694\n",
            "Train step - Step 20, Loss 0.11795017123222351\n",
            "Train step - Step 30, Loss 0.10954466462135315\n",
            "Train step - Step 40, Loss 0.10734477639198303\n",
            "Train step - Step 50, Loss 0.10397682338953018\n",
            "Train epoch - Accuracy: 0.15800865800865802 Loss: 0.12358277398786503 Corrects: 1095\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.10475577414035797\n",
            "Train step - Step 70, Loss 0.10249276459217072\n",
            "Train step - Step 80, Loss 0.1014714315533638\n",
            "Train step - Step 90, Loss 0.09823089838027954\n",
            "Train step - Step 100, Loss 0.09785713255405426\n",
            "Train epoch - Accuracy: 0.258008658008658 Loss: 0.10161625203417149 Corrects: 1788\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.10083706676959991\n",
            "Train step - Step 120, Loss 0.09877265244722366\n",
            "Train step - Step 130, Loss 0.10033499449491501\n",
            "Train step - Step 140, Loss 0.09950342774391174\n",
            "Train step - Step 150, Loss 0.09740973263978958\n",
            "Train step - Step 160, Loss 0.10065687447786331\n",
            "Train epoch - Accuracy: 0.3238095238095238 Loss: 0.0990502049697598 Corrects: 2244\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.10388877242803574\n",
            "Train step - Step 180, Loss 0.0967281311750412\n",
            "Train step - Step 190, Loss 0.09715460240840912\n",
            "Train step - Step 200, Loss 0.09799136966466904\n",
            "Train step - Step 210, Loss 0.09347053617238998\n",
            "Train epoch - Accuracy: 0.36666666666666664 Loss: 0.09793159939337946 Corrects: 2541\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1007627472281456\n",
            "Train step - Step 230, Loss 0.09623070806264877\n",
            "Train step - Step 240, Loss 0.09622650593519211\n",
            "Train step - Step 250, Loss 0.09514244645833969\n",
            "Train step - Step 260, Loss 0.09363701939582825\n",
            "Train step - Step 270, Loss 0.09182032942771912\n",
            "Train epoch - Accuracy: 0.3913419913419913 Loss: 0.09690875242024789 Corrects: 2712\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.09676682204008102\n",
            "Train step - Step 290, Loss 0.0988515317440033\n",
            "Train step - Step 300, Loss 0.10012407600879669\n",
            "Train step - Step 310, Loss 0.09459316730499268\n",
            "Train step - Step 320, Loss 0.09304594993591309\n",
            "Train epoch - Accuracy: 0.4183261183261183 Loss: 0.09636685378838755 Corrects: 2899\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.09756171703338623\n",
            "Train step - Step 340, Loss 0.09449177980422974\n",
            "Train step - Step 350, Loss 0.09695526212453842\n",
            "Train step - Step 360, Loss 0.0977332592010498\n",
            "Train step - Step 370, Loss 0.09721431881189346\n",
            "Train step - Step 380, Loss 0.09760873019695282\n",
            "Train epoch - Accuracy: 0.4396825396825397 Loss: 0.0957881086983034 Corrects: 3047\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.10200654715299606\n",
            "Train step - Step 400, Loss 0.08880539238452911\n",
            "Train step - Step 410, Loss 0.09705458581447601\n",
            "Train step - Step 420, Loss 0.09438879787921906\n",
            "Train step - Step 430, Loss 0.09484666585922241\n",
            "Train epoch - Accuracy: 0.45584415584415583 Loss: 0.09555034888384147 Corrects: 3159\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.10045842826366425\n",
            "Train step - Step 450, Loss 0.09582044184207916\n",
            "Train step - Step 460, Loss 0.09668039530515671\n",
            "Train step - Step 470, Loss 0.09822851419448853\n",
            "Train step - Step 480, Loss 0.09411564469337463\n",
            "Train step - Step 490, Loss 0.09571383148431778\n",
            "Train epoch - Accuracy: 0.47373737373737373 Loss: 0.09503608345125317 Corrects: 3283\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.09230822324752808\n",
            "Train step - Step 510, Loss 0.095219187438488\n",
            "Train step - Step 520, Loss 0.09579285234212875\n",
            "Train step - Step 530, Loss 0.09451623260974884\n",
            "Train step - Step 540, Loss 0.10186664760112762\n",
            "Train epoch - Accuracy: 0.4910533910533911 Loss: 0.0949608062747409 Corrects: 3403\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.0967300683259964\n",
            "Train step - Step 560, Loss 0.09382897615432739\n",
            "Train step - Step 570, Loss 0.09694860875606537\n",
            "Train step - Step 580, Loss 0.09821928292512894\n",
            "Train step - Step 590, Loss 0.09338978677988052\n",
            "Train step - Step 600, Loss 0.09095317125320435\n",
            "Train epoch - Accuracy: 0.5028860028860029 Loss: 0.09456169436461309 Corrects: 3485\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.09636306762695312\n",
            "Train step - Step 620, Loss 0.08847685158252716\n",
            "Train step - Step 630, Loss 0.09211833029985428\n",
            "Train step - Step 640, Loss 0.09403685480356216\n",
            "Train step - Step 650, Loss 0.08793388307094574\n",
            "Train epoch - Accuracy: 0.5102453102453103 Loss: 0.09436423207215244 Corrects: 3536\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.09732742607593536\n",
            "Train step - Step 670, Loss 0.09337373822927475\n",
            "Train step - Step 680, Loss 0.08893270790576935\n",
            "Train step - Step 690, Loss 0.0893477275967598\n",
            "Train step - Step 700, Loss 0.09374624490737915\n",
            "Train step - Step 710, Loss 0.09412480890750885\n",
            "Train epoch - Accuracy: 0.5261183261183261 Loss: 0.09413991744642133 Corrects: 3646\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.09814301133155823\n",
            "Train step - Step 730, Loss 0.09360716491937637\n",
            "Train step - Step 740, Loss 0.09531784802675247\n",
            "Train step - Step 750, Loss 0.09621433913707733\n",
            "Train step - Step 760, Loss 0.09609156101942062\n",
            "Train epoch - Accuracy: 0.5262626262626262 Loss: 0.0938808226288655 Corrects: 3647\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.09405727684497833\n",
            "Train step - Step 780, Loss 0.09274137765169144\n",
            "Train step - Step 790, Loss 0.09194093197584152\n",
            "Train step - Step 800, Loss 0.09810043126344681\n",
            "Train step - Step 810, Loss 0.09425795823335648\n",
            "Train step - Step 820, Loss 0.09477344155311584\n",
            "Train epoch - Accuracy: 0.5367965367965368 Loss: 0.0938630510094706 Corrects: 3720\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.09267917275428772\n",
            "Train step - Step 840, Loss 0.09542223066091537\n",
            "Train step - Step 850, Loss 0.10039200633764267\n",
            "Train step - Step 860, Loss 0.0976080596446991\n",
            "Train step - Step 870, Loss 0.09995004534721375\n",
            "Train epoch - Accuracy: 0.543001443001443 Loss: 0.09362385429517188 Corrects: 3763\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.09323501586914062\n",
            "Train step - Step 890, Loss 0.09442393481731415\n",
            "Train step - Step 900, Loss 0.0924193412065506\n",
            "Train step - Step 910, Loss 0.09411804378032684\n",
            "Train step - Step 920, Loss 0.0943809375166893\n",
            "Train step - Step 930, Loss 0.09436827898025513\n",
            "Train epoch - Accuracy: 0.5427128427128427 Loss: 0.09339731590013312 Corrects: 3761\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.09017563611268997\n",
            "Train step - Step 950, Loss 0.0939713642001152\n",
            "Train step - Step 960, Loss 0.09182848036289215\n",
            "Train step - Step 970, Loss 0.09537749737501144\n",
            "Train step - Step 980, Loss 0.09233740717172623\n",
            "Train epoch - Accuracy: 0.5639249639249639 Loss: 0.09330687308079237 Corrects: 3908\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.09270815551280975\n",
            "Train step - Step 1000, Loss 0.09242039918899536\n",
            "Train step - Step 1010, Loss 0.09464893490076065\n",
            "Train step - Step 1020, Loss 0.0973992645740509\n",
            "Train step - Step 1030, Loss 0.09843868017196655\n",
            "Train step - Step 1040, Loss 0.09213203936815262\n",
            "Train epoch - Accuracy: 0.5554112554112555 Loss: 0.09317452664585169 Corrects: 3849\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.0912092998623848\n",
            "Train step - Step 1060, Loss 0.08835422247648239\n",
            "Train step - Step 1070, Loss 0.09255706518888474\n",
            "Train step - Step 1080, Loss 0.09727472811937332\n",
            "Train step - Step 1090, Loss 0.08963335305452347\n",
            "Train epoch - Accuracy: 0.564069264069264 Loss: 0.09333834998406373 Corrects: 3909\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.09374074637889862\n",
            "Train step - Step 1110, Loss 0.08775705844163895\n",
            "Train step - Step 1120, Loss 0.09972728788852692\n",
            "Train step - Step 1130, Loss 0.09382078796625137\n",
            "Train step - Step 1140, Loss 0.09162423014640808\n",
            "Train step - Step 1150, Loss 0.0921730026602745\n",
            "Train epoch - Accuracy: 0.5722943722943723 Loss: 0.0930195242639572 Corrects: 3966\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.09543260931968689\n",
            "Train step - Step 1170, Loss 0.09060879796743393\n",
            "Train step - Step 1180, Loss 0.09036187082529068\n",
            "Train step - Step 1190, Loss 0.09306245297193527\n",
            "Train step - Step 1200, Loss 0.09171420335769653\n",
            "Train epoch - Accuracy: 0.580952380952381 Loss: 0.09268032297986582 Corrects: 4026\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.08893030881881714\n",
            "Train step - Step 1220, Loss 0.0900377407670021\n",
            "Train step - Step 1230, Loss 0.08989875018596649\n",
            "Train step - Step 1240, Loss 0.09444309771060944\n",
            "Train step - Step 1250, Loss 0.09327789396047592\n",
            "Train step - Step 1260, Loss 0.09716934710741043\n",
            "Train epoch - Accuracy: 0.577922077922078 Loss: 0.092708786511404 Corrects: 4005\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.09237153083086014\n",
            "Train step - Step 1280, Loss 0.09156419336795807\n",
            "Train step - Step 1290, Loss 0.09341729432344437\n",
            "Train step - Step 1300, Loss 0.09339646995067596\n",
            "Train step - Step 1310, Loss 0.09251316636800766\n",
            "Train epoch - Accuracy: 0.578932178932179 Loss: 0.09252518569623237 Corrects: 4012\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.08901673555374146\n",
            "Train step - Step 1330, Loss 0.08875829726457596\n",
            "Train step - Step 1340, Loss 0.09046868979930878\n",
            "Train step - Step 1350, Loss 0.08718384057283401\n",
            "Train step - Step 1360, Loss 0.0908629298210144\n",
            "Train step - Step 1370, Loss 0.09348349273204803\n",
            "Train epoch - Accuracy: 0.5965367965367966 Loss: 0.09235004092664774 Corrects: 4134\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.09110207110643387\n",
            "Train step - Step 1390, Loss 0.08984339982271194\n",
            "Train step - Step 1400, Loss 0.09170496463775635\n",
            "Train step - Step 1410, Loss 0.094670869410038\n",
            "Train step - Step 1420, Loss 0.09491665661334991\n",
            "Train epoch - Accuracy: 0.5965367965367966 Loss: 0.0925741694706343 Corrects: 4134\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.08975286781787872\n",
            "Train step - Step 1440, Loss 0.09378183633089066\n",
            "Train step - Step 1450, Loss 0.08915585279464722\n",
            "Train step - Step 1460, Loss 0.09621704369783401\n",
            "Train step - Step 1470, Loss 0.09252319484949112\n",
            "Train step - Step 1480, Loss 0.09038899093866348\n",
            "Train epoch - Accuracy: 0.592929292929293 Loss: 0.09223283636578578 Corrects: 4109\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.09316832572221756\n",
            "Train step - Step 1500, Loss 0.09140649437904358\n",
            "Train step - Step 1510, Loss 0.09380216896533966\n",
            "Train step - Step 1520, Loss 0.090377077460289\n",
            "Train step - Step 1530, Loss 0.09110433608293533\n",
            "Train epoch - Accuracy: 0.5988455988455988 Loss: 0.09223115274529436 Corrects: 4150\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09547539800405502\n",
            "Train step - Step 1550, Loss 0.08933202922344208\n",
            "Train step - Step 1560, Loss 0.09476801007986069\n",
            "Train step - Step 1570, Loss 0.09079644083976746\n",
            "Train step - Step 1580, Loss 0.09261820465326309\n",
            "Train step - Step 1590, Loss 0.09007133543491364\n",
            "Train epoch - Accuracy: 0.6070707070707071 Loss: 0.09219182177109464 Corrects: 4207\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.09540124982595444\n",
            "Train step - Step 1610, Loss 0.09563659876585007\n",
            "Train step - Step 1620, Loss 0.08677627146244049\n",
            "Train step - Step 1630, Loss 0.09260134398937225\n",
            "Train step - Step 1640, Loss 0.09490149468183517\n",
            "Train epoch - Accuracy: 0.6077922077922078 Loss: 0.0922914616774343 Corrects: 4212\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.09412772953510284\n",
            "Train step - Step 1660, Loss 0.08831410109996796\n",
            "Train step - Step 1670, Loss 0.09315679967403412\n",
            "Train step - Step 1680, Loss 0.09152461588382721\n",
            "Train step - Step 1690, Loss 0.09275640547275543\n",
            "Train step - Step 1700, Loss 0.09485238790512085\n",
            "Train epoch - Accuracy: 0.6070707070707071 Loss: 0.09213901232245336 Corrects: 4207\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.09778256714344025\n",
            "Train step - Step 1720, Loss 0.09239280223846436\n",
            "Train step - Step 1730, Loss 0.09007269889116287\n",
            "Train step - Step 1740, Loss 0.0902145653963089\n",
            "Train step - Step 1750, Loss 0.09144163131713867\n",
            "Train epoch - Accuracy: 0.6076479076479077 Loss: 0.09196116162240935 Corrects: 4211\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.09106405824422836\n",
            "Train step - Step 1770, Loss 0.095995232462883\n",
            "Train step - Step 1780, Loss 0.09401267021894455\n",
            "Train step - Step 1790, Loss 0.09052887558937073\n",
            "Train step - Step 1800, Loss 0.09389857202768326\n",
            "Train step - Step 1810, Loss 0.08654608577489853\n",
            "Train epoch - Accuracy: 0.6275613275613275 Loss: 0.09168401946452101 Corrects: 4349\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.09369306266307831\n",
            "Train step - Step 1830, Loss 0.09525586664676666\n",
            "Train step - Step 1840, Loss 0.09128690510988235\n",
            "Train step - Step 1850, Loss 0.09043004363775253\n",
            "Train step - Step 1860, Loss 0.08878330141305923\n",
            "Train epoch - Accuracy: 0.6122655122655123 Loss: 0.09176848937164653 Corrects: 4243\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.0925220474600792\n",
            "Train step - Step 1880, Loss 0.0915864035487175\n",
            "Train step - Step 1890, Loss 0.08858805894851685\n",
            "Train step - Step 1900, Loss 0.0920771062374115\n",
            "Train step - Step 1910, Loss 0.09486639499664307\n",
            "Train step - Step 1920, Loss 0.08717263489961624\n",
            "Train epoch - Accuracy: 0.6173160173160173 Loss: 0.091742128252037 Corrects: 4278\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.09650786221027374\n",
            "Train step - Step 1940, Loss 0.09455455094575882\n",
            "Train step - Step 1950, Loss 0.09428384155035019\n",
            "Train step - Step 1960, Loss 0.0887395516037941\n",
            "Train step - Step 1970, Loss 0.09441842883825302\n",
            "Train epoch - Accuracy: 0.627994227994228 Loss: 0.09198595735890869 Corrects: 4352\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.08833719044923782\n",
            "Train step - Step 1990, Loss 0.08964786678552628\n",
            "Train step - Step 2000, Loss 0.09165365993976593\n",
            "Train step - Step 2010, Loss 0.09435790032148361\n",
            "Train step - Step 2020, Loss 0.09044765681028366\n",
            "Train step - Step 2030, Loss 0.08891815692186356\n",
            "Train epoch - Accuracy: 0.6323232323232323 Loss: 0.09120323873658545 Corrects: 4382\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.09359878301620483\n",
            "Train step - Step 2050, Loss 0.0869961529970169\n",
            "Train step - Step 2060, Loss 0.0901060700416565\n",
            "Train step - Step 2070, Loss 0.09015766531229019\n",
            "Train step - Step 2080, Loss 0.08991144597530365\n",
            "Train epoch - Accuracy: 0.6341991341991342 Loss: 0.09139236498618711 Corrects: 4395\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.09366122633218765\n",
            "Train step - Step 2100, Loss 0.08743791282176971\n",
            "Train step - Step 2110, Loss 0.09441114217042923\n",
            "Train step - Step 2120, Loss 0.09232305735349655\n",
            "Train step - Step 2130, Loss 0.08767441660165787\n",
            "Train step - Step 2140, Loss 0.09197649359703064\n",
            "Train epoch - Accuracy: 0.6331890331890332 Loss: 0.09130200984502079 Corrects: 4388\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.09171966463327408\n",
            "Train step - Step 2160, Loss 0.09109463542699814\n",
            "Train step - Step 2170, Loss 0.0898628979921341\n",
            "Train step - Step 2180, Loss 0.09193278104066849\n",
            "Train step - Step 2190, Loss 0.08669951558113098\n",
            "Train epoch - Accuracy: 0.6327561327561327 Loss: 0.09114749227767383 Corrects: 4385\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09271638095378876\n",
            "Train step - Step 2210, Loss 0.09104938060045242\n",
            "Train step - Step 2220, Loss 0.084483303129673\n",
            "Train step - Step 2230, Loss 0.09173616021871567\n",
            "Train step - Step 2240, Loss 0.08853121101856232\n",
            "Train step - Step 2250, Loss 0.09123456478118896\n",
            "Train epoch - Accuracy: 0.6327561327561327 Loss: 0.09154388396684913 Corrects: 4385\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.0960894227027893\n",
            "Train step - Step 2270, Loss 0.0920179933309555\n",
            "Train step - Step 2280, Loss 0.09135279059410095\n",
            "Train step - Step 2290, Loss 0.09161137044429779\n",
            "Train step - Step 2300, Loss 0.09391871839761734\n",
            "Train epoch - Accuracy: 0.63997113997114 Loss: 0.09113632993823693 Corrects: 4435\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.09040907770395279\n",
            "Train step - Step 2320, Loss 0.09362556040287018\n",
            "Train step - Step 2330, Loss 0.09363105148077011\n",
            "Train step - Step 2340, Loss 0.09257686883211136\n",
            "Train step - Step 2350, Loss 0.089112788438797\n",
            "Train step - Step 2360, Loss 0.08732553571462631\n",
            "Train epoch - Accuracy: 0.6346320346320347 Loss: 0.09123730385974373 Corrects: 4398\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.08678439259529114\n",
            "Train step - Step 2380, Loss 0.09554070234298706\n",
            "Train step - Step 2390, Loss 0.09362044930458069\n",
            "Train step - Step 2400, Loss 0.09136535227298737\n",
            "Train step - Step 2410, Loss 0.09526778757572174\n",
            "Train epoch - Accuracy: 0.6467532467532467 Loss: 0.09106620411680202 Corrects: 4482\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.09133601933717728\n",
            "Train step - Step 2430, Loss 0.08870679885149002\n",
            "Train step - Step 2440, Loss 0.08717011660337448\n",
            "Train step - Step 2450, Loss 0.09145701676607132\n",
            "Train step - Step 2460, Loss 0.08805472403764725\n",
            "Train step - Step 2470, Loss 0.0901135578751564\n",
            "Train epoch - Accuracy: 0.6496392496392497 Loss: 0.09081799695201079 Corrects: 4502\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.09034863114356995\n",
            "Train step - Step 2490, Loss 0.09042955189943314\n",
            "Train step - Step 2500, Loss 0.08588405698537827\n",
            "Train step - Step 2510, Loss 0.09104902297258377\n",
            "Train step - Step 2520, Loss 0.09451604634523392\n",
            "Train epoch - Accuracy: 0.6525252525252525 Loss: 0.09079013838826491 Corrects: 4522\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.08852171152830124\n",
            "Train step - Step 2540, Loss 0.08962300419807434\n",
            "Train step - Step 2550, Loss 0.0855366438627243\n",
            "Train step - Step 2560, Loss 0.09153097867965698\n",
            "Train step - Step 2570, Loss 0.09031963348388672\n",
            "Train step - Step 2580, Loss 0.0891755223274231\n",
            "Train epoch - Accuracy: 0.6523809523809524 Loss: 0.09070643520286417 Corrects: 4521\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.09090057760477066\n",
            "Train step - Step 2600, Loss 0.09010934829711914\n",
            "Train step - Step 2610, Loss 0.09286630153656006\n",
            "Train step - Step 2620, Loss 0.09031423181295395\n",
            "Train step - Step 2630, Loss 0.09279437363147736\n",
            "Train epoch - Accuracy: 0.6546897546897547 Loss: 0.09088164124352935 Corrects: 4537\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.08964187651872635\n",
            "Train step - Step 2650, Loss 0.08703417330980301\n",
            "Train step - Step 2660, Loss 0.09335345029830933\n",
            "Train step - Step 2670, Loss 0.08875631541013718\n",
            "Train step - Step 2680, Loss 0.09550254046916962\n",
            "Train step - Step 2690, Loss 0.09452563524246216\n",
            "Train epoch - Accuracy: 0.6522366522366523 Loss: 0.09065086092439736 Corrects: 4520\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.08853287994861603\n",
            "Train step - Step 2710, Loss 0.0938190296292305\n",
            "Train step - Step 2720, Loss 0.09016012400388718\n",
            "Train step - Step 2730, Loss 0.09315425157546997\n",
            "Train step - Step 2740, Loss 0.08986856043338776\n",
            "Train epoch - Accuracy: 0.6663780663780664 Loss: 0.0901827126676902 Corrects: 4618\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.09040103852748871\n",
            "Train step - Step 2760, Loss 0.08888586610555649\n",
            "Train step - Step 2770, Loss 0.09597811847925186\n",
            "Train step - Step 2780, Loss 0.09411762654781342\n",
            "Train step - Step 2790, Loss 0.08985001593828201\n",
            "Train step - Step 2800, Loss 0.09293615072965622\n",
            "Train epoch - Accuracy: 0.6649350649350649 Loss: 0.09000288412770496 Corrects: 4608\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.0906086266040802\n",
            "Train step - Step 2820, Loss 0.08803316205739975\n",
            "Train step - Step 2830, Loss 0.09266669303178787\n",
            "Train step - Step 2840, Loss 0.08792770653963089\n",
            "Train step - Step 2850, Loss 0.08809129893779755\n",
            "Train epoch - Accuracy: 0.6678210678210679 Loss: 0.09005463347161487 Corrects: 4628\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.0893852636218071\n",
            "Train step - Step 2870, Loss 0.08980898559093475\n",
            "Train step - Step 2880, Loss 0.0892607718706131\n",
            "Train step - Step 2890, Loss 0.09290014207363129\n",
            "Train step - Step 2900, Loss 0.09199726581573486\n",
            "Train step - Step 2910, Loss 0.0910102054476738\n",
            "Train epoch - Accuracy: 0.6617604617604618 Loss: 0.0899054564438857 Corrects: 4586\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.09337305277585983\n",
            "Train step - Step 2930, Loss 0.08609239757061005\n",
            "Train step - Step 2940, Loss 0.0918145626783371\n",
            "Train step - Step 2950, Loss 0.08832021802663803\n",
            "Train step - Step 2960, Loss 0.09155113995075226\n",
            "Train epoch - Accuracy: 0.6606060606060606 Loss: 0.09020944151914481 Corrects: 4578\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09166397154331207\n",
            "Train step - Step 2980, Loss 0.0900692567229271\n",
            "Train step - Step 2990, Loss 0.09551555663347244\n",
            "Train step - Step 3000, Loss 0.08694089949131012\n",
            "Train step - Step 3010, Loss 0.09085777401924133\n",
            "Train step - Step 3020, Loss 0.09193301200866699\n",
            "Train epoch - Accuracy: 0.6676767676767676 Loss: 0.08991591263815094 Corrects: 4627\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.09410066157579422\n",
            "Train step - Step 3040, Loss 0.08992022275924683\n",
            "Train step - Step 3050, Loss 0.08922892063856125\n",
            "Train step - Step 3060, Loss 0.09129775315523148\n",
            "Train step - Step 3070, Loss 0.09231378138065338\n",
            "Train epoch - Accuracy: 0.6643578643578644 Loss: 0.08986416639918716 Corrects: 4604\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.09313207119703293\n",
            "Train step - Step 3090, Loss 0.09030251204967499\n",
            "Train step - Step 3100, Loss 0.08742376416921616\n",
            "Train step - Step 3110, Loss 0.09145908057689667\n",
            "Train step - Step 3120, Loss 0.09367465227842331\n",
            "Train step - Step 3130, Loss 0.0902230441570282\n",
            "Train epoch - Accuracy: 0.6616161616161617 Loss: 0.08996621938193859 Corrects: 4585\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.08967951685190201\n",
            "Train step - Step 3150, Loss 0.09117648005485535\n",
            "Train step - Step 3160, Loss 0.08995434641838074\n",
            "Train step - Step 3170, Loss 0.09025384485721588\n",
            "Train step - Step 3180, Loss 0.0916251540184021\n",
            "Train epoch - Accuracy: 0.6636363636363637 Loss: 0.08985520562353244 Corrects: 4599\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09176044166088104\n",
            "Train step - Step 3200, Loss 0.08487745374441147\n",
            "Train step - Step 3210, Loss 0.0906929150223732\n",
            "Train step - Step 3220, Loss 0.09607219696044922\n",
            "Train step - Step 3230, Loss 0.08713848888874054\n",
            "Train step - Step 3240, Loss 0.09150630235671997\n",
            "Train epoch - Accuracy: 0.6685425685425685 Loss: 0.09001390297949573 Corrects: 4633\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.0866662859916687\n",
            "Train step - Step 3260, Loss 0.08715452253818512\n",
            "Train step - Step 3270, Loss 0.08876781910657883\n",
            "Train step - Step 3280, Loss 0.09332261979579926\n",
            "Train step - Step 3290, Loss 0.08751757442951202\n",
            "Train epoch - Accuracy: 0.6617604617604618 Loss: 0.09002613480515982 Corrects: 4586\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.08900132775306702\n",
            "Train step - Step 3310, Loss 0.09117435663938522\n",
            "Train step - Step 3320, Loss 0.08754123002290726\n",
            "Train step - Step 3330, Loss 0.0910492092370987\n",
            "Train step - Step 3340, Loss 0.09243156015872955\n",
            "Train step - Step 3350, Loss 0.08462509512901306\n",
            "Train epoch - Accuracy: 0.6645021645021645 Loss: 0.0898785587427076 Corrects: 4605\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.09279618412256241\n",
            "Train step - Step 3370, Loss 0.09103182703256607\n",
            "Train step - Step 3380, Loss 0.08944923430681229\n",
            "Train step - Step 3390, Loss 0.08873159438371658\n",
            "Train step - Step 3400, Loss 0.08892364799976349\n",
            "Train epoch - Accuracy: 0.6652236652236653 Loss: 0.08992000530765515 Corrects: 4610\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.08895432204008102\n",
            "Train step - Step 3420, Loss 0.09628245234489441\n",
            "Train step - Step 3430, Loss 0.09325236082077026\n",
            "Train step - Step 3440, Loss 0.09790047258138657\n",
            "Train step - Step 3450, Loss 0.08854864537715912\n",
            "Train step - Step 3460, Loss 0.08589434623718262\n",
            "Train epoch - Accuracy: 0.6666666666666666 Loss: 0.08961332276528015 Corrects: 4620\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.08740982413291931\n",
            "Train step - Step 3480, Loss 0.09146972000598907\n",
            "Train step - Step 3490, Loss 0.08568663895130157\n",
            "Train step - Step 3500, Loss 0.09608694911003113\n",
            "Train step - Step 3510, Loss 0.09144475311040878\n",
            "Train epoch - Accuracy: 0.6747474747474748 Loss: 0.08970881148764237 Corrects: 4676\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.0892508402466774\n",
            "Train step - Step 3530, Loss 0.09214629977941513\n",
            "Train step - Step 3540, Loss 0.08694403618574142\n",
            "Train step - Step 3550, Loss 0.08993265777826309\n",
            "Train step - Step 3560, Loss 0.09115811437368393\n",
            "Train step - Step 3570, Loss 0.09185383468866348\n",
            "Train epoch - Accuracy: 0.668975468975469 Loss: 0.08971987217449695 Corrects: 4636\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.08826811611652374\n",
            "Train step - Step 3590, Loss 0.08668764680624008\n",
            "Train step - Step 3600, Loss 0.0951109305024147\n",
            "Train step - Step 3610, Loss 0.089548259973526\n",
            "Train step - Step 3620, Loss 0.09136075526475906\n",
            "Train epoch - Accuracy: 0.6711399711399711 Loss: 0.08964151665890888 Corrects: 4651\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.0902092456817627\n",
            "Train step - Step 3640, Loss 0.08631578087806702\n",
            "Train step - Step 3650, Loss 0.08680541813373566\n",
            "Train step - Step 3660, Loss 0.08966346085071564\n",
            "Train step - Step 3670, Loss 0.08895386010408401\n",
            "Train step - Step 3680, Loss 0.0862693265080452\n",
            "Train epoch - Accuracy: 0.6734487734487734 Loss: 0.08974470607775115 Corrects: 4667\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.09214439243078232\n",
            "Train step - Step 3700, Loss 0.08815889060497284\n",
            "Train step - Step 3710, Loss 0.0890786200761795\n",
            "Train step - Step 3720, Loss 0.08815164864063263\n",
            "Train step - Step 3730, Loss 0.09058108925819397\n",
            "Train epoch - Accuracy: 0.672005772005772 Loss: 0.08962447665857547 Corrects: 4657\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.09597942233085632\n",
            "Train step - Step 3750, Loss 0.0901431068778038\n",
            "Train step - Step 3760, Loss 0.08927261084318161\n",
            "Train step - Step 3770, Loss 0.0921730175614357\n",
            "Train step - Step 3780, Loss 0.09179286658763885\n",
            "Train step - Step 3790, Loss 0.08862975239753723\n",
            "Train epoch - Accuracy: 0.6743145743145743 Loss: 0.08965046115294852 Corrects: 4673\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.09207706153392792\n",
            "Train step - Step 3810, Loss 0.09011490643024445\n",
            "Train step - Step 3820, Loss 0.0941111296415329\n",
            "Train step - Step 3830, Loss 0.09060460329055786\n",
            "Train step - Step 3840, Loss 0.08884210884571075\n",
            "Train epoch - Accuracy: 0.674025974025974 Loss: 0.08965544071247396 Corrects: 4671\n",
            "Training finished in 454.5032968521118 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee20d290>\n",
            "Constructing exemplars of class 35\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [1870, 13691, 12537, 40629, 8838, 17005, 7124, 24005, 24706, 21140, 36050, 3456, 24220, 1303, 18022, 39900, 47964, 27629, 9299, 11912, 24005, 38644, 36741, 4099, 16036, 34967, 18634, 142]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee4370d0>\n",
            "Constructing exemplars of class 27\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [7425, 15228, 6539, 30848, 28338, 25329, 48999, 39260, 718, 46338, 10626, 29200, 15494, 11177, 5194, 7473, 10719, 1388, 22112, 39325, 9832, 662, 43902, 44954, 6861, 35319, 18038, 19642]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a5a5a50>\n",
            "Constructing exemplars of class 86\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [6002, 32856, 24935, 12375, 47890, 47494, 22594, 42707, 24004, 40492, 10660, 10354, 34543, 41507, 30757, 31683, 28302, 48302, 44794, 37391, 34234, 46670, 9985, 38753, 43723, 45299, 30586, 13493]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a24e750>\n",
            "Constructing exemplars of class 70\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [39649, 2508, 27591, 44126, 40444, 6823, 10989, 17699, 34013, 32728, 35129, 28866, 40420, 32622, 34427, 31267, 43433, 16232, 42253, 2722, 37331, 15724, 48658, 41538, 33235, 5900, 37414, 16556]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee490cd0>\n",
            "Constructing exemplars of class 50\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [49242, 39816, 22675, 47500, 44534, 40724, 18182, 45107, 12381, 4440, 5260, 16229, 31361, 43261, 6379, 38256, 1047, 20080, 43094, 30354, 43799, 43472, 28336, 33345, 21504, 38839, 10533, 31166]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee5915d0>\n",
            "Constructing exemplars of class 69\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [43024, 23250, 42920, 22747, 19182, 46042, 19250, 14775, 7654, 4418, 26511, 18238, 34343, 13875, 13927, 39788, 33826, 31481, 16686, 4612, 26576, 7662, 32283, 39450, 3628, 41400, 25360, 3907]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee567610>\n",
            "Constructing exemplars of class 53\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [26054, 3732, 1427, 24891, 44656, 47602, 37417, 8196, 18804, 47682, 46679, 28080, 5933, 29528, 25518, 45085, 7157, 36546, 37443, 11377, 40073, 20464, 69, 41825, 27141, 19970, 12652, 33444]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee5915d0>\n",
            "Constructing exemplars of class 17\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [12140, 11961, 38513, 9173, 27131, 20136, 43848, 23145, 6935, 49809, 18619, 19784, 46626, 36800, 33955, 28741, 5834, 29296, 7213, 26373, 30668, 48287, 33441, 20976, 31490, 39312, 45288, 31305]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a05ae90>\n",
            "Constructing exemplars of class 84\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [22622, 13566, 16849, 11336, 32623, 3922, 35213, 34727, 20439, 32222, 28852, 21156, 12311, 12589, 12904, 16837, 36534, 37813, 5814, 48540, 42386, 37019, 9766, 49449, 42689, 31447, 1883, 28162]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a574250>\n",
            "Constructing exemplars of class 52\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [30612, 4723, 28005, 11503, 32577, 13662, 45386, 11413, 38872, 25762, 32591, 44637, 47338, 41003, 12733, 35712, 24473, 44732, 27974, 41763, 6346, 17282, 45117, 11413, 23954, 3770, 45789, 26892]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.09744459390640259\n",
            "Train step - Step 0, Loss 0.08587566763162613\n",
            "Train step - Step 0, Loss 0.08771403878927231\n",
            "Train step - Step 0, Loss 0.08028331398963928\n",
            "Train step - Step 0, Loss 0.08024359494447708\n",
            "Train step - Step 0, Loss 0.07567302137613297\n",
            "Train step - Step 0, Loss 0.08313189446926117\n",
            "Train step - Step 0, Loss 0.08061772584915161\n",
            "Train step - Step 0, Loss 0.08460330218076706\n",
            "Train step - Step 0, Loss 0.08793668448925018\n",
            "Train step - Step 0, Loss 0.08253484964370728\n",
            "Train step - Step 0, Loss 0.07721991091966629\n",
            "Train step - Step 0, Loss 0.08749424666166306\n",
            "Train step - Step 0, Loss 0.08194056898355484\n",
            "Train step - Step 0, Loss 0.07562320679426193\n",
            "Train step - Step 0, Loss 0.07057850807905197\n",
            "Train epoch - Accuracy: 0.3324829931972789 Loss: 0.08296440192023102 Corrects: 3910\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.07956230640411377\n",
            "Train step - Step 0, Loss 0.07971647381782532\n",
            "Train step - Step 0, Loss 0.08358413726091385\n",
            "Train step - Step 0, Loss 0.0808340460062027\n",
            "Train step - Step 0, Loss 0.0767742395401001\n",
            "Train step - Step 0, Loss 0.07853791117668152\n",
            "Train step - Step 0, Loss 0.08372407406568527\n",
            "Train step - Step 0, Loss 0.0820964127779007\n",
            "Train step - Step 0, Loss 0.07992030680179596\n",
            "Train step - Step 0, Loss 0.07935887575149536\n",
            "Train step - Step 0, Loss 0.0775861069560051\n",
            "Train step - Step 0, Loss 0.07461214065551758\n",
            "Train step - Step 0, Loss 0.07800215482711792\n",
            "Train step - Step 0, Loss 0.07466568797826767\n",
            "Train step - Step 0, Loss 0.08211014419794083\n",
            "Train step - Step 0, Loss 0.08416780084371567\n",
            "Train epoch - Accuracy: 0.3270408163265306 Loss: 0.07950285426816162 Corrects: 3846\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.08073781430721283\n",
            "Train step - Step 0, Loss 0.08061831444501877\n",
            "Train step - Step 0, Loss 0.0810321494936943\n",
            "Train step - Step 0, Loss 0.07974277436733246\n",
            "Train step - Step 0, Loss 0.07638633996248245\n",
            "Train step - Step 0, Loss 0.07707434147596359\n",
            "Train step - Step 0, Loss 0.0775114893913269\n",
            "Train step - Step 0, Loss 0.08199302107095718\n",
            "Train step - Step 0, Loss 0.08245861530303955\n",
            "Train step - Step 0, Loss 0.081418976187706\n",
            "Train step - Step 0, Loss 0.08315400779247284\n",
            "Train step - Step 0, Loss 0.07626605778932571\n",
            "Train step - Step 0, Loss 0.07997801899909973\n",
            "Train step - Step 0, Loss 0.07445935904979706\n",
            "Train step - Step 0, Loss 0.0768662616610527\n",
            "Train step - Step 0, Loss 0.08610676229000092\n",
            "Train epoch - Accuracy: 0.32576530612244897 Loss: 0.07945181417221926 Corrects: 3831\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.08409228175878525\n",
            "Train step - Step 0, Loss 0.06970923393964767\n",
            "Train step - Step 0, Loss 0.07768352329730988\n",
            "Train step - Step 0, Loss 0.07808006554841995\n",
            "Train step - Step 0, Loss 0.07492886483669281\n",
            "Train step - Step 0, Loss 0.08223889768123627\n",
            "Train step - Step 0, Loss 0.07856860756874084\n",
            "Train step - Step 0, Loss 0.08013554662466049\n",
            "Train step - Step 0, Loss 0.07871110737323761\n",
            "Train step - Step 0, Loss 0.07575523108243942\n",
            "Train step - Step 0, Loss 0.07587631791830063\n",
            "Train step - Step 0, Loss 0.07798648625612259\n",
            "Train step - Step 0, Loss 0.0793447270989418\n",
            "Train step - Step 0, Loss 0.08194702118635178\n",
            "Train step - Step 0, Loss 0.0826849564909935\n",
            "Train step - Step 0, Loss 0.07540372014045715\n",
            "Train epoch - Accuracy: 0.3246598639455782 Loss: 0.07845267142568316 Corrects: 3818\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.0760824903845787\n",
            "Train step - Step 0, Loss 0.08149181306362152\n",
            "Train step - Step 0, Loss 0.07756170630455017\n",
            "Train step - Step 0, Loss 0.07753568887710571\n",
            "Train step - Step 0, Loss 0.07932838797569275\n",
            "Train step - Step 0, Loss 0.07813101261854172\n",
            "Train step - Step 0, Loss 0.07542312890291214\n",
            "Train step - Step 0, Loss 0.07521069049835205\n",
            "Train step - Step 0, Loss 0.08068081736564636\n",
            "Train step - Step 0, Loss 0.0785353034734726\n",
            "Train step - Step 0, Loss 0.07841136306524277\n",
            "Train step - Step 0, Loss 0.0825091153383255\n",
            "Train step - Step 0, Loss 0.07690118253231049\n",
            "Train step - Step 0, Loss 0.07609160244464874\n",
            "Train step - Step 0, Loss 0.08740614354610443\n",
            "Train step - Step 0, Loss 0.0778111070394516\n",
            "Train epoch - Accuracy: 0.3261904761904762 Loss: 0.07873413337736714 Corrects: 3836\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.08179057389497757\n",
            "Train step - Step 0, Loss 0.07843434065580368\n",
            "Train step - Step 0, Loss 0.07977582514286041\n",
            "Train step - Step 0, Loss 0.07449225336313248\n",
            "Train step - Step 0, Loss 0.07877461612224579\n",
            "Train step - Step 0, Loss 0.07853364199399948\n",
            "Train step - Step 0, Loss 0.07409072667360306\n",
            "Train step - Step 0, Loss 0.07653453201055527\n",
            "Train step - Step 0, Loss 0.07985153794288635\n",
            "Train step - Step 0, Loss 0.07497673481702805\n",
            "Train step - Step 0, Loss 0.07944799214601517\n",
            "Train step - Step 0, Loss 0.08043381571769714\n",
            "Train step - Step 0, Loss 0.0757911279797554\n",
            "Train step - Step 0, Loss 0.08110372722148895\n",
            "Train step - Step 0, Loss 0.07849173992872238\n",
            "Train step - Step 0, Loss 0.07508348673582077\n",
            "Train epoch - Accuracy: 0.3268707482993197 Loss: 0.07810525878959773 Corrects: 3844\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.07601068913936615\n",
            "Train step - Step 0, Loss 0.08275578916072845\n",
            "Train step - Step 0, Loss 0.0785662904381752\n",
            "Train step - Step 0, Loss 0.08026833832263947\n",
            "Train step - Step 0, Loss 0.07302659749984741\n",
            "Train step - Step 0, Loss 0.07219421863555908\n",
            "Train step - Step 0, Loss 0.0805007815361023\n",
            "Train step - Step 0, Loss 0.08168425410985947\n",
            "Train step - Step 0, Loss 0.07769915461540222\n",
            "Train step - Step 0, Loss 0.07632382959127426\n",
            "Train step - Step 0, Loss 0.07725303620100021\n",
            "Train step - Step 0, Loss 0.07757394015789032\n",
            "Train step - Step 0, Loss 0.08065793663263321\n",
            "Train step - Step 0, Loss 0.07716263085603714\n",
            "Train step - Step 0, Loss 0.07626581192016602\n",
            "Train step - Step 0, Loss 0.08007398247718811\n",
            "Train epoch - Accuracy: 0.3237244897959184 Loss: 0.07790801099368504 Corrects: 3807\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.07501138001680374\n",
            "Train step - Step 0, Loss 0.08043202012777328\n",
            "Train step - Step 0, Loss 0.08087749779224396\n",
            "Train step - Step 0, Loss 0.07422273606061935\n",
            "Train step - Step 0, Loss 0.08156304806470871\n",
            "Train step - Step 0, Loss 0.08143392950296402\n",
            "Train step - Step 0, Loss 0.07622884958982468\n",
            "Train step - Step 0, Loss 0.07798135280609131\n",
            "Train step - Step 0, Loss 0.08113591372966766\n",
            "Train step - Step 0, Loss 0.07914743572473526\n",
            "Train step - Step 0, Loss 0.07690847665071487\n",
            "Train step - Step 0, Loss 0.08112364262342453\n",
            "Train step - Step 0, Loss 0.07452414929866791\n",
            "Train step - Step 0, Loss 0.07348155230283737\n",
            "Train step - Step 0, Loss 0.07958152890205383\n",
            "Train step - Step 0, Loss 0.07050425559282303\n",
            "Train epoch - Accuracy: 0.32108843537414966 Loss: 0.07808562240430288 Corrects: 3776\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.0845286101102829\n",
            "Train step - Step 0, Loss 0.0795576274394989\n",
            "Train step - Step 0, Loss 0.07702217251062393\n",
            "Train step - Step 0, Loss 0.07278256118297577\n",
            "Train step - Step 0, Loss 0.07880492508411407\n",
            "Train step - Step 0, Loss 0.07390786707401276\n",
            "Train step - Step 0, Loss 0.07987963408231735\n",
            "Train step - Step 0, Loss 0.07539242506027222\n",
            "Train step - Step 0, Loss 0.07311557978391647\n",
            "Train step - Step 0, Loss 0.07863634824752808\n",
            "Train step - Step 0, Loss 0.07435304671525955\n",
            "Train step - Step 0, Loss 0.07855646312236786\n",
            "Train step - Step 0, Loss 0.08038566261529922\n",
            "Train step - Step 0, Loss 0.07992295920848846\n",
            "Train step - Step 0, Loss 0.07747926563024521\n",
            "Train step - Step 0, Loss 0.07966943830251694\n",
            "Train epoch - Accuracy: 0.3215136054421769 Loss: 0.07766346758117482 Corrects: 3781\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.08059074729681015\n",
            "Train step - Step 0, Loss 0.07709819823503494\n",
            "Train step - Step 0, Loss 0.07944345474243164\n",
            "Train step - Step 0, Loss 0.07847460359334946\n",
            "Train step - Step 0, Loss 0.07826419174671173\n",
            "Train step - Step 0, Loss 0.08038324862718582\n",
            "Train step - Step 0, Loss 0.07897341996431351\n",
            "Train step - Step 0, Loss 0.07113618403673172\n",
            "Train step - Step 0, Loss 0.07356448471546173\n",
            "Train step - Step 0, Loss 0.07860928773880005\n",
            "Train step - Step 0, Loss 0.07620643079280853\n",
            "Train step - Step 0, Loss 0.07710243761539459\n",
            "Train step - Step 0, Loss 0.07859726995229721\n",
            "Train step - Step 0, Loss 0.07563012093305588\n",
            "Train step - Step 0, Loss 0.07271941006183624\n",
            "Train step - Step 0, Loss 0.07897292077541351\n",
            "Train epoch - Accuracy: 0.32610544217687076 Loss: 0.07715738957025567 Corrects: 3835\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.08193190395832062\n",
            "Train step - Step 0, Loss 0.0762745589017868\n",
            "Train step - Step 0, Loss 0.07504849135875702\n",
            "Train step - Step 0, Loss 0.07814767211675644\n",
            "Train step - Step 0, Loss 0.07509013265371323\n",
            "Train step - Step 0, Loss 0.08176752924919128\n",
            "Train step - Step 0, Loss 0.07865911722183228\n",
            "Train step - Step 0, Loss 0.07521391659975052\n",
            "Train step - Step 0, Loss 0.0744723528623581\n",
            "Train step - Step 0, Loss 0.08351242542266846\n",
            "Train step - Step 0, Loss 0.07582619786262512\n",
            "Train step - Step 0, Loss 0.07716517150402069\n",
            "Train step - Step 0, Loss 0.07594336569309235\n",
            "Train step - Step 0, Loss 0.07888451218605042\n",
            "Train step - Step 0, Loss 0.07764420658349991\n",
            "Train step - Step 0, Loss 0.08130735903978348\n",
            "Train epoch - Accuracy: 0.32551020408163267 Loss: 0.07777894555914158 Corrects: 3828\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.07595261186361313\n",
            "Train step - Step 0, Loss 0.0763736292719841\n",
            "Train step - Step 0, Loss 0.08308036625385284\n",
            "Train step - Step 0, Loss 0.07996610552072525\n",
            "Train step - Step 0, Loss 0.07574346661567688\n",
            "Train step - Step 0, Loss 0.07565043866634369\n",
            "Train step - Step 0, Loss 0.0729348286986351\n",
            "Train step - Step 0, Loss 0.07644043117761612\n",
            "Train step - Step 0, Loss 0.07769370824098587\n",
            "Train step - Step 0, Loss 0.076908640563488\n",
            "Train step - Step 0, Loss 0.07219433784484863\n",
            "Train step - Step 0, Loss 0.07396844774484634\n",
            "Train step - Step 0, Loss 0.07991651445627213\n",
            "Train step - Step 0, Loss 0.07394620031118393\n",
            "Train step - Step 0, Loss 0.07916620373725891\n",
            "Train step - Step 0, Loss 0.07651761174201965\n",
            "Train epoch - Accuracy: 0.32083333333333336 Loss: 0.0766594406293363 Corrects: 3773\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.0778263658285141\n",
            "Train step - Step 0, Loss 0.07617336511611938\n",
            "Train step - Step 0, Loss 0.08011214435100555\n",
            "Train step - Step 0, Loss 0.08336018770933151\n",
            "Train step - Step 0, Loss 0.0785781517624855\n",
            "Train step - Step 0, Loss 0.07294990867376328\n",
            "Train step - Step 0, Loss 0.07516755908727646\n",
            "Train step - Step 0, Loss 0.0835239440202713\n",
            "Train step - Step 0, Loss 0.0773652121424675\n",
            "Train step - Step 0, Loss 0.07752388715744019\n",
            "Train step - Step 0, Loss 0.07766465842723846\n",
            "Train step - Step 0, Loss 0.07569389045238495\n",
            "Train step - Step 0, Loss 0.07796180993318558\n",
            "Train step - Step 0, Loss 0.07383367419242859\n",
            "Train step - Step 0, Loss 0.072813481092453\n",
            "Train step - Step 0, Loss 0.07278179377317429\n",
            "Train epoch - Accuracy: 0.3162414965986395 Loss: 0.07727624819594986 Corrects: 3719\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.07566291838884354\n",
            "Train step - Step 0, Loss 0.07670895755290985\n",
            "Train step - Step 0, Loss 0.07681232690811157\n",
            "Train step - Step 0, Loss 0.0767611563205719\n",
            "Train step - Step 0, Loss 0.07943867892026901\n",
            "Train step - Step 0, Loss 0.0756835862994194\n",
            "Train step - Step 0, Loss 0.07247520983219147\n",
            "Train step - Step 0, Loss 0.07749315351247787\n",
            "Train step - Step 0, Loss 0.07686880230903625\n",
            "Train step - Step 0, Loss 0.07443810999393463\n",
            "Train step - Step 0, Loss 0.07980078458786011\n",
            "Train step - Step 0, Loss 0.07908525317907333\n",
            "Train step - Step 0, Loss 0.07861460745334625\n",
            "Train step - Step 0, Loss 0.0754811093211174\n",
            "Train step - Step 0, Loss 0.07516727596521378\n",
            "Train step - Step 0, Loss 0.08539845794439316\n",
            "Train epoch - Accuracy: 0.3233843537414966 Loss: 0.07687699256502852 Corrects: 3803\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.07353734225034714\n",
            "Train step - Step 0, Loss 0.0761326253414154\n",
            "Train step - Step 0, Loss 0.07833132147789001\n",
            "Train step - Step 0, Loss 0.07531992346048355\n",
            "Train step - Step 0, Loss 0.07618970423936844\n",
            "Train step - Step 0, Loss 0.08131236582994461\n",
            "Train step - Step 0, Loss 0.07732094079256058\n",
            "Train step - Step 0, Loss 0.0779673233628273\n",
            "Train step - Step 0, Loss 0.07991829514503479\n",
            "Train step - Step 0, Loss 0.07640544325113297\n",
            "Train step - Step 0, Loss 0.07619857788085938\n",
            "Train step - Step 0, Loss 0.07378560304641724\n",
            "Train step - Step 0, Loss 0.07704459875822067\n",
            "Train step - Step 0, Loss 0.08218909800052643\n",
            "Train step - Step 0, Loss 0.07530307024717331\n",
            "Train step - Step 0, Loss 0.07953011989593506\n",
            "Train epoch - Accuracy: 0.3233843537414966 Loss: 0.07717938909725267 Corrects: 3803\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.07750989496707916\n",
            "Train step - Step 0, Loss 0.07668840885162354\n",
            "Train step - Step 0, Loss 0.07411281019449234\n",
            "Train step - Step 0, Loss 0.0805368572473526\n",
            "Train step - Step 0, Loss 0.07956711947917938\n",
            "Train step - Step 0, Loss 0.07641595602035522\n",
            "Train step - Step 0, Loss 0.0758584514260292\n",
            "Train step - Step 0, Loss 0.07962296158075333\n",
            "Train step - Step 0, Loss 0.07658969610929489\n",
            "Train step - Step 0, Loss 0.07189462333917618\n",
            "Train step - Step 0, Loss 0.07372159510850906\n",
            "Train step - Step 0, Loss 0.07681558281183243\n",
            "Train step - Step 0, Loss 0.07672478258609772\n",
            "Train step - Step 0, Loss 0.07610391825437546\n",
            "Train step - Step 0, Loss 0.07345497608184814\n",
            "Train step - Step 0, Loss 0.07859551906585693\n",
            "Train epoch - Accuracy: 0.32474489795918365 Loss: 0.07641983567451945 Corrects: 3819\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.08198126405477524\n",
            "Train step - Step 0, Loss 0.08264476805925369\n",
            "Train step - Step 0, Loss 0.07456682622432709\n",
            "Train step - Step 0, Loss 0.07922760397195816\n",
            "Train step - Step 0, Loss 0.075530506670475\n",
            "Train step - Step 0, Loss 0.07745065540075302\n",
            "Train step - Step 0, Loss 0.07433293014764786\n",
            "Train step - Step 0, Loss 0.07570512592792511\n",
            "Train step - Step 0, Loss 0.07674912363290787\n",
            "Train step - Step 0, Loss 0.07382813096046448\n",
            "Train step - Step 0, Loss 0.08209007233381271\n",
            "Train step - Step 0, Loss 0.07843790203332901\n",
            "Train step - Step 0, Loss 0.07543489336967468\n",
            "Train step - Step 0, Loss 0.0758172869682312\n",
            "Train step - Step 0, Loss 0.07847415655851364\n",
            "Train step - Step 0, Loss 0.071314737200737\n",
            "Train epoch - Accuracy: 0.31819727891156463 Loss: 0.07735883113072843 Corrects: 3742\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.07341182976961136\n",
            "Train step - Step 0, Loss 0.0768275260925293\n",
            "Train step - Step 0, Loss 0.07503622025251389\n",
            "Train step - Step 0, Loss 0.0737159252166748\n",
            "Train step - Step 0, Loss 0.07676690071821213\n",
            "Train step - Step 0, Loss 0.07895717024803162\n",
            "Train step - Step 0, Loss 0.08035529404878616\n",
            "Train step - Step 0, Loss 0.07490644603967667\n",
            "Train step - Step 0, Loss 0.07912752032279968\n",
            "Train step - Step 0, Loss 0.07849252223968506\n",
            "Train step - Step 0, Loss 0.07765859365463257\n",
            "Train step - Step 0, Loss 0.07585098594427109\n",
            "Train step - Step 0, Loss 0.08047595620155334\n",
            "Train step - Step 0, Loss 0.07723122090101242\n",
            "Train step - Step 0, Loss 0.07610918581485748\n",
            "Train step - Step 0, Loss 0.0697208046913147\n",
            "Train epoch - Accuracy: 0.3193877551020408 Loss: 0.07684643584854749 Corrects: 3756\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.07624077051877975\n",
            "Train step - Step 0, Loss 0.0741444081068039\n",
            "Train step - Step 0, Loss 0.07461392134428024\n",
            "Train step - Step 0, Loss 0.07856383174657822\n",
            "Train step - Step 0, Loss 0.07650327682495117\n",
            "Train step - Step 0, Loss 0.07458528131246567\n",
            "Train step - Step 0, Loss 0.07191288471221924\n",
            "Train step - Step 0, Loss 0.07472441345453262\n",
            "Train step - Step 0, Loss 0.07796924561262131\n",
            "Train step - Step 0, Loss 0.07975465804338455\n",
            "Train step - Step 0, Loss 0.07560314983129501\n",
            "Train step - Step 0, Loss 0.07221195101737976\n",
            "Train step - Step 0, Loss 0.07542400062084198\n",
            "Train step - Step 0, Loss 0.07981187850236893\n",
            "Train step - Step 0, Loss 0.07808125019073486\n",
            "Train step - Step 0, Loss 0.08310418576002121\n",
            "Train epoch - Accuracy: 0.3201530612244898 Loss: 0.07615444766623633 Corrects: 3765\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.0773993730545044\n",
            "Train step - Step 0, Loss 0.07536734640598297\n",
            "Train step - Step 0, Loss 0.07362096011638641\n",
            "Train step - Step 0, Loss 0.074257493019104\n",
            "Train step - Step 0, Loss 0.08114003390073776\n",
            "Train step - Step 0, Loss 0.0757543072104454\n",
            "Train step - Step 0, Loss 0.07539021968841553\n",
            "Train step - Step 0, Loss 0.07556330412626266\n",
            "Train step - Step 0, Loss 0.07510177046060562\n",
            "Train step - Step 0, Loss 0.07297340035438538\n",
            "Train step - Step 0, Loss 0.08270592987537384\n",
            "Train step - Step 0, Loss 0.07786190509796143\n",
            "Train step - Step 0, Loss 0.0784439966082573\n",
            "Train step - Step 0, Loss 0.07629489153623581\n",
            "Train step - Step 0, Loss 0.0793967992067337\n",
            "Train step - Step 0, Loss 0.07692158222198486\n",
            "Train epoch - Accuracy: 0.32848639455782314 Loss: 0.07675492082323347 Corrects: 3863\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.08112239092588425\n",
            "Train step - Step 0, Loss 0.07927267253398895\n",
            "Train step - Step 0, Loss 0.07836496829986572\n",
            "Train step - Step 0, Loss 0.07649783790111542\n",
            "Train step - Step 0, Loss 0.07569790631532669\n",
            "Train step - Step 0, Loss 0.079610675573349\n",
            "Train step - Step 0, Loss 0.07422371953725815\n",
            "Train step - Step 0, Loss 0.07334952056407928\n",
            "Train step - Step 0, Loss 0.07569076865911484\n",
            "Train step - Step 0, Loss 0.08249632269144058\n",
            "Train step - Step 0, Loss 0.0753026157617569\n",
            "Train step - Step 0, Loss 0.0758293941617012\n",
            "Train step - Step 0, Loss 0.07365300506353378\n",
            "Train step - Step 0, Loss 0.08239865303039551\n",
            "Train step - Step 0, Loss 0.07383989542722702\n",
            "Train step - Step 0, Loss 0.07949203997850418\n",
            "Train epoch - Accuracy: 0.3289965986394558 Loss: 0.07720434997154742 Corrects: 3869\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.07465146481990814\n",
            "Train step - Step 0, Loss 0.07559527456760406\n",
            "Train step - Step 0, Loss 0.07788906991481781\n",
            "Train step - Step 0, Loss 0.07576794922351837\n",
            "Train step - Step 0, Loss 0.0738622173666954\n",
            "Train step - Step 0, Loss 0.07918205857276917\n",
            "Train step - Step 0, Loss 0.07280591875314713\n",
            "Train step - Step 0, Loss 0.08068420737981796\n",
            "Train step - Step 0, Loss 0.07860392332077026\n",
            "Train step - Step 0, Loss 0.07862503826618195\n",
            "Train step - Step 0, Loss 0.07902456074953079\n",
            "Train step - Step 0, Loss 0.07573629170656204\n",
            "Train step - Step 0, Loss 0.0783262699842453\n",
            "Train step - Step 0, Loss 0.07593924552202225\n",
            "Train step - Step 0, Loss 0.07358094304800034\n",
            "Train step - Step 0, Loss 0.07216858118772507\n",
            "Train epoch - Accuracy: 0.3237244897959184 Loss: 0.07659279117170645 Corrects: 3807\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.08086834847927094\n",
            "Train step - Step 0, Loss 0.07272648066282272\n",
            "Train step - Step 0, Loss 0.07737850397825241\n",
            "Train step - Step 0, Loss 0.0769490972161293\n",
            "Train step - Step 0, Loss 0.07183972746133804\n",
            "Train step - Step 0, Loss 0.07656931132078171\n",
            "Train step - Step 0, Loss 0.07475503534078598\n",
            "Train step - Step 0, Loss 0.08296045660972595\n",
            "Train step - Step 0, Loss 0.07781393826007843\n",
            "Train step - Step 0, Loss 0.08394688367843628\n",
            "Train step - Step 0, Loss 0.07245656847953796\n",
            "Train step - Step 0, Loss 0.07535488158464432\n",
            "Train step - Step 0, Loss 0.07574242353439331\n",
            "Train step - Step 0, Loss 0.08022214472293854\n",
            "Train step - Step 0, Loss 0.07101422548294067\n",
            "Train step - Step 0, Loss 0.07007819414138794\n",
            "Train epoch - Accuracy: 0.32261904761904764 Loss: 0.07657126285591905 Corrects: 3794\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.07964061200618744\n",
            "Train step - Step 0, Loss 0.07566067576408386\n",
            "Train step - Step 0, Loss 0.07745563238859177\n",
            "Train step - Step 0, Loss 0.07615946233272552\n",
            "Train step - Step 0, Loss 0.07158764451742172\n",
            "Train step - Step 0, Loss 0.07414386421442032\n",
            "Train step - Step 0, Loss 0.07305451482534409\n",
            "Train step - Step 0, Loss 0.07228410989046097\n",
            "Train step - Step 0, Loss 0.07686873525381088\n",
            "Train step - Step 0, Loss 0.07566233724355698\n",
            "Train step - Step 0, Loss 0.07593019306659698\n",
            "Train step - Step 0, Loss 0.07947355508804321\n",
            "Train step - Step 0, Loss 0.07481961697340012\n",
            "Train step - Step 0, Loss 0.07796075940132141\n",
            "Train step - Step 0, Loss 0.0858820453286171\n",
            "Train step - Step 0, Loss 0.07679478079080582\n",
            "Train epoch - Accuracy: 0.3210034013605442 Loss: 0.07644617974149938 Corrects: 3775\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.07839909195899963\n",
            "Train step - Step 0, Loss 0.08299458771944046\n",
            "Train step - Step 0, Loss 0.07113038003444672\n",
            "Train step - Step 0, Loss 0.07677142322063446\n",
            "Train step - Step 0, Loss 0.07295682281255722\n",
            "Train step - Step 0, Loss 0.07473311573266983\n",
            "Train step - Step 0, Loss 0.07855045795440674\n",
            "Train step - Step 0, Loss 0.07197152078151703\n",
            "Train step - Step 0, Loss 0.08082055300474167\n",
            "Train step - Step 0, Loss 0.07649180293083191\n",
            "Train step - Step 0, Loss 0.07867517322301865\n",
            "Train step - Step 0, Loss 0.07804914563894272\n",
            "Train step - Step 0, Loss 0.07248544692993164\n",
            "Train step - Step 0, Loss 0.07719980180263519\n",
            "Train step - Step 0, Loss 0.0719890147447586\n",
            "Train step - Step 0, Loss 0.08180897682905197\n",
            "Train epoch - Accuracy: 0.31785714285714284 Loss: 0.07632872775501134 Corrects: 3738\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.07671967893838882\n",
            "Train step - Step 0, Loss 0.07635126262903214\n",
            "Train step - Step 0, Loss 0.07775674015283585\n",
            "Train step - Step 0, Loss 0.07782059162855148\n",
            "Train step - Step 0, Loss 0.07607757300138474\n",
            "Train step - Step 0, Loss 0.07689455151557922\n",
            "Train step - Step 0, Loss 0.07438035309314728\n",
            "Train step - Step 0, Loss 0.07109121233224869\n",
            "Train step - Step 0, Loss 0.07440066337585449\n",
            "Train step - Step 0, Loss 0.07233396172523499\n",
            "Train step - Step 0, Loss 0.07688548415899277\n",
            "Train step - Step 0, Loss 0.08016600459814072\n",
            "Train step - Step 0, Loss 0.07145004719495773\n",
            "Train step - Step 0, Loss 0.07573246210813522\n",
            "Train step - Step 0, Loss 0.08297835290431976\n",
            "Train step - Step 0, Loss 0.07238443195819855\n",
            "Train epoch - Accuracy: 0.32193877551020406 Loss: 0.07599406199795859 Corrects: 3786\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.0741136372089386\n",
            "Train step - Step 0, Loss 0.07623425871133804\n",
            "Train step - Step 0, Loss 0.07181752473115921\n",
            "Train step - Step 0, Loss 0.07834243774414062\n",
            "Train step - Step 0, Loss 0.07901401072740555\n",
            "Train step - Step 0, Loss 0.07117210328578949\n",
            "Train step - Step 0, Loss 0.07431107759475708\n",
            "Train step - Step 0, Loss 0.07584414631128311\n",
            "Train step - Step 0, Loss 0.0815911516547203\n",
            "Train step - Step 0, Loss 0.0763782411813736\n",
            "Train step - Step 0, Loss 0.07699176669120789\n",
            "Train step - Step 0, Loss 0.07580054551362991\n",
            "Train step - Step 0, Loss 0.08445892482995987\n",
            "Train step - Step 0, Loss 0.0740557312965393\n",
            "Train step - Step 0, Loss 0.08194936066865921\n",
            "Train step - Step 0, Loss 0.07170369476079941\n",
            "Train epoch - Accuracy: 0.33069727891156464 Loss: 0.076700886384565 Corrects: 3889\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.08106860518455505\n",
            "Train step - Step 0, Loss 0.07306666672229767\n",
            "Train step - Step 0, Loss 0.07176966220140457\n",
            "Train step - Step 0, Loss 0.07983741909265518\n",
            "Train step - Step 0, Loss 0.07484821230173111\n",
            "Train step - Step 0, Loss 0.07754851132631302\n",
            "Train step - Step 0, Loss 0.07744738459587097\n",
            "Train step - Step 0, Loss 0.0784212201833725\n",
            "Train step - Step 0, Loss 0.08064061403274536\n",
            "Train step - Step 0, Loss 0.07768704742193222\n",
            "Train step - Step 0, Loss 0.07954562455415726\n",
            "Train step - Step 0, Loss 0.07455296814441681\n",
            "Train step - Step 0, Loss 0.07250215858221054\n",
            "Train step - Step 0, Loss 0.07095365226268768\n",
            "Train step - Step 0, Loss 0.07365930825471878\n",
            "Train step - Step 0, Loss 0.07074840366840363\n",
            "Train epoch - Accuracy: 0.32482993197278914 Loss: 0.0761245995759964 Corrects: 3820\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.07483083009719849\n",
            "Train step - Step 0, Loss 0.07256684452295303\n",
            "Train step - Step 0, Loss 0.07141510397195816\n",
            "Train step - Step 0, Loss 0.07442782819271088\n",
            "Train step - Step 0, Loss 0.07765284925699234\n",
            "Train step - Step 0, Loss 0.07980130612850189\n",
            "Train step - Step 0, Loss 0.07462242245674133\n",
            "Train step - Step 0, Loss 0.07548948377370834\n",
            "Train step - Step 0, Loss 0.07750796526670456\n",
            "Train step - Step 0, Loss 0.07605261355638504\n",
            "Train step - Step 0, Loss 0.07771365344524384\n",
            "Train step - Step 0, Loss 0.07803694903850555\n",
            "Train step - Step 0, Loss 0.08114750683307648\n",
            "Train step - Step 0, Loss 0.07659118622541428\n",
            "Train step - Step 0, Loss 0.07878774404525757\n",
            "Train step - Step 0, Loss 0.08583953231573105\n",
            "Train epoch - Accuracy: 0.32389455782312926 Loss: 0.07663471939004197 Corrects: 3809\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.08171957731246948\n",
            "Train step - Step 0, Loss 0.07639812678098679\n",
            "Train step - Step 0, Loss 0.0716567263007164\n",
            "Train step - Step 0, Loss 0.07485422492027283\n",
            "Train step - Step 0, Loss 0.07869904488325119\n",
            "Train step - Step 0, Loss 0.07283216714859009\n",
            "Train step - Step 0, Loss 0.0805472806096077\n",
            "Train step - Step 0, Loss 0.0816822350025177\n",
            "Train step - Step 0, Loss 0.07306739687919617\n",
            "Train step - Step 0, Loss 0.07671798020601273\n",
            "Train step - Step 0, Loss 0.07473443448543549\n",
            "Train step - Step 0, Loss 0.07122303545475006\n",
            "Train step - Step 0, Loss 0.07646071165800095\n",
            "Train step - Step 0, Loss 0.07576218992471695\n",
            "Train step - Step 0, Loss 0.07274438440799713\n",
            "Train step - Step 0, Loss 0.07468566298484802\n",
            "Train epoch - Accuracy: 0.31760204081632654 Loss: 0.07591436967557791 Corrects: 3735\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.07729501277208328\n",
            "Train step - Step 0, Loss 0.07620072364807129\n",
            "Train step - Step 0, Loss 0.07551462203264236\n",
            "Train step - Step 0, Loss 0.07263588905334473\n",
            "Train step - Step 0, Loss 0.07411979883909225\n",
            "Train step - Step 0, Loss 0.07734876871109009\n",
            "Train step - Step 0, Loss 0.07134624570608139\n",
            "Train step - Step 0, Loss 0.07617136836051941\n",
            "Train step - Step 0, Loss 0.07584072649478912\n",
            "Train step - Step 0, Loss 0.07667271047830582\n",
            "Train step - Step 0, Loss 0.07446232438087463\n",
            "Train step - Step 0, Loss 0.07887064665555954\n",
            "Train step - Step 0, Loss 0.07271215319633484\n",
            "Train step - Step 0, Loss 0.07694786041975021\n",
            "Train step - Step 0, Loss 0.076097272336483\n",
            "Train step - Step 0, Loss 0.07377083599567413\n",
            "Train epoch - Accuracy: 0.3223639455782313 Loss: 0.07544747816056621 Corrects: 3791\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.08048457652330399\n",
            "Train step - Step 0, Loss 0.07589086145162582\n",
            "Train step - Step 0, Loss 0.0791904628276825\n",
            "Train step - Step 0, Loss 0.07902389019727707\n",
            "Train step - Step 0, Loss 0.07920704782009125\n",
            "Train step - Step 0, Loss 0.07410664856433868\n",
            "Train step - Step 0, Loss 0.08022091537714005\n",
            "Train step - Step 0, Loss 0.07637454569339752\n",
            "Train step - Step 0, Loss 0.07582639902830124\n",
            "Train step - Step 0, Loss 0.07773719727993011\n",
            "Train step - Step 0, Loss 0.07352210581302643\n",
            "Train step - Step 0, Loss 0.07664181292057037\n",
            "Train step - Step 0, Loss 0.07249826192855835\n",
            "Train step - Step 0, Loss 0.07400273531675339\n",
            "Train step - Step 0, Loss 0.07241380959749222\n",
            "Train step - Step 0, Loss 0.0726735070347786\n",
            "Train epoch - Accuracy: 0.3185374149659864 Loss: 0.0763984810636968 Corrects: 3746\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.07652425020933151\n",
            "Train step - Step 0, Loss 0.07551665604114532\n",
            "Train step - Step 0, Loss 0.08424504846334457\n",
            "Train step - Step 0, Loss 0.0785536840558052\n",
            "Train step - Step 0, Loss 0.07221430540084839\n",
            "Train step - Step 0, Loss 0.07570803165435791\n",
            "Train step - Step 0, Loss 0.07460201531648636\n",
            "Train step - Step 0, Loss 0.07809770107269287\n",
            "Train step - Step 0, Loss 0.07597380131483078\n",
            "Train step - Step 0, Loss 0.0797390565276146\n",
            "Train step - Step 0, Loss 0.07486847043037415\n",
            "Train step - Step 0, Loss 0.0775940865278244\n",
            "Train step - Step 0, Loss 0.07449644804000854\n",
            "Train step - Step 0, Loss 0.07594384998083115\n",
            "Train step - Step 0, Loss 0.07945585250854492\n",
            "Train step - Step 0, Loss 0.07698063552379608\n",
            "Train epoch - Accuracy: 0.32482993197278914 Loss: 0.07690381754417809 Corrects: 3820\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.07653617113828659\n",
            "Train step - Step 0, Loss 0.08043473213911057\n",
            "Train step - Step 0, Loss 0.07430241256952286\n",
            "Train step - Step 0, Loss 0.07482926547527313\n",
            "Train step - Step 0, Loss 0.08112486451864243\n",
            "Train step - Step 0, Loss 0.07466784864664078\n",
            "Train step - Step 0, Loss 0.0755012258887291\n",
            "Train step - Step 0, Loss 0.07596665620803833\n",
            "Train step - Step 0, Loss 0.07769940793514252\n",
            "Train step - Step 0, Loss 0.07598905265331268\n",
            "Train step - Step 0, Loss 0.07911774516105652\n",
            "Train step - Step 0, Loss 0.07372436672449112\n",
            "Train step - Step 0, Loss 0.07519517093896866\n",
            "Train step - Step 0, Loss 0.07766113430261612\n",
            "Train step - Step 0, Loss 0.07484754174947739\n",
            "Train step - Step 0, Loss 0.07464338839054108\n",
            "Train epoch - Accuracy: 0.32253401360544215 Loss: 0.0764684835867006 Corrects: 3793\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.07296159118413925\n",
            "Train step - Step 0, Loss 0.07477890700101852\n",
            "Train step - Step 0, Loss 0.07497943192720413\n",
            "Train step - Step 0, Loss 0.07630513608455658\n",
            "Train step - Step 0, Loss 0.07892433553934097\n",
            "Train step - Step 0, Loss 0.0782150849699974\n",
            "Train step - Step 0, Loss 0.08025778084993362\n",
            "Train step - Step 0, Loss 0.07524330914020538\n",
            "Train step - Step 0, Loss 0.07773900032043457\n",
            "Train step - Step 0, Loss 0.0788566991686821\n",
            "Train step - Step 0, Loss 0.07707212120294571\n",
            "Train step - Step 0, Loss 0.07655594497919083\n",
            "Train step - Step 0, Loss 0.07467757165431976\n",
            "Train step - Step 0, Loss 0.07763423025608063\n",
            "Train step - Step 0, Loss 0.07482090592384338\n",
            "Train step - Step 0, Loss 0.07596606761217117\n",
            "Train epoch - Accuracy: 0.32602040816326533 Loss: 0.07658850261751486 Corrects: 3834\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.07461276650428772\n",
            "Train step - Step 0, Loss 0.07102791965007782\n",
            "Train step - Step 0, Loss 0.07998570054769516\n",
            "Train step - Step 0, Loss 0.07389403879642487\n",
            "Train step - Step 0, Loss 0.0781673714518547\n",
            "Train step - Step 0, Loss 0.07904943078756332\n",
            "Train step - Step 0, Loss 0.07495494186878204\n",
            "Train step - Step 0, Loss 0.07393322139978409\n",
            "Train step - Step 0, Loss 0.07495275139808655\n",
            "Train step - Step 0, Loss 0.07527125626802444\n",
            "Train step - Step 0, Loss 0.07274612039327621\n",
            "Train step - Step 0, Loss 0.07891333848237991\n",
            "Train step - Step 0, Loss 0.07778096944093704\n",
            "Train step - Step 0, Loss 0.07917368412017822\n",
            "Train step - Step 0, Loss 0.07827389985322952\n",
            "Train step - Step 0, Loss 0.07252508401870728\n",
            "Train epoch - Accuracy: 0.31947278911564625 Loss: 0.0761078530428361 Corrects: 3757\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.07760051637887955\n",
            "Train step - Step 0, Loss 0.07460302859544754\n",
            "Train step - Step 0, Loss 0.07438904047012329\n",
            "Train step - Step 0, Loss 0.0790761187672615\n",
            "Train step - Step 0, Loss 0.07213529199361801\n",
            "Train step - Step 0, Loss 0.07771514356136322\n",
            "Train step - Step 0, Loss 0.07737953215837479\n",
            "Train step - Step 0, Loss 0.07707668840885162\n",
            "Train step - Step 0, Loss 0.07479727268218994\n",
            "Train step - Step 0, Loss 0.07437204569578171\n",
            "Train step - Step 0, Loss 0.08002831041812897\n",
            "Train step - Step 0, Loss 0.07522885501384735\n",
            "Train step - Step 0, Loss 0.08157823234796524\n",
            "Train step - Step 0, Loss 0.07197913527488708\n",
            "Train step - Step 0, Loss 0.07867895066738129\n",
            "Train step - Step 0, Loss 0.07972227036952972\n",
            "Train epoch - Accuracy: 0.3302721088435374 Loss: 0.0765094773501766 Corrects: 3884\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.07455761730670929\n",
            "Train step - Step 0, Loss 0.0782041996717453\n",
            "Train step - Step 0, Loss 0.0779615268111229\n",
            "Train step - Step 0, Loss 0.07849770039319992\n",
            "Train step - Step 0, Loss 0.07042983919382095\n",
            "Train step - Step 0, Loss 0.07998470216989517\n",
            "Train step - Step 0, Loss 0.07391371577978134\n",
            "Train step - Step 0, Loss 0.07414832711219788\n",
            "Train step - Step 0, Loss 0.07216177880764008\n",
            "Train step - Step 0, Loss 0.0841607078909874\n",
            "Train step - Step 0, Loss 0.07823988050222397\n",
            "Train step - Step 0, Loss 0.0742521584033966\n",
            "Train step - Step 0, Loss 0.07341255247592926\n",
            "Train step - Step 0, Loss 0.07208520919084549\n",
            "Train step - Step 0, Loss 0.0758853405714035\n",
            "Train step - Step 0, Loss 0.0715668722987175\n",
            "Train epoch - Accuracy: 0.3217687074829932 Loss: 0.07577207535505295 Corrects: 3784\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.07680147886276245\n",
            "Train step - Step 0, Loss 0.07972314208745956\n",
            "Train step - Step 0, Loss 0.07419518381357193\n",
            "Train step - Step 0, Loss 0.07403542101383209\n",
            "Train step - Step 0, Loss 0.07962944358587265\n",
            "Train step - Step 0, Loss 0.07687727361917496\n",
            "Train step - Step 0, Loss 0.0723646804690361\n",
            "Train step - Step 0, Loss 0.07400888949632645\n",
            "Train step - Step 0, Loss 0.07771868258714676\n",
            "Train step - Step 0, Loss 0.07204195111989975\n",
            "Train step - Step 0, Loss 0.07495007663965225\n",
            "Train step - Step 0, Loss 0.07504498213529587\n",
            "Train step - Step 0, Loss 0.0768626481294632\n",
            "Train step - Step 0, Loss 0.0759798213839531\n",
            "Train step - Step 0, Loss 0.07341447472572327\n",
            "Train step - Step 0, Loss 0.08166451752185822\n",
            "Train epoch - Accuracy: 0.3233843537414966 Loss: 0.07570078768292252 Corrects: 3803\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.07764583081007004\n",
            "Train step - Step 0, Loss 0.07930643111467361\n",
            "Train step - Step 0, Loss 0.07438967376947403\n",
            "Train step - Step 0, Loss 0.07949159294366837\n",
            "Train step - Step 0, Loss 0.07554369419813156\n",
            "Train step - Step 0, Loss 0.07751930505037308\n",
            "Train step - Step 0, Loss 0.07226496189832687\n",
            "Train step - Step 0, Loss 0.07124722003936768\n",
            "Train step - Step 0, Loss 0.08074409514665604\n",
            "Train step - Step 0, Loss 0.08147776126861572\n",
            "Train step - Step 0, Loss 0.07638030499219894\n",
            "Train step - Step 0, Loss 0.07569532841444016\n",
            "Train step - Step 0, Loss 0.07717780768871307\n",
            "Train step - Step 0, Loss 0.07562888413667679\n",
            "Train step - Step 0, Loss 0.07287748903036118\n",
            "Train step - Step 0, Loss 0.06469880789518356\n",
            "Train epoch - Accuracy: 0.3199829931972789 Loss: 0.07625200052042397 Corrects: 3763\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.07519973814487457\n",
            "Train step - Step 0, Loss 0.0736956000328064\n",
            "Train step - Step 0, Loss 0.07680340856313705\n",
            "Train step - Step 0, Loss 0.07430423051118851\n",
            "Train step - Step 0, Loss 0.07956305146217346\n",
            "Train step - Step 0, Loss 0.0771658644080162\n",
            "Train step - Step 0, Loss 0.07389146834611893\n",
            "Train step - Step 0, Loss 0.07488188147544861\n",
            "Train step - Step 0, Loss 0.0720217153429985\n",
            "Train step - Step 0, Loss 0.07900716364383698\n",
            "Train step - Step 0, Loss 0.07558805495500565\n",
            "Train step - Step 0, Loss 0.07442297786474228\n",
            "Train step - Step 0, Loss 0.0781879648566246\n",
            "Train step - Step 0, Loss 0.07613835483789444\n",
            "Train step - Step 0, Loss 0.07957038283348083\n",
            "Train step - Step 0, Loss 0.07951447367668152\n",
            "Train epoch - Accuracy: 0.32933673469387753 Loss: 0.07610057993811004 Corrects: 3873\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.0745542049407959\n",
            "Train step - Step 0, Loss 0.07909878343343735\n",
            "Train step - Step 0, Loss 0.07323064655065536\n",
            "Train step - Step 0, Loss 0.07333160936832428\n",
            "Train step - Step 0, Loss 0.07453616708517075\n",
            "Train step - Step 0, Loss 0.0754580944776535\n",
            "Train step - Step 0, Loss 0.08029624074697495\n",
            "Train step - Step 0, Loss 0.0740044116973877\n",
            "Train step - Step 0, Loss 0.0733814388513565\n",
            "Train step - Step 0, Loss 0.07646893709897995\n",
            "Train step - Step 0, Loss 0.07426300644874573\n",
            "Train step - Step 0, Loss 0.0778120905160904\n",
            "Train step - Step 0, Loss 0.0749649628996849\n",
            "Train step - Step 0, Loss 0.0735408142209053\n",
            "Train step - Step 0, Loss 0.07941364496946335\n",
            "Train step - Step 0, Loss 0.08167912065982819\n",
            "Train epoch - Accuracy: 0.325 Loss: 0.07574725084158838 Corrects: 3822\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.0741293653845787\n",
            "Train step - Step 0, Loss 0.07346054911613464\n",
            "Train step - Step 0, Loss 0.07382876425981522\n",
            "Train step - Step 0, Loss 0.08012648671865463\n",
            "Train step - Step 0, Loss 0.07605587691068649\n",
            "Train step - Step 0, Loss 0.07650689780712128\n",
            "Train step - Step 0, Loss 0.07616360485553741\n",
            "Train step - Step 0, Loss 0.07745715975761414\n",
            "Train step - Step 0, Loss 0.0758325532078743\n",
            "Train step - Step 0, Loss 0.07393956929445267\n",
            "Train step - Step 0, Loss 0.07839416712522507\n",
            "Train step - Step 0, Loss 0.07999175041913986\n",
            "Train step - Step 0, Loss 0.08173298090696335\n",
            "Train step - Step 0, Loss 0.07530444860458374\n",
            "Train step - Step 0, Loss 0.07300427556037903\n",
            "Train step - Step 0, Loss 0.06975505501031876\n",
            "Train epoch - Accuracy: 0.31981292517006804 Loss: 0.07625971622004801 Corrects: 3761\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.07385224848985672\n",
            "Train step - Step 0, Loss 0.07584796100854874\n",
            "Train step - Step 0, Loss 0.0766393169760704\n",
            "Train step - Step 0, Loss 0.07772713154554367\n",
            "Train step - Step 0, Loss 0.07772258669137955\n",
            "Train step - Step 0, Loss 0.07721330225467682\n",
            "Train step - Step 0, Loss 0.07518056780099869\n",
            "Train step - Step 0, Loss 0.07613060623407364\n",
            "Train step - Step 0, Loss 0.07249384373426437\n",
            "Train step - Step 0, Loss 0.07506648451089859\n",
            "Train step - Step 0, Loss 0.07494273781776428\n",
            "Train step - Step 0, Loss 0.07389341294765472\n",
            "Train step - Step 0, Loss 0.0767473354935646\n",
            "Train step - Step 0, Loss 0.07847359031438828\n",
            "Train step - Step 0, Loss 0.07475722581148148\n",
            "Train step - Step 0, Loss 0.07149288803339005\n",
            "Train epoch - Accuracy: 0.3177721088435374 Loss: 0.07569174720924728 Corrects: 3737\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.07441738247871399\n",
            "Train step - Step 0, Loss 0.07726038992404938\n",
            "Train step - Step 0, Loss 0.07564283907413483\n",
            "Train step - Step 0, Loss 0.07659891247749329\n",
            "Train step - Step 0, Loss 0.07657421380281448\n",
            "Train step - Step 0, Loss 0.07438747584819794\n",
            "Train step - Step 0, Loss 0.0783400684595108\n",
            "Train step - Step 0, Loss 0.07578492909669876\n",
            "Train step - Step 0, Loss 0.07589426636695862\n",
            "Train step - Step 0, Loss 0.07956922799348831\n",
            "Train step - Step 0, Loss 0.07477758079767227\n",
            "Train step - Step 0, Loss 0.07622560858726501\n",
            "Train step - Step 0, Loss 0.07539842277765274\n",
            "Train step - Step 0, Loss 0.07352005690336227\n",
            "Train step - Step 0, Loss 0.07296562194824219\n",
            "Train step - Step 0, Loss 0.07555534690618515\n",
            "Train epoch - Accuracy: 0.3215136054421769 Loss: 0.07581832113922858 Corrects: 3781\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.07455667108297348\n",
            "Train step - Step 0, Loss 0.076018787920475\n",
            "Train step - Step 0, Loss 0.0777437686920166\n",
            "Train step - Step 0, Loss 0.07998722791671753\n",
            "Train step - Step 0, Loss 0.07413572072982788\n",
            "Train step - Step 0, Loss 0.07624658942222595\n",
            "Train step - Step 0, Loss 0.07700616866350174\n",
            "Train step - Step 0, Loss 0.07336021214723587\n",
            "Train step - Step 0, Loss 0.07636255770921707\n",
            "Train step - Step 0, Loss 0.07511623948812485\n",
            "Train step - Step 0, Loss 0.0747077688574791\n",
            "Train step - Step 0, Loss 0.07878369837999344\n",
            "Train step - Step 0, Loss 0.07198183983564377\n",
            "Train step - Step 0, Loss 0.07422076910734177\n",
            "Train step - Step 0, Loss 0.07542155683040619\n",
            "Train step - Step 0, Loss 0.07494718581438065\n",
            "Train epoch - Accuracy: 0.32329931972789117 Loss: 0.07569440472490933 Corrects: 3802\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.08446753770112991\n",
            "Train step - Step 0, Loss 0.07276108115911484\n",
            "Train step - Step 0, Loss 0.07995326071977615\n",
            "Train step - Step 0, Loss 0.07585258781909943\n",
            "Train step - Step 0, Loss 0.07317504286766052\n",
            "Train step - Step 0, Loss 0.07838808000087738\n",
            "Train step - Step 0, Loss 0.0767175704240799\n",
            "Train step - Step 0, Loss 0.07384999096393585\n",
            "Train step - Step 0, Loss 0.07430423051118851\n",
            "Train step - Step 0, Loss 0.07333546131849289\n",
            "Train step - Step 0, Loss 0.07650457322597504\n",
            "Train step - Step 0, Loss 0.0737098753452301\n",
            "Train step - Step 0, Loss 0.07638092339038849\n",
            "Train step - Step 0, Loss 0.07390417903661728\n",
            "Train step - Step 0, Loss 0.08129952102899551\n",
            "Train step - Step 0, Loss 0.07216337323188782\n",
            "Train epoch - Accuracy: 0.3217687074829932 Loss: 0.07622236536473644 Corrects: 3784\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.07585575431585312\n",
            "Train step - Step 0, Loss 0.0746893584728241\n",
            "Train step - Step 0, Loss 0.07726749777793884\n",
            "Train step - Step 0, Loss 0.08063763380050659\n",
            "Train step - Step 0, Loss 0.07447472959756851\n",
            "Train step - Step 0, Loss 0.07119418680667877\n",
            "Train step - Step 0, Loss 0.0774725079536438\n",
            "Train step - Step 0, Loss 0.0787767544388771\n",
            "Train step - Step 0, Loss 0.07895288616418839\n",
            "Train step - Step 0, Loss 0.07561788707971573\n",
            "Train step - Step 0, Loss 0.0771123468875885\n",
            "Train step - Step 0, Loss 0.07525185495615005\n",
            "Train step - Step 0, Loss 0.07285415381193161\n",
            "Train step - Step 0, Loss 0.07695477455854416\n",
            "Train step - Step 0, Loss 0.07324504852294922\n",
            "Train step - Step 0, Loss 0.07028744369745255\n",
            "Train epoch - Accuracy: 0.32108843537414966 Loss: 0.07590675600329223 Corrects: 3776\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.07520785182714462\n",
            "Train step - Step 0, Loss 0.07422927021980286\n",
            "Train step - Step 0, Loss 0.07637125253677368\n",
            "Train step - Step 0, Loss 0.07977265864610672\n",
            "Train step - Step 0, Loss 0.07690614461898804\n",
            "Train step - Step 0, Loss 0.07501265406608582\n",
            "Train step - Step 0, Loss 0.07588981837034225\n",
            "Train step - Step 0, Loss 0.07827825099229813\n",
            "Train step - Step 0, Loss 0.07661175727844238\n",
            "Train step - Step 0, Loss 0.0707894116640091\n",
            "Train step - Step 0, Loss 0.07726237922906876\n",
            "Train step - Step 0, Loss 0.07311494648456573\n",
            "Train step - Step 0, Loss 0.0748562216758728\n",
            "Train step - Step 0, Loss 0.07370399683713913\n",
            "Train step - Step 0, Loss 0.07689467072486877\n",
            "Train step - Step 0, Loss 0.06666179746389389\n",
            "Train epoch - Accuracy: 0.3233843537414966 Loss: 0.07547644714311677 Corrects: 3803\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.07053155452013016\n",
            "Train step - Step 0, Loss 0.08241560310125351\n",
            "Train step - Step 0, Loss 0.07957665622234344\n",
            "Train step - Step 0, Loss 0.07302019000053406\n",
            "Train step - Step 0, Loss 0.07636544108390808\n",
            "Train step - Step 0, Loss 0.07373202592134476\n",
            "Train step - Step 0, Loss 0.07964108139276505\n",
            "Train step - Step 0, Loss 0.07047285884618759\n",
            "Train step - Step 0, Loss 0.08163997530937195\n",
            "Train step - Step 0, Loss 0.07538208365440369\n",
            "Train step - Step 0, Loss 0.07192914932966232\n",
            "Train step - Step 0, Loss 0.0767768919467926\n",
            "Train step - Step 0, Loss 0.07478778809309006\n",
            "Train step - Step 0, Loss 0.07487096637487411\n",
            "Train step - Step 0, Loss 0.0803261548280716\n",
            "Train step - Step 0, Loss 0.07782648503780365\n",
            "Train epoch - Accuracy: 0.33231292517006805 Loss: 0.07613317206197856 Corrects: 3908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.38 0.0686594694852829\n",
            "TEST GROUP:  0.542\n",
            "TEST ALL:  0.44971428571428573\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  8000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 95, 96, 9, 13, 17, 21, 29, 37, 45, 49, 53, 57, 61, 65, 69, 81, 85, 93, 88, 84, 80, 40, 4, 8, 16, 20, 24, 32, 36, 44, 76, 48, 52, 56, 60, 64, 68, 72, 97, 2, 6, 51, 23, 27, 31, 35, 39, 43, 47, 55, 15, 59, 63, 67, 71, 75, 79, 83, 19, 7, 10, 50, 14, 18, 22, 30, 34, 38, 42, 54, 98, 70, 74, 78, 82, 86, 90, 94, 0]\n",
            "TRAIN_SET CLASSES:  [71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "VALIDATION CLASSES:  [51, 48, 44, 43, 38, 37, 29, 78, 74, 71]\n",
            "GROUP:  8\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "Len TOTAL train susbset:  6910\n",
            "training\n",
            "num classes till now:  80\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.20989863574504852\n",
            "Train step - Step 10, Loss 0.12072384357452393\n",
            "Train step - Step 20, Loss 0.11568106710910797\n",
            "Train step - Step 30, Loss 0.1037750169634819\n",
            "Train step - Step 40, Loss 0.10997650772333145\n",
            "Train step - Step 50, Loss 0.10690180212259293\n",
            "Train epoch - Accuracy: 0.15904486251808972 Loss: 0.12166015881877905 Corrects: 1099\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.10776346176862717\n",
            "Train step - Step 70, Loss 0.10497602075338364\n",
            "Train step - Step 80, Loss 0.10152029991149902\n",
            "Train step - Step 90, Loss 0.0986364409327507\n",
            "Train step - Step 100, Loss 0.1011282429099083\n",
            "Train epoch - Accuracy: 0.21837916063675833 Loss: 0.10317847158991653 Corrects: 1509\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.10152561962604523\n",
            "Train step - Step 120, Loss 0.10110817104578018\n",
            "Train step - Step 130, Loss 0.09707239270210266\n",
            "Train step - Step 140, Loss 0.09982927143573761\n",
            "Train step - Step 150, Loss 0.09776534140110016\n",
            "Train step - Step 160, Loss 0.1006641611456871\n",
            "Train epoch - Accuracy: 0.2609261939218524 Loss: 0.10111485120830936 Corrects: 1803\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.10080324858427048\n",
            "Train step - Step 180, Loss 0.101959228515625\n",
            "Train step - Step 190, Loss 0.10156185925006866\n",
            "Train step - Step 200, Loss 0.09576454013586044\n",
            "Train step - Step 210, Loss 0.09894534200429916\n",
            "Train epoch - Accuracy: 0.2939218523878437 Loss: 0.09973333377051458 Corrects: 2031\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.09803538769483566\n",
            "Train step - Step 230, Loss 0.10075652599334717\n",
            "Train step - Step 240, Loss 0.09928583353757858\n",
            "Train step - Step 250, Loss 0.09752696007490158\n",
            "Train step - Step 260, Loss 0.09727215766906738\n",
            "Train epoch - Accuracy: 0.3360347322720695 Loss: 0.09905785176412414 Corrects: 2322\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 270, Loss 0.09693888574838638\n",
            "Train step - Step 280, Loss 0.09690185636281967\n",
            "Train step - Step 290, Loss 0.09603216499090195\n",
            "Train step - Step 300, Loss 0.09909919649362564\n",
            "Train step - Step 310, Loss 0.09992039203643799\n",
            "Train step - Step 320, Loss 0.09976450353860855\n",
            "Train epoch - Accuracy: 0.34949348769898697 Loss: 0.09811767356958127 Corrects: 2415\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.0965656116604805\n",
            "Train step - Step 340, Loss 0.09695925563573837\n",
            "Train step - Step 350, Loss 0.09443923085927963\n",
            "Train step - Step 360, Loss 0.09675667434930801\n",
            "Train step - Step 370, Loss 0.09899014234542847\n",
            "Train epoch - Accuracy: 0.3670043415340087 Loss: 0.09811368595846483 Corrects: 2536\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 380, Loss 0.0977674052119255\n",
            "Train step - Step 390, Loss 0.09731627255678177\n",
            "Train step - Step 400, Loss 0.09659676998853683\n",
            "Train step - Step 410, Loss 0.09598427265882492\n",
            "Train step - Step 420, Loss 0.0939122810959816\n",
            "Train step - Step 430, Loss 0.09586606919765472\n",
            "Train epoch - Accuracy: 0.37785817655571635 Loss: 0.09767339644487273 Corrects: 2611\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.09967061132192612\n",
            "Train step - Step 450, Loss 0.10333007574081421\n",
            "Train step - Step 460, Loss 0.0962565690279007\n",
            "Train step - Step 470, Loss 0.09732242673635483\n",
            "Train step - Step 480, Loss 0.10148756951093674\n",
            "Train epoch - Accuracy: 0.3939218523878437 Loss: 0.09771485580117933 Corrects: 2722\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 490, Loss 0.09731263667345047\n",
            "Train step - Step 500, Loss 0.09651064872741699\n",
            "Train step - Step 510, Loss 0.09637172520160675\n",
            "Train step - Step 520, Loss 0.09835191816091537\n",
            "Train step - Step 530, Loss 0.09907834231853485\n",
            "Train epoch - Accuracy: 0.4101302460202605 Loss: 0.0971300776891529 Corrects: 2834\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 540, Loss 0.0931592583656311\n",
            "Train step - Step 550, Loss 0.09947573393583298\n",
            "Train step - Step 560, Loss 0.09613088518381119\n",
            "Train step - Step 570, Loss 0.10078909248113632\n",
            "Train step - Step 580, Loss 0.09626754373311996\n",
            "Train step - Step 590, Loss 0.10013888031244278\n",
            "Train epoch - Accuracy: 0.41678726483357453 Loss: 0.09690421160024776 Corrects: 2880\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 600, Loss 0.0958421379327774\n",
            "Train step - Step 610, Loss 0.10089969635009766\n",
            "Train step - Step 620, Loss 0.09618716686964035\n",
            "Train step - Step 630, Loss 0.09502995759248734\n",
            "Train step - Step 640, Loss 0.09317559003829956\n",
            "Train epoch - Accuracy: 0.4264833574529667 Loss: 0.09654498272366531 Corrects: 2947\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 650, Loss 0.09397721290588379\n",
            "Train step - Step 660, Loss 0.09428458660840988\n",
            "Train step - Step 670, Loss 0.09677805751562119\n",
            "Train step - Step 680, Loss 0.09821881353855133\n",
            "Train step - Step 690, Loss 0.09827857464551926\n",
            "Train step - Step 700, Loss 0.0965224876999855\n",
            "Train epoch - Accuracy: 0.4328509406657019 Loss: 0.0967098871421193 Corrects: 2991\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.09645235538482666\n",
            "Train step - Step 720, Loss 0.09517502784729004\n",
            "Train step - Step 730, Loss 0.09730014204978943\n",
            "Train step - Step 740, Loss 0.09707466512918472\n",
            "Train step - Step 750, Loss 0.0957973301410675\n",
            "Train epoch - Accuracy: 0.4467438494934877 Loss: 0.09640294835294898 Corrects: 3087\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 760, Loss 0.09529014676809311\n",
            "Train step - Step 770, Loss 0.09619889408349991\n",
            "Train step - Step 780, Loss 0.0952046662569046\n",
            "Train step - Step 790, Loss 0.09578591585159302\n",
            "Train step - Step 800, Loss 0.09577502310276031\n",
            "Train epoch - Accuracy: 0.4447178002894356 Loss: 0.0961644686273314 Corrects: 3073\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 810, Loss 0.09652258455753326\n",
            "Train step - Step 820, Loss 0.09353820234537125\n",
            "Train step - Step 830, Loss 0.09482157975435257\n",
            "Train step - Step 840, Loss 0.09787557274103165\n",
            "Train step - Step 850, Loss 0.09917154908180237\n",
            "Train step - Step 860, Loss 0.09490563720464706\n",
            "Train epoch - Accuracy: 0.450506512301013 Loss: 0.09593501512160695 Corrects: 3113\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 870, Loss 0.10039602965116501\n",
            "Train step - Step 880, Loss 0.09631826728582382\n",
            "Train step - Step 890, Loss 0.09569162130355835\n",
            "Train step - Step 900, Loss 0.09581524133682251\n",
            "Train step - Step 910, Loss 0.09955088049173355\n",
            "Train epoch - Accuracy: 0.4736613603473227 Loss: 0.09585284054840008 Corrects: 3273\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 920, Loss 0.09238383919000626\n",
            "Train step - Step 930, Loss 0.09154634177684784\n",
            "Train step - Step 940, Loss 0.09301196783781052\n",
            "Train step - Step 950, Loss 0.09653473645448685\n",
            "Train step - Step 960, Loss 0.09491556137800217\n",
            "Train step - Step 970, Loss 0.0930606946349144\n",
            "Train epoch - Accuracy: 0.478726483357453 Loss: 0.09539707794289513 Corrects: 3308\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.09807389974594116\n",
            "Train step - Step 990, Loss 0.09699944406747818\n",
            "Train step - Step 1000, Loss 0.09926314651966095\n",
            "Train step - Step 1010, Loss 0.09491604566574097\n",
            "Train step - Step 1020, Loss 0.09544288367033005\n",
            "Train epoch - Accuracy: 0.4813314037626628 Loss: 0.09543765987311362 Corrects: 3326\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1030, Loss 0.09227696806192398\n",
            "Train step - Step 1040, Loss 0.09509215503931046\n",
            "Train step - Step 1050, Loss 0.09385737776756287\n",
            "Train step - Step 1060, Loss 0.09710134565830231\n",
            "Train step - Step 1070, Loss 0.09105781465768814\n",
            "Train epoch - Accuracy: 0.48437047756874096 Loss: 0.09520876261199435 Corrects: 3347\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1080, Loss 0.0974123626947403\n",
            "Train step - Step 1090, Loss 0.09467878192663193\n",
            "Train step - Step 1100, Loss 0.09231722354888916\n",
            "Train step - Step 1110, Loss 0.09568869322538376\n",
            "Train step - Step 1120, Loss 0.09403936564922333\n",
            "Train step - Step 1130, Loss 0.09118147194385529\n",
            "Train epoch - Accuracy: 0.4821997105643994 Loss: 0.0951762112302304 Corrects: 3332\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.0988144800066948\n",
            "Train step - Step 1150, Loss 0.1000179573893547\n",
            "Train step - Step 1160, Loss 0.0937730073928833\n",
            "Train step - Step 1170, Loss 0.09779862314462662\n",
            "Train step - Step 1180, Loss 0.10375312715768814\n",
            "Train epoch - Accuracy: 0.49421128798842257 Loss: 0.09533313071589739 Corrects: 3415\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1190, Loss 0.09215628355741501\n",
            "Train step - Step 1200, Loss 0.0935366079211235\n",
            "Train step - Step 1210, Loss 0.09209561347961426\n",
            "Train step - Step 1220, Loss 0.09215331077575684\n",
            "Train step - Step 1230, Loss 0.09654977172613144\n",
            "Train step - Step 1240, Loss 0.09823591262102127\n",
            "Train epoch - Accuracy: 0.4927641099855282 Loss: 0.09499116067474037 Corrects: 3405\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.09147452563047409\n",
            "Train step - Step 1260, Loss 0.09403197467327118\n",
            "Train step - Step 1270, Loss 0.0952700600028038\n",
            "Train step - Step 1280, Loss 0.09405948221683502\n",
            "Train step - Step 1290, Loss 0.09538470953702927\n",
            "Train epoch - Accuracy: 0.5018813314037627 Loss: 0.09485310429947076 Corrects: 3468\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1300, Loss 0.0935404896736145\n",
            "Train step - Step 1310, Loss 0.093789242208004\n",
            "Train step - Step 1320, Loss 0.09758450835943222\n",
            "Train step - Step 1330, Loss 0.09417296946048737\n",
            "Train step - Step 1340, Loss 0.09329776465892792\n",
            "Train epoch - Accuracy: 0.5028943560057887 Loss: 0.0947599095390778 Corrects: 3475\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1350, Loss 0.09367354214191437\n",
            "Train step - Step 1360, Loss 0.09360440820455551\n",
            "Train step - Step 1370, Loss 0.09337010234594345\n",
            "Train step - Step 1380, Loss 0.0978415459394455\n",
            "Train step - Step 1390, Loss 0.09922041743993759\n",
            "Train step - Step 1400, Loss 0.09858440607786179\n",
            "Train epoch - Accuracy: 0.5109985528219971 Loss: 0.09449271934724233 Corrects: 3531\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.09309612959623337\n",
            "Train step - Step 1420, Loss 0.09390466660261154\n",
            "Train step - Step 1430, Loss 0.09638408571481705\n",
            "Train step - Step 1440, Loss 0.09591656178236008\n",
            "Train step - Step 1450, Loss 0.0906720831990242\n",
            "Train epoch - Accuracy: 0.5111432706222866 Loss: 0.0949088095518856 Corrects: 3532\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1460, Loss 0.09926065057516098\n",
            "Train step - Step 1470, Loss 0.09432786703109741\n",
            "Train step - Step 1480, Loss 0.09668400883674622\n",
            "Train step - Step 1490, Loss 0.09415002912282944\n",
            "Train step - Step 1500, Loss 0.09578748792409897\n",
            "Train step - Step 1510, Loss 0.09916780889034271\n",
            "Train epoch - Accuracy: 0.5114327062228654 Loss: 0.09442690539722333 Corrects: 3534\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1520, Loss 0.09241387993097305\n",
            "Train step - Step 1530, Loss 0.09337209165096283\n",
            "Train step - Step 1540, Loss 0.08851732313632965\n",
            "Train step - Step 1550, Loss 0.09775753319263458\n",
            "Train step - Step 1560, Loss 0.09549932181835175\n",
            "Train epoch - Accuracy: 0.5218523878437048 Loss: 0.09437409034254927 Corrects: 3606\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1570, Loss 0.0906277522444725\n",
            "Train step - Step 1580, Loss 0.09880008548498154\n",
            "Train step - Step 1590, Loss 0.09217606484889984\n",
            "Train step - Step 1600, Loss 0.09541632980108261\n",
            "Train step - Step 1610, Loss 0.09389714151620865\n",
            "Train epoch - Accuracy: 0.5257597684515195 Loss: 0.0945515451831514 Corrects: 3633\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1620, Loss 0.09770702570676804\n",
            "Train step - Step 1630, Loss 0.0902906209230423\n",
            "Train step - Step 1640, Loss 0.09665139764547348\n",
            "Train step - Step 1650, Loss 0.09091350436210632\n",
            "Train step - Step 1660, Loss 0.09352993220090866\n",
            "Train step - Step 1670, Loss 0.0962878167629242\n",
            "Train epoch - Accuracy: 0.5250361794500723 Loss: 0.09408886192202051 Corrects: 3628\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.09747288376092911\n",
            "Train step - Step 1690, Loss 0.09792429208755493\n",
            "Train step - Step 1700, Loss 0.09749645739793777\n",
            "Train step - Step 1710, Loss 0.09284752607345581\n",
            "Train step - Step 1720, Loss 0.08860727399587631\n",
            "Train epoch - Accuracy: 0.5332850940665702 Loss: 0.0943106817073484 Corrects: 3685\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1730, Loss 0.09427320957183838\n",
            "Train step - Step 1740, Loss 0.09428609162569046\n",
            "Train step - Step 1750, Loss 0.09751031547784805\n",
            "Train step - Step 1760, Loss 0.09178466349840164\n",
            "Train step - Step 1770, Loss 0.09218006581068039\n",
            "Train step - Step 1780, Loss 0.0981549546122551\n",
            "Train epoch - Accuracy: 0.5299565846599131 Loss: 0.094018925885992 Corrects: 3662\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1790, Loss 0.09478547424077988\n",
            "Train step - Step 1800, Loss 0.09378062933683395\n",
            "Train step - Step 1810, Loss 0.09383437782526016\n",
            "Train step - Step 1820, Loss 0.08943792432546616\n",
            "Train step - Step 1830, Loss 0.09510783106088638\n",
            "Train epoch - Accuracy: 0.5402315484804631 Loss: 0.09386661421890369 Corrects: 3733\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.09252836555242538\n",
            "Train step - Step 1850, Loss 0.09259974956512451\n",
            "Train step - Step 1860, Loss 0.09591913968324661\n",
            "Train step - Step 1870, Loss 0.09115144610404968\n",
            "Train step - Step 1880, Loss 0.09697683155536652\n",
            "Train epoch - Accuracy: 0.5490593342981187 Loss: 0.09376822185585364 Corrects: 3794\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1890, Loss 0.09511394798755646\n",
            "Train step - Step 1900, Loss 0.0979323759675026\n",
            "Train step - Step 1910, Loss 0.09162893891334534\n",
            "Train step - Step 1920, Loss 0.0938718318939209\n",
            "Train step - Step 1930, Loss 0.09581887722015381\n",
            "Train step - Step 1940, Loss 0.0961083397269249\n",
            "Train epoch - Accuracy: 0.5410998552821997 Loss: 0.09383550372335914 Corrects: 3739\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1950, Loss 0.09300382435321808\n",
            "Train step - Step 1960, Loss 0.09369247406721115\n",
            "Train step - Step 1970, Loss 0.09721451997756958\n",
            "Train step - Step 1980, Loss 0.08922091871500015\n",
            "Train step - Step 1990, Loss 0.09474896639585495\n",
            "Train epoch - Accuracy: 0.5452966714905934 Loss: 0.09381410594053793 Corrects: 3768\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2000, Loss 0.09068578481674194\n",
            "Train step - Step 2010, Loss 0.09398278594017029\n",
            "Train step - Step 2020, Loss 0.0909157395362854\n",
            "Train step - Step 2030, Loss 0.09571167081594467\n",
            "Train step - Step 2040, Loss 0.09395994246006012\n",
            "Train step - Step 2050, Loss 0.09395506232976913\n",
            "Train epoch - Accuracy: 0.5520984081041969 Loss: 0.09374074709484442 Corrects: 3815\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2060, Loss 0.09531298279762268\n",
            "Train step - Step 2070, Loss 0.09468411654233932\n",
            "Train step - Step 2080, Loss 0.09910792112350464\n",
            "Train step - Step 2090, Loss 0.09026505798101425\n",
            "Train step - Step 2100, Loss 0.09259724617004395\n",
            "Train epoch - Accuracy: 0.5518089725036179 Loss: 0.09359525499700982 Corrects: 3813\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2110, Loss 0.09483450651168823\n",
            "Train step - Step 2120, Loss 0.09378081560134888\n",
            "Train step - Step 2130, Loss 0.0931316688656807\n",
            "Train step - Step 2140, Loss 0.08974718302488327\n",
            "Train step - Step 2150, Loss 0.09365694224834442\n",
            "Train epoch - Accuracy: 0.5557163531114327 Loss: 0.09329447723849638 Corrects: 3840\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2160, Loss 0.08918922394514084\n",
            "Train step - Step 2170, Loss 0.09295862913131714\n",
            "Train step - Step 2180, Loss 0.1000514030456543\n",
            "Train step - Step 2190, Loss 0.09212516993284225\n",
            "Train step - Step 2200, Loss 0.09081392735242844\n",
            "Train step - Step 2210, Loss 0.09332381933927536\n",
            "Train epoch - Accuracy: 0.5558610709117221 Loss: 0.09344968260542183 Corrects: 3841\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2220, Loss 0.09876321256160736\n",
            "Train step - Step 2230, Loss 0.0947490930557251\n",
            "Train step - Step 2240, Loss 0.09105432033538818\n",
            "Train step - Step 2250, Loss 0.09888088703155518\n",
            "Train step - Step 2260, Loss 0.09146958589553833\n",
            "Train epoch - Accuracy: 0.5603473227206947 Loss: 0.09362621068652563 Corrects: 3872\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2270, Loss 0.09367550909519196\n",
            "Train step - Step 2280, Loss 0.09220198541879654\n",
            "Train step - Step 2290, Loss 0.09163103997707367\n",
            "Train step - Step 2300, Loss 0.09726007282733917\n",
            "Train step - Step 2310, Loss 0.0972105860710144\n",
            "Train step - Step 2320, Loss 0.09033761918544769\n",
            "Train epoch - Accuracy: 0.5523878437047757 Loss: 0.0934355335647049 Corrects: 3817\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2330, Loss 0.09410379827022552\n",
            "Train step - Step 2340, Loss 0.08959972113370895\n",
            "Train step - Step 2350, Loss 0.09329292923212051\n",
            "Train step - Step 2360, Loss 0.08892524242401123\n",
            "Train step - Step 2370, Loss 0.09275417774915695\n",
            "Train epoch - Accuracy: 0.5622286541244573 Loss: 0.09332718290658142 Corrects: 3885\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2380, Loss 0.09134764969348907\n",
            "Train step - Step 2390, Loss 0.09498757123947144\n",
            "Train step - Step 2400, Loss 0.09644713252782822\n",
            "Train step - Step 2410, Loss 0.09047883003950119\n",
            "Train step - Step 2420, Loss 0.09535800665616989\n",
            "Train epoch - Accuracy: 0.5642547033285094 Loss: 0.09337230518611227 Corrects: 3899\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2430, Loss 0.09189092367887497\n",
            "Train step - Step 2440, Loss 0.09057362377643585\n",
            "Train step - Step 2450, Loss 0.09417855739593506\n",
            "Train step - Step 2460, Loss 0.09233912080526352\n",
            "Train step - Step 2470, Loss 0.09139479696750641\n",
            "Train step - Step 2480, Loss 0.0939849242568016\n",
            "Train epoch - Accuracy: 0.5696092619392186 Loss: 0.09294655340280271 Corrects: 3936\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2490, Loss 0.09297262877225876\n",
            "Train step - Step 2500, Loss 0.09022405743598938\n",
            "Train step - Step 2510, Loss 0.09163136035203934\n",
            "Train step - Step 2520, Loss 0.09657036513090134\n",
            "Train step - Step 2530, Loss 0.09300025552511215\n",
            "Train epoch - Accuracy: 0.5761215629522431 Loss: 0.09312305482786402 Corrects: 3981\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2540, Loss 0.08871104568243027\n",
            "Train step - Step 2550, Loss 0.09311339259147644\n",
            "Train step - Step 2560, Loss 0.09487970918416977\n",
            "Train step - Step 2570, Loss 0.0893089696764946\n",
            "Train step - Step 2580, Loss 0.09488709270954132\n",
            "Train step - Step 2590, Loss 0.09148707240819931\n",
            "Train epoch - Accuracy: 0.5712011577424023 Loss: 0.09288161517742229 Corrects: 3947\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2600, Loss 0.09540657699108124\n",
            "Train step - Step 2610, Loss 0.09559869766235352\n",
            "Train step - Step 2620, Loss 0.09081178903579712\n",
            "Train step - Step 2630, Loss 0.09251423180103302\n",
            "Train step - Step 2640, Loss 0.09520725160837173\n",
            "Train epoch - Accuracy: 0.5678726483357452 Loss: 0.09291887682702193 Corrects: 3924\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2650, Loss 0.09616687148809433\n",
            "Train step - Step 2660, Loss 0.09258165955543518\n",
            "Train step - Step 2670, Loss 0.09188523143529892\n",
            "Train step - Step 2680, Loss 0.08703024685382843\n",
            "Train step - Step 2690, Loss 0.09388785064220428\n",
            "Train epoch - Accuracy: 0.5778581765557164 Loss: 0.09269843630266258 Corrects: 3993\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2700, Loss 0.09321708977222443\n",
            "Train step - Step 2710, Loss 0.0913284569978714\n",
            "Train step - Step 2720, Loss 0.09445523470640182\n",
            "Train step - Step 2730, Loss 0.09265818446874619\n",
            "Train step - Step 2740, Loss 0.0918198749423027\n",
            "Train step - Step 2750, Loss 0.0977286845445633\n",
            "Train epoch - Accuracy: 0.5850940665701881 Loss: 0.09234011632574968 Corrects: 4043\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2760, Loss 0.09434404224157333\n",
            "Train step - Step 2770, Loss 0.09032383561134338\n",
            "Train step - Step 2780, Loss 0.09316295385360718\n",
            "Train step - Step 2790, Loss 0.09052123874425888\n",
            "Train step - Step 2800, Loss 0.09391994774341583\n",
            "Train epoch - Accuracy: 0.5795947901591896 Loss: 0.0924212874340597 Corrects: 4005\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.08952520787715912\n",
            "Train step - Step 2820, Loss 0.09294633567333221\n",
            "Train step - Step 2830, Loss 0.09020385891199112\n",
            "Train step - Step 2840, Loss 0.09720885008573532\n",
            "Train step - Step 2850, Loss 0.09440606087446213\n",
            "Train step - Step 2860, Loss 0.09340289235115051\n",
            "Train epoch - Accuracy: 0.5811866859623733 Loss: 0.09229891231410238 Corrects: 4016\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2870, Loss 0.09430690854787827\n",
            "Train step - Step 2880, Loss 0.090056873857975\n",
            "Train step - Step 2890, Loss 0.09659623354673386\n",
            "Train step - Step 2900, Loss 0.0891638770699501\n",
            "Train step - Step 2910, Loss 0.09469922631978989\n",
            "Train epoch - Accuracy: 0.5817655571635311 Loss: 0.0922829301070891 Corrects: 4020\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.09370898455381393\n",
            "Train step - Step 2930, Loss 0.08845370262861252\n",
            "Train step - Step 2940, Loss 0.09230520576238632\n",
            "Train step - Step 2950, Loss 0.0912357047200203\n",
            "Train step - Step 2960, Loss 0.09405314177274704\n",
            "Train epoch - Accuracy: 0.5832127351664255 Loss: 0.09250553381641419 Corrects: 4030\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.09329979121685028\n",
            "Train step - Step 2980, Loss 0.08989989012479782\n",
            "Train step - Step 2990, Loss 0.0923754945397377\n",
            "Train step - Step 3000, Loss 0.08986898511648178\n",
            "Train step - Step 3010, Loss 0.09491086006164551\n",
            "Train step - Step 3020, Loss 0.09283993393182755\n",
            "Train epoch - Accuracy: 0.5863965267727931 Loss: 0.09223182540812817 Corrects: 4052\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.08907486498355865\n",
            "Train step - Step 3040, Loss 0.09383437037467957\n",
            "Train step - Step 3050, Loss 0.09173382818698883\n",
            "Train step - Step 3060, Loss 0.09020521491765976\n",
            "Train step - Step 3070, Loss 0.09239988774061203\n",
            "Train epoch - Accuracy: 0.5855282199710564 Loss: 0.09238150194179477 Corrects: 4046\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.09309492260217667\n",
            "Train step - Step 3090, Loss 0.08994962275028229\n",
            "Train step - Step 3100, Loss 0.09261312335729599\n",
            "Train step - Step 3110, Loss 0.09176108241081238\n",
            "Train step - Step 3120, Loss 0.09375566244125366\n",
            "Train step - Step 3130, Loss 0.09704545885324478\n",
            "Train epoch - Accuracy: 0.5843704775687409 Loss: 0.09215384622774317 Corrects: 4038\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.09379503130912781\n",
            "Train step - Step 3150, Loss 0.09012649953365326\n",
            "Train step - Step 3160, Loss 0.09348469227552414\n",
            "Train step - Step 3170, Loss 0.09306912869215012\n",
            "Train step - Step 3180, Loss 0.0937228873372078\n",
            "Train epoch - Accuracy: 0.58972503617945 Loss: 0.09234480524891192 Corrects: 4075\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09251856058835983\n",
            "Train step - Step 3200, Loss 0.09163015335798264\n",
            "Train step - Step 3210, Loss 0.08834414184093475\n",
            "Train step - Step 3220, Loss 0.09201877564191818\n",
            "Train step - Step 3230, Loss 0.08864249289035797\n",
            "Train epoch - Accuracy: 0.5869753979739508 Loss: 0.09223812950934067 Corrects: 4056\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3240, Loss 0.0915665403008461\n",
            "Train step - Step 3250, Loss 0.09358787536621094\n",
            "Train step - Step 3260, Loss 0.09614087641239166\n",
            "Train step - Step 3270, Loss 0.09341132640838623\n",
            "Train step - Step 3280, Loss 0.08435969799757004\n",
            "Train step - Step 3290, Loss 0.09012205898761749\n",
            "Train epoch - Accuracy: 0.5930535455861071 Loss: 0.09213841419704744 Corrects: 4098\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.09230787307024002\n",
            "Train step - Step 3310, Loss 0.09127217531204224\n",
            "Train step - Step 3320, Loss 0.09364990144968033\n",
            "Train step - Step 3330, Loss 0.09400053322315216\n",
            "Train step - Step 3340, Loss 0.09690489619970322\n",
            "Train epoch - Accuracy: 0.5894356005788712 Loss: 0.09240532740195823 Corrects: 4073\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3350, Loss 0.09082670509815216\n",
            "Train step - Step 3360, Loss 0.09437683969736099\n",
            "Train step - Step 3370, Loss 0.09003962576389313\n",
            "Train step - Step 3380, Loss 0.09350434690713882\n",
            "Train step - Step 3390, Loss 0.0878114402294159\n",
            "Train step - Step 3400, Loss 0.09062673896551132\n",
            "Train epoch - Accuracy: 0.5890014471780028 Loss: 0.0921306534480255 Corrects: 4070\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3410, Loss 0.09432049840688705\n",
            "Train step - Step 3420, Loss 0.09506658464670181\n",
            "Train step - Step 3430, Loss 0.09168841689825058\n",
            "Train step - Step 3440, Loss 0.09091675281524658\n",
            "Train step - Step 3450, Loss 0.09351304918527603\n",
            "Train epoch - Accuracy: 0.5929088277858177 Loss: 0.09224242795738574 Corrects: 4097\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3460, Loss 0.0990225300192833\n",
            "Train step - Step 3470, Loss 0.0934145376086235\n",
            "Train step - Step 3480, Loss 0.08882951736450195\n",
            "Train step - Step 3490, Loss 0.0894523486495018\n",
            "Train step - Step 3500, Loss 0.09190603345632553\n",
            "Train epoch - Accuracy: 0.5917510853835022 Loss: 0.09222867269333124 Corrects: 4089\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3510, Loss 0.09370620548725128\n",
            "Train step - Step 3520, Loss 0.09003245085477829\n",
            "Train step - Step 3530, Loss 0.09113066643476486\n",
            "Train step - Step 3540, Loss 0.09079047292470932\n",
            "Train step - Step 3550, Loss 0.0918990969657898\n",
            "Train step - Step 3560, Loss 0.09224139899015427\n",
            "Train epoch - Accuracy: 0.5904486251808972 Loss: 0.09223910699316804 Corrects: 4080\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3570, Loss 0.09512646496295929\n",
            "Train step - Step 3580, Loss 0.09323427826166153\n",
            "Train step - Step 3590, Loss 0.09075681120157242\n",
            "Train step - Step 3600, Loss 0.09217449277639389\n",
            "Train step - Step 3610, Loss 0.09199606627225876\n",
            "Train epoch - Accuracy: 0.5937771345875543 Loss: 0.09198648385088971 Corrects: 4103\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3620, Loss 0.08928479999303818\n",
            "Train step - Step 3630, Loss 0.09301839768886566\n",
            "Train step - Step 3640, Loss 0.093904510140419\n",
            "Train step - Step 3650, Loss 0.0907837450504303\n",
            "Train step - Step 3660, Loss 0.0933242067694664\n",
            "Train step - Step 3670, Loss 0.09374459832906723\n",
            "Train epoch - Accuracy: 0.5917510853835022 Loss: 0.09219195760150377 Corrects: 4089\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3680, Loss 0.09080138057470322\n",
            "Train step - Step 3690, Loss 0.09078212827444077\n",
            "Train step - Step 3700, Loss 0.09580282866954803\n",
            "Train step - Step 3710, Loss 0.09386081993579865\n",
            "Train step - Step 3720, Loss 0.09413352608680725\n",
            "Train epoch - Accuracy: 0.5916063675832127 Loss: 0.09221243160074595 Corrects: 4088\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3730, Loss 0.09025690704584122\n",
            "Train step - Step 3740, Loss 0.09402637928724289\n",
            "Train step - Step 3750, Loss 0.09221351891756058\n",
            "Train step - Step 3760, Loss 0.08689987659454346\n",
            "Train step - Step 3770, Loss 0.0891665443778038\n",
            "Train epoch - Accuracy: 0.596671490593343 Loss: 0.09223090016246704 Corrects: 4123\n",
            "Training finished in 449.98201298713684 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52, 71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee329ed0>\n",
            "Constructing exemplars of class 71\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [37060, 21986, 45010, 3298, 15331, 11608, 29800, 10449, 48752, 35218, 36084, 8651, 42378, 43729, 46296, 46824, 31048, 37920, 16579, 46824, 19525, 5409, 33530, 24729, 18574]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee5d7590>\n",
            "Constructing exemplars of class 51\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [43046, 17658, 43362, 30484, 17658, 48047, 9829, 46159, 379, 47680, 7410, 23401, 1265, 34377, 12133, 8091, 28804, 6800, 47629, 16670, 10039, 44154, 2315, 29546, 28029]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1b86d0>\n",
            "Constructing exemplars of class 43\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [8508, 11864, 18563, 10870, 8745, 10845, 14223, 48970, 26077, 4508, 18590, 45857, 33725, 29262, 38954, 34845, 21985, 8686, 11988, 28105, 38193, 42633, 7545, 6588, 23217]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1a3490>\n",
            "Constructing exemplars of class 78\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [30048, 20522, 8841, 33627, 29612, 42037, 37001, 23046, 21795, 45034, 31093, 24015, 12747, 39558, 3002, 11739, 8382, 1811, 19728, 2146, 37575, 22083, 40108, 33525, 28872]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30006aa50>\n",
            "Constructing exemplars of class 74\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [36029, 37051, 39363, 42769, 1075, 18260, 4973, 36079, 44013, 46237, 20, 42581, 26836, 40916, 46774, 40453, 42582, 25336, 20611, 28842, 23788, 26445, 15829, 31828, 36749]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309dea810>\n",
            "Constructing exemplars of class 38\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [25166, 37333, 45325, 22049, 6324, 39316, 46556, 34485, 15537, 42905, 33337, 23233, 48229, 45909, 15417, 48734, 9326, 46103, 32053, 17930, 29220, 37752, 13238, 34215, 11868]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30005e590>\n",
            "Constructing exemplars of class 37\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [38632, 29530, 31192, 12157, 26645, 49047, 9279, 23168, 49321, 15982, 45715, 14500, 17778, 8229, 20162, 21756, 41525, 6807, 23078, 39965, 10289, 38426, 38081, 33675, 28901]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a224790>\n",
            "Constructing exemplars of class 29\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [677, 20097, 31016, 24016, 18684, 10355, 34102, 21911, 31523, 22621, 46026, 20166, 43105, 44082, 33855, 33938, 6291, 44695, 32440, 45032, 39593, 15765, 906, 17123, 12048]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a1a8c50>\n",
            "Constructing exemplars of class 48\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [22004, 38973, 44553, 26026, 1644, 42732, 6710, 31378, 45950, 30497, 29245, 15888, 36091, 31343, 44506, 15083, 35481, 45763, 41982, 34150, 36200, 39972, 5882, 9137, 34826]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee34cf10>\n",
            "Constructing exemplars of class 44\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [36940, 27405, 33957, 32228, 36211, 31247, 39821, 18538, 38578, 39668, 9748, 49826, 38667, 24035, 8139, 45649, 4698, 46055, 15575, 15900, 37629, 48691, 3503, 26472, 43945]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.09877540916204453\n",
            "Train step - Step 0, Loss 0.09734082221984863\n",
            "Train step - Step 0, Loss 0.09399760514497757\n",
            "Train step - Step 0, Loss 0.09361016005277634\n",
            "Train step - Step 0, Loss 0.08637242019176483\n",
            "Train step - Step 0, Loss 0.08344892412424088\n",
            "Train step - Step 0, Loss 0.07675279676914215\n",
            "Train step - Step 0, Loss 0.07961299270391464\n",
            "Train step - Step 0, Loss 0.08230573683977127\n",
            "Train step - Step 0, Loss 0.07563242316246033\n",
            "Train step - Step 0, Loss 0.07341064512729645\n",
            "Train step - Step 0, Loss 0.07241660356521606\n",
            "Train step - Step 0, Loss 0.08129765093326569\n",
            "Train step - Step 0, Loss 0.07854586094617844\n",
            "Train step - Step 0, Loss 0.07516530901193619\n",
            "Train step - Step 0, Loss 0.07156666368246078\n",
            "Train epoch - Accuracy: 0.28975 Loss: 0.0827785295844078 Corrects: 3477\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.07442236691713333\n",
            "Train step - Step 0, Loss 0.08087924122810364\n",
            "Train step - Step 0, Loss 0.07698391377925873\n",
            "Train step - Step 0, Loss 0.0699661523103714\n",
            "Train step - Step 0, Loss 0.07428374886512756\n",
            "Train step - Step 0, Loss 0.07703067362308502\n",
            "Train step - Step 0, Loss 0.0764211043715477\n",
            "Train step - Step 0, Loss 0.07834132760763168\n",
            "Train step - Step 0, Loss 0.07865222543478012\n",
            "Train step - Step 0, Loss 0.08094718307256699\n",
            "Train step - Step 0, Loss 0.07756346464157104\n",
            "Train step - Step 0, Loss 0.0754062831401825\n",
            "Train step - Step 0, Loss 0.07385621219873428\n",
            "Train step - Step 0, Loss 0.08026793599128723\n",
            "Train step - Step 0, Loss 0.07720062136650085\n",
            "Train step - Step 0, Loss 0.0746663436293602\n",
            "Train epoch - Accuracy: 0.29391666666666666 Loss: 0.07672889083623886 Corrects: 3527\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.07552045583724976\n",
            "Train step - Step 0, Loss 0.07339557260274887\n",
            "Train step - Step 0, Loss 0.07394568622112274\n",
            "Train step - Step 0, Loss 0.07649766653776169\n",
            "Train step - Step 0, Loss 0.07754600793123245\n",
            "Train step - Step 0, Loss 0.07600311189889908\n",
            "Train step - Step 0, Loss 0.08062558621168137\n",
            "Train step - Step 0, Loss 0.08183877170085907\n",
            "Train step - Step 0, Loss 0.07833488285541534\n",
            "Train step - Step 0, Loss 0.074700266122818\n",
            "Train step - Step 0, Loss 0.07343218475580215\n",
            "Train step - Step 0, Loss 0.0752045065164566\n",
            "Train step - Step 0, Loss 0.07173679769039154\n",
            "Train step - Step 0, Loss 0.07460048049688339\n",
            "Train step - Step 0, Loss 0.08132531493902206\n",
            "Train step - Step 0, Loss 0.0731314867734909\n",
            "Train epoch - Accuracy: 0.28883333333333333 Loss: 0.07618652617931367 Corrects: 3466\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.0702773928642273\n",
            "Train step - Step 0, Loss 0.0765402540564537\n",
            "Train step - Step 0, Loss 0.07909633964300156\n",
            "Train step - Step 0, Loss 0.07681073993444443\n",
            "Train step - Step 0, Loss 0.07221924513578415\n",
            "Train step - Step 0, Loss 0.07898662239313126\n",
            "Train step - Step 0, Loss 0.07682114839553833\n",
            "Train step - Step 0, Loss 0.08161154389381409\n",
            "Train step - Step 0, Loss 0.07574263215065002\n",
            "Train step - Step 0, Loss 0.0739024356007576\n",
            "Train step - Step 0, Loss 0.07071640342473984\n",
            "Train step - Step 0, Loss 0.08016245067119598\n",
            "Train step - Step 0, Loss 0.07398969680070877\n",
            "Train step - Step 0, Loss 0.07330761104822159\n",
            "Train step - Step 0, Loss 0.07305542379617691\n",
            "Train step - Step 0, Loss 0.07484652101993561\n",
            "Train epoch - Accuracy: 0.28733333333333333 Loss: 0.07552121698856354 Corrects: 3448\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.07803697884082794\n",
            "Train step - Step 0, Loss 0.07308512181043625\n",
            "Train step - Step 0, Loss 0.07649827748537064\n",
            "Train step - Step 0, Loss 0.07798101752996445\n",
            "Train step - Step 0, Loss 0.07462023198604584\n",
            "Train step - Step 0, Loss 0.07710034400224686\n",
            "Train step - Step 0, Loss 0.07522345334291458\n",
            "Train step - Step 0, Loss 0.08205214142799377\n",
            "Train step - Step 0, Loss 0.0744149386882782\n",
            "Train step - Step 0, Loss 0.0741196945309639\n",
            "Train step - Step 0, Loss 0.07738900929689407\n",
            "Train step - Step 0, Loss 0.07870077341794968\n",
            "Train step - Step 0, Loss 0.07204382866621017\n",
            "Train step - Step 0, Loss 0.06743566691875458\n",
            "Train step - Step 0, Loss 0.07423251867294312\n",
            "Train step - Step 0, Loss 0.07847323268651962\n",
            "Train epoch - Accuracy: 0.2886666666666667 Loss: 0.0756467050909996 Corrects: 3464\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.07905303686857224\n",
            "Train step - Step 0, Loss 0.07675158232450485\n",
            "Train step - Step 0, Loss 0.0740487277507782\n",
            "Train step - Step 0, Loss 0.07237259298563004\n",
            "Train step - Step 0, Loss 0.0697692483663559\n",
            "Train step - Step 0, Loss 0.07613089680671692\n",
            "Train step - Step 0, Loss 0.07552964240312576\n",
            "Train step - Step 0, Loss 0.07666017860174179\n",
            "Train step - Step 0, Loss 0.08238376677036285\n",
            "Train step - Step 0, Loss 0.07355352491140366\n",
            "Train step - Step 0, Loss 0.07251385599374771\n",
            "Train step - Step 0, Loss 0.08250265568494797\n",
            "Train step - Step 0, Loss 0.07318039238452911\n",
            "Train step - Step 0, Loss 0.07538250833749771\n",
            "Train step - Step 0, Loss 0.07649797946214676\n",
            "Train step - Step 0, Loss 0.07277238368988037\n",
            "Train epoch - Accuracy: 0.29 Loss: 0.07563605308532714 Corrects: 3480\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.07573099434375763\n",
            "Train step - Step 0, Loss 0.07820374518632889\n",
            "Train step - Step 0, Loss 0.07532873004674911\n",
            "Train step - Step 0, Loss 0.07462813705205917\n",
            "Train step - Step 0, Loss 0.07307114452123642\n",
            "Train step - Step 0, Loss 0.07677288353443146\n",
            "Train step - Step 0, Loss 0.07315980643033981\n",
            "Train step - Step 0, Loss 0.07685461640357971\n",
            "Train step - Step 0, Loss 0.06858961284160614\n",
            "Train step - Step 0, Loss 0.07276136428117752\n",
            "Train step - Step 0, Loss 0.07450166344642639\n",
            "Train step - Step 0, Loss 0.07658712565898895\n",
            "Train step - Step 0, Loss 0.07470663636922836\n",
            "Train step - Step 0, Loss 0.07806987315416336\n",
            "Train step - Step 0, Loss 0.0746791660785675\n",
            "Train step - Step 0, Loss 0.07453042268753052\n",
            "Train epoch - Accuracy: 0.2916666666666667 Loss: 0.07489452886581421 Corrects: 3500\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.07419923692941666\n",
            "Train step - Step 0, Loss 0.0766257494688034\n",
            "Train step - Step 0, Loss 0.07694575190544128\n",
            "Train step - Step 0, Loss 0.0707593709230423\n",
            "Train step - Step 0, Loss 0.0726238563656807\n",
            "Train step - Step 0, Loss 0.07386740297079086\n",
            "Train step - Step 0, Loss 0.07580610364675522\n",
            "Train step - Step 0, Loss 0.07630966603755951\n",
            "Train step - Step 0, Loss 0.0759485587477684\n",
            "Train step - Step 0, Loss 0.07574266195297241\n",
            "Train step - Step 0, Loss 0.07030577957630157\n",
            "Train step - Step 0, Loss 0.07861247658729553\n",
            "Train step - Step 0, Loss 0.07608125358819962\n",
            "Train step - Step 0, Loss 0.07280413806438446\n",
            "Train step - Step 0, Loss 0.07457747310400009\n",
            "Train step - Step 0, Loss 0.07526080310344696\n",
            "Train epoch - Accuracy: 0.29375 Loss: 0.07476783883571625 Corrects: 3525\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.0736822783946991\n",
            "Train step - Step 0, Loss 0.07420887798070908\n",
            "Train step - Step 0, Loss 0.0730777159333229\n",
            "Train step - Step 0, Loss 0.08142752945423126\n",
            "Train step - Step 0, Loss 0.07617990672588348\n",
            "Train step - Step 0, Loss 0.07327933609485626\n",
            "Train step - Step 0, Loss 0.07525374740362167\n",
            "Train step - Step 0, Loss 0.07306482642889023\n",
            "Train step - Step 0, Loss 0.07736939191818237\n",
            "Train step - Step 0, Loss 0.07615841925144196\n",
            "Train step - Step 0, Loss 0.07343317568302155\n",
            "Train step - Step 0, Loss 0.07506734132766724\n",
            "Train step - Step 0, Loss 0.07142602652311325\n",
            "Train step - Step 0, Loss 0.07233888655900955\n",
            "Train step - Step 0, Loss 0.0723235011100769\n",
            "Train step - Step 0, Loss 0.07537001371383667\n",
            "Train epoch - Accuracy: 0.28491666666666665 Loss: 0.07458542203903198 Corrects: 3419\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.07382765412330627\n",
            "Train step - Step 0, Loss 0.07429251074790955\n",
            "Train step - Step 0, Loss 0.06964904814958572\n",
            "Train step - Step 0, Loss 0.07469145953655243\n",
            "Train step - Step 0, Loss 0.07450880110263824\n",
            "Train step - Step 0, Loss 0.07422453165054321\n",
            "Train step - Step 0, Loss 0.07513593882322311\n",
            "Train step - Step 0, Loss 0.07617124170064926\n",
            "Train step - Step 0, Loss 0.07468558847904205\n",
            "Train step - Step 0, Loss 0.07856253534555435\n",
            "Train step - Step 0, Loss 0.07115315645933151\n",
            "Train step - Step 0, Loss 0.07596044987440109\n",
            "Train step - Step 0, Loss 0.07242914289236069\n",
            "Train step - Step 0, Loss 0.07611661404371262\n",
            "Train step - Step 0, Loss 0.07650129497051239\n",
            "Train step - Step 0, Loss 0.07838305830955505\n",
            "Train epoch - Accuracy: 0.29233333333333333 Loss: 0.07468156027793885 Corrects: 3508\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.071744404733181\n",
            "Train step - Step 0, Loss 0.07330735772848129\n",
            "Train step - Step 0, Loss 0.07492842525243759\n",
            "Train step - Step 0, Loss 0.07648732513189316\n",
            "Train step - Step 0, Loss 0.07573319226503372\n",
            "Train step - Step 0, Loss 0.0711827278137207\n",
            "Train step - Step 0, Loss 0.0706261545419693\n",
            "Train step - Step 0, Loss 0.07287807762622833\n",
            "Train step - Step 0, Loss 0.07068834453821182\n",
            "Train step - Step 0, Loss 0.07557988911867142\n",
            "Train step - Step 0, Loss 0.07334128022193909\n",
            "Train step - Step 0, Loss 0.07709144800901413\n",
            "Train step - Step 0, Loss 0.07506133615970612\n",
            "Train step - Step 0, Loss 0.07649114727973938\n",
            "Train step - Step 0, Loss 0.07339153438806534\n",
            "Train step - Step 0, Loss 0.08013715595006943\n",
            "Train epoch - Accuracy: 0.28925 Loss: 0.0741515755057335 Corrects: 3471\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.07020944356918335\n",
            "Train step - Step 0, Loss 0.0780777558684349\n",
            "Train step - Step 0, Loss 0.07082199305295944\n",
            "Train step - Step 0, Loss 0.07725803554058075\n",
            "Train step - Step 0, Loss 0.07258298993110657\n",
            "Train step - Step 0, Loss 0.07380971312522888\n",
            "Train step - Step 0, Loss 0.07725293189287186\n",
            "Train step - Step 0, Loss 0.07328170537948608\n",
            "Train step - Step 0, Loss 0.07445148378610611\n",
            "Train step - Step 0, Loss 0.07331505417823792\n",
            "Train step - Step 0, Loss 0.07385188341140747\n",
            "Train step - Step 0, Loss 0.07065935432910919\n",
            "Train step - Step 0, Loss 0.07225263863801956\n",
            "Train step - Step 0, Loss 0.07243175804615021\n",
            "Train step - Step 0, Loss 0.07784907519817352\n",
            "Train step - Step 0, Loss 0.07360974699258804\n",
            "Train epoch - Accuracy: 0.2881666666666667 Loss: 0.0738631621003151 Corrects: 3458\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.07662096619606018\n",
            "Train step - Step 0, Loss 0.0718349814414978\n",
            "Train step - Step 0, Loss 0.07131831347942352\n",
            "Train step - Step 0, Loss 0.07641948759555817\n",
            "Train step - Step 0, Loss 0.07257404923439026\n",
            "Train step - Step 0, Loss 0.0762195959687233\n",
            "Train step - Step 0, Loss 0.07010868936777115\n",
            "Train step - Step 0, Loss 0.07069259881973267\n",
            "Train step - Step 0, Loss 0.07517311722040176\n",
            "Train step - Step 0, Loss 0.073872409760952\n",
            "Train step - Step 0, Loss 0.07417266070842743\n",
            "Train step - Step 0, Loss 0.07227452844381332\n",
            "Train step - Step 0, Loss 0.07163622230291367\n",
            "Train step - Step 0, Loss 0.07707240432500839\n",
            "Train step - Step 0, Loss 0.06983592361211777\n",
            "Train step - Step 0, Loss 0.07770467549562454\n",
            "Train epoch - Accuracy: 0.29283333333333333 Loss: 0.07349704772233963 Corrects: 3514\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.07351626455783844\n",
            "Train step - Step 0, Loss 0.07148738950490952\n",
            "Train step - Step 0, Loss 0.07625465840101242\n",
            "Train step - Step 0, Loss 0.07404310256242752\n",
            "Train step - Step 0, Loss 0.07341452687978745\n",
            "Train step - Step 0, Loss 0.07255540043115616\n",
            "Train step - Step 0, Loss 0.07437163591384888\n",
            "Train step - Step 0, Loss 0.07287190109491348\n",
            "Train step - Step 0, Loss 0.07546485960483551\n",
            "Train step - Step 0, Loss 0.07065816223621368\n",
            "Train step - Step 0, Loss 0.07543115317821503\n",
            "Train step - Step 0, Loss 0.07239391654729843\n",
            "Train step - Step 0, Loss 0.07688204944133759\n",
            "Train step - Step 0, Loss 0.07483174651861191\n",
            "Train step - Step 0, Loss 0.07115091383457184\n",
            "Train step - Step 0, Loss 0.07772134244441986\n",
            "Train epoch - Accuracy: 0.28625 Loss: 0.07384982526302337 Corrects: 3435\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.07158276438713074\n",
            "Train step - Step 0, Loss 0.07364426553249359\n",
            "Train step - Step 0, Loss 0.07292760908603668\n",
            "Train step - Step 0, Loss 0.07597190141677856\n",
            "Train step - Step 0, Loss 0.07333441823720932\n",
            "Train step - Step 0, Loss 0.07505037635564804\n",
            "Train step - Step 0, Loss 0.0701078474521637\n",
            "Train step - Step 0, Loss 0.07692374289035797\n",
            "Train step - Step 0, Loss 0.07359204441308975\n",
            "Train step - Step 0, Loss 0.07038147002458572\n",
            "Train step - Step 0, Loss 0.0756974145770073\n",
            "Train step - Step 0, Loss 0.07911887764930725\n",
            "Train step - Step 0, Loss 0.06786084175109863\n",
            "Train step - Step 0, Loss 0.07490997761487961\n",
            "Train step - Step 0, Loss 0.06926870346069336\n",
            "Train step - Step 0, Loss 0.07635881751775742\n",
            "Train epoch - Accuracy: 0.293 Loss: 0.07347817701101303 Corrects: 3516\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.0721295103430748\n",
            "Train step - Step 0, Loss 0.07532753050327301\n",
            "Train step - Step 0, Loss 0.07310675829648972\n",
            "Train step - Step 0, Loss 0.07215234637260437\n",
            "Train step - Step 0, Loss 0.07378513365983963\n",
            "Train step - Step 0, Loss 0.07444534450769424\n",
            "Train step - Step 0, Loss 0.07472807914018631\n",
            "Train step - Step 0, Loss 0.07547089457511902\n",
            "Train step - Step 0, Loss 0.07215779274702072\n",
            "Train step - Step 0, Loss 0.06996229290962219\n",
            "Train step - Step 0, Loss 0.07273437082767487\n",
            "Train step - Step 0, Loss 0.07947205007076263\n",
            "Train step - Step 0, Loss 0.07018285244703293\n",
            "Train step - Step 0, Loss 0.07640509307384491\n",
            "Train step - Step 0, Loss 0.07273877412080765\n",
            "Train step - Step 0, Loss 0.07432813942432404\n",
            "Train epoch - Accuracy: 0.283 Loss: 0.07368025028705597 Corrects: 3396\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.07277459651231766\n",
            "Train step - Step 0, Loss 0.07378831505775452\n",
            "Train step - Step 0, Loss 0.07613416016101837\n",
            "Train step - Step 0, Loss 0.074458047747612\n",
            "Train step - Step 0, Loss 0.06907782703638077\n",
            "Train step - Step 0, Loss 0.07334072887897491\n",
            "Train step - Step 0, Loss 0.0741591602563858\n",
            "Train step - Step 0, Loss 0.07094819098711014\n",
            "Train step - Step 0, Loss 0.07464445382356644\n",
            "Train step - Step 0, Loss 0.0759086161851883\n",
            "Train step - Step 0, Loss 0.07412450760602951\n",
            "Train step - Step 0, Loss 0.07219198346138\n",
            "Train step - Step 0, Loss 0.06787429004907608\n",
            "Train step - Step 0, Loss 0.07158329337835312\n",
            "Train step - Step 0, Loss 0.07895730435848236\n",
            "Train step - Step 0, Loss 0.07123316824436188\n",
            "Train epoch - Accuracy: 0.28525 Loss: 0.0732471171617508 Corrects: 3423\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.07375799119472504\n",
            "Train step - Step 0, Loss 0.07227230817079544\n",
            "Train step - Step 0, Loss 0.0733102411031723\n",
            "Train step - Step 0, Loss 0.07337182760238647\n",
            "Train step - Step 0, Loss 0.07868930697441101\n",
            "Train step - Step 0, Loss 0.07317432016134262\n",
            "Train step - Step 0, Loss 0.06995284557342529\n",
            "Train step - Step 0, Loss 0.07255607098340988\n",
            "Train step - Step 0, Loss 0.07181577384471893\n",
            "Train step - Step 0, Loss 0.07102524489164352\n",
            "Train step - Step 0, Loss 0.07229354977607727\n",
            "Train step - Step 0, Loss 0.0740157812833786\n",
            "Train step - Step 0, Loss 0.07204905152320862\n",
            "Train step - Step 0, Loss 0.07610215246677399\n",
            "Train step - Step 0, Loss 0.07877763360738754\n",
            "Train step - Step 0, Loss 0.07226893305778503\n",
            "Train epoch - Accuracy: 0.28458333333333335 Loss: 0.07349325966835021 Corrects: 3415\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.07507261633872986\n",
            "Train step - Step 0, Loss 0.07328822463750839\n",
            "Train step - Step 0, Loss 0.07641180604696274\n",
            "Train step - Step 0, Loss 0.07194918394088745\n",
            "Train step - Step 0, Loss 0.07321397960186005\n",
            "Train step - Step 0, Loss 0.06943903118371964\n",
            "Train step - Step 0, Loss 0.07279617339372635\n",
            "Train step - Step 0, Loss 0.0733599066734314\n",
            "Train step - Step 0, Loss 0.07580385357141495\n",
            "Train step - Step 0, Loss 0.07214365154504776\n",
            "Train step - Step 0, Loss 0.07129397243261337\n",
            "Train step - Step 0, Loss 0.06891912966966629\n",
            "Train step - Step 0, Loss 0.07367466390132904\n",
            "Train step - Step 0, Loss 0.07708688080310822\n",
            "Train step - Step 0, Loss 0.07900684326887131\n",
            "Train step - Step 0, Loss 0.07169497013092041\n",
            "Train epoch - Accuracy: 0.2911666666666667 Loss: 0.07348923349380493 Corrects: 3494\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.07467012107372284\n",
            "Train step - Step 0, Loss 0.0756499245762825\n",
            "Train step - Step 0, Loss 0.07461031526327133\n",
            "Train step - Step 0, Loss 0.0746937021613121\n",
            "Train step - Step 0, Loss 0.07696911692619324\n",
            "Train step - Step 0, Loss 0.07657422870397568\n",
            "Train step - Step 0, Loss 0.07121221721172333\n",
            "Train step - Step 0, Loss 0.06966520845890045\n",
            "Train step - Step 0, Loss 0.07378353923559189\n",
            "Train step - Step 0, Loss 0.07197675853967667\n",
            "Train step - Step 0, Loss 0.0752442255616188\n",
            "Train step - Step 0, Loss 0.0696214884519577\n",
            "Train step - Step 0, Loss 0.06892761588096619\n",
            "Train step - Step 0, Loss 0.07339965552091599\n",
            "Train step - Step 0, Loss 0.07668548077344894\n",
            "Train step - Step 0, Loss 0.07345172017812729\n",
            "Train epoch - Accuracy: 0.2921666666666667 Loss: 0.07357381910085678 Corrects: 3506\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.07440261542797089\n",
            "Train step - Step 0, Loss 0.07539709657430649\n",
            "Train step - Step 0, Loss 0.07909714430570602\n",
            "Train step - Step 0, Loss 0.07225483655929565\n",
            "Train step - Step 0, Loss 0.07327619940042496\n",
            "Train step - Step 0, Loss 0.07493523508310318\n",
            "Train step - Step 0, Loss 0.07319796830415726\n",
            "Train step - Step 0, Loss 0.0717523992061615\n",
            "Train step - Step 0, Loss 0.0711759626865387\n",
            "Train step - Step 0, Loss 0.07122228294610977\n",
            "Train step - Step 0, Loss 0.06897202134132385\n",
            "Train step - Step 0, Loss 0.0699705183506012\n",
            "Train step - Step 0, Loss 0.07328146696090698\n",
            "Train step - Step 0, Loss 0.07202161103487015\n",
            "Train step - Step 0, Loss 0.07423250377178192\n",
            "Train step - Step 0, Loss 0.07765285670757294\n",
            "Train epoch - Accuracy: 0.29225 Loss: 0.07319826543331147 Corrects: 3507\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.07760661095380783\n",
            "Train step - Step 0, Loss 0.06905051320791245\n",
            "Train step - Step 0, Loss 0.07182592153549194\n",
            "Train step - Step 0, Loss 0.0700639933347702\n",
            "Train step - Step 0, Loss 0.07256696373224258\n",
            "Train step - Step 0, Loss 0.07553689181804657\n",
            "Train step - Step 0, Loss 0.07413718104362488\n",
            "Train step - Step 0, Loss 0.06974940747022629\n",
            "Train step - Step 0, Loss 0.07709752023220062\n",
            "Train step - Step 0, Loss 0.07635978609323502\n",
            "Train step - Step 0, Loss 0.07175330072641373\n",
            "Train step - Step 0, Loss 0.07349076867103577\n",
            "Train step - Step 0, Loss 0.07026626914739609\n",
            "Train step - Step 0, Loss 0.07453974336385727\n",
            "Train step - Step 0, Loss 0.0740780383348465\n",
            "Train step - Step 0, Loss 0.07045909017324448\n",
            "Train epoch - Accuracy: 0.289 Loss: 0.07309822982549667 Corrects: 3468\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.07308188825845718\n",
            "Train step - Step 0, Loss 0.07251705229282379\n",
            "Train step - Step 0, Loss 0.07271156460046768\n",
            "Train step - Step 0, Loss 0.07221920043230057\n",
            "Train step - Step 0, Loss 0.07394935190677643\n",
            "Train step - Step 0, Loss 0.0774865373969078\n",
            "Train step - Step 0, Loss 0.07372316718101501\n",
            "Train step - Step 0, Loss 0.07270102947950363\n",
            "Train step - Step 0, Loss 0.07455042004585266\n",
            "Train step - Step 0, Loss 0.07161253690719604\n",
            "Train step - Step 0, Loss 0.0787365660071373\n",
            "Train step - Step 0, Loss 0.07461317628622055\n",
            "Train step - Step 0, Loss 0.07550479471683502\n",
            "Train step - Step 0, Loss 0.07169714570045471\n",
            "Train step - Step 0, Loss 0.07433005422353745\n",
            "Train step - Step 0, Loss 0.07668741792440414\n",
            "Train epoch - Accuracy: 0.29 Loss: 0.07407130378484726 Corrects: 3480\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.07743759453296661\n",
            "Train step - Step 0, Loss 0.07025931775569916\n",
            "Train step - Step 0, Loss 0.07320617139339447\n",
            "Train step - Step 0, Loss 0.07480663806200027\n",
            "Train step - Step 0, Loss 0.07396455109119415\n",
            "Train step - Step 0, Loss 0.07491739839315414\n",
            "Train step - Step 0, Loss 0.06865300238132477\n",
            "Train step - Step 0, Loss 0.07599107921123505\n",
            "Train step - Step 0, Loss 0.06851495802402496\n",
            "Train step - Step 0, Loss 0.0756349116563797\n",
            "Train step - Step 0, Loss 0.074127696454525\n",
            "Train step - Step 0, Loss 0.0730818435549736\n",
            "Train step - Step 0, Loss 0.07208665460348129\n",
            "Train step - Step 0, Loss 0.07539164274930954\n",
            "Train step - Step 0, Loss 0.07068108767271042\n",
            "Train step - Step 0, Loss 0.07595740258693695\n",
            "Train epoch - Accuracy: 0.2885 Loss: 0.07335858714580536 Corrects: 3462\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.07371965050697327\n",
            "Train step - Step 0, Loss 0.07123063504695892\n",
            "Train step - Step 0, Loss 0.07329443842172623\n",
            "Train step - Step 0, Loss 0.07292775064706802\n",
            "Train step - Step 0, Loss 0.07151876389980316\n",
            "Train step - Step 0, Loss 0.07610165327787399\n",
            "Train step - Step 0, Loss 0.0694577693939209\n",
            "Train step - Step 0, Loss 0.07545827329158783\n",
            "Train step - Step 0, Loss 0.07615744322538376\n",
            "Train step - Step 0, Loss 0.07318403571844101\n",
            "Train step - Step 0, Loss 0.07571787387132645\n",
            "Train step - Step 0, Loss 0.07744293659925461\n",
            "Train step - Step 0, Loss 0.07506509870290756\n",
            "Train step - Step 0, Loss 0.07021768391132355\n",
            "Train step - Step 0, Loss 0.07257343083620071\n",
            "Train step - Step 0, Loss 0.07214994728565216\n",
            "Train epoch - Accuracy: 0.28908333333333336 Loss: 0.07354631388187409 Corrects: 3469\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.0723348930478096\n",
            "Train step - Step 0, Loss 0.07541782408952713\n",
            "Train step - Step 0, Loss 0.07505340874195099\n",
            "Train step - Step 0, Loss 0.07230187952518463\n",
            "Train step - Step 0, Loss 0.07282008975744247\n",
            "Train step - Step 0, Loss 0.07601481676101685\n",
            "Train step - Step 0, Loss 0.07472705096006393\n",
            "Train step - Step 0, Loss 0.0667702853679657\n",
            "Train step - Step 0, Loss 0.07443634420633316\n",
            "Train step - Step 0, Loss 0.0763997733592987\n",
            "Train step - Step 0, Loss 0.07335762679576874\n",
            "Train step - Step 0, Loss 0.07258247584104538\n",
            "Train step - Step 0, Loss 0.07100092619657516\n",
            "Train step - Step 0, Loss 0.07417377084493637\n",
            "Train step - Step 0, Loss 0.07228098064661026\n",
            "Train step - Step 0, Loss 0.07473070919513702\n",
            "Train epoch - Accuracy: 0.28941666666666666 Loss: 0.07336824572086334 Corrects: 3473\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.0699639767408371\n",
            "Train step - Step 0, Loss 0.07367171347141266\n",
            "Train step - Step 0, Loss 0.07513216137886047\n",
            "Train step - Step 0, Loss 0.07100820541381836\n",
            "Train step - Step 0, Loss 0.07363905012607574\n",
            "Train step - Step 0, Loss 0.06920965015888214\n",
            "Train step - Step 0, Loss 0.07075905054807663\n",
            "Train step - Step 0, Loss 0.06966158002614975\n",
            "Train step - Step 0, Loss 0.07279468327760696\n",
            "Train step - Step 0, Loss 0.07220148295164108\n",
            "Train step - Step 0, Loss 0.0766618475317955\n",
            "Train step - Step 0, Loss 0.07418952137231827\n",
            "Train step - Step 0, Loss 0.07084381580352783\n",
            "Train step - Step 0, Loss 0.07661109417676926\n",
            "Train step - Step 0, Loss 0.07948113232851028\n",
            "Train step - Step 0, Loss 0.07389754801988602\n",
            "Train epoch - Accuracy: 0.2940833333333333 Loss: 0.07308895570039749 Corrects: 3529\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.07162854075431824\n",
            "Train step - Step 0, Loss 0.07216174155473709\n",
            "Train step - Step 0, Loss 0.07873993366956711\n",
            "Train step - Step 0, Loss 0.07035507261753082\n",
            "Train step - Step 0, Loss 0.07609687000513077\n",
            "Train step - Step 0, Loss 0.07596001774072647\n",
            "Train step - Step 0, Loss 0.0724979117512703\n",
            "Train step - Step 0, Loss 0.07000461220741272\n",
            "Train step - Step 0, Loss 0.07349971681833267\n",
            "Train step - Step 0, Loss 0.0723075121641159\n",
            "Train step - Step 0, Loss 0.0707630068063736\n",
            "Train step - Step 0, Loss 0.07304483652114868\n",
            "Train step - Step 0, Loss 0.07411664724349976\n",
            "Train step - Step 0, Loss 0.07096417993307114\n",
            "Train step - Step 0, Loss 0.07525637000799179\n",
            "Train step - Step 0, Loss 0.07496242970228195\n",
            "Train epoch - Accuracy: 0.29183333333333333 Loss: 0.07323190325498581 Corrects: 3502\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.0758248120546341\n",
            "Train step - Step 0, Loss 0.0721433013677597\n",
            "Train step - Step 0, Loss 0.07482043653726578\n",
            "Train step - Step 0, Loss 0.07173611968755722\n",
            "Train step - Step 0, Loss 0.07280450314283371\n",
            "Train step - Step 0, Loss 0.07676710188388824\n",
            "Train step - Step 0, Loss 0.07351507246494293\n",
            "Train step - Step 0, Loss 0.07251156121492386\n",
            "Train step - Step 0, Loss 0.07046877592802048\n",
            "Train step - Step 0, Loss 0.07278258353471756\n",
            "Train step - Step 0, Loss 0.07060394436120987\n",
            "Train step - Step 0, Loss 0.06990396231412888\n",
            "Train step - Step 0, Loss 0.0747002512216568\n",
            "Train step - Step 0, Loss 0.07479587197303772\n",
            "Train step - Step 0, Loss 0.0684719979763031\n",
            "Train step - Step 0, Loss 0.07572408020496368\n",
            "Train epoch - Accuracy: 0.28583333333333333 Loss: 0.07290738213062287 Corrects: 3430\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.0712161436676979\n",
            "Train step - Step 0, Loss 0.0729561522603035\n",
            "Train step - Step 0, Loss 0.07244215905666351\n",
            "Train step - Step 0, Loss 0.0748639926314354\n",
            "Train step - Step 0, Loss 0.07144468277692795\n",
            "Train step - Step 0, Loss 0.07082568854093552\n",
            "Train step - Step 0, Loss 0.08005277812480927\n",
            "Train step - Step 0, Loss 0.0711834654211998\n",
            "Train step - Step 0, Loss 0.07117422670125961\n",
            "Train step - Step 0, Loss 0.0697091668844223\n",
            "Train step - Step 0, Loss 0.06992842257022858\n",
            "Train step - Step 0, Loss 0.07122647762298584\n",
            "Train step - Step 0, Loss 0.07434653490781784\n",
            "Train step - Step 0, Loss 0.0701339915394783\n",
            "Train step - Step 0, Loss 0.07130057364702225\n",
            "Train step - Step 0, Loss 0.07163725793361664\n",
            "Train epoch - Accuracy: 0.28741666666666665 Loss: 0.07216497552394867 Corrects: 3449\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.07323136925697327\n",
            "Train step - Step 0, Loss 0.06871094554662704\n",
            "Train step - Step 0, Loss 0.07079439610242844\n",
            "Train step - Step 0, Loss 0.0725584551692009\n",
            "Train step - Step 0, Loss 0.07195393741130829\n",
            "Train step - Step 0, Loss 0.06794741004705429\n",
            "Train step - Step 0, Loss 0.07537246495485306\n",
            "Train step - Step 0, Loss 0.07419953495264053\n",
            "Train step - Step 0, Loss 0.07154332846403122\n",
            "Train step - Step 0, Loss 0.0753604918718338\n",
            "Train step - Step 0, Loss 0.0797220915555954\n",
            "Train step - Step 0, Loss 0.07645677030086517\n",
            "Train step - Step 0, Loss 0.07411346584558487\n",
            "Train step - Step 0, Loss 0.07549121230840683\n",
            "Train step - Step 0, Loss 0.07327932864427567\n",
            "Train step - Step 0, Loss 0.07223008573055267\n",
            "Train epoch - Accuracy: 0.2828333333333333 Loss: 0.07333625638484954 Corrects: 3394\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.0742553249001503\n",
            "Train step - Step 0, Loss 0.07191513478755951\n",
            "Train step - Step 0, Loss 0.06959132850170135\n",
            "Train step - Step 0, Loss 0.07043512910604477\n",
            "Train step - Step 0, Loss 0.07787773013114929\n",
            "Train step - Step 0, Loss 0.0699949860572815\n",
            "Train step - Step 0, Loss 0.07110283523797989\n",
            "Train step - Step 0, Loss 0.07391700148582458\n",
            "Train step - Step 0, Loss 0.0741359069943428\n",
            "Train step - Step 0, Loss 0.0764228031039238\n",
            "Train step - Step 0, Loss 0.07240818440914154\n",
            "Train step - Step 0, Loss 0.07072708010673523\n",
            "Train step - Step 0, Loss 0.07301308959722519\n",
            "Train step - Step 0, Loss 0.07114142179489136\n",
            "Train step - Step 0, Loss 0.07302204519510269\n",
            "Train step - Step 0, Loss 0.07238007336854935\n",
            "Train epoch - Accuracy: 0.28825 Loss: 0.07265264302492142 Corrects: 3459\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.07100862264633179\n",
            "Train step - Step 0, Loss 0.07389743626117706\n",
            "Train step - Step 0, Loss 0.0739312544465065\n",
            "Train step - Step 0, Loss 0.07334870100021362\n",
            "Train step - Step 0, Loss 0.076764315366745\n",
            "Train step - Step 0, Loss 0.07232758402824402\n",
            "Train step - Step 0, Loss 0.07700953632593155\n",
            "Train step - Step 0, Loss 0.07469262182712555\n",
            "Train step - Step 0, Loss 0.07009104639291763\n",
            "Train step - Step 0, Loss 0.0726189911365509\n",
            "Train step - Step 0, Loss 0.07233037054538727\n",
            "Train step - Step 0, Loss 0.07361160963773727\n",
            "Train step - Step 0, Loss 0.07393141090869904\n",
            "Train step - Step 0, Loss 0.06975801289081573\n",
            "Train step - Step 0, Loss 0.07324723154306412\n",
            "Train step - Step 0, Loss 0.07737740874290466\n",
            "Train epoch - Accuracy: 0.29158333333333336 Loss: 0.0734034960269928 Corrects: 3499\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.07791367173194885\n",
            "Train step - Step 0, Loss 0.07271018624305725\n",
            "Train step - Step 0, Loss 0.07509646564722061\n",
            "Train step - Step 0, Loss 0.07122769951820374\n",
            "Train step - Step 0, Loss 0.07439683377742767\n",
            "Train step - Step 0, Loss 0.07416388392448425\n",
            "Train step - Step 0, Loss 0.07156489044427872\n",
            "Train step - Step 0, Loss 0.07234947383403778\n",
            "Train step - Step 0, Loss 0.07240645587444305\n",
            "Train step - Step 0, Loss 0.0751548558473587\n",
            "Train step - Step 0, Loss 0.07328043133020401\n",
            "Train step - Step 0, Loss 0.06803607940673828\n",
            "Train step - Step 0, Loss 0.07333091646432877\n",
            "Train step - Step 0, Loss 0.07257364690303802\n",
            "Train step - Step 0, Loss 0.06999830901622772\n",
            "Train step - Step 0, Loss 0.07182237505912781\n",
            "Train epoch - Accuracy: 0.27775 Loss: 0.07290193819999695 Corrects: 3333\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.06932967156171799\n",
            "Train step - Step 0, Loss 0.0756848081946373\n",
            "Train step - Step 0, Loss 0.06906845420598984\n",
            "Train step - Step 0, Loss 0.07588516920804977\n",
            "Train step - Step 0, Loss 0.07339303195476532\n",
            "Train step - Step 0, Loss 0.07233608514070511\n",
            "Train step - Step 0, Loss 0.07208149880170822\n",
            "Train step - Step 0, Loss 0.0716700628399849\n",
            "Train step - Step 0, Loss 0.07426683604717255\n",
            "Train step - Step 0, Loss 0.07531067728996277\n",
            "Train step - Step 0, Loss 0.07531186938285828\n",
            "Train step - Step 0, Loss 0.07310586422681808\n",
            "Train step - Step 0, Loss 0.07239418476819992\n",
            "Train step - Step 0, Loss 0.07137979567050934\n",
            "Train step - Step 0, Loss 0.07003726065158844\n",
            "Train step - Step 0, Loss 0.07232025265693665\n",
            "Train epoch - Accuracy: 0.2915 Loss: 0.0727331473827362 Corrects: 3498\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.07532820105552673\n",
            "Train step - Step 0, Loss 0.07541508972644806\n",
            "Train step - Step 0, Loss 0.07581953704357147\n",
            "Train step - Step 0, Loss 0.07472353428602219\n",
            "Train step - Step 0, Loss 0.0719928964972496\n",
            "Train step - Step 0, Loss 0.0754295140504837\n",
            "Train step - Step 0, Loss 0.07427460700273514\n",
            "Train step - Step 0, Loss 0.07221166789531708\n",
            "Train step - Step 0, Loss 0.06889865547418594\n",
            "Train step - Step 0, Loss 0.069517120718956\n",
            "Train step - Step 0, Loss 0.07216674089431763\n",
            "Train step - Step 0, Loss 0.07605203241109848\n",
            "Train step - Step 0, Loss 0.07590948790311813\n",
            "Train step - Step 0, Loss 0.07179329544305801\n",
            "Train step - Step 0, Loss 0.07532776147127151\n",
            "Train step - Step 0, Loss 0.06852326542139053\n",
            "Train epoch - Accuracy: 0.2945833333333333 Loss: 0.07345197969675064 Corrects: 3535\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.07444941252470016\n",
            "Train step - Step 0, Loss 0.07342206686735153\n",
            "Train step - Step 0, Loss 0.07405198365449905\n",
            "Train step - Step 0, Loss 0.06823752820491791\n",
            "Train step - Step 0, Loss 0.07288029044866562\n",
            "Train step - Step 0, Loss 0.07047317922115326\n",
            "Train step - Step 0, Loss 0.0718202292919159\n",
            "Train step - Step 0, Loss 0.07588353753089905\n",
            "Train step - Step 0, Loss 0.07204745709896088\n",
            "Train step - Step 0, Loss 0.07218827307224274\n",
            "Train step - Step 0, Loss 0.07681970298290253\n",
            "Train step - Step 0, Loss 0.06956985592842102\n",
            "Train step - Step 0, Loss 0.06781341880559921\n",
            "Train step - Step 0, Loss 0.07264357060194016\n",
            "Train step - Step 0, Loss 0.07358834147453308\n",
            "Train step - Step 0, Loss 0.07240679860115051\n",
            "Train epoch - Accuracy: 0.28683333333333333 Loss: 0.07239315819740295 Corrects: 3442\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.072197824716568\n",
            "Train step - Step 0, Loss 0.07543078809976578\n",
            "Train step - Step 0, Loss 0.07516980916261673\n",
            "Train step - Step 0, Loss 0.07105155289173126\n",
            "Train step - Step 0, Loss 0.07502701878547668\n",
            "Train step - Step 0, Loss 0.07466750591993332\n",
            "Train step - Step 0, Loss 0.07016873359680176\n",
            "Train step - Step 0, Loss 0.07389470934867859\n",
            "Train step - Step 0, Loss 0.07001998275518417\n",
            "Train step - Step 0, Loss 0.07097174972295761\n",
            "Train step - Step 0, Loss 0.07410026341676712\n",
            "Train step - Step 0, Loss 0.07416041195392609\n",
            "Train step - Step 0, Loss 0.07064557075500488\n",
            "Train step - Step 0, Loss 0.0761495903134346\n",
            "Train step - Step 0, Loss 0.06964410841464996\n",
            "Train step - Step 0, Loss 0.07286819815635681\n",
            "Train epoch - Accuracy: 0.28558333333333336 Loss: 0.07288590359687805 Corrects: 3427\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.07085549831390381\n",
            "Train step - Step 0, Loss 0.07250373810529709\n",
            "Train step - Step 0, Loss 0.06751882284879684\n",
            "Train step - Step 0, Loss 0.07242201268672943\n",
            "Train step - Step 0, Loss 0.07132688164710999\n",
            "Train step - Step 0, Loss 0.07285096496343613\n",
            "Train step - Step 0, Loss 0.07228460162878036\n",
            "Train step - Step 0, Loss 0.0739600881934166\n",
            "Train step - Step 0, Loss 0.06944739073514938\n",
            "Train step - Step 0, Loss 0.07386089861392975\n",
            "Train step - Step 0, Loss 0.07384644448757172\n",
            "Train step - Step 0, Loss 0.07419592142105103\n",
            "Train step - Step 0, Loss 0.07049298286437988\n",
            "Train step - Step 0, Loss 0.07619443535804749\n",
            "Train step - Step 0, Loss 0.08043864369392395\n",
            "Train step - Step 0, Loss 0.07031186670064926\n",
            "Train epoch - Accuracy: 0.29133333333333333 Loss: 0.07271323150396347 Corrects: 3496\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.07416829466819763\n",
            "Train step - Step 0, Loss 0.07193192094564438\n",
            "Train step - Step 0, Loss 0.07220329344272614\n",
            "Train step - Step 0, Loss 0.07271336019039154\n",
            "Train step - Step 0, Loss 0.07641913741827011\n",
            "Train step - Step 0, Loss 0.06884141266345978\n",
            "Train step - Step 0, Loss 0.0747438594698906\n",
            "Train step - Step 0, Loss 0.07081528753042221\n",
            "Train step - Step 0, Loss 0.06710413098335266\n",
            "Train step - Step 0, Loss 0.07747974246740341\n",
            "Train step - Step 0, Loss 0.07073602080345154\n",
            "Train step - Step 0, Loss 0.07264579832553864\n",
            "Train step - Step 0, Loss 0.07073787599802017\n",
            "Train step - Step 0, Loss 0.07226985692977905\n",
            "Train step - Step 0, Loss 0.07308415323495865\n",
            "Train step - Step 0, Loss 0.07734411209821701\n",
            "Train epoch - Accuracy: 0.29 Loss: 0.0725909897685051 Corrects: 3480\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.06810477375984192\n",
            "Train step - Step 0, Loss 0.07164034247398376\n",
            "Train step - Step 0, Loss 0.07470408082008362\n",
            "Train step - Step 0, Loss 0.07265777885913849\n",
            "Train step - Step 0, Loss 0.06820561736822128\n",
            "Train step - Step 0, Loss 0.07213368266820908\n",
            "Train step - Step 0, Loss 0.07133326679468155\n",
            "Train step - Step 0, Loss 0.0758863314986229\n",
            "Train step - Step 0, Loss 0.07379291951656342\n",
            "Train step - Step 0, Loss 0.07231984287500381\n",
            "Train step - Step 0, Loss 0.07478143274784088\n",
            "Train step - Step 0, Loss 0.07217181473970413\n",
            "Train step - Step 0, Loss 0.0770692527294159\n",
            "Train step - Step 0, Loss 0.0755918100476265\n",
            "Train step - Step 0, Loss 0.07155603170394897\n",
            "Train step - Step 0, Loss 0.06976786255836487\n",
            "Train epoch - Accuracy: 0.294 Loss: 0.07267544913291932 Corrects: 3528\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.07779034227132797\n",
            "Train step - Step 0, Loss 0.07533473521471024\n",
            "Train step - Step 0, Loss 0.07113876938819885\n",
            "Train step - Step 0, Loss 0.06902699172496796\n",
            "Train step - Step 0, Loss 0.07235223054885864\n",
            "Train step - Step 0, Loss 0.07428368180990219\n",
            "Train step - Step 0, Loss 0.06794505566358566\n",
            "Train step - Step 0, Loss 0.07366856187582016\n",
            "Train step - Step 0, Loss 0.07205075025558472\n",
            "Train step - Step 0, Loss 0.07093113660812378\n",
            "Train step - Step 0, Loss 0.07228147238492966\n",
            "Train step - Step 0, Loss 0.0724499449133873\n",
            "Train step - Step 0, Loss 0.0725768655538559\n",
            "Train step - Step 0, Loss 0.0693177729845047\n",
            "Train step - Step 0, Loss 0.07380100339651108\n",
            "Train step - Step 0, Loss 0.070519357919693\n",
            "Train epoch - Accuracy: 0.285 Loss: 0.07225753045082092 Corrects: 3420\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.06931333243846893\n",
            "Train step - Step 0, Loss 0.07522869855165482\n",
            "Train step - Step 0, Loss 0.07543554902076721\n",
            "Train step - Step 0, Loss 0.07111038267612457\n",
            "Train step - Step 0, Loss 0.07354576140642166\n",
            "Train step - Step 0, Loss 0.06960031390190125\n",
            "Train step - Step 0, Loss 0.07728251069784164\n",
            "Train step - Step 0, Loss 0.0744529440999031\n",
            "Train step - Step 0, Loss 0.07638824731111526\n",
            "Train step - Step 0, Loss 0.0754687488079071\n",
            "Train step - Step 0, Loss 0.07042936980724335\n",
            "Train step - Step 0, Loss 0.07287503778934479\n",
            "Train step - Step 0, Loss 0.07190637290477753\n",
            "Train step - Step 0, Loss 0.07248307019472122\n",
            "Train step - Step 0, Loss 0.07191912829875946\n",
            "Train step - Step 0, Loss 0.06968939304351807\n",
            "Train epoch - Accuracy: 0.29241666666666666 Loss: 0.07302370166778564 Corrects: 3509\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.07219087332487106\n",
            "Train step - Step 0, Loss 0.06798223406076431\n",
            "Train step - Step 0, Loss 0.06881491839885712\n",
            "Train step - Step 0, Loss 0.07351177930831909\n",
            "Train step - Step 0, Loss 0.07184264808893204\n",
            "Train step - Step 0, Loss 0.07348009943962097\n",
            "Train step - Step 0, Loss 0.07395560294389725\n",
            "Train step - Step 0, Loss 0.0713602751493454\n",
            "Train step - Step 0, Loss 0.07441208511590958\n",
            "Train step - Step 0, Loss 0.07248635590076447\n",
            "Train step - Step 0, Loss 0.0703078880906105\n",
            "Train step - Step 0, Loss 0.07287047058343887\n",
            "Train step - Step 0, Loss 0.07511233538389206\n",
            "Train step - Step 0, Loss 0.07570454478263855\n",
            "Train step - Step 0, Loss 0.07381509244441986\n",
            "Train step - Step 0, Loss 0.07650572806596756\n",
            "Train epoch - Accuracy: 0.285 Loss: 0.0726824501156807 Corrects: 3420\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.06986971199512482\n",
            "Train step - Step 0, Loss 0.07407306134700775\n",
            "Train step - Step 0, Loss 0.07367069274187088\n",
            "Train step - Step 0, Loss 0.08007147908210754\n",
            "Train step - Step 0, Loss 0.07658952474594116\n",
            "Train step - Step 0, Loss 0.07357531785964966\n",
            "Train step - Step 0, Loss 0.07020345330238342\n",
            "Train step - Step 0, Loss 0.071906678378582\n",
            "Train step - Step 0, Loss 0.07088229805231094\n",
            "Train step - Step 0, Loss 0.0731125995516777\n",
            "Train step - Step 0, Loss 0.07085659354925156\n",
            "Train step - Step 0, Loss 0.07195154577493668\n",
            "Train step - Step 0, Loss 0.07346827536821365\n",
            "Train step - Step 0, Loss 0.07013130187988281\n",
            "Train step - Step 0, Loss 0.0677231028676033\n",
            "Train step - Step 0, Loss 0.06848101317882538\n",
            "Train epoch - Accuracy: 0.29433333333333334 Loss: 0.07237672126293182 Corrects: 3532\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.07236036658287048\n",
            "Train step - Step 0, Loss 0.06716781109571457\n",
            "Train step - Step 0, Loss 0.07289205491542816\n",
            "Train step - Step 0, Loss 0.07178323715925217\n",
            "Train step - Step 0, Loss 0.07856179028749466\n",
            "Train step - Step 0, Loss 0.07750528305768967\n",
            "Train step - Step 0, Loss 0.07303139567375183\n",
            "Train step - Step 0, Loss 0.07069528102874756\n",
            "Train step - Step 0, Loss 0.07238053530454636\n",
            "Train step - Step 0, Loss 0.07209695130586624\n",
            "Train step - Step 0, Loss 0.0734819620847702\n",
            "Train step - Step 0, Loss 0.07089149206876755\n",
            "Train step - Step 0, Loss 0.07207784056663513\n",
            "Train step - Step 0, Loss 0.0741487666964531\n",
            "Train step - Step 0, Loss 0.07375042140483856\n",
            "Train step - Step 0, Loss 0.07097970694303513\n",
            "Train epoch - Accuracy: 0.289 Loss: 0.07278000038862228 Corrects: 3468\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.07346120476722717\n",
            "Train step - Step 0, Loss 0.07310206443071365\n",
            "Train step - Step 0, Loss 0.07121222466230392\n",
            "Train step - Step 0, Loss 0.07536659389734268\n",
            "Train step - Step 0, Loss 0.07688885182142258\n",
            "Train step - Step 0, Loss 0.0698215439915657\n",
            "Train step - Step 0, Loss 0.07286439090967178\n",
            "Train step - Step 0, Loss 0.06819228082895279\n",
            "Train step - Step 0, Loss 0.06987665593624115\n",
            "Train step - Step 0, Loss 0.07078906893730164\n",
            "Train step - Step 0, Loss 0.07328107953071594\n",
            "Train step - Step 0, Loss 0.06998809427022934\n",
            "Train step - Step 0, Loss 0.07334975153207779\n",
            "Train step - Step 0, Loss 0.07164346426725388\n",
            "Train step - Step 0, Loss 0.0717264711856842\n",
            "Train step - Step 0, Loss 0.07241382449865341\n",
            "Train epoch - Accuracy: 0.2848333333333333 Loss: 0.0721166324019432 Corrects: 3418\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.07180402427911758\n",
            "Train step - Step 0, Loss 0.07274510711431503\n",
            "Train step - Step 0, Loss 0.07223588973283768\n",
            "Train step - Step 0, Loss 0.0746266171336174\n",
            "Train step - Step 0, Loss 0.07374471426010132\n",
            "Train step - Step 0, Loss 0.07556382566690445\n",
            "Train step - Step 0, Loss 0.06904974579811096\n",
            "Train step - Step 0, Loss 0.07011078298091888\n",
            "Train step - Step 0, Loss 0.07285398244857788\n",
            "Train step - Step 0, Loss 0.07123877108097076\n",
            "Train step - Step 0, Loss 0.07100921869277954\n",
            "Train step - Step 0, Loss 0.07065001875162125\n",
            "Train step - Step 0, Loss 0.06782203167676926\n",
            "Train step - Step 0, Loss 0.07127353549003601\n",
            "Train step - Step 0, Loss 0.0716443583369255\n",
            "Train step - Step 0, Loss 0.07590390741825104\n",
            "Train epoch - Accuracy: 0.2896666666666667 Loss: 0.07192400419712067 Corrects: 3476\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.07113441079854965\n",
            "Train step - Step 0, Loss 0.0698656290769577\n",
            "Train step - Step 0, Loss 0.07257631421089172\n",
            "Train step - Step 0, Loss 0.07336501777172089\n",
            "Train step - Step 0, Loss 0.07342945784330368\n",
            "Train step - Step 0, Loss 0.06964632123708725\n",
            "Train step - Step 0, Loss 0.0696774572134018\n",
            "Train step - Step 0, Loss 0.07245088368654251\n",
            "Train step - Step 0, Loss 0.072547547519207\n",
            "Train step - Step 0, Loss 0.07342234998941422\n",
            "Train step - Step 0, Loss 0.07089641690254211\n",
            "Train step - Step 0, Loss 0.07429094612598419\n",
            "Train step - Step 0, Loss 0.0728742778301239\n",
            "Train step - Step 0, Loss 0.07325050234794617\n",
            "Train step - Step 0, Loss 0.07426037639379501\n",
            "Train step - Step 0, Loss 0.0719001442193985\n",
            "Train epoch - Accuracy: 0.2885 Loss: 0.07223203194141388 Corrects: 3462\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.06935066729784012\n",
            "Train step - Step 0, Loss 0.07244984805583954\n",
            "Train step - Step 0, Loss 0.07420386373996735\n",
            "Train step - Step 0, Loss 0.0758885070681572\n",
            "Train step - Step 0, Loss 0.07396393269300461\n",
            "Train step - Step 0, Loss 0.07179172337055206\n",
            "Train step - Step 0, Loss 0.07188590615987778\n",
            "Train step - Step 0, Loss 0.07150307297706604\n",
            "Train step - Step 0, Loss 0.07204660773277283\n",
            "Train step - Step 0, Loss 0.07179935276508331\n",
            "Train step - Step 0, Loss 0.0750378966331482\n",
            "Train step - Step 0, Loss 0.07397483289241791\n",
            "Train step - Step 0, Loss 0.06999627500772476\n",
            "Train step - Step 0, Loss 0.07128402590751648\n",
            "Train step - Step 0, Loss 0.07561812549829483\n",
            "Train step - Step 0, Loss 0.06748035550117493\n",
            "Train epoch - Accuracy: 0.28825 Loss: 0.07251007103919983 Corrects: 3459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.4 0.058390725404024124\n",
            "TEST GROUP:  0.441\n",
            "TEST ALL:  0.405\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  9000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 10, 26, 34, 42, 50, 58, 74, 82, 90, 98, 19, 27, 35, 43, 51, 59, 67, 75, 83, 99, 18, 2, 87, 97, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 9, 17, 41, 49, 57, 65, 81, 4, 12, 20, 28, 22, 30, 38, 46, 54, 70, 78, 86, 94, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 14, 6, 93, 5, 36, 44, 52, 60, 68, 76, 84, 92, 13, 85, 21, 29, 37, 45, 53, 61, 69, 77, 0]\n",
            "TRAIN_SET CLASSES:  [87, 58, 46, 26, 77, 41, 5, 92, 28, 12]\n",
            "VALIDATION CLASSES:  [28, 58, 46, 41, 92, 26, 87, 77, 12, 5]\n",
            "GROUP:  9\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [87, 58, 46, 26, 77, 41, 5, 92, 28, 12]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  90\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.18130478262901306\n",
            "Train step - Step 10, Loss 0.11776713281869888\n",
            "Train step - Step 20, Loss 0.11492538452148438\n",
            "Train step - Step 30, Loss 0.10959713160991669\n",
            "Train step - Step 40, Loss 0.10494540631771088\n",
            "Train step - Step 50, Loss 0.10141608119010925\n",
            "Train epoch - Accuracy: 0.13079136690647483 Loss: 0.11701951498179126 Corrects: 909\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.10338050127029419\n",
            "Train step - Step 70, Loss 0.10353871434926987\n",
            "Train step - Step 80, Loss 0.09818354994058609\n",
            "Train step - Step 90, Loss 0.09977463632822037\n",
            "Train step - Step 100, Loss 0.0989948958158493\n",
            "Train epoch - Accuracy: 0.1856115107913669 Loss: 0.1015333258633991 Corrects: 1290\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.0959215834736824\n",
            "Train step - Step 120, Loss 0.10105542093515396\n",
            "Train step - Step 130, Loss 0.10021035373210907\n",
            "Train step - Step 140, Loss 0.09826795756816864\n",
            "Train step - Step 150, Loss 0.09496381878852844\n",
            "Train step - Step 160, Loss 0.0966532826423645\n",
            "Train epoch - Accuracy: 0.2227338129496403 Loss: 0.09904876367008086 Corrects: 1548\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.09889248013496399\n",
            "Train step - Step 180, Loss 0.09722069650888443\n",
            "Train step - Step 190, Loss 0.1013827994465828\n",
            "Train step - Step 200, Loss 0.09845849126577377\n",
            "Train step - Step 210, Loss 0.0952128991484642\n",
            "Train epoch - Accuracy: 0.2710791366906475 Loss: 0.09789562966540563 Corrects: 1884\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.09613244980573654\n",
            "Train step - Step 230, Loss 0.0979861170053482\n",
            "Train step - Step 240, Loss 0.09790050238370895\n",
            "Train step - Step 250, Loss 0.09727555513381958\n",
            "Train step - Step 260, Loss 0.10044736415147781\n",
            "Train step - Step 270, Loss 0.0943504124879837\n",
            "Train epoch - Accuracy: 0.3061870503597122 Loss: 0.09722653152916928 Corrects: 2128\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.09654195606708527\n",
            "Train step - Step 290, Loss 0.09769532829523087\n",
            "Train step - Step 300, Loss 0.09806559234857559\n",
            "Train step - Step 310, Loss 0.09408453106880188\n",
            "Train step - Step 320, Loss 0.09948381036520004\n",
            "Train epoch - Accuracy: 0.32705035971223023 Loss: 0.09639622653559815 Corrects: 2273\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.09598300606012344\n",
            "Train step - Step 340, Loss 0.09709477424621582\n",
            "Train step - Step 350, Loss 0.09963203221559525\n",
            "Train step - Step 360, Loss 0.10009457170963287\n",
            "Train step - Step 370, Loss 0.09439483284950256\n",
            "Train step - Step 380, Loss 0.09400501847267151\n",
            "Train epoch - Accuracy: 0.3669064748201439 Loss: 0.09605565219903164 Corrects: 2550\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.09612151235342026\n",
            "Train step - Step 400, Loss 0.09625579416751862\n",
            "Train step - Step 410, Loss 0.0977289080619812\n",
            "Train step - Step 420, Loss 0.09910909831523895\n",
            "Train step - Step 430, Loss 0.09652666002511978\n",
            "Train epoch - Accuracy: 0.3781294964028777 Loss: 0.09581712230075178 Corrects: 2628\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.09198417514562607\n",
            "Train step - Step 450, Loss 0.09207616746425629\n",
            "Train step - Step 460, Loss 0.09793451428413391\n",
            "Train step - Step 470, Loss 0.09545982629060745\n",
            "Train step - Step 480, Loss 0.09748160094022751\n",
            "Train step - Step 490, Loss 0.09471927583217621\n",
            "Train epoch - Accuracy: 0.39280575539568346 Loss: 0.09530472776443838 Corrects: 2730\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.09530562162399292\n",
            "Train step - Step 510, Loss 0.09530646353960037\n",
            "Train step - Step 520, Loss 0.0950322151184082\n",
            "Train step - Step 530, Loss 0.08930680900812149\n",
            "Train step - Step 540, Loss 0.09801218658685684\n",
            "Train epoch - Accuracy: 0.3981294964028777 Loss: 0.09505364701044645 Corrects: 2767\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.0971614196896553\n",
            "Train step - Step 560, Loss 0.09083190560340881\n",
            "Train step - Step 570, Loss 0.09723413735628128\n",
            "Train step - Step 580, Loss 0.09743490815162659\n",
            "Train step - Step 590, Loss 0.09435539692640305\n",
            "Train step - Step 600, Loss 0.1012590229511261\n",
            "Train epoch - Accuracy: 0.418705035971223 Loss: 0.09503250489346415 Corrects: 2910\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.09514710307121277\n",
            "Train step - Step 620, Loss 0.09498628973960876\n",
            "Train step - Step 630, Loss 0.09591889381408691\n",
            "Train step - Step 640, Loss 0.09903247654438019\n",
            "Train step - Step 650, Loss 0.09345205128192902\n",
            "Train epoch - Accuracy: 0.4343884892086331 Loss: 0.09462644310306302 Corrects: 3019\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.09222130477428436\n",
            "Train step - Step 670, Loss 0.09514369070529938\n",
            "Train step - Step 680, Loss 0.09129779785871506\n",
            "Train step - Step 690, Loss 0.1001320332288742\n",
            "Train step - Step 700, Loss 0.09105394035577774\n",
            "Train step - Step 710, Loss 0.09207897633314133\n",
            "Train epoch - Accuracy: 0.440863309352518 Loss: 0.09433258217015712 Corrects: 3064\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.0934864729642868\n",
            "Train step - Step 730, Loss 0.09545489400625229\n",
            "Train step - Step 740, Loss 0.09577035903930664\n",
            "Train step - Step 750, Loss 0.09480229020118713\n",
            "Train step - Step 760, Loss 0.09386707097291946\n",
            "Train epoch - Accuracy: 0.45525179856115106 Loss: 0.09441657704200676 Corrects: 3164\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.0951656699180603\n",
            "Train step - Step 780, Loss 0.09355034679174423\n",
            "Train step - Step 790, Loss 0.09249486029148102\n",
            "Train step - Step 800, Loss 0.09369000792503357\n",
            "Train step - Step 810, Loss 0.09184347838163376\n",
            "Train step - Step 820, Loss 0.09388533979654312\n",
            "Train epoch - Accuracy: 0.4637410071942446 Loss: 0.09426161994822592 Corrects: 3223\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.09561417251825333\n",
            "Train step - Step 840, Loss 0.09741845726966858\n",
            "Train step - Step 850, Loss 0.09655587375164032\n",
            "Train step - Step 860, Loss 0.09167911112308502\n",
            "Train step - Step 870, Loss 0.09520687907934189\n",
            "Train epoch - Accuracy: 0.46964028776978417 Loss: 0.09402124321503605 Corrects: 3264\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.09244007617235184\n",
            "Train step - Step 890, Loss 0.09469214826822281\n",
            "Train step - Step 900, Loss 0.09531735628843307\n",
            "Train step - Step 910, Loss 0.09491533041000366\n",
            "Train step - Step 920, Loss 0.09483763575553894\n",
            "Train step - Step 930, Loss 0.09190869331359863\n",
            "Train epoch - Accuracy: 0.47827338129496405 Loss: 0.09398346616853055 Corrects: 3324\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.09847310930490494\n",
            "Train step - Step 950, Loss 0.09630238264799118\n",
            "Train step - Step 960, Loss 0.09509898722171783\n",
            "Train step - Step 970, Loss 0.09083011746406555\n",
            "Train step - Step 980, Loss 0.09409070014953613\n",
            "Train epoch - Accuracy: 0.4900719424460432 Loss: 0.09360193127136436 Corrects: 3406\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.09364438056945801\n",
            "Train step - Step 1000, Loss 0.09728041291236877\n",
            "Train step - Step 1010, Loss 0.09225556999444962\n",
            "Train step - Step 1020, Loss 0.09732995927333832\n",
            "Train step - Step 1030, Loss 0.09409639984369278\n",
            "Train step - Step 1040, Loss 0.0947059839963913\n",
            "Train epoch - Accuracy: 0.4902158273381295 Loss: 0.0939178857443144 Corrects: 3407\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.09659352153539658\n",
            "Train step - Step 1060, Loss 0.09596829116344452\n",
            "Train step - Step 1070, Loss 0.09717249870300293\n",
            "Train step - Step 1080, Loss 0.0897899642586708\n",
            "Train step - Step 1090, Loss 0.09480791538953781\n",
            "Train epoch - Accuracy: 0.4953956834532374 Loss: 0.09346942924338279 Corrects: 3443\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.09356333315372467\n",
            "Train step - Step 1110, Loss 0.09040259569883347\n",
            "Train step - Step 1120, Loss 0.09511618316173553\n",
            "Train step - Step 1130, Loss 0.09019860625267029\n",
            "Train step - Step 1140, Loss 0.08977623283863068\n",
            "Train step - Step 1150, Loss 0.09683234244585037\n",
            "Train epoch - Accuracy: 0.5067625899280576 Loss: 0.09329999488463504 Corrects: 3522\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.0936780720949173\n",
            "Train step - Step 1170, Loss 0.09381484985351562\n",
            "Train step - Step 1180, Loss 0.09234229475259781\n",
            "Train step - Step 1190, Loss 0.0965728759765625\n",
            "Train step - Step 1200, Loss 0.09354798495769501\n",
            "Train epoch - Accuracy: 0.5148201438848921 Loss: 0.09344577624643449 Corrects: 3578\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.09308485686779022\n",
            "Train step - Step 1220, Loss 0.0937960296869278\n",
            "Train step - Step 1230, Loss 0.09231980890035629\n",
            "Train step - Step 1240, Loss 0.09430747479200363\n",
            "Train step - Step 1250, Loss 0.09507592767477036\n",
            "Train step - Step 1260, Loss 0.09227460622787476\n",
            "Train epoch - Accuracy: 0.5194244604316547 Loss: 0.09307337072899016 Corrects: 3610\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.09661777317523956\n",
            "Train step - Step 1280, Loss 0.09044596552848816\n",
            "Train step - Step 1290, Loss 0.09587357938289642\n",
            "Train step - Step 1300, Loss 0.09257297962903976\n",
            "Train step - Step 1310, Loss 0.08992709964513779\n",
            "Train epoch - Accuracy: 0.5243165467625899 Loss: 0.09314216012362954 Corrects: 3644\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.09466549754142761\n",
            "Train step - Step 1330, Loss 0.09061978757381439\n",
            "Train step - Step 1340, Loss 0.09422560781240463\n",
            "Train step - Step 1350, Loss 0.0922023132443428\n",
            "Train step - Step 1360, Loss 0.0924983024597168\n",
            "Train step - Step 1370, Loss 0.09063232690095901\n",
            "Train epoch - Accuracy: 0.5248920863309352 Loss: 0.09300480054436827 Corrects: 3648\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.09039288759231567\n",
            "Train step - Step 1390, Loss 0.09115020185709\n",
            "Train step - Step 1400, Loss 0.09174060076475143\n",
            "Train step - Step 1410, Loss 0.09554693847894669\n",
            "Train step - Step 1420, Loss 0.0917801633477211\n",
            "Train epoch - Accuracy: 0.5293525179856116 Loss: 0.09304859517503986 Corrects: 3679\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.08934110403060913\n",
            "Train step - Step 1440, Loss 0.09134023636579514\n",
            "Train step - Step 1450, Loss 0.0908811092376709\n",
            "Train step - Step 1460, Loss 0.09617704153060913\n",
            "Train step - Step 1470, Loss 0.0961487665772438\n",
            "Train step - Step 1480, Loss 0.09441488236188889\n",
            "Train epoch - Accuracy: 0.5410071942446043 Loss: 0.0926894111105864 Corrects: 3760\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.0907670184969902\n",
            "Train step - Step 1500, Loss 0.09256122261285782\n",
            "Train step - Step 1510, Loss 0.09080483019351959\n",
            "Train step - Step 1520, Loss 0.09167508035898209\n",
            "Train step - Step 1530, Loss 0.0964755266904831\n",
            "Train epoch - Accuracy: 0.5359712230215827 Loss: 0.0927641689026956 Corrects: 3725\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09321674704551697\n",
            "Train step - Step 1550, Loss 0.09843114763498306\n",
            "Train step - Step 1560, Loss 0.09177352488040924\n",
            "Train step - Step 1570, Loss 0.09470206499099731\n",
            "Train step - Step 1580, Loss 0.09125455468893051\n",
            "Train step - Step 1590, Loss 0.09263613075017929\n",
            "Train epoch - Accuracy: 0.5410071942446043 Loss: 0.09261728859419445 Corrects: 3760\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.09349282830953598\n",
            "Train step - Step 1610, Loss 0.0939808115363121\n",
            "Train step - Step 1620, Loss 0.08948782831430435\n",
            "Train step - Step 1630, Loss 0.09551136195659637\n",
            "Train step - Step 1640, Loss 0.0924181342124939\n",
            "Train epoch - Accuracy: 0.541294964028777 Loss: 0.0926323146764323 Corrects: 3762\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.08938731998205185\n",
            "Train step - Step 1660, Loss 0.09012485295534134\n",
            "Train step - Step 1670, Loss 0.09157729148864746\n",
            "Train step - Step 1680, Loss 0.09334257245063782\n",
            "Train step - Step 1690, Loss 0.09251376241445541\n",
            "Train step - Step 1700, Loss 0.09364238381385803\n",
            "Train epoch - Accuracy: 0.5446043165467626 Loss: 0.09243915754685299 Corrects: 3785\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.08923091739416122\n",
            "Train step - Step 1720, Loss 0.09370717406272888\n",
            "Train step - Step 1730, Loss 0.0939629077911377\n",
            "Train step - Step 1740, Loss 0.09037011861801147\n",
            "Train step - Step 1750, Loss 0.09524932503700256\n",
            "Train epoch - Accuracy: 0.5494964028776979 Loss: 0.09225104486341956 Corrects: 3819\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.094594806432724\n",
            "Train step - Step 1770, Loss 0.0912167876958847\n",
            "Train step - Step 1780, Loss 0.09154698997735977\n",
            "Train step - Step 1790, Loss 0.09218936413526535\n",
            "Train step - Step 1800, Loss 0.09405827522277832\n",
            "Train step - Step 1810, Loss 0.09266746789216995\n",
            "Train epoch - Accuracy: 0.5516546762589928 Loss: 0.09263563805561272 Corrects: 3834\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.09421376138925552\n",
            "Train step - Step 1830, Loss 0.08990656584501266\n",
            "Train step - Step 1840, Loss 0.09237659722566605\n",
            "Train step - Step 1850, Loss 0.09211074560880661\n",
            "Train step - Step 1860, Loss 0.09032948315143585\n",
            "Train epoch - Accuracy: 0.5564028776978417 Loss: 0.09199204666580228 Corrects: 3867\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.09564720094203949\n",
            "Train step - Step 1880, Loss 0.09002698212862015\n",
            "Train step - Step 1890, Loss 0.0893435925245285\n",
            "Train step - Step 1900, Loss 0.09255099296569824\n",
            "Train step - Step 1910, Loss 0.09159085899591446\n",
            "Train step - Step 1920, Loss 0.09246476739645004\n",
            "Train epoch - Accuracy: 0.5643165467625899 Loss: 0.09211576141899439 Corrects: 3922\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.09374161809682846\n",
            "Train step - Step 1940, Loss 0.09375729411840439\n",
            "Train step - Step 1950, Loss 0.09102316945791245\n",
            "Train step - Step 1960, Loss 0.09222434461116791\n",
            "Train step - Step 1970, Loss 0.09500393271446228\n",
            "Train epoch - Accuracy: 0.5694964028776979 Loss: 0.09204580016702199 Corrects: 3958\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.09261394292116165\n",
            "Train step - Step 1990, Loss 0.09433171153068542\n",
            "Train step - Step 2000, Loss 0.08911759406328201\n",
            "Train step - Step 2010, Loss 0.09148772060871124\n",
            "Train step - Step 2020, Loss 0.09315088391304016\n",
            "Train step - Step 2030, Loss 0.09449245780706406\n",
            "Train epoch - Accuracy: 0.5743884892086331 Loss: 0.09214569554268885 Corrects: 3992\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.09263712912797928\n",
            "Train step - Step 2050, Loss 0.09408160299062729\n",
            "Train step - Step 2060, Loss 0.08922732621431351\n",
            "Train step - Step 2070, Loss 0.09384303539991379\n",
            "Train step - Step 2080, Loss 0.09163215756416321\n",
            "Train epoch - Accuracy: 0.5706474820143885 Loss: 0.09203722150420113 Corrects: 3966\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.0940583273768425\n",
            "Train step - Step 2100, Loss 0.09360648691654205\n",
            "Train step - Step 2110, Loss 0.09622132033109665\n",
            "Train step - Step 2120, Loss 0.0916127860546112\n",
            "Train step - Step 2130, Loss 0.09267454594373703\n",
            "Train step - Step 2140, Loss 0.09584791958332062\n",
            "Train epoch - Accuracy: 0.5779856115107914 Loss: 0.09217928383418982 Corrects: 4017\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.09253298491239548\n",
            "Train step - Step 2160, Loss 0.0910312756896019\n",
            "Train step - Step 2170, Loss 0.08610747009515762\n",
            "Train step - Step 2180, Loss 0.08658672124147415\n",
            "Train step - Step 2190, Loss 0.09195495396852493\n",
            "Train epoch - Accuracy: 0.5774100719424461 Loss: 0.0917525118246353 Corrects: 4013\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.0892113670706749\n",
            "Train step - Step 2210, Loss 0.09127318114042282\n",
            "Train step - Step 2220, Loss 0.09312941133975983\n",
            "Train step - Step 2230, Loss 0.09197196364402771\n",
            "Train step - Step 2240, Loss 0.0917467325925827\n",
            "Train step - Step 2250, Loss 0.09211326390504837\n",
            "Train epoch - Accuracy: 0.5801438848920863 Loss: 0.09180760347157073 Corrects: 4032\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.09429129958152771\n",
            "Train step - Step 2270, Loss 0.08892583101987839\n",
            "Train step - Step 2280, Loss 0.09327846020460129\n",
            "Train step - Step 2290, Loss 0.09061867743730545\n",
            "Train step - Step 2300, Loss 0.08996126800775528\n",
            "Train epoch - Accuracy: 0.5900719424460432 Loss: 0.09159465148294572 Corrects: 4101\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.09315121918916702\n",
            "Train step - Step 2320, Loss 0.08934634923934937\n",
            "Train step - Step 2330, Loss 0.0895252674818039\n",
            "Train step - Step 2340, Loss 0.08800861984491348\n",
            "Train step - Step 2350, Loss 0.09214350581169128\n",
            "Train step - Step 2360, Loss 0.0924932062625885\n",
            "Train epoch - Accuracy: 0.5874820143884892 Loss: 0.09173009745937458 Corrects: 4083\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.09103694558143616\n",
            "Train step - Step 2380, Loss 0.09436024725437164\n",
            "Train step - Step 2390, Loss 0.09046334028244019\n",
            "Train step - Step 2400, Loss 0.09324377775192261\n",
            "Train step - Step 2410, Loss 0.09655025601387024\n",
            "Train epoch - Accuracy: 0.5905035971223022 Loss: 0.09152451734963081 Corrects: 4104\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.09791421890258789\n",
            "Train step - Step 2430, Loss 0.09323158860206604\n",
            "Train step - Step 2440, Loss 0.09298964589834213\n",
            "Train step - Step 2450, Loss 0.09204073995351791\n",
            "Train step - Step 2460, Loss 0.09534589946269989\n",
            "Train step - Step 2470, Loss 0.09179874509572983\n",
            "Train epoch - Accuracy: 0.5955395683453237 Loss: 0.0916132583120744 Corrects: 4139\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.0917559340596199\n",
            "Train step - Step 2490, Loss 0.09182790666818619\n",
            "Train step - Step 2500, Loss 0.0915272980928421\n",
            "Train step - Step 2510, Loss 0.09018874913454056\n",
            "Train step - Step 2520, Loss 0.08979415893554688\n",
            "Train epoch - Accuracy: 0.5920863309352518 Loss: 0.09142286952022169 Corrects: 4115\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.0935945212841034\n",
            "Train step - Step 2540, Loss 0.09293849766254425\n",
            "Train step - Step 2550, Loss 0.09214290976524353\n",
            "Train step - Step 2560, Loss 0.09216469526290894\n",
            "Train step - Step 2570, Loss 0.09147202223539352\n",
            "Train step - Step 2580, Loss 0.09328866004943848\n",
            "Train epoch - Accuracy: 0.5948201438848921 Loss: 0.09145175149758085 Corrects: 4134\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.0881085991859436\n",
            "Train step - Step 2600, Loss 0.09467044472694397\n",
            "Train step - Step 2610, Loss 0.09246253967285156\n",
            "Train step - Step 2620, Loss 0.0899592712521553\n",
            "Train step - Step 2630, Loss 0.09193827211856842\n",
            "Train epoch - Accuracy: 0.6018705035971224 Loss: 0.0915037115829454 Corrects: 4183\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.08571869134902954\n",
            "Train step - Step 2650, Loss 0.0942964255809784\n",
            "Train step - Step 2660, Loss 0.09482390433549881\n",
            "Train step - Step 2670, Loss 0.09176769107580185\n",
            "Train step - Step 2680, Loss 0.09152135252952576\n",
            "Train step - Step 2690, Loss 0.09425528347492218\n",
            "Train epoch - Accuracy: 0.6014388489208633 Loss: 0.09135653602347957 Corrects: 4180\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.08817335218191147\n",
            "Train step - Step 2710, Loss 0.09222223609685898\n",
            "Train step - Step 2720, Loss 0.09145571291446686\n",
            "Train step - Step 2730, Loss 0.08952333778142929\n",
            "Train step - Step 2740, Loss 0.09152925759553909\n",
            "Train epoch - Accuracy: 0.6077697841726619 Loss: 0.09091872014158921 Corrects: 4224\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.09364049136638641\n",
            "Train step - Step 2760, Loss 0.09416865557432175\n",
            "Train step - Step 2770, Loss 0.09038028866052628\n",
            "Train step - Step 2780, Loss 0.09021613001823425\n",
            "Train step - Step 2790, Loss 0.0908254012465477\n",
            "Train step - Step 2800, Loss 0.09160872548818588\n",
            "Train epoch - Accuracy: 0.6106474820143885 Loss: 0.09103944393156244 Corrects: 4244\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.09458521753549576\n",
            "Train step - Step 2820, Loss 0.08997873216867447\n",
            "Train step - Step 2830, Loss 0.09128104895353317\n",
            "Train step - Step 2840, Loss 0.088910773396492\n",
            "Train step - Step 2850, Loss 0.08741827309131622\n",
            "Train epoch - Accuracy: 0.6063309352517986 Loss: 0.0909444933143451 Corrects: 4214\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.08952153474092484\n",
            "Train step - Step 2870, Loss 0.09018894284963608\n",
            "Train step - Step 2880, Loss 0.08902306109666824\n",
            "Train step - Step 2890, Loss 0.08774007111787796\n",
            "Train step - Step 2900, Loss 0.09488971531391144\n",
            "Train step - Step 2910, Loss 0.0901997908949852\n",
            "Train epoch - Accuracy: 0.6060431654676259 Loss: 0.09094819776445842 Corrects: 4212\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.08809570223093033\n",
            "Train step - Step 2930, Loss 0.08580352365970612\n",
            "Train step - Step 2940, Loss 0.09162109345197678\n",
            "Train step - Step 2950, Loss 0.09039181470870972\n",
            "Train step - Step 2960, Loss 0.08895599097013474\n",
            "Train epoch - Accuracy: 0.6145323741007194 Loss: 0.09093882034365222 Corrects: 4271\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.0905114933848381\n",
            "Train step - Step 2980, Loss 0.08954469114542007\n",
            "Train step - Step 2990, Loss 0.08910492807626724\n",
            "Train step - Step 3000, Loss 0.08945823460817337\n",
            "Train step - Step 3010, Loss 0.08886054903268814\n",
            "Train step - Step 3020, Loss 0.09023823589086533\n",
            "Train epoch - Accuracy: 0.6126618705035971 Loss: 0.09079035947648742 Corrects: 4258\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.09082444757223129\n",
            "Train step - Step 3040, Loss 0.08829215914011002\n",
            "Train step - Step 3050, Loss 0.0909842923283577\n",
            "Train step - Step 3060, Loss 0.0877871960401535\n",
            "Train step - Step 3070, Loss 0.09320297837257385\n",
            "Train epoch - Accuracy: 0.6132374100719424 Loss: 0.09083786675612704 Corrects: 4262\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.08927231281995773\n",
            "Train step - Step 3090, Loss 0.09387552738189697\n",
            "Train step - Step 3100, Loss 0.09157443046569824\n",
            "Train step - Step 3110, Loss 0.09054864197969437\n",
            "Train step - Step 3120, Loss 0.08792728930711746\n",
            "Train step - Step 3130, Loss 0.09168829768896103\n",
            "Train epoch - Accuracy: 0.6082014388489209 Loss: 0.09077613896388802 Corrects: 4227\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.08785949647426605\n",
            "Train step - Step 3150, Loss 0.09100350737571716\n",
            "Train step - Step 3160, Loss 0.09079643338918686\n",
            "Train step - Step 3170, Loss 0.09131735563278198\n",
            "Train step - Step 3180, Loss 0.09036535024642944\n",
            "Train epoch - Accuracy: 0.6123741007194244 Loss: 0.09054461334034693 Corrects: 4256\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.0910012498497963\n",
            "Train step - Step 3200, Loss 0.09146559238433838\n",
            "Train step - Step 3210, Loss 0.09335210919380188\n",
            "Train step - Step 3220, Loss 0.09364863485097885\n",
            "Train step - Step 3230, Loss 0.08930666744709015\n",
            "Train step - Step 3240, Loss 0.08836731314659119\n",
            "Train epoch - Accuracy: 0.6135251798561151 Loss: 0.09077502639816819 Corrects: 4264\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09278414398431778\n",
            "Train step - Step 3260, Loss 0.09439966827630997\n",
            "Train step - Step 3270, Loss 0.09098897874355316\n",
            "Train step - Step 3280, Loss 0.09271910041570663\n",
            "Train step - Step 3290, Loss 0.09371273219585419\n",
            "Train epoch - Accuracy: 0.6143884892086331 Loss: 0.09099009542156467 Corrects: 4270\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.09274376183748245\n",
            "Train step - Step 3310, Loss 0.08940142393112183\n",
            "Train step - Step 3320, Loss 0.08898326009511948\n",
            "Train step - Step 3330, Loss 0.09480637311935425\n",
            "Train step - Step 3340, Loss 0.09123910218477249\n",
            "Train step - Step 3350, Loss 0.09199747443199158\n",
            "Train epoch - Accuracy: 0.6224460431654676 Loss: 0.09059987243345316 Corrects: 4326\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.09078522026538849\n",
            "Train step - Step 3370, Loss 0.08590275794267654\n",
            "Train step - Step 3380, Loss 0.094023697078228\n",
            "Train step - Step 3390, Loss 0.09234502911567688\n",
            "Train step - Step 3400, Loss 0.09479072690010071\n",
            "Train epoch - Accuracy: 0.6155395683453238 Loss: 0.09080385479138052 Corrects: 4278\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09453672170639038\n",
            "Train step - Step 3420, Loss 0.09037560224533081\n",
            "Train step - Step 3430, Loss 0.09318777918815613\n",
            "Train step - Step 3440, Loss 0.0862560048699379\n",
            "Train step - Step 3450, Loss 0.09046770632266998\n",
            "Train step - Step 3460, Loss 0.09319030493497849\n",
            "Train epoch - Accuracy: 0.6185611510791367 Loss: 0.09074375549237505 Corrects: 4299\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.08697451651096344\n",
            "Train step - Step 3480, Loss 0.08848711103200912\n",
            "Train step - Step 3490, Loss 0.09626300632953644\n",
            "Train step - Step 3500, Loss 0.09017875790596008\n",
            "Train step - Step 3510, Loss 0.09072789549827576\n",
            "Train epoch - Accuracy: 0.6166906474820144 Loss: 0.09066274822615891 Corrects: 4286\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.09083779901266098\n",
            "Train step - Step 3530, Loss 0.09101445227861404\n",
            "Train step - Step 3540, Loss 0.09189530462026596\n",
            "Train step - Step 3550, Loss 0.09024135023355484\n",
            "Train step - Step 3560, Loss 0.09479306638240814\n",
            "Train step - Step 3570, Loss 0.08617915958166122\n",
            "Train epoch - Accuracy: 0.6151079136690647 Loss: 0.0905822295722344 Corrects: 4275\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.09170370548963547\n",
            "Train step - Step 3590, Loss 0.09000925719738007\n",
            "Train step - Step 3600, Loss 0.08716164529323578\n",
            "Train step - Step 3610, Loss 0.09315484762191772\n",
            "Train step - Step 3620, Loss 0.08548924326896667\n",
            "Train epoch - Accuracy: 0.6175539568345324 Loss: 0.0905485784149856 Corrects: 4292\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.0920649841427803\n",
            "Train step - Step 3640, Loss 0.09541899710893631\n",
            "Train step - Step 3650, Loss 0.0896710529923439\n",
            "Train step - Step 3660, Loss 0.09314024448394775\n",
            "Train step - Step 3670, Loss 0.09048905223608017\n",
            "Train step - Step 3680, Loss 0.09243031591176987\n",
            "Train epoch - Accuracy: 0.6152517985611511 Loss: 0.09065311622490986 Corrects: 4276\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.08762144297361374\n",
            "Train step - Step 3700, Loss 0.09018322080373764\n",
            "Train step - Step 3710, Loss 0.08794665336608887\n",
            "Train step - Step 3720, Loss 0.08805166929960251\n",
            "Train step - Step 3730, Loss 0.09389512985944748\n",
            "Train epoch - Accuracy: 0.619568345323741 Loss: 0.09043826987846292 Corrects: 4306\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.0922081246972084\n",
            "Train step - Step 3750, Loss 0.09189705550670624\n",
            "Train step - Step 3760, Loss 0.09267321974039078\n",
            "Train step - Step 3770, Loss 0.0911175012588501\n",
            "Train step - Step 3780, Loss 0.09225758910179138\n",
            "Train step - Step 3790, Loss 0.09073545783758163\n",
            "Train epoch - Accuracy: 0.6233093525179856 Loss: 0.09061009755880713 Corrects: 4332\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.0891622006893158\n",
            "Train step - Step 3810, Loss 0.09509528428316116\n",
            "Train step - Step 3820, Loss 0.0909683033823967\n",
            "Train step - Step 3830, Loss 0.09075357764959335\n",
            "Train step - Step 3840, Loss 0.09115459024906158\n",
            "Train epoch - Accuracy: 0.6153956834532374 Loss: 0.09069013214797425 Corrects: 4277\n",
            "Training finished in 458.7864656448364 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52, 71, 51, 43, 78, 74, 38, 37, 29, 48, 44, 87, 58, 46, 26, 77, 41, 5, 92, 28, 12]\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  22\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee37b210>\n",
            "Constructing exemplars of class 87\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [30775, 35251, 4393, 1884, 3238, 46795, 44805, 6107, 20762, 30937, 39516, 17276, 6448, 23777, 1884, 478, 49355, 37152, 29517, 23546, 47397, 11642]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee291ed0>\n",
            "Constructing exemplars of class 58\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [30320, 38394, 963, 8182, 26545, 23098, 2396, 33007, 43110, 30408, 15431, 1596, 37983, 21254, 17357, 47002, 6805, 40962, 39162, 48026, 15323, 37258]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff3000437d0>\n",
            "Constructing exemplars of class 46\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [42149, 17179, 1473, 77, 39727, 46919, 26215, 35121, 36325, 11882, 16144, 46919, 24868, 37206, 26419, 14141, 29080, 24360, 16110, 37685, 49558, 35144]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee5d7a50>\n",
            "Constructing exemplars of class 26\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [41794, 48807, 9906, 24887, 33567, 8050, 43862, 884, 40681, 27422, 2473, 19159, 29834, 364, 49678, 49587, 45642, 12046, 38815, 33567, 25716, 38807]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309de9b90>\n",
            "Constructing exemplars of class 77\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [29258, 26912, 32721, 7453, 34828, 8947, 31791, 46784, 45253, 40737, 30357, 5098, 457, 30181, 18002, 5255, 25206, 32919, 35588, 1493, 8275, 16806]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee3becd0>\n",
            "Constructing exemplars of class 41\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [48108, 26049, 46191, 20661, 2732, 17789, 27123, 34704, 19366, 44508, 33786, 27523, 14932, 20836, 19364, 26608, 22575, 45271, 35789, 46534, 2732, 41020]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a252810>\n",
            "Constructing exemplars of class 5\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [11119, 24055, 12814, 17205, 2345, 42284, 28867, 22883, 9180, 23252, 17824, 41077, 9984, 15354, 21530, 20808, 27807, 29268, 38419, 31621, 32588, 35597]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee21fd10>\n",
            "Constructing exemplars of class 92\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [38004, 31696, 9506, 17512, 27882, 33217, 4227, 16846, 10313, 10600, 44522, 16811, 47611, 41056, 28917, 17512, 29568, 25226, 36370, 10591, 22015, 43209]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff3000437d0>\n",
            "Constructing exemplars of class 28\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [38740, 35169, 9461, 39904, 8174, 22179, 43992, 21215, 35698, 24680, 1460, 39172, 18866, 12996, 27695, 25849, 12205, 47119, 3561, 4299, 42992, 21179]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee347ad0>\n",
            "Constructing exemplars of class 12\n",
            "lunghezza exemplar set:  22\n",
            "exemplar set:  [48914, 16943, 14134, 5550, 41361, 49421, 21150, 31901, 42328, 45549, 29075, 48529, 41716, 10279, 32131, 12178, 26192, 28089, 46788, 4133, 28645, 696]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.07281697541475296\n",
            "Train step - Step 0, Loss 0.07536628097295761\n",
            "Train step - Step 0, Loss 0.07407841086387634\n",
            "Train step - Step 0, Loss 0.07178164273500443\n",
            "Train step - Step 0, Loss 0.0729941800236702\n",
            "Train step - Step 0, Loss 0.07164467871189117\n",
            "Train step - Step 0, Loss 0.07283343374729156\n",
            "Train step - Step 0, Loss 0.07199768722057343\n",
            "Train step - Step 0, Loss 0.07152853906154633\n",
            "Train step - Step 0, Loss 0.06844566017389297\n",
            "Train step - Step 0, Loss 0.07003237307071686\n",
            "Train step - Step 0, Loss 0.07051704823970795\n",
            "Train step - Step 0, Loss 0.07054398953914642\n",
            "Train step - Step 0, Loss 0.07070404291152954\n",
            "Train step - Step 0, Loss 0.0727921649813652\n",
            "Train step - Step 0, Loss 0.07370682060718536\n",
            "Train epoch - Accuracy: 0.27365319865319865 Loss: 0.0719274136454168 Corrects: 3251\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.07097973674535751\n",
            "Train step - Step 0, Loss 0.0719967857003212\n",
            "Train step - Step 0, Loss 0.06837087124586105\n",
            "Train step - Step 0, Loss 0.07432026416063309\n",
            "Train step - Step 0, Loss 0.07093070447444916\n",
            "Train step - Step 0, Loss 0.07316159456968307\n",
            "Train step - Step 0, Loss 0.07025520503520966\n",
            "Train step - Step 0, Loss 0.07280174642801285\n",
            "Train step - Step 0, Loss 0.06885417550802231\n",
            "Train step - Step 0, Loss 0.07149125635623932\n",
            "Train step - Step 0, Loss 0.07283064723014832\n",
            "Train step - Step 0, Loss 0.07086177170276642\n",
            "Train step - Step 0, Loss 0.07272443175315857\n",
            "Train step - Step 0, Loss 0.07238830626010895\n",
            "Train step - Step 0, Loss 0.07149981707334518\n",
            "Train step - Step 0, Loss 0.07268606126308441\n",
            "Train epoch - Accuracy: 0.2740740740740741 Loss: 0.07159847469642909 Corrects: 3256\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.07379801571369171\n",
            "Train step - Step 0, Loss 0.06989815086126328\n",
            "Train step - Step 0, Loss 0.07243146002292633\n",
            "Train step - Step 0, Loss 0.06761804968118668\n",
            "Train step - Step 0, Loss 0.07461242377758026\n",
            "Train step - Step 0, Loss 0.07255356013774872\n",
            "Train step - Step 0, Loss 0.06805339455604553\n",
            "Train step - Step 0, Loss 0.07058222591876984\n",
            "Train step - Step 0, Loss 0.07166676223278046\n",
            "Train step - Step 0, Loss 0.07008407264947891\n",
            "Train step - Step 0, Loss 0.07386361807584763\n",
            "Train step - Step 0, Loss 0.0784614160656929\n",
            "Train step - Step 0, Loss 0.07258820533752441\n",
            "Train step - Step 0, Loss 0.07233205437660217\n",
            "Train step - Step 0, Loss 0.07231723517179489\n",
            "Train step - Step 0, Loss 0.06857883185148239\n",
            "Train epoch - Accuracy: 0.27095959595959596 Loss: 0.07195196586726892 Corrects: 3219\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.07030696421861649\n",
            "Train step - Step 0, Loss 0.07194837927818298\n",
            "Train step - Step 0, Loss 0.07180235534906387\n",
            "Train step - Step 0, Loss 0.07384345680475235\n",
            "Train step - Step 0, Loss 0.07112111896276474\n",
            "Train step - Step 0, Loss 0.07126423716545105\n",
            "Train step - Step 0, Loss 0.07059012353420258\n",
            "Train step - Step 0, Loss 0.06922977417707443\n",
            "Train step - Step 0, Loss 0.0742800161242485\n",
            "Train step - Step 0, Loss 0.07148464024066925\n",
            "Train step - Step 0, Loss 0.07113421708345413\n",
            "Train step - Step 0, Loss 0.07263638079166412\n",
            "Train step - Step 0, Loss 0.06987688690423965\n",
            "Train step - Step 0, Loss 0.07116340100765228\n",
            "Train step - Step 0, Loss 0.06929941475391388\n",
            "Train step - Step 0, Loss 0.07219075411558151\n",
            "Train epoch - Accuracy: 0.26961279461279464 Loss: 0.07135811118465481 Corrects: 3203\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.07177436351776123\n",
            "Train step - Step 0, Loss 0.07097761332988739\n",
            "Train step - Step 0, Loss 0.07190028578042984\n",
            "Train step - Step 0, Loss 0.06875059008598328\n",
            "Train step - Step 0, Loss 0.07080899924039841\n",
            "Train step - Step 0, Loss 0.06977509707212448\n",
            "Train step - Step 0, Loss 0.0733499526977539\n",
            "Train step - Step 0, Loss 0.071809783577919\n",
            "Train step - Step 0, Loss 0.07184448093175888\n",
            "Train step - Step 0, Loss 0.07191033661365509\n",
            "Train step - Step 0, Loss 0.07218441367149353\n",
            "Train step - Step 0, Loss 0.07552015036344528\n",
            "Train step - Step 0, Loss 0.07450827211141586\n",
            "Train step - Step 0, Loss 0.06914425641298294\n",
            "Train step - Step 0, Loss 0.07273630052804947\n",
            "Train step - Step 0, Loss 0.0726046934723854\n",
            "Train epoch - Accuracy: 0.27365319865319865 Loss: 0.07182405469092455 Corrects: 3251\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.07185110449790955\n",
            "Train step - Step 0, Loss 0.07100792229175568\n",
            "Train step - Step 0, Loss 0.07219632714986801\n",
            "Train step - Step 0, Loss 0.07119598239660263\n",
            "Train step - Step 0, Loss 0.07095237821340561\n",
            "Train step - Step 0, Loss 0.07386268675327301\n",
            "Train step - Step 0, Loss 0.0728796198964119\n",
            "Train step - Step 0, Loss 0.07488294690847397\n",
            "Train step - Step 0, Loss 0.06735183298587799\n",
            "Train step - Step 0, Loss 0.07230197638273239\n",
            "Train step - Step 0, Loss 0.07162808626890182\n",
            "Train step - Step 0, Loss 0.06872624158859253\n",
            "Train step - Step 0, Loss 0.07061003148555756\n",
            "Train step - Step 0, Loss 0.07205471396446228\n",
            "Train step - Step 0, Loss 0.06975117325782776\n",
            "Train step - Step 0, Loss 0.07542259991168976\n",
            "Train epoch - Accuracy: 0.2724747474747475 Loss: 0.07153825407678431 Corrects: 3237\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.07027322053909302\n",
            "Train step - Step 0, Loss 0.07287725061178207\n",
            "Train step - Step 0, Loss 0.0747256651520729\n",
            "Train step - Step 0, Loss 0.06971116364002228\n",
            "Train step - Step 0, Loss 0.07254723459482193\n",
            "Train step - Step 0, Loss 0.0737752690911293\n",
            "Train step - Step 0, Loss 0.07161237299442291\n",
            "Train step - Step 0, Loss 0.06870871782302856\n",
            "Train step - Step 0, Loss 0.07353591173887253\n",
            "Train step - Step 0, Loss 0.07161346822977066\n",
            "Train step - Step 0, Loss 0.07333625853061676\n",
            "Train step - Step 0, Loss 0.07148994505405426\n",
            "Train step - Step 0, Loss 0.07358697801828384\n",
            "Train step - Step 0, Loss 0.07033446431159973\n",
            "Train step - Step 0, Loss 0.07000087946653366\n",
            "Train step - Step 0, Loss 0.07453985512256622\n",
            "Train epoch - Accuracy: 0.26826599326599326 Loss: 0.07195599882891685 Corrects: 3187\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.07223998010158539\n",
            "Train step - Step 0, Loss 0.07445704191923141\n",
            "Train step - Step 0, Loss 0.06925644725561142\n",
            "Train step - Step 0, Loss 0.07053614407777786\n",
            "Train step - Step 0, Loss 0.07092901319265366\n",
            "Train step - Step 0, Loss 0.0730406641960144\n",
            "Train step - Step 0, Loss 0.06989621371030807\n",
            "Train step - Step 0, Loss 0.0725736990571022\n",
            "Train step - Step 0, Loss 0.0744285136461258\n",
            "Train step - Step 0, Loss 0.07063629478216171\n",
            "Train step - Step 0, Loss 0.07447952777147293\n",
            "Train step - Step 0, Loss 0.07560031861066818\n",
            "Train step - Step 0, Loss 0.07219955325126648\n",
            "Train step - Step 0, Loss 0.0710517168045044\n",
            "Train step - Step 0, Loss 0.07056640833616257\n",
            "Train step - Step 0, Loss 0.06629115343093872\n",
            "Train epoch - Accuracy: 0.2643939393939394 Loss: 0.07194928581064397 Corrects: 3141\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.07171841710805893\n",
            "Train step - Step 0, Loss 0.07613256573677063\n",
            "Train step - Step 0, Loss 0.07421348989009857\n",
            "Train step - Step 0, Loss 0.06973706930875778\n",
            "Train step - Step 0, Loss 0.07276153564453125\n",
            "Train step - Step 0, Loss 0.07335152477025986\n",
            "Train step - Step 0, Loss 0.07125503569841385\n",
            "Train step - Step 0, Loss 0.07173283398151398\n",
            "Train step - Step 0, Loss 0.0706692785024643\n",
            "Train step - Step 0, Loss 0.0722418874502182\n",
            "Train step - Step 0, Loss 0.07270821183919907\n",
            "Train step - Step 0, Loss 0.06969678401947021\n",
            "Train step - Step 0, Loss 0.06964179128408432\n",
            "Train step - Step 0, Loss 0.07380020618438721\n",
            "Train step - Step 0, Loss 0.07402097433805466\n",
            "Train step - Step 0, Loss 0.06931649893522263\n",
            "Train epoch - Accuracy: 0.26885521885521885 Loss: 0.0721566845822816 Corrects: 3194\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.06994921714067459\n",
            "Train step - Step 0, Loss 0.0729900598526001\n",
            "Train step - Step 0, Loss 0.07249411195516586\n",
            "Train step - Step 0, Loss 0.06934651732444763\n",
            "Train step - Step 0, Loss 0.0694553330540657\n",
            "Train step - Step 0, Loss 0.07027426362037659\n",
            "Train step - Step 0, Loss 0.07687212526798248\n",
            "Train step - Step 0, Loss 0.07403504103422165\n",
            "Train step - Step 0, Loss 0.06879089772701263\n",
            "Train step - Step 0, Loss 0.07225269079208374\n",
            "Train step - Step 0, Loss 0.07116194814443588\n",
            "Train step - Step 0, Loss 0.07147660851478577\n",
            "Train step - Step 0, Loss 0.07222116738557816\n",
            "Train step - Step 0, Loss 0.07245618849992752\n",
            "Train step - Step 0, Loss 0.07016278058290482\n",
            "Train step - Step 0, Loss 0.06938140839338303\n",
            "Train epoch - Accuracy: 0.2641414141414141 Loss: 0.07152882334258821 Corrects: 3138\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.06913670897483826\n",
            "Train step - Step 0, Loss 0.07174456119537354\n",
            "Train step - Step 0, Loss 0.07089709490537643\n",
            "Train step - Step 0, Loss 0.07237090915441513\n",
            "Train step - Step 0, Loss 0.07492407411336899\n",
            "Train step - Step 0, Loss 0.07564300298690796\n",
            "Train step - Step 0, Loss 0.06932412832975388\n",
            "Train step - Step 0, Loss 0.07041718810796738\n",
            "Train step - Step 0, Loss 0.07349979877471924\n",
            "Train step - Step 0, Loss 0.07510478049516678\n",
            "Train step - Step 0, Loss 0.07511391490697861\n",
            "Train step - Step 0, Loss 0.0711665228009224\n",
            "Train step - Step 0, Loss 0.07149115204811096\n",
            "Train step - Step 0, Loss 0.07062749564647675\n",
            "Train step - Step 0, Loss 0.06959030032157898\n",
            "Train step - Step 0, Loss 0.06781267374753952\n",
            "Train epoch - Accuracy: 0.27154882154882154 Loss: 0.07194109566584982 Corrects: 3226\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.06945846974849701\n",
            "Train step - Step 0, Loss 0.07266265153884888\n",
            "Train step - Step 0, Loss 0.07258046418428421\n",
            "Train step - Step 0, Loss 0.0712733045220375\n",
            "Train step - Step 0, Loss 0.07297534495592117\n",
            "Train step - Step 0, Loss 0.07307200133800507\n",
            "Train step - Step 0, Loss 0.06940681487321854\n",
            "Train step - Step 0, Loss 0.0738314613699913\n",
            "Train step - Step 0, Loss 0.07356537878513336\n",
            "Train step - Step 0, Loss 0.06971988826990128\n",
            "Train step - Step 0, Loss 0.07174727320671082\n",
            "Train step - Step 0, Loss 0.0730108693242073\n",
            "Train step - Step 0, Loss 0.0720512643456459\n",
            "Train step - Step 0, Loss 0.06973415613174438\n",
            "Train step - Step 0, Loss 0.07072866708040237\n",
            "Train step - Step 0, Loss 0.07320086658000946\n",
            "Train epoch - Accuracy: 0.26531986531986534 Loss: 0.0717660390066378 Corrects: 3152\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.07181620597839355\n",
            "Train step - Step 0, Loss 0.07275155186653137\n",
            "Train step - Step 0, Loss 0.06959245353937149\n",
            "Train step - Step 0, Loss 0.06962893158197403\n",
            "Train step - Step 0, Loss 0.06855670362710953\n",
            "Train step - Step 0, Loss 0.07130436599254608\n",
            "Train step - Step 0, Loss 0.07345045357942581\n",
            "Train step - Step 0, Loss 0.0747675746679306\n",
            "Train step - Step 0, Loss 0.07251322269439697\n",
            "Train step - Step 0, Loss 0.06965483725070953\n",
            "Train step - Step 0, Loss 0.068455770611763\n",
            "Train step - Step 0, Loss 0.07021452486515045\n",
            "Train step - Step 0, Loss 0.07383017987012863\n",
            "Train step - Step 0, Loss 0.07279881834983826\n",
            "Train step - Step 0, Loss 0.07428821176290512\n",
            "Train step - Step 0, Loss 0.07245416939258575\n",
            "Train epoch - Accuracy: 0.271969696969697 Loss: 0.07160156432426337 Corrects: 3231\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.07132476568222046\n",
            "Train step - Step 0, Loss 0.07164105027914047\n",
            "Train step - Step 0, Loss 0.07168959081172943\n",
            "Train step - Step 0, Loss 0.0719531998038292\n",
            "Train step - Step 0, Loss 0.07184405624866486\n",
            "Train step - Step 0, Loss 0.07050491124391556\n",
            "Train step - Step 0, Loss 0.07181412726640701\n",
            "Train step - Step 0, Loss 0.07071728259325027\n",
            "Train step - Step 0, Loss 0.0714184045791626\n",
            "Train step - Step 0, Loss 0.07090464979410172\n",
            "Train step - Step 0, Loss 0.070838563144207\n",
            "Train step - Step 0, Loss 0.07207471132278442\n",
            "Train step - Step 0, Loss 0.07447607070207596\n",
            "Train step - Step 0, Loss 0.07373129576444626\n",
            "Train step - Step 0, Loss 0.072481170296669\n",
            "Train step - Step 0, Loss 0.07645706832408905\n",
            "Train epoch - Accuracy: 0.2654040404040404 Loss: 0.0719678771917266 Corrects: 3153\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.07656428217887878\n",
            "Train step - Step 0, Loss 0.07314816862344742\n",
            "Train step - Step 0, Loss 0.07262547314167023\n",
            "Train step - Step 0, Loss 0.0706796869635582\n",
            "Train step - Step 0, Loss 0.06842178851366043\n",
            "Train step - Step 0, Loss 0.06611887365579605\n",
            "Train step - Step 0, Loss 0.06993386894464493\n",
            "Train step - Step 0, Loss 0.07651316374540329\n",
            "Train step - Step 0, Loss 0.07100122421979904\n",
            "Train step - Step 0, Loss 0.07053631544113159\n",
            "Train step - Step 0, Loss 0.07242482155561447\n",
            "Train step - Step 0, Loss 0.06969861686229706\n",
            "Train step - Step 0, Loss 0.07016564905643463\n",
            "Train step - Step 0, Loss 0.07201199233531952\n",
            "Train step - Step 0, Loss 0.06997004896402359\n",
            "Train step - Step 0, Loss 0.06876078993082047\n",
            "Train epoch - Accuracy: 0.2628787878787879 Loss: 0.07124335156245665 Corrects: 3123\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.07048095762729645\n",
            "Train step - Step 0, Loss 0.07222383469343185\n",
            "Train step - Step 0, Loss 0.07064341753721237\n",
            "Train step - Step 0, Loss 0.07027547061443329\n",
            "Train step - Step 0, Loss 0.07195718586444855\n",
            "Train step - Step 0, Loss 0.06994292140007019\n",
            "Train step - Step 0, Loss 0.07010099291801453\n",
            "Train step - Step 0, Loss 0.07392524182796478\n",
            "Train step - Step 0, Loss 0.07136035710573196\n",
            "Train step - Step 0, Loss 0.06746610254049301\n",
            "Train step - Step 0, Loss 0.06915059685707092\n",
            "Train step - Step 0, Loss 0.073036789894104\n",
            "Train step - Step 0, Loss 0.0743463784456253\n",
            "Train step - Step 0, Loss 0.06966565549373627\n",
            "Train step - Step 0, Loss 0.07267308980226517\n",
            "Train step - Step 0, Loss 0.07209795713424683\n",
            "Train epoch - Accuracy: 0.2681818181818182 Loss: 0.07117866085033224 Corrects: 3186\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.06975400447845459\n",
            "Train step - Step 0, Loss 0.07558047771453857\n",
            "Train step - Step 0, Loss 0.071178138256073\n",
            "Train step - Step 0, Loss 0.07021987438201904\n",
            "Train step - Step 0, Loss 0.07550480961799622\n",
            "Train step - Step 0, Loss 0.07240282744169235\n",
            "Train step - Step 0, Loss 0.07201939076185226\n",
            "Train step - Step 0, Loss 0.06799796968698502\n",
            "Train step - Step 0, Loss 0.07082616537809372\n",
            "Train step - Step 0, Loss 0.07053563743829727\n",
            "Train step - Step 0, Loss 0.07034889608621597\n",
            "Train step - Step 0, Loss 0.07111147791147232\n",
            "Train step - Step 0, Loss 0.07403998076915741\n",
            "Train step - Step 0, Loss 0.07236278057098389\n",
            "Train step - Step 0, Loss 0.07097084820270538\n",
            "Train step - Step 0, Loss 0.06795506924390793\n",
            "Train epoch - Accuracy: 0.27154882154882154 Loss: 0.07154470900393496 Corrects: 3226\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.07332257181406021\n",
            "Train step - Step 0, Loss 0.07185657322406769\n",
            "Train step - Step 0, Loss 0.06823108345270157\n",
            "Train step - Step 0, Loss 0.0716436579823494\n",
            "Train step - Step 0, Loss 0.07338391989469528\n",
            "Train step - Step 0, Loss 0.07047004252672195\n",
            "Train step - Step 0, Loss 0.07170227915048599\n",
            "Train step - Step 0, Loss 0.07588359713554382\n",
            "Train step - Step 0, Loss 0.07164661586284637\n",
            "Train step - Step 0, Loss 0.07053481042385101\n",
            "Train step - Step 0, Loss 0.06776012480258942\n",
            "Train step - Step 0, Loss 0.07307711988687515\n",
            "Train step - Step 0, Loss 0.07242393493652344\n",
            "Train step - Step 0, Loss 0.07039378583431244\n",
            "Train step - Step 0, Loss 0.0722678080201149\n",
            "Train step - Step 0, Loss 0.06828390061855316\n",
            "Train epoch - Accuracy: 0.2641414141414141 Loss: 0.07153816587395138 Corrects: 3138\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.07152139395475388\n",
            "Train step - Step 0, Loss 0.07580842822790146\n",
            "Train step - Step 0, Loss 0.070525161921978\n",
            "Train step - Step 0, Loss 0.07156535983085632\n",
            "Train step - Step 0, Loss 0.06712672859430313\n",
            "Train step - Step 0, Loss 0.0700252577662468\n",
            "Train step - Step 0, Loss 0.07493958622217178\n",
            "Train step - Step 0, Loss 0.07372274249792099\n",
            "Train step - Step 0, Loss 0.07050959020853043\n",
            "Train step - Step 0, Loss 0.0697694718837738\n",
            "Train step - Step 0, Loss 0.07239441573619843\n",
            "Train step - Step 0, Loss 0.07219432294368744\n",
            "Train step - Step 0, Loss 0.07211577892303467\n",
            "Train step - Step 0, Loss 0.07284962385892868\n",
            "Train step - Step 0, Loss 0.07173453271389008\n",
            "Train step - Step 0, Loss 0.06811629235744476\n",
            "Train epoch - Accuracy: 0.2641414141414141 Loss: 0.07167559804940464 Corrects: 3138\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.07343984395265579\n",
            "Train step - Step 0, Loss 0.07271353155374527\n",
            "Train step - Step 0, Loss 0.06909874081611633\n",
            "Train step - Step 0, Loss 0.0702630877494812\n",
            "Train step - Step 0, Loss 0.06886178255081177\n",
            "Train step - Step 0, Loss 0.07091058790683746\n",
            "Train step - Step 0, Loss 0.07166272401809692\n",
            "Train step - Step 0, Loss 0.06962031126022339\n",
            "Train step - Step 0, Loss 0.07022605836391449\n",
            "Train step - Step 0, Loss 0.07110272347927094\n",
            "Train step - Step 0, Loss 0.0719226747751236\n",
            "Train step - Step 0, Loss 0.07319245487451553\n",
            "Train step - Step 0, Loss 0.07018990814685822\n",
            "Train step - Step 0, Loss 0.0776008889079094\n",
            "Train step - Step 0, Loss 0.07315972447395325\n",
            "Train step - Step 0, Loss 0.0747239738702774\n",
            "Train epoch - Accuracy: 0.2670875420875421 Loss: 0.0716924060173709 Corrects: 3173\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.07403308898210526\n",
            "Train step - Step 0, Loss 0.0700477734208107\n",
            "Train step - Step 0, Loss 0.07539733499288559\n",
            "Train step - Step 0, Loss 0.0693364143371582\n",
            "Train step - Step 0, Loss 0.07005931437015533\n",
            "Train step - Step 0, Loss 0.07103723287582397\n",
            "Train step - Step 0, Loss 0.07311401516199112\n",
            "Train step - Step 0, Loss 0.07213761657476425\n",
            "Train step - Step 0, Loss 0.07404040545225143\n",
            "Train step - Step 0, Loss 0.07019006460905075\n",
            "Train step - Step 0, Loss 0.07393555343151093\n",
            "Train step - Step 0, Loss 0.0684276595711708\n",
            "Train step - Step 0, Loss 0.07232628762722015\n",
            "Train step - Step 0, Loss 0.06992232799530029\n",
            "Train step - Step 0, Loss 0.07137834280729294\n",
            "Train step - Step 0, Loss 0.07377024739980698\n",
            "Train epoch - Accuracy: 0.26994949494949494 Loss: 0.07175519907414311 Corrects: 3207\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.06889664381742477\n",
            "Train step - Step 0, Loss 0.07094337791204453\n",
            "Train step - Step 0, Loss 0.07084566354751587\n",
            "Train step - Step 0, Loss 0.06909205764532089\n",
            "Train step - Step 0, Loss 0.07080791145563126\n",
            "Train step - Step 0, Loss 0.07198844850063324\n",
            "Train step - Step 0, Loss 0.07305613905191422\n",
            "Train step - Step 0, Loss 0.07122566550970078\n",
            "Train step - Step 0, Loss 0.0721573457121849\n",
            "Train step - Step 0, Loss 0.07071013003587723\n",
            "Train step - Step 0, Loss 0.07085264474153519\n",
            "Train step - Step 0, Loss 0.07135973870754242\n",
            "Train step - Step 0, Loss 0.07063380628824234\n",
            "Train step - Step 0, Loss 0.0729968324303627\n",
            "Train step - Step 0, Loss 0.07150431722402573\n",
            "Train step - Step 0, Loss 0.07271479815244675\n",
            "Train epoch - Accuracy: 0.2707912457912458 Loss: 0.07118582847443494 Corrects: 3217\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.07556402683258057\n",
            "Train step - Step 0, Loss 0.07326915860176086\n",
            "Train step - Step 0, Loss 0.0685480609536171\n",
            "Train step - Step 0, Loss 0.06791171431541443\n",
            "Train step - Step 0, Loss 0.0746137946844101\n",
            "Train step - Step 0, Loss 0.0712164118885994\n",
            "Train step - Step 0, Loss 0.07242349535226822\n",
            "Train step - Step 0, Loss 0.0689203143119812\n",
            "Train step - Step 0, Loss 0.0725526437163353\n",
            "Train step - Step 0, Loss 0.0704570785164833\n",
            "Train step - Step 0, Loss 0.06796086579561234\n",
            "Train step - Step 0, Loss 0.06939948350191116\n",
            "Train step - Step 0, Loss 0.06623473018407822\n",
            "Train step - Step 0, Loss 0.0728776678442955\n",
            "Train step - Step 0, Loss 0.07244198769330978\n",
            "Train step - Step 0, Loss 0.07202771306037903\n",
            "Train epoch - Accuracy: 0.26262626262626265 Loss: 0.07099180119206207 Corrects: 3120\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.07320112735033035\n",
            "Train step - Step 0, Loss 0.07221554219722748\n",
            "Train step - Step 0, Loss 0.069628044962883\n",
            "Train step - Step 0, Loss 0.06904412060976028\n",
            "Train step - Step 0, Loss 0.07001592963933945\n",
            "Train step - Step 0, Loss 0.07102648168802261\n",
            "Train step - Step 0, Loss 0.07056226581335068\n",
            "Train step - Step 0, Loss 0.0727730318903923\n",
            "Train step - Step 0, Loss 0.07322192937135696\n",
            "Train step - Step 0, Loss 0.07084160298109055\n",
            "Train step - Step 0, Loss 0.07036054879426956\n",
            "Train step - Step 0, Loss 0.073882557451725\n",
            "Train step - Step 0, Loss 0.06899002194404602\n",
            "Train step - Step 0, Loss 0.07019682973623276\n",
            "Train step - Step 0, Loss 0.07083303481340408\n",
            "Train step - Step 0, Loss 0.07212173193693161\n",
            "Train epoch - Accuracy: 0.26986531986531986 Loss: 0.07114990746433085 Corrects: 3206\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.0729462131857872\n",
            "Train step - Step 0, Loss 0.07059872895479202\n",
            "Train step - Step 0, Loss 0.07338761538267136\n",
            "Train step - Step 0, Loss 0.07618953287601471\n",
            "Train step - Step 0, Loss 0.07283735275268555\n",
            "Train step - Step 0, Loss 0.06884542852640152\n",
            "Train step - Step 0, Loss 0.07012958824634552\n",
            "Train step - Step 0, Loss 0.07145199924707413\n",
            "Train step - Step 0, Loss 0.06910396367311478\n",
            "Train step - Step 0, Loss 0.06938280910253525\n",
            "Train step - Step 0, Loss 0.06942056864500046\n",
            "Train step - Step 0, Loss 0.07084596157073975\n",
            "Train step - Step 0, Loss 0.0726558119058609\n",
            "Train step - Step 0, Loss 0.07151492685079575\n",
            "Train step - Step 0, Loss 0.07022809982299805\n",
            "Train step - Step 0, Loss 0.07134365290403366\n",
            "Train epoch - Accuracy: 0.2679292929292929 Loss: 0.07130381821682959 Corrects: 3183\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.07141384482383728\n",
            "Train step - Step 0, Loss 0.0687682256102562\n",
            "Train step - Step 0, Loss 0.07320509105920792\n",
            "Train step - Step 0, Loss 0.07289613783359528\n",
            "Train step - Step 0, Loss 0.07007545232772827\n",
            "Train step - Step 0, Loss 0.07312089949846268\n",
            "Train step - Step 0, Loss 0.0735764354467392\n",
            "Train step - Step 0, Loss 0.07172208279371262\n",
            "Train step - Step 0, Loss 0.0706423744559288\n",
            "Train step - Step 0, Loss 0.073033906519413\n",
            "Train step - Step 0, Loss 0.07186522334814072\n",
            "Train step - Step 0, Loss 0.06932143867015839\n",
            "Train step - Step 0, Loss 0.06967492401599884\n",
            "Train step - Step 0, Loss 0.0718458965420723\n",
            "Train step - Step 0, Loss 0.06819158047437668\n",
            "Train step - Step 0, Loss 0.07488787919282913\n",
            "Train epoch - Accuracy: 0.26624579124579123 Loss: 0.07139925377236472 Corrects: 3163\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.07013779133558273\n",
            "Train step - Step 0, Loss 0.06994739919900894\n",
            "Train step - Step 0, Loss 0.06874549388885498\n",
            "Train step - Step 0, Loss 0.07221566140651703\n",
            "Train step - Step 0, Loss 0.07100709527730942\n",
            "Train step - Step 0, Loss 0.07219582051038742\n",
            "Train step - Step 0, Loss 0.07002048939466476\n",
            "Train step - Step 0, Loss 0.0720595270395279\n",
            "Train step - Step 0, Loss 0.07345150411128998\n",
            "Train step - Step 0, Loss 0.07069800794124603\n",
            "Train step - Step 0, Loss 0.07144653797149658\n",
            "Train step - Step 0, Loss 0.0708782821893692\n",
            "Train step - Step 0, Loss 0.06820106506347656\n",
            "Train step - Step 0, Loss 0.07277465611696243\n",
            "Train step - Step 0, Loss 0.07190806418657303\n",
            "Train step - Step 0, Loss 0.07221696525812149\n",
            "Train epoch - Accuracy: 0.27121212121212124 Loss: 0.07108131543253407 Corrects: 3222\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.07591919600963593\n",
            "Train step - Step 0, Loss 0.06738470494747162\n",
            "Train step - Step 0, Loss 0.07032699137926102\n",
            "Train step - Step 0, Loss 0.0727202519774437\n",
            "Train step - Step 0, Loss 0.06996377557516098\n",
            "Train step - Step 0, Loss 0.06806886196136475\n",
            "Train step - Step 0, Loss 0.0706150159239769\n",
            "Train step - Step 0, Loss 0.06977679580450058\n",
            "Train step - Step 0, Loss 0.07012917846441269\n",
            "Train step - Step 0, Loss 0.07289444655179977\n",
            "Train step - Step 0, Loss 0.07432912290096283\n",
            "Train step - Step 0, Loss 0.07152795791625977\n",
            "Train step - Step 0, Loss 0.07133445888757706\n",
            "Train step - Step 0, Loss 0.07186941802501678\n",
            "Train step - Step 0, Loss 0.0705258920788765\n",
            "Train step - Step 0, Loss 0.07400854676961899\n",
            "Train epoch - Accuracy: 0.2612794612794613 Loss: 0.07124541897063304 Corrects: 3104\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.07209859788417816\n",
            "Train step - Step 0, Loss 0.07037822157144547\n",
            "Train step - Step 0, Loss 0.07137933373451233\n",
            "Train step - Step 0, Loss 0.07113835215568542\n",
            "Train step - Step 0, Loss 0.07652422785758972\n",
            "Train step - Step 0, Loss 0.07049515843391418\n",
            "Train step - Step 0, Loss 0.0702105164527893\n",
            "Train step - Step 0, Loss 0.06911471486091614\n",
            "Train step - Step 0, Loss 0.07370045781135559\n",
            "Train step - Step 0, Loss 0.07275031507015228\n",
            "Train step - Step 0, Loss 0.06885536760091782\n",
            "Train step - Step 0, Loss 0.07064353674650192\n",
            "Train step - Step 0, Loss 0.06928432732820511\n",
            "Train step - Step 0, Loss 0.07178065180778503\n",
            "Train step - Step 0, Loss 0.07105521857738495\n",
            "Train step - Step 0, Loss 0.07346548140048981\n",
            "Train epoch - Accuracy: 0.26961279461279464 Loss: 0.07135973768402831 Corrects: 3203\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.07420128583908081\n",
            "Train step - Step 0, Loss 0.06766422092914581\n",
            "Train step - Step 0, Loss 0.07010544836521149\n",
            "Train step - Step 0, Loss 0.07104243338108063\n",
            "Train step - Step 0, Loss 0.07151490449905396\n",
            "Train step - Step 0, Loss 0.07084251940250397\n",
            "Train step - Step 0, Loss 0.07011008262634277\n",
            "Train step - Step 0, Loss 0.07389627397060394\n",
            "Train step - Step 0, Loss 0.06990408152341843\n",
            "Train step - Step 0, Loss 0.0689910277724266\n",
            "Train step - Step 0, Loss 0.07522949576377869\n",
            "Train step - Step 0, Loss 0.0729832574725151\n",
            "Train step - Step 0, Loss 0.06821608543395996\n",
            "Train step - Step 0, Loss 0.0727459117770195\n",
            "Train step - Step 0, Loss 0.07454711198806763\n",
            "Train step - Step 0, Loss 0.06876112520694733\n",
            "Train epoch - Accuracy: 0.2674242424242424 Loss: 0.07138430178165436 Corrects: 3177\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.06890611350536346\n",
            "Train step - Step 0, Loss 0.07012226432561874\n",
            "Train step - Step 0, Loss 0.07031310349702835\n",
            "Train step - Step 0, Loss 0.0707765743136406\n",
            "Train step - Step 0, Loss 0.07152244448661804\n",
            "Train step - Step 0, Loss 0.06932424008846283\n",
            "Train step - Step 0, Loss 0.07069340348243713\n",
            "Train step - Step 0, Loss 0.06916400790214539\n",
            "Train step - Step 0, Loss 0.0711689442396164\n",
            "Train step - Step 0, Loss 0.0733550563454628\n",
            "Train step - Step 0, Loss 0.07355184108018875\n",
            "Train step - Step 0, Loss 0.07001978158950806\n",
            "Train step - Step 0, Loss 0.07301107048988342\n",
            "Train step - Step 0, Loss 0.07198639959096909\n",
            "Train step - Step 0, Loss 0.07282590866088867\n",
            "Train step - Step 0, Loss 0.07119335234165192\n",
            "Train epoch - Accuracy: 0.2708754208754209 Loss: 0.07111841858637453 Corrects: 3218\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.07449009269475937\n",
            "Train step - Step 0, Loss 0.06809411942958832\n",
            "Train step - Step 0, Loss 0.07558421045541763\n",
            "Train step - Step 0, Loss 0.07448955625295639\n",
            "Train step - Step 0, Loss 0.06982232630252838\n",
            "Train step - Step 0, Loss 0.07424913346767426\n",
            "Train step - Step 0, Loss 0.0756639763712883\n",
            "Train step - Step 0, Loss 0.06934197247028351\n",
            "Train step - Step 0, Loss 0.07183082401752472\n",
            "Train step - Step 0, Loss 0.06649403274059296\n",
            "Train step - Step 0, Loss 0.07278842478990555\n",
            "Train step - Step 0, Loss 0.06889501214027405\n",
            "Train step - Step 0, Loss 0.06813783943653107\n",
            "Train step - Step 0, Loss 0.06827642768621445\n",
            "Train step - Step 0, Loss 0.07225435972213745\n",
            "Train step - Step 0, Loss 0.07053416222333908\n",
            "Train epoch - Accuracy: 0.2664983164983165 Loss: 0.07133577028007218 Corrects: 3166\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.07058615982532501\n",
            "Train step - Step 0, Loss 0.07001951336860657\n",
            "Train step - Step 0, Loss 0.06560639292001724\n",
            "Train step - Step 0, Loss 0.0711236372590065\n",
            "Train step - Step 0, Loss 0.07222529500722885\n",
            "Train step - Step 0, Loss 0.07203740626573563\n",
            "Train step - Step 0, Loss 0.07011981308460236\n",
            "Train step - Step 0, Loss 0.07111501693725586\n",
            "Train step - Step 0, Loss 0.07301314920186996\n",
            "Train step - Step 0, Loss 0.0730251669883728\n",
            "Train step - Step 0, Loss 0.06887108832597733\n",
            "Train step - Step 0, Loss 0.07232466340065002\n",
            "Train step - Step 0, Loss 0.07073237001895905\n",
            "Train step - Step 0, Loss 0.07052651047706604\n",
            "Train step - Step 0, Loss 0.06988052278757095\n",
            "Train step - Step 0, Loss 0.06965413689613342\n",
            "Train epoch - Accuracy: 0.26296296296296295 Loss: 0.0707139932145976 Corrects: 3124\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.06521983444690704\n",
            "Train step - Step 0, Loss 0.07343105971813202\n",
            "Train step - Step 0, Loss 0.06851998716592789\n",
            "Train step - Step 0, Loss 0.07126227766275406\n",
            "Train step - Step 0, Loss 0.07338285446166992\n",
            "Train step - Step 0, Loss 0.07090488076210022\n",
            "Train step - Step 0, Loss 0.06971189379692078\n",
            "Train step - Step 0, Loss 0.06884271651506424\n",
            "Train step - Step 0, Loss 0.07303206622600555\n",
            "Train step - Step 0, Loss 0.07172080129384995\n",
            "Train step - Step 0, Loss 0.07313652336597443\n",
            "Train step - Step 0, Loss 0.07311584055423737\n",
            "Train step - Step 0, Loss 0.07275860011577606\n",
            "Train step - Step 0, Loss 0.07076516002416611\n",
            "Train step - Step 0, Loss 0.07183106988668442\n",
            "Train step - Step 0, Loss 0.0680614486336708\n",
            "Train epoch - Accuracy: 0.2701178451178451 Loss: 0.07108133301289395 Corrects: 3209\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.07226180285215378\n",
            "Train step - Step 0, Loss 0.07486647367477417\n",
            "Train step - Step 0, Loss 0.07237593829631805\n",
            "Train step - Step 0, Loss 0.07038465142250061\n",
            "Train step - Step 0, Loss 0.06921088695526123\n",
            "Train step - Step 0, Loss 0.06956033408641815\n",
            "Train step - Step 0, Loss 0.0741664245724678\n",
            "Train step - Step 0, Loss 0.07126795500516891\n",
            "Train step - Step 0, Loss 0.07254350185394287\n",
            "Train step - Step 0, Loss 0.0690966546535492\n",
            "Train step - Step 0, Loss 0.06869924068450928\n",
            "Train step - Step 0, Loss 0.06823661178350449\n",
            "Train step - Step 0, Loss 0.07234442979097366\n",
            "Train step - Step 0, Loss 0.07002528011798859\n",
            "Train step - Step 0, Loss 0.07182863354682922\n",
            "Train step - Step 0, Loss 0.06691159307956696\n",
            "Train epoch - Accuracy: 0.2604377104377104 Loss: 0.07099692144177176 Corrects: 3094\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.07183627784252167\n",
            "Train step - Step 0, Loss 0.07226752489805222\n",
            "Train step - Step 0, Loss 0.07038930058479309\n",
            "Train step - Step 0, Loss 0.06696698814630508\n",
            "Train step - Step 0, Loss 0.07323774695396423\n",
            "Train step - Step 0, Loss 0.0726751759648323\n",
            "Train step - Step 0, Loss 0.0696856901049614\n",
            "Train step - Step 0, Loss 0.07360333949327469\n",
            "Train step - Step 0, Loss 0.07246100902557373\n",
            "Train step - Step 0, Loss 0.07604474574327469\n",
            "Train step - Step 0, Loss 0.07054011523723602\n",
            "Train step - Step 0, Loss 0.07000996172428131\n",
            "Train step - Step 0, Loss 0.06861913949251175\n",
            "Train step - Step 0, Loss 0.07338119298219681\n",
            "Train step - Step 0, Loss 0.06945231556892395\n",
            "Train step - Step 0, Loss 0.07061736285686493\n",
            "Train epoch - Accuracy: 0.2718855218855219 Loss: 0.07138730748133226 Corrects: 3230\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.06933870911598206\n",
            "Train step - Step 0, Loss 0.07081116735935211\n",
            "Train step - Step 0, Loss 0.06694944947957993\n",
            "Train step - Step 0, Loss 0.07361891120672226\n",
            "Train step - Step 0, Loss 0.07044187933206558\n",
            "Train step - Step 0, Loss 0.06985614448785782\n",
            "Train step - Step 0, Loss 0.06922260671854019\n",
            "Train step - Step 0, Loss 0.07258456200361252\n",
            "Train step - Step 0, Loss 0.07188262790441513\n",
            "Train step - Step 0, Loss 0.07139663398265839\n",
            "Train step - Step 0, Loss 0.06907089799642563\n",
            "Train step - Step 0, Loss 0.07182590663433075\n",
            "Train step - Step 0, Loss 0.07011681795120239\n",
            "Train step - Step 0, Loss 0.06920257955789566\n",
            "Train step - Step 0, Loss 0.07341033220291138\n",
            "Train step - Step 0, Loss 0.06847363710403442\n",
            "Train epoch - Accuracy: 0.27095959595959596 Loss: 0.07058270663926096 Corrects: 3219\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.07227949053049088\n",
            "Train step - Step 0, Loss 0.06824244558811188\n",
            "Train step - Step 0, Loss 0.07349254190921783\n",
            "Train step - Step 0, Loss 0.07118168473243713\n",
            "Train step - Step 0, Loss 0.07209673523902893\n",
            "Train step - Step 0, Loss 0.07273449003696442\n",
            "Train step - Step 0, Loss 0.07179994136095047\n",
            "Train step - Step 0, Loss 0.0704602301120758\n",
            "Train step - Step 0, Loss 0.07085517793893814\n",
            "Train step - Step 0, Loss 0.06981559842824936\n",
            "Train step - Step 0, Loss 0.0728260725736618\n",
            "Train step - Step 0, Loss 0.07415862381458282\n",
            "Train step - Step 0, Loss 0.06777086853981018\n",
            "Train step - Step 0, Loss 0.07086963206529617\n",
            "Train step - Step 0, Loss 0.06913240253925323\n",
            "Train step - Step 0, Loss 0.06863317638635635\n",
            "Train epoch - Accuracy: 0.26750841750841753 Loss: 0.07110385369471829 Corrects: 3178\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.07204612344503403\n",
            "Train step - Step 0, Loss 0.07321733236312866\n",
            "Train step - Step 0, Loss 0.07340181618928909\n",
            "Train step - Step 0, Loss 0.06994756311178207\n",
            "Train step - Step 0, Loss 0.07112819701433182\n",
            "Train step - Step 0, Loss 0.0696902722120285\n",
            "Train step - Step 0, Loss 0.06848586350679398\n",
            "Train step - Step 0, Loss 0.07225096970796585\n",
            "Train step - Step 0, Loss 0.07057666033506393\n",
            "Train step - Step 0, Loss 0.07030513137578964\n",
            "Train step - Step 0, Loss 0.07108387351036072\n",
            "Train step - Step 0, Loss 0.07118873298168182\n",
            "Train step - Step 0, Loss 0.07006528973579407\n",
            "Train step - Step 0, Loss 0.07120873779058456\n",
            "Train step - Step 0, Loss 0.06777024269104004\n",
            "Train step - Step 0, Loss 0.07122873514890671\n",
            "Train epoch - Accuracy: 0.26885521885521885 Loss: 0.07083670468342425 Corrects: 3194\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.07196765393018723\n",
            "Train step - Step 0, Loss 0.07184360176324844\n",
            "Train step - Step 0, Loss 0.07051758468151093\n",
            "Train step - Step 0, Loss 0.07085300236940384\n",
            "Train step - Step 0, Loss 0.06939670443534851\n",
            "Train step - Step 0, Loss 0.07104755192995071\n",
            "Train step - Step 0, Loss 0.07108444720506668\n",
            "Train step - Step 0, Loss 0.0734957680106163\n",
            "Train step - Step 0, Loss 0.06931758671998978\n",
            "Train step - Step 0, Loss 0.07008960843086243\n",
            "Train step - Step 0, Loss 0.07183586061000824\n",
            "Train step - Step 0, Loss 0.07062961161136627\n",
            "Train step - Step 0, Loss 0.06989333778619766\n",
            "Train step - Step 0, Loss 0.07256369292736053\n",
            "Train step - Step 0, Loss 0.07012435048818588\n",
            "Train step - Step 0, Loss 0.07481606304645538\n",
            "Train epoch - Accuracy: 0.2697811447811448 Loss: 0.0710936819363122 Corrects: 3205\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.072793148458004\n",
            "Train step - Step 0, Loss 0.07388313859701157\n",
            "Train step - Step 0, Loss 0.07419642060995102\n",
            "Train step - Step 0, Loss 0.0701877698302269\n",
            "Train step - Step 0, Loss 0.07449216395616531\n",
            "Train step - Step 0, Loss 0.06956511735916138\n",
            "Train step - Step 0, Loss 0.07037726044654846\n",
            "Train step - Step 0, Loss 0.07184762507677078\n",
            "Train step - Step 0, Loss 0.06922696530818939\n",
            "Train step - Step 0, Loss 0.07023931294679642\n",
            "Train step - Step 0, Loss 0.07270127534866333\n",
            "Train step - Step 0, Loss 0.06705205887556076\n",
            "Train step - Step 0, Loss 0.06997592747211456\n",
            "Train step - Step 0, Loss 0.07119259238243103\n",
            "Train step - Step 0, Loss 0.07090924680233002\n",
            "Train step - Step 0, Loss 0.06941041350364685\n",
            "Train epoch - Accuracy: 0.26346801346801346 Loss: 0.07118714536079253 Corrects: 3130\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.07058257609605789\n",
            "Train step - Step 0, Loss 0.07081865519285202\n",
            "Train step - Step 0, Loss 0.0704076811671257\n",
            "Train step - Step 0, Loss 0.06889088451862335\n",
            "Train step - Step 0, Loss 0.06969423592090607\n",
            "Train step - Step 0, Loss 0.06785105168819427\n",
            "Train step - Step 0, Loss 0.0695243701338768\n",
            "Train step - Step 0, Loss 0.07085935771465302\n",
            "Train step - Step 0, Loss 0.07047563046216965\n",
            "Train step - Step 0, Loss 0.07047531753778458\n",
            "Train step - Step 0, Loss 0.0703386515378952\n",
            "Train step - Step 0, Loss 0.07308979332447052\n",
            "Train step - Step 0, Loss 0.07256828248500824\n",
            "Train step - Step 0, Loss 0.07363329827785492\n",
            "Train step - Step 0, Loss 0.07202380895614624\n",
            "Train step - Step 0, Loss 0.06855148077011108\n",
            "Train epoch - Accuracy: 0.2680976430976431 Loss: 0.07068231768078274 Corrects: 3185\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.06877006590366364\n",
            "Train step - Step 0, Loss 0.07451263815164566\n",
            "Train step - Step 0, Loss 0.07263246923685074\n",
            "Train step - Step 0, Loss 0.07123356312513351\n",
            "Train step - Step 0, Loss 0.07090701162815094\n",
            "Train step - Step 0, Loss 0.07052658498287201\n",
            "Train step - Step 0, Loss 0.06954098492860794\n",
            "Train step - Step 0, Loss 0.07186109572649002\n",
            "Train step - Step 0, Loss 0.06724727898836136\n",
            "Train step - Step 0, Loss 0.07273051887750626\n",
            "Train step - Step 0, Loss 0.07459232211112976\n",
            "Train step - Step 0, Loss 0.07120121270418167\n",
            "Train step - Step 0, Loss 0.07066205888986588\n",
            "Train step - Step 0, Loss 0.07205650955438614\n",
            "Train step - Step 0, Loss 0.0683174878358841\n",
            "Train step - Step 0, Loss 0.07116758078336716\n",
            "Train epoch - Accuracy: 0.2632996632996633 Loss: 0.07112091191188254 Corrects: 3128\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.0734674334526062\n",
            "Train step - Step 0, Loss 0.0718599259853363\n",
            "Train step - Step 0, Loss 0.07341205328702927\n",
            "Train step - Step 0, Loss 0.07315699011087418\n",
            "Train step - Step 0, Loss 0.07016222923994064\n",
            "Train step - Step 0, Loss 0.06922649592161179\n",
            "Train step - Step 0, Loss 0.07394324243068695\n",
            "Train step - Step 0, Loss 0.07056104391813278\n",
            "Train step - Step 0, Loss 0.0725335106253624\n",
            "Train step - Step 0, Loss 0.07159341126680374\n",
            "Train step - Step 0, Loss 0.06855074316263199\n",
            "Train step - Step 0, Loss 0.06941255927085876\n",
            "Train step - Step 0, Loss 0.06958670169115067\n",
            "Train step - Step 0, Loss 0.06889455020427704\n",
            "Train step - Step 0, Loss 0.06980013847351074\n",
            "Train step - Step 0, Loss 0.07217825949192047\n",
            "Train epoch - Accuracy: 0.265993265993266 Loss: 0.07111076125592897 Corrects: 3160\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.06964191794395447\n",
            "Train step - Step 0, Loss 0.06888000667095184\n",
            "Train step - Step 0, Loss 0.0699775218963623\n",
            "Train step - Step 0, Loss 0.07339081913232803\n",
            "Train step - Step 0, Loss 0.07170691341161728\n",
            "Train step - Step 0, Loss 0.06809760630130768\n",
            "Train step - Step 0, Loss 0.07077015936374664\n",
            "Train step - Step 0, Loss 0.06751101464033127\n",
            "Train step - Step 0, Loss 0.07377748936414719\n",
            "Train step - Step 0, Loss 0.07027368247509003\n",
            "Train step - Step 0, Loss 0.0715465247631073\n",
            "Train step - Step 0, Loss 0.07203037291765213\n",
            "Train step - Step 0, Loss 0.07194103300571442\n",
            "Train step - Step 0, Loss 0.07121062278747559\n",
            "Train step - Step 0, Loss 0.0711708590388298\n",
            "Train step - Step 0, Loss 0.06947628408670425\n",
            "Train epoch - Accuracy: 0.2691919191919192 Loss: 0.07075513870728137 Corrects: 3198\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.07414904981851578\n",
            "Train step - Step 0, Loss 0.06895960867404938\n",
            "Train step - Step 0, Loss 0.071089006960392\n",
            "Train step - Step 0, Loss 0.07320453226566315\n",
            "Train step - Step 0, Loss 0.07439275830984116\n",
            "Train step - Step 0, Loss 0.07105842977762222\n",
            "Train step - Step 0, Loss 0.07094430923461914\n",
            "Train step - Step 0, Loss 0.06838209182024002\n",
            "Train step - Step 0, Loss 0.06872355192899704\n",
            "Train step - Step 0, Loss 0.07124526053667068\n",
            "Train step - Step 0, Loss 0.07131374627351761\n",
            "Train step - Step 0, Loss 0.07279068231582642\n",
            "Train step - Step 0, Loss 0.07307597994804382\n",
            "Train step - Step 0, Loss 0.07086241245269775\n",
            "Train step - Step 0, Loss 0.06729739159345627\n",
            "Train step - Step 0, Loss 0.07038479298353195\n",
            "Train epoch - Accuracy: 0.2679292929292929 Loss: 0.0711422502542987 Corrects: 3183\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.07287324965000153\n",
            "Train step - Step 0, Loss 0.0727999359369278\n",
            "Train step - Step 0, Loss 0.07087227702140808\n",
            "Train step - Step 0, Loss 0.06789476424455643\n",
            "Train step - Step 0, Loss 0.06774958968162537\n",
            "Train step - Step 0, Loss 0.07090049237012863\n",
            "Train step - Step 0, Loss 0.07082244753837585\n",
            "Train step - Step 0, Loss 0.07247711718082428\n",
            "Train step - Step 0, Loss 0.06936735659837723\n",
            "Train step - Step 0, Loss 0.07284985482692719\n",
            "Train step - Step 0, Loss 0.07246895134449005\n",
            "Train step - Step 0, Loss 0.07056749612092972\n",
            "Train step - Step 0, Loss 0.06774218380451202\n",
            "Train step - Step 0, Loss 0.06918350607156754\n",
            "Train step - Step 0, Loss 0.07654181122779846\n",
            "Train step - Step 0, Loss 0.06939177215099335\n",
            "Train epoch - Accuracy: 0.2712962962962963 Loss: 0.07095844375364709 Corrects: 3223\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.06914085149765015\n",
            "Train step - Step 0, Loss 0.07066594809293747\n",
            "Train step - Step 0, Loss 0.0746256485581398\n",
            "Train step - Step 0, Loss 0.07277947664260864\n",
            "Train step - Step 0, Loss 0.07171829044818878\n",
            "Train step - Step 0, Loss 0.067563995718956\n",
            "Train step - Step 0, Loss 0.07134584337472916\n",
            "Train step - Step 0, Loss 0.06956429779529572\n",
            "Train step - Step 0, Loss 0.06903886795043945\n",
            "Train step - Step 0, Loss 0.07358551025390625\n",
            "Train step - Step 0, Loss 0.06621450930833817\n",
            "Train step - Step 0, Loss 0.07088418304920197\n",
            "Train step - Step 0, Loss 0.07291745394468307\n",
            "Train step - Step 0, Loss 0.07306832075119019\n",
            "Train step - Step 0, Loss 0.06913284957408905\n",
            "Train step - Step 0, Loss 0.0730084776878357\n",
            "Train epoch - Accuracy: 0.27306397306397306 Loss: 0.07088282963242194 Corrects: 3244\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.06808093190193176\n",
            "Train step - Step 0, Loss 0.07574671506881714\n",
            "Train step - Step 0, Loss 0.06754953414201736\n",
            "Train step - Step 0, Loss 0.07372801005840302\n",
            "Train step - Step 0, Loss 0.07432140409946442\n",
            "Train step - Step 0, Loss 0.07081165164709091\n",
            "Train step - Step 0, Loss 0.07096310704946518\n",
            "Train step - Step 0, Loss 0.06936366111040115\n",
            "Train step - Step 0, Loss 0.0679323822259903\n",
            "Train step - Step 0, Loss 0.07306042313575745\n",
            "Train step - Step 0, Loss 0.07005219161510468\n",
            "Train step - Step 0, Loss 0.06942703574895859\n",
            "Train step - Step 0, Loss 0.07096448540687561\n",
            "Train step - Step 0, Loss 0.07424617558717728\n",
            "Train step - Step 0, Loss 0.07012350112199783\n",
            "Train step - Step 0, Loss 0.07183635979890823\n",
            "Train epoch - Accuracy: 0.26456228956228955 Loss: 0.07111398810991133 Corrects: 3143\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.06950578838586807\n",
            "Train step - Step 0, Loss 0.06860542297363281\n",
            "Train step - Step 0, Loss 0.07084640860557556\n",
            "Train step - Step 0, Loss 0.06943845748901367\n",
            "Train step - Step 0, Loss 0.07426076382398605\n",
            "Train step - Step 0, Loss 0.07655210047960281\n",
            "Train step - Step 0, Loss 0.06939676403999329\n",
            "Train step - Step 0, Loss 0.07099498808383942\n",
            "Train step - Step 0, Loss 0.070393867790699\n",
            "Train step - Step 0, Loss 0.07488416135311127\n",
            "Train step - Step 0, Loss 0.072350412607193\n",
            "Train step - Step 0, Loss 0.0690092146396637\n",
            "Train step - Step 0, Loss 0.06948365271091461\n",
            "Train step - Step 0, Loss 0.06734102219343185\n",
            "Train step - Step 0, Loss 0.06611745059490204\n",
            "Train step - Step 0, Loss 0.07334957271814346\n",
            "Train epoch - Accuracy: 0.26776094276094276 Loss: 0.0706949875059754 Corrects: 3181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.52 0.05520527437329292\n",
            "TEST GROUP:  0.54\n",
            "TEST ALL:  0.38266666666666665\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  10000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 82, 2, 10, 18, 26, 34, 42, 50, 58, 66, 74, 90, 87, 98, 3, 11, 19, 27, 35, 43, 51, 59, 67, 97, 89, 81, 73, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 1, 9, 17, 25, 33, 41, 49, 57, 65, 75, 83, 91, 93, 14, 22, 30, 38, 46, 54, 62, 70, 78, 86, 94, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 6, 85, 99, 77, 4, 12, 20, 28, 36, 44, 52, 60, 68, 76, 84, 92, 5, 13, 21, 29, 37, 45, 53, 61, 69, 0]\n",
            "TRAIN_SET CLASSES:  [91, 11, 3, 66, 62, 89, 73, 33, 25, 1]\n",
            "VALIDATION CLASSES:  [62, 25, 33, 91, 89, 11, 73, 3, 66, 1]\n",
            "GROUP:  10\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [91, 11, 3, 66, 62, 89, 73, 33, 25, 1]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  100\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.1527811586856842\n",
            "Train step - Step 10, Loss 0.1131708100438118\n",
            "Train step - Step 20, Loss 0.102824367582798\n",
            "Train step - Step 30, Loss 0.10780378431081772\n",
            "Train step - Step 40, Loss 0.0964813232421875\n",
            "Train step - Step 50, Loss 0.098739393055439\n",
            "Train epoch - Accuracy: 0.13261183261183263 Loss: 0.10795705199542671 Corrects: 919\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.09968818724155426\n",
            "Train step - Step 70, Loss 0.09971245378255844\n",
            "Train step - Step 80, Loss 0.09621088951826096\n",
            "Train step - Step 90, Loss 0.09510888904333115\n",
            "Train step - Step 100, Loss 0.09520570188760757\n",
            "Train epoch - Accuracy: 0.2072150072150072 Loss: 0.09600872630078727 Corrects: 1436\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.0981699600815773\n",
            "Train step - Step 120, Loss 0.09650906175374985\n",
            "Train step - Step 130, Loss 0.0948498323559761\n",
            "Train step - Step 140, Loss 0.09507478773593903\n",
            "Train step - Step 150, Loss 0.09240857511758804\n",
            "Train step - Step 160, Loss 0.09274417906999588\n",
            "Train epoch - Accuracy: 0.26464646464646463 Loss: 0.09443493161839668 Corrects: 1834\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.08907458931207657\n",
            "Train step - Step 180, Loss 0.09493110328912735\n",
            "Train step - Step 190, Loss 0.09529407322406769\n",
            "Train step - Step 200, Loss 0.09070795029401779\n",
            "Train step - Step 210, Loss 0.09222524613142014\n",
            "Train epoch - Accuracy: 0.3142857142857143 Loss: 0.09330179087312362 Corrects: 2178\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.09696067869663239\n",
            "Train step - Step 230, Loss 0.09194036573171616\n",
            "Train step - Step 240, Loss 0.09005329012870789\n",
            "Train step - Step 250, Loss 0.09750322997570038\n",
            "Train step - Step 260, Loss 0.09217538684606552\n",
            "Train step - Step 270, Loss 0.09072563052177429\n",
            "Train epoch - Accuracy: 0.32886002886002885 Loss: 0.09269063830762715 Corrects: 2279\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.09179309755563736\n",
            "Train step - Step 290, Loss 0.0935640037059784\n",
            "Train step - Step 300, Loss 0.09056733548641205\n",
            "Train step - Step 310, Loss 0.09212110936641693\n",
            "Train step - Step 320, Loss 0.0915120467543602\n",
            "Train epoch - Accuracy: 0.3621933621933622 Loss: 0.09208168684576153 Corrects: 2510\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.08982434868812561\n",
            "Train step - Step 340, Loss 0.09140776097774506\n",
            "Train step - Step 350, Loss 0.09309085458517075\n",
            "Train step - Step 360, Loss 0.09644065052270889\n",
            "Train step - Step 370, Loss 0.09121044725179672\n",
            "Train step - Step 380, Loss 0.09501371532678604\n",
            "Train epoch - Accuracy: 0.3784992784992785 Loss: 0.09181147198613415 Corrects: 2623\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.09196949005126953\n",
            "Train step - Step 400, Loss 0.08885117620229721\n",
            "Train step - Step 410, Loss 0.09249186515808105\n",
            "Train step - Step 420, Loss 0.08932483196258545\n",
            "Train step - Step 430, Loss 0.09018964320421219\n",
            "Train epoch - Accuracy: 0.40274170274170273 Loss: 0.09151775944456565 Corrects: 2791\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.09176768362522125\n",
            "Train step - Step 450, Loss 0.08923650532960892\n",
            "Train step - Step 460, Loss 0.09224429726600647\n",
            "Train step - Step 470, Loss 0.09070640057325363\n",
            "Train step - Step 480, Loss 0.09361305832862854\n",
            "Train step - Step 490, Loss 0.08889083564281464\n",
            "Train epoch - Accuracy: 0.4046176046176046 Loss: 0.0912018494129525 Corrects: 2804\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.09004706889390945\n",
            "Train step - Step 510, Loss 0.08888950943946838\n",
            "Train step - Step 520, Loss 0.09608102589845657\n",
            "Train step - Step 530, Loss 0.09165141731500626\n",
            "Train step - Step 540, Loss 0.08833876997232437\n",
            "Train epoch - Accuracy: 0.42077922077922075 Loss: 0.09114188104222863 Corrects: 2916\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.08989617973566055\n",
            "Train step - Step 560, Loss 0.08725851029157639\n",
            "Train step - Step 570, Loss 0.09252385795116425\n",
            "Train step - Step 580, Loss 0.08935483545064926\n",
            "Train step - Step 590, Loss 0.09176690876483917\n",
            "Train step - Step 600, Loss 0.0902508869767189\n",
            "Train epoch - Accuracy: 0.43636363636363634 Loss: 0.09096873714595302 Corrects: 3024\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.09573221206665039\n",
            "Train step - Step 620, Loss 0.09103897213935852\n",
            "Train step - Step 630, Loss 0.08574269711971283\n",
            "Train step - Step 640, Loss 0.08551052212715149\n",
            "Train step - Step 650, Loss 0.09072669595479965\n",
            "Train epoch - Accuracy: 0.4378066378066378 Loss: 0.09076150925171496 Corrects: 3034\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.09280452877283096\n",
            "Train step - Step 670, Loss 0.09314414113759995\n",
            "Train step - Step 680, Loss 0.09347248077392578\n",
            "Train step - Step 690, Loss 0.09105342626571655\n",
            "Train step - Step 700, Loss 0.08919170498847961\n",
            "Train step - Step 710, Loss 0.09279422461986542\n",
            "Train epoch - Accuracy: 0.4509379509379509 Loss: 0.09046517668606399 Corrects: 3125\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.08977328985929489\n",
            "Train step - Step 730, Loss 0.09109774976968765\n",
            "Train step - Step 740, Loss 0.08755239099264145\n",
            "Train step - Step 750, Loss 0.0891994759440422\n",
            "Train step - Step 760, Loss 0.0900912955403328\n",
            "Train epoch - Accuracy: 0.4533910533910534 Loss: 0.09032465136283403 Corrects: 3142\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.09265102446079254\n",
            "Train step - Step 780, Loss 0.09368935972452164\n",
            "Train step - Step 790, Loss 0.09175589680671692\n",
            "Train step - Step 800, Loss 0.08910608291625977\n",
            "Train step - Step 810, Loss 0.08622953295707703\n",
            "Train step - Step 820, Loss 0.08968325704336166\n",
            "Train epoch - Accuracy: 0.46825396825396826 Loss: 0.09037992391966466 Corrects: 3245\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.09180225431919098\n",
            "Train step - Step 840, Loss 0.08872090280056\n",
            "Train step - Step 850, Loss 0.08450900763273239\n",
            "Train step - Step 860, Loss 0.08746644854545593\n",
            "Train step - Step 870, Loss 0.090523861348629\n",
            "Train epoch - Accuracy: 0.4733044733044733 Loss: 0.08997467337619691 Corrects: 3280\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.09117259830236435\n",
            "Train step - Step 890, Loss 0.08651723712682724\n",
            "Train step - Step 900, Loss 0.08979114145040512\n",
            "Train step - Step 910, Loss 0.09288850426673889\n",
            "Train step - Step 920, Loss 0.08762207627296448\n",
            "Train step - Step 930, Loss 0.09005044400691986\n",
            "Train epoch - Accuracy: 0.4784992784992785 Loss: 0.09001060474400568 Corrects: 3316\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.09123265743255615\n",
            "Train step - Step 950, Loss 0.09015794843435287\n",
            "Train step - Step 960, Loss 0.08907407522201538\n",
            "Train step - Step 970, Loss 0.08802670985460281\n",
            "Train step - Step 980, Loss 0.09054715931415558\n",
            "Train epoch - Accuracy: 0.48528138528138526 Loss: 0.08986830894780193 Corrects: 3363\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.09035789966583252\n",
            "Train step - Step 1000, Loss 0.09233514219522476\n",
            "Train step - Step 1010, Loss 0.08919979631900787\n",
            "Train step - Step 1020, Loss 0.09044500440359116\n",
            "Train step - Step 1030, Loss 0.08333810418844223\n",
            "Train step - Step 1040, Loss 0.08695048838853836\n",
            "Train epoch - Accuracy: 0.49033189033189034 Loss: 0.08981659600960056 Corrects: 3398\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.08792714774608612\n",
            "Train step - Step 1060, Loss 0.09030523151159286\n",
            "Train step - Step 1070, Loss 0.08883611112833023\n",
            "Train step - Step 1080, Loss 0.09135165810585022\n",
            "Train step - Step 1090, Loss 0.09026278555393219\n",
            "Train epoch - Accuracy: 0.4911976911976912 Loss: 0.0895457497815377 Corrects: 3404\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.08414077758789062\n",
            "Train step - Step 1110, Loss 0.09129492193460464\n",
            "Train step - Step 1120, Loss 0.08878804743289948\n",
            "Train step - Step 1130, Loss 0.08718723803758621\n",
            "Train step - Step 1140, Loss 0.08719364553689957\n",
            "Train step - Step 1150, Loss 0.09256888926029205\n",
            "Train epoch - Accuracy: 0.4961038961038961 Loss: 0.0896792007150588 Corrects: 3438\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.08952086418867111\n",
            "Train step - Step 1170, Loss 0.08659934997558594\n",
            "Train step - Step 1180, Loss 0.08970832824707031\n",
            "Train step - Step 1190, Loss 0.0887257531285286\n",
            "Train step - Step 1200, Loss 0.08908902853727341\n",
            "Train epoch - Accuracy: 0.5025974025974026 Loss: 0.08960953243883141 Corrects: 3483\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.08879049122333527\n",
            "Train step - Step 1220, Loss 0.08564496785402298\n",
            "Train step - Step 1230, Loss 0.08941507339477539\n",
            "Train step - Step 1240, Loss 0.09161169826984406\n",
            "Train step - Step 1250, Loss 0.08602424710988998\n",
            "Train step - Step 1260, Loss 0.08754003047943115\n",
            "Train epoch - Accuracy: 0.5099567099567099 Loss: 0.08930974415198377 Corrects: 3534\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.08938735723495483\n",
            "Train step - Step 1280, Loss 0.0933389961719513\n",
            "Train step - Step 1290, Loss 0.09178492426872253\n",
            "Train step - Step 1300, Loss 0.08848061412572861\n",
            "Train step - Step 1310, Loss 0.0922146588563919\n",
            "Train epoch - Accuracy: 0.5167388167388167 Loss: 0.08938742764455415 Corrects: 3581\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.0850958600640297\n",
            "Train step - Step 1330, Loss 0.08877525478601456\n",
            "Train step - Step 1340, Loss 0.08719400316476822\n",
            "Train step - Step 1350, Loss 0.08737771958112717\n",
            "Train step - Step 1360, Loss 0.09031913429498672\n",
            "Train step - Step 1370, Loss 0.08915451169013977\n",
            "Train epoch - Accuracy: 0.5165945165945166 Loss: 0.08932197050958829 Corrects: 3580\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.09011205285787582\n",
            "Train step - Step 1390, Loss 0.08734472095966339\n",
            "Train step - Step 1400, Loss 0.08811332285404205\n",
            "Train step - Step 1410, Loss 0.0871228501200676\n",
            "Train step - Step 1420, Loss 0.08907346427440643\n",
            "Train epoch - Accuracy: 0.5219336219336219 Loss: 0.08892069986630312 Corrects: 3617\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.0880332812666893\n",
            "Train step - Step 1440, Loss 0.08536993712186813\n",
            "Train step - Step 1450, Loss 0.08870381861925125\n",
            "Train step - Step 1460, Loss 0.08890628814697266\n",
            "Train step - Step 1470, Loss 0.08886408805847168\n",
            "Train step - Step 1480, Loss 0.08737608045339584\n",
            "Train epoch - Accuracy: 0.5197691197691198 Loss: 0.08924282061589228 Corrects: 3602\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.0879448875784874\n",
            "Train step - Step 1500, Loss 0.09150879830121994\n",
            "Train step - Step 1510, Loss 0.086102195084095\n",
            "Train step - Step 1520, Loss 0.08897066116333008\n",
            "Train step - Step 1530, Loss 0.08734022080898285\n",
            "Train epoch - Accuracy: 0.5294372294372295 Loss: 0.08895419679076813 Corrects: 3669\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09086772799491882\n",
            "Train step - Step 1550, Loss 0.08860544115304947\n",
            "Train step - Step 1560, Loss 0.09006961435079575\n",
            "Train step - Step 1570, Loss 0.09111738950014114\n",
            "Train step - Step 1580, Loss 0.09016826748847961\n",
            "Train step - Step 1590, Loss 0.08872474730014801\n",
            "Train epoch - Accuracy: 0.5288600288600288 Loss: 0.08891614644558399 Corrects: 3665\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.08687339723110199\n",
            "Train step - Step 1610, Loss 0.08732770383358002\n",
            "Train step - Step 1620, Loss 0.08759685605764389\n",
            "Train step - Step 1630, Loss 0.0837099626660347\n",
            "Train step - Step 1640, Loss 0.08678584545850754\n",
            "Train epoch - Accuracy: 0.5334776334776334 Loss: 0.08891226802166406 Corrects: 3697\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.08626814931631088\n",
            "Train step - Step 1660, Loss 0.08758126944303513\n",
            "Train step - Step 1670, Loss 0.08646444231271744\n",
            "Train step - Step 1680, Loss 0.08928225934505463\n",
            "Train step - Step 1690, Loss 0.08651244640350342\n",
            "Train step - Step 1700, Loss 0.08877281099557877\n",
            "Train epoch - Accuracy: 0.5375180375180375 Loss: 0.0890174662438994 Corrects: 3725\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.09090986102819443\n",
            "Train step - Step 1720, Loss 0.08857261389493942\n",
            "Train step - Step 1730, Loss 0.09311390668153763\n",
            "Train step - Step 1740, Loss 0.08568809926509857\n",
            "Train step - Step 1750, Loss 0.0883791521191597\n",
            "Train epoch - Accuracy: 0.5388167388167389 Loss: 0.08894007704818747 Corrects: 3734\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.08861292898654938\n",
            "Train step - Step 1770, Loss 0.0921691283583641\n",
            "Train step - Step 1780, Loss 0.08919865638017654\n",
            "Train step - Step 1790, Loss 0.08619312196969986\n",
            "Train step - Step 1800, Loss 0.08881445974111557\n",
            "Train step - Step 1810, Loss 0.0885901153087616\n",
            "Train epoch - Accuracy: 0.5505050505050505 Loss: 0.08879223933596632 Corrects: 3815\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.08808954805135727\n",
            "Train step - Step 1830, Loss 0.0905081257224083\n",
            "Train step - Step 1840, Loss 0.08775889873504639\n",
            "Train step - Step 1850, Loss 0.08486462384462357\n",
            "Train step - Step 1860, Loss 0.08926481008529663\n",
            "Train epoch - Accuracy: 0.5440115440115441 Loss: 0.08852119773067266 Corrects: 3770\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.08497098833322525\n",
            "Train step - Step 1880, Loss 0.08795052021741867\n",
            "Train step - Step 1890, Loss 0.09094463288784027\n",
            "Train step - Step 1900, Loss 0.08870763331651688\n",
            "Train step - Step 1910, Loss 0.08859918266534805\n",
            "Train step - Step 1920, Loss 0.08778232336044312\n",
            "Train epoch - Accuracy: 0.5479076479076479 Loss: 0.08861826472683214 Corrects: 3797\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.08904214948415756\n",
            "Train step - Step 1940, Loss 0.09036169201135635\n",
            "Train step - Step 1950, Loss 0.09130393713712692\n",
            "Train step - Step 1960, Loss 0.08864776045084\n",
            "Train step - Step 1970, Loss 0.08890493214130402\n",
            "Train epoch - Accuracy: 0.5532467532467532 Loss: 0.08878690106270117 Corrects: 3834\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.0879838764667511\n",
            "Train step - Step 1990, Loss 0.08997447043657303\n",
            "Train step - Step 2000, Loss 0.08653402328491211\n",
            "Train step - Step 2010, Loss 0.08784164488315582\n",
            "Train step - Step 2020, Loss 0.0905686542391777\n",
            "Train step - Step 2030, Loss 0.08836359530687332\n",
            "Train epoch - Accuracy: 0.5593073593073593 Loss: 0.08866997593409055 Corrects: 3876\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.08504115790128708\n",
            "Train step - Step 2050, Loss 0.0874357745051384\n",
            "Train step - Step 2060, Loss 0.09346843510866165\n",
            "Train step - Step 2070, Loss 0.08903920650482178\n",
            "Train step - Step 2080, Loss 0.0887560024857521\n",
            "Train epoch - Accuracy: 0.5506493506493506 Loss: 0.08843362090778557 Corrects: 3816\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.08474166691303253\n",
            "Train step - Step 2100, Loss 0.08920657634735107\n",
            "Train step - Step 2110, Loss 0.08883949369192123\n",
            "Train step - Step 2120, Loss 0.08978690952062607\n",
            "Train step - Step 2130, Loss 0.09040679782629013\n",
            "Train step - Step 2140, Loss 0.09110774844884872\n",
            "Train epoch - Accuracy: 0.5584415584415584 Loss: 0.08810583192204673 Corrects: 3870\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.08905047923326492\n",
            "Train step - Step 2160, Loss 0.08963146060705185\n",
            "Train step - Step 2170, Loss 0.08664821088314056\n",
            "Train step - Step 2180, Loss 0.09050491452217102\n",
            "Train step - Step 2190, Loss 0.08933144062757492\n",
            "Train epoch - Accuracy: 0.5601731601731602 Loss: 0.08850399554205836 Corrects: 3882\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09012619405984879\n",
            "Train step - Step 2210, Loss 0.09055181592702866\n",
            "Train step - Step 2220, Loss 0.08716141432523727\n",
            "Train step - Step 2230, Loss 0.08784729987382889\n",
            "Train step - Step 2240, Loss 0.0870947614312172\n",
            "Train step - Step 2250, Loss 0.08972886949777603\n",
            "Train epoch - Accuracy: 0.5588744588744589 Loss: 0.08837895051913516 Corrects: 3873\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.08875901997089386\n",
            "Train step - Step 2270, Loss 0.08781930804252625\n",
            "Train step - Step 2280, Loss 0.09049120545387268\n",
            "Train step - Step 2290, Loss 0.08725923299789429\n",
            "Train step - Step 2300, Loss 0.09126225858926773\n",
            "Train epoch - Accuracy: 0.5694083694083694 Loss: 0.08829094402674817 Corrects: 3946\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.08768130838871002\n",
            "Train step - Step 2320, Loss 0.0936187133193016\n",
            "Train step - Step 2330, Loss 0.08698862046003342\n",
            "Train step - Step 2340, Loss 0.08853255957365036\n",
            "Train step - Step 2350, Loss 0.08735377341508865\n",
            "Train step - Step 2360, Loss 0.09392575919628143\n",
            "Train epoch - Accuracy: 0.5675324675324676 Loss: 0.08823145880413606 Corrects: 3933\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.08852462470531464\n",
            "Train step - Step 2380, Loss 0.08654100447893143\n",
            "Train step - Step 2390, Loss 0.08750592917203903\n",
            "Train step - Step 2400, Loss 0.08716490864753723\n",
            "Train step - Step 2410, Loss 0.09021176397800446\n",
            "Train epoch - Accuracy: 0.5714285714285714 Loss: 0.08825449843986381 Corrects: 3960\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.09239257872104645\n",
            "Train step - Step 2430, Loss 0.08878008276224136\n",
            "Train step - Step 2440, Loss 0.09034400433301926\n",
            "Train step - Step 2450, Loss 0.08725575357675552\n",
            "Train step - Step 2460, Loss 0.08893802762031555\n",
            "Train step - Step 2470, Loss 0.08564310520887375\n",
            "Train epoch - Accuracy: 0.5790764790764791 Loss: 0.08807693038882976 Corrects: 4013\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.08800501376390457\n",
            "Train step - Step 2490, Loss 0.09024184942245483\n",
            "Train step - Step 2500, Loss 0.0881936252117157\n",
            "Train step - Step 2510, Loss 0.0905894860625267\n",
            "Train step - Step 2520, Loss 0.08708808571100235\n",
            "Train epoch - Accuracy: 0.5816738816738817 Loss: 0.08822286042988214 Corrects: 4031\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.08565068244934082\n",
            "Train step - Step 2540, Loss 0.0854482427239418\n",
            "Train step - Step 2550, Loss 0.08772287517786026\n",
            "Train step - Step 2560, Loss 0.08401243388652802\n",
            "Train step - Step 2570, Loss 0.08988998085260391\n",
            "Train step - Step 2580, Loss 0.087812639772892\n",
            "Train epoch - Accuracy: 0.5725829725829726 Loss: 0.0879902435738115 Corrects: 3968\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.09271682798862457\n",
            "Train step - Step 2600, Loss 0.08777356892824173\n",
            "Train step - Step 2610, Loss 0.0901530459523201\n",
            "Train step - Step 2620, Loss 0.09075506776571274\n",
            "Train step - Step 2630, Loss 0.09195216000080109\n",
            "Train epoch - Accuracy: 0.5790764790764791 Loss: 0.08811121864666327 Corrects: 4013\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.08379052579402924\n",
            "Train step - Step 2650, Loss 0.08731526881456375\n",
            "Train step - Step 2660, Loss 0.09053339064121246\n",
            "Train step - Step 2670, Loss 0.09065459668636322\n",
            "Train step - Step 2680, Loss 0.0913010761141777\n",
            "Train step - Step 2690, Loss 0.08636491745710373\n",
            "Train epoch - Accuracy: 0.57994227994228 Loss: 0.08787642585121708 Corrects: 4019\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.09072458744049072\n",
            "Train step - Step 2710, Loss 0.08429902046918869\n",
            "Train step - Step 2720, Loss 0.08930953592061996\n",
            "Train step - Step 2730, Loss 0.09007972478866577\n",
            "Train step - Step 2740, Loss 0.08701345324516296\n",
            "Train epoch - Accuracy: 0.5909090909090909 Loss: 0.08764417508420834 Corrects: 4095\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.08900487422943115\n",
            "Train step - Step 2760, Loss 0.08308036625385284\n",
            "Train step - Step 2770, Loss 0.08640078455209732\n",
            "Train step - Step 2780, Loss 0.0841093361377716\n",
            "Train step - Step 2790, Loss 0.08801142126321793\n",
            "Train step - Step 2800, Loss 0.0883815586566925\n",
            "Train epoch - Accuracy: 0.5904761904761905 Loss: 0.08736656229045311 Corrects: 4092\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.08636467158794403\n",
            "Train step - Step 2820, Loss 0.0903644934296608\n",
            "Train step - Step 2830, Loss 0.0905725434422493\n",
            "Train step - Step 2840, Loss 0.08891741186380386\n",
            "Train step - Step 2850, Loss 0.08926182240247726\n",
            "Train epoch - Accuracy: 0.5891774891774891 Loss: 0.08749843481686208 Corrects: 4083\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.08594972640275955\n",
            "Train step - Step 2870, Loss 0.0868690088391304\n",
            "Train step - Step 2880, Loss 0.08725643903017044\n",
            "Train step - Step 2890, Loss 0.08571618795394897\n",
            "Train step - Step 2900, Loss 0.08543223142623901\n",
            "Train step - Step 2910, Loss 0.08896787464618683\n",
            "Train epoch - Accuracy: 0.5952380952380952 Loss: 0.08714076090297658 Corrects: 4125\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.08973998576402664\n",
            "Train step - Step 2930, Loss 0.08358801901340485\n",
            "Train step - Step 2940, Loss 0.08771315962076187\n",
            "Train step - Step 2950, Loss 0.0825381800532341\n",
            "Train step - Step 2960, Loss 0.0864735096693039\n",
            "Train epoch - Accuracy: 0.5914862914862915 Loss: 0.08742649804204057 Corrects: 4099\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.08897905051708221\n",
            "Train step - Step 2980, Loss 0.08823634684085846\n",
            "Train step - Step 2990, Loss 0.08588822185993195\n",
            "Train step - Step 3000, Loss 0.0886135920882225\n",
            "Train step - Step 3010, Loss 0.08780180662870407\n",
            "Train step - Step 3020, Loss 0.08730599284172058\n",
            "Train epoch - Accuracy: 0.591919191919192 Loss: 0.08744633190903657 Corrects: 4102\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.0871015414595604\n",
            "Train step - Step 3040, Loss 0.08467766642570496\n",
            "Train step - Step 3050, Loss 0.08459928631782532\n",
            "Train step - Step 3060, Loss 0.08850786089897156\n",
            "Train step - Step 3070, Loss 0.0873577669262886\n",
            "Train epoch - Accuracy: 0.5823953823953824 Loss: 0.08775947560350617 Corrects: 4036\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.08748001605272293\n",
            "Train step - Step 3090, Loss 0.08710671961307526\n",
            "Train step - Step 3100, Loss 0.09052154421806335\n",
            "Train step - Step 3110, Loss 0.08811066299676895\n",
            "Train step - Step 3120, Loss 0.08699768781661987\n",
            "Train step - Step 3130, Loss 0.08551914989948273\n",
            "Train epoch - Accuracy: 0.5978354978354978 Loss: 0.08748014600245983 Corrects: 4143\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.09038105607032776\n",
            "Train step - Step 3150, Loss 0.08500424027442932\n",
            "Train step - Step 3160, Loss 0.08802682906389236\n",
            "Train step - Step 3170, Loss 0.08552776277065277\n",
            "Train step - Step 3180, Loss 0.08370118588209152\n",
            "Train epoch - Accuracy: 0.6008658008658009 Loss: 0.08744993959627455 Corrects: 4164\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.09259483218193054\n",
            "Train step - Step 3200, Loss 0.08459221571683884\n",
            "Train step - Step 3210, Loss 0.08832869678735733\n",
            "Train step - Step 3220, Loss 0.08466851711273193\n",
            "Train step - Step 3230, Loss 0.08874982595443726\n",
            "Train step - Step 3240, Loss 0.08876340836286545\n",
            "Train epoch - Accuracy: 0.5961038961038961 Loss: 0.08738576446002697 Corrects: 4131\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.0847356766462326\n",
            "Train step - Step 3260, Loss 0.08977073431015015\n",
            "Train step - Step 3270, Loss 0.08960108458995819\n",
            "Train step - Step 3280, Loss 0.08568089455366135\n",
            "Train step - Step 3290, Loss 0.09052400290966034\n",
            "Train epoch - Accuracy: 0.5897546897546898 Loss: 0.08766938644914228 Corrects: 4087\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.08732181042432785\n",
            "Train step - Step 3310, Loss 0.08854597061872482\n",
            "Train step - Step 3320, Loss 0.08779445290565491\n",
            "Train step - Step 3330, Loss 0.0892314687371254\n",
            "Train step - Step 3340, Loss 0.0862479954957962\n",
            "Train step - Step 3350, Loss 0.08618173748254776\n",
            "Train epoch - Accuracy: 0.5962481962481962 Loss: 0.08752845793016373 Corrects: 4132\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.08488377183675766\n",
            "Train step - Step 3370, Loss 0.09176002442836761\n",
            "Train step - Step 3380, Loss 0.08470527827739716\n",
            "Train step - Step 3390, Loss 0.09236297756433487\n",
            "Train step - Step 3400, Loss 0.08773330599069595\n",
            "Train epoch - Accuracy: 0.5936507936507937 Loss: 0.0875575130270501 Corrects: 4114\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.08677402138710022\n",
            "Train step - Step 3420, Loss 0.09026462584733963\n",
            "Train step - Step 3430, Loss 0.0882018655538559\n",
            "Train step - Step 3440, Loss 0.08946218341588974\n",
            "Train step - Step 3450, Loss 0.08935977518558502\n",
            "Train step - Step 3460, Loss 0.0905851274728775\n",
            "Train epoch - Accuracy: 0.5935064935064935 Loss: 0.0875355270195317 Corrects: 4113\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.08631530404090881\n",
            "Train step - Step 3480, Loss 0.08837588876485825\n",
            "Train step - Step 3490, Loss 0.08725745975971222\n",
            "Train step - Step 3500, Loss 0.08497243374586105\n",
            "Train step - Step 3510, Loss 0.08831634372472763\n",
            "Train epoch - Accuracy: 0.5953823953823953 Loss: 0.08732437639998496 Corrects: 4126\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.0845874771475792\n",
            "Train step - Step 3530, Loss 0.08716823160648346\n",
            "Train step - Step 3540, Loss 0.08581468462944031\n",
            "Train step - Step 3550, Loss 0.08590664714574814\n",
            "Train step - Step 3560, Loss 0.08553540706634521\n",
            "Train step - Step 3570, Loss 0.08759818971157074\n",
            "Train epoch - Accuracy: 0.5927849927849927 Loss: 0.08734106631979109 Corrects: 4108\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.08813634514808655\n",
            "Train step - Step 3590, Loss 0.08937601000070572\n",
            "Train step - Step 3600, Loss 0.08761588484048843\n",
            "Train step - Step 3610, Loss 0.0879901796579361\n",
            "Train step - Step 3620, Loss 0.08804970234632492\n",
            "Train epoch - Accuracy: 0.5878787878787879 Loss: 0.08738404417794848 Corrects: 4074\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09167411923408508\n",
            "Train step - Step 3640, Loss 0.08475574105978012\n",
            "Train step - Step 3650, Loss 0.08782367408275604\n",
            "Train step - Step 3660, Loss 0.08736716955900192\n",
            "Train step - Step 3670, Loss 0.08852145820856094\n",
            "Train step - Step 3680, Loss 0.09006095677614212\n",
            "Train epoch - Accuracy: 0.5956709956709957 Loss: 0.08747946836301602 Corrects: 4128\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.08477453887462616\n",
            "Train step - Step 3700, Loss 0.08240334689617157\n",
            "Train step - Step 3710, Loss 0.08787959814071655\n",
            "Train step - Step 3720, Loss 0.08733240514993668\n",
            "Train step - Step 3730, Loss 0.08820436894893646\n",
            "Train epoch - Accuracy: 0.5924963924963925 Loss: 0.08731762317007927 Corrects: 4106\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.08896961063146591\n",
            "Train step - Step 3750, Loss 0.08476310223340988\n",
            "Train step - Step 3760, Loss 0.08540410548448563\n",
            "Train step - Step 3770, Loss 0.08946897089481354\n",
            "Train step - Step 3780, Loss 0.08699049055576324\n",
            "Train step - Step 3790, Loss 0.0852602943778038\n",
            "Train epoch - Accuracy: 0.5975468975468975 Loss: 0.08756545970020184 Corrects: 4141\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.08809003978967667\n",
            "Train step - Step 3810, Loss 0.08749301731586456\n",
            "Train step - Step 3820, Loss 0.08403105288743973\n",
            "Train step - Step 3830, Loss 0.0848577693104744\n",
            "Train step - Step 3840, Loss 0.08698470890522003\n",
            "Train epoch - Accuracy: 0.5946608946608947 Loss: 0.08730794075677577 Corrects: 4121\n",
            "Training finished in 460.67982721328735 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52, 71, 51, 43, 78, 74, 38, 37, 29, 48, 44, 87, 58, 46, 26, 77, 41, 5, 92, 28, 12, 91, 11, 3, 66, 62, 89, 73, 33, 25, 1]\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  20\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee55b250>\n",
            "Constructing exemplars of class 91\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [17071, 16224, 47996, 12842, 8587, 29615, 40545, 21719, 30866, 22494, 26279, 44311, 39619, 15519, 38374, 8416, 19231, 32894, 28521, 3038]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee490d50>\n",
            "Constructing exemplars of class 11\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [3695, 28632, 29279, 37, 29202, 39545, 34199, 33937, 49514, 4011, 24045, 21793, 19281, 35117, 11325, 15539, 36488, 4890, 15992, 9505]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a25a190>\n",
            "Constructing exemplars of class 3\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [35335, 18092, 14199, 9434, 11138, 13302, 20380, 20266, 46319, 20572, 45475, 44319, 28728, 40211, 15311, 17820, 40840, 9937, 3887, 1283]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff30a16de90>\n",
            "Constructing exemplars of class 66\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [38589, 3989, 32338, 34787, 34246, 30174, 12559, 13901, 19981, 15818, 13293, 15503, 17039, 6900, 20795, 3890, 7530, 45544, 10192, 23253]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee3eb2d0>\n",
            "Constructing exemplars of class 62\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [15676, 45981, 14909, 9341, 18868, 49760, 5517, 1278, 15162, 18401, 7484, 10007, 16432, 19971, 37828, 46963, 20565, 22167, 40808, 15075]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee23e810>\n",
            "Constructing exemplars of class 89\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [13883, 33976, 20624, 27304, 43455, 48534, 17162, 21438, 30529, 384, 21509, 30755, 5896, 16917, 43065, 27569, 26505, 46428, 37437, 16580]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee5d9650>\n",
            "Constructing exemplars of class 73\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [25797, 41818, 15253, 41033, 20198, 3023, 20043, 44049, 47134, 11124, 2244, 12965, 5721, 8926, 944, 15925, 46436, 27620, 15727, 23150]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff309f89690>\n",
            "Constructing exemplars of class 33\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [30728, 7645, 21136, 35755, 7740, 38220, 26869, 13039, 4181, 43792, 78, 39368, 9874, 21406, 29339, 15543, 9319, 43922, 48920, 40011]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee48cd10>\n",
            "Constructing exemplars of class 25\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [6942, 24732, 17968, 10044, 21669, 44757, 6364, 26321, 1540, 15190, 44456, 10224, 14106, 18750, 1257, 33443, 11222, 33378, 42030, 9674]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7ff2ee45f1d0>\n",
            "Constructing exemplars of class 1\n",
            "lunghezza exemplar set:  20\n",
            "exemplar set:  [46920, 18827, 21619, 12413, 30161, 1565, 16966, 30195, 6648, 2998, 7383, 49209, 4969, 37322, 43882, 33601, 15553, 49445, 38181, 17120]\n",
            "current lr = 0.005000\n",
            "Starting epoch 1/50\n",
            "Train step - Step 0, Loss 0.07328930497169495\n",
            "Train step - Step 0, Loss 0.07001112401485443\n",
            "Train step - Step 0, Loss 0.07691682130098343\n",
            "Train step - Step 0, Loss 0.070864237844944\n",
            "Train step - Step 0, Loss 0.07337907701730728\n",
            "Train step - Step 0, Loss 0.07398348301649094\n",
            "Train step - Step 0, Loss 0.06926017999649048\n",
            "Train step - Step 0, Loss 0.07250050455331802\n",
            "Train step - Step 0, Loss 0.07066294550895691\n",
            "Train step - Step 0, Loss 0.06894826889038086\n",
            "Train step - Step 0, Loss 0.07032589614391327\n",
            "Train step - Step 0, Loss 0.074273020029068\n",
            "Train step - Step 0, Loss 0.07124873995780945\n",
            "Train step - Step 0, Loss 0.07286697626113892\n",
            "Train step - Step 0, Loss 0.07112310081720352\n",
            "Train step - Step 0, Loss 0.07139880955219269\n",
            "Train epoch - Accuracy: 0.25033333333333335 Loss: 0.0719537879228592 Corrects: 3004\n",
            "Starting epoch 2/50\n",
            "Train step - Step 0, Loss 0.07170730084180832\n",
            "Train step - Step 0, Loss 0.07254369556903839\n",
            "Train step - Step 0, Loss 0.07245665043592453\n",
            "Train step - Step 0, Loss 0.07369982451200485\n",
            "Train step - Step 0, Loss 0.07324690371751785\n",
            "Train step - Step 0, Loss 0.07339391112327576\n",
            "Train step - Step 0, Loss 0.07284005731344223\n",
            "Train step - Step 0, Loss 0.06908527761697769\n",
            "Train step - Step 0, Loss 0.06957242637872696\n",
            "Train step - Step 0, Loss 0.07125755399465561\n",
            "Train step - Step 0, Loss 0.07196402549743652\n",
            "Train step - Step 0, Loss 0.0709758996963501\n",
            "Train step - Step 0, Loss 0.0718010663986206\n",
            "Train step - Step 0, Loss 0.07062509655952454\n",
            "Train step - Step 0, Loss 0.06799731403589249\n",
            "Train step - Step 0, Loss 0.06874851137399673\n",
            "Train epoch - Accuracy: 0.2465 Loss: 0.07143262869119645 Corrects: 2958\n",
            "Starting epoch 3/50\n",
            "Train step - Step 0, Loss 0.07170005142688751\n",
            "Train step - Step 0, Loss 0.06995576620101929\n",
            "Train step - Step 0, Loss 0.0741286501288414\n",
            "Train step - Step 0, Loss 0.07264869660139084\n",
            "Train step - Step 0, Loss 0.06940528005361557\n",
            "Train step - Step 0, Loss 0.07207377254962921\n",
            "Train step - Step 0, Loss 0.07021471858024597\n",
            "Train step - Step 0, Loss 0.07288851588964462\n",
            "Train step - Step 0, Loss 0.06851229816675186\n",
            "Train step - Step 0, Loss 0.06941577047109604\n",
            "Train step - Step 0, Loss 0.07335637509822845\n",
            "Train step - Step 0, Loss 0.07407039403915405\n",
            "Train step - Step 0, Loss 0.07252419739961624\n",
            "Train step - Step 0, Loss 0.06725721061229706\n",
            "Train step - Step 0, Loss 0.07207582145929337\n",
            "Train step - Step 0, Loss 0.070383720099926\n",
            "Train epoch - Accuracy: 0.2539166666666667 Loss: 0.07130990999937058 Corrects: 3047\n",
            "Starting epoch 4/50\n",
            "Train step - Step 0, Loss 0.06712392717599869\n",
            "Train step - Step 0, Loss 0.07101865112781525\n",
            "Train step - Step 0, Loss 0.06940311938524246\n",
            "Train step - Step 0, Loss 0.07253634184598923\n",
            "Train step - Step 0, Loss 0.07005789875984192\n",
            "Train step - Step 0, Loss 0.07302935421466827\n",
            "Train step - Step 0, Loss 0.07407369464635849\n",
            "Train step - Step 0, Loss 0.07363752275705338\n",
            "Train step - Step 0, Loss 0.06949641555547714\n",
            "Train step - Step 0, Loss 0.06892558932304382\n",
            "Train step - Step 0, Loss 0.07386847585439682\n",
            "Train step - Step 0, Loss 0.07071200013160706\n",
            "Train step - Step 0, Loss 0.07223377376794815\n",
            "Train step - Step 0, Loss 0.07211226224899292\n",
            "Train step - Step 0, Loss 0.07352452725172043\n",
            "Train step - Step 0, Loss 0.07026594132184982\n",
            "Train epoch - Accuracy: 0.24375 Loss: 0.07140286511182785 Corrects: 2925\n",
            "Starting epoch 5/50\n",
            "Train step - Step 0, Loss 0.07224567234516144\n",
            "Train step - Step 0, Loss 0.06720241904258728\n",
            "Train step - Step 0, Loss 0.07269420474767685\n",
            "Train step - Step 0, Loss 0.06838033348321915\n",
            "Train step - Step 0, Loss 0.07113870978355408\n",
            "Train step - Step 0, Loss 0.06915213167667389\n",
            "Train step - Step 0, Loss 0.07204325497150421\n",
            "Train step - Step 0, Loss 0.0694529339671135\n",
            "Train step - Step 0, Loss 0.07067877054214478\n",
            "Train step - Step 0, Loss 0.07176706194877625\n",
            "Train step - Step 0, Loss 0.07450363039970398\n",
            "Train step - Step 0, Loss 0.07417289167642593\n",
            "Train step - Step 0, Loss 0.07396604120731354\n",
            "Train step - Step 0, Loss 0.0715663880109787\n",
            "Train step - Step 0, Loss 0.0693841427564621\n",
            "Train step - Step 0, Loss 0.06904876977205276\n",
            "Train epoch - Accuracy: 0.2509166666666667 Loss: 0.07113626033067703 Corrects: 3011\n",
            "Starting epoch 6/50\n",
            "Train step - Step 0, Loss 0.06968982517719269\n",
            "Train step - Step 0, Loss 0.07177326083183289\n",
            "Train step - Step 0, Loss 0.07081343978643417\n",
            "Train step - Step 0, Loss 0.06825625151395798\n",
            "Train step - Step 0, Loss 0.07100977003574371\n",
            "Train step - Step 0, Loss 0.07047300785779953\n",
            "Train step - Step 0, Loss 0.07209394127130508\n",
            "Train step - Step 0, Loss 0.0674649178981781\n",
            "Train step - Step 0, Loss 0.07207954674959183\n",
            "Train step - Step 0, Loss 0.07206335663795471\n",
            "Train step - Step 0, Loss 0.06946974247694016\n",
            "Train step - Step 0, Loss 0.07105910032987595\n",
            "Train step - Step 0, Loss 0.07023962587118149\n",
            "Train step - Step 0, Loss 0.07152686268091202\n",
            "Train step - Step 0, Loss 0.07494433969259262\n",
            "Train step - Step 0, Loss 0.0755898505449295\n",
            "Train epoch - Accuracy: 0.24658333333333332 Loss: 0.07105284130573272 Corrects: 2959\n",
            "Starting epoch 7/50\n",
            "Train step - Step 0, Loss 0.06760134547948837\n",
            "Train step - Step 0, Loss 0.07081880420446396\n",
            "Train step - Step 0, Loss 0.06960305571556091\n",
            "Train step - Step 0, Loss 0.07267286628484726\n",
            "Train step - Step 0, Loss 0.06828287988901138\n",
            "Train step - Step 0, Loss 0.07127396017313004\n",
            "Train step - Step 0, Loss 0.073440782725811\n",
            "Train step - Step 0, Loss 0.07164479792118073\n",
            "Train step - Step 0, Loss 0.06975334137678146\n",
            "Train step - Step 0, Loss 0.06854499876499176\n",
            "Train step - Step 0, Loss 0.07402628660202026\n",
            "Train step - Step 0, Loss 0.07297992706298828\n",
            "Train step - Step 0, Loss 0.07208510488271713\n",
            "Train step - Step 0, Loss 0.07216010242700577\n",
            "Train step - Step 0, Loss 0.07113265246152878\n",
            "Train step - Step 0, Loss 0.07169493287801743\n",
            "Train epoch - Accuracy: 0.249 Loss: 0.07109313529729844 Corrects: 2988\n",
            "Starting epoch 8/50\n",
            "Train step - Step 0, Loss 0.07347482442855835\n",
            "Train step - Step 0, Loss 0.07327578216791153\n",
            "Train step - Step 0, Loss 0.07404118776321411\n",
            "Train step - Step 0, Loss 0.07449717074632645\n",
            "Train step - Step 0, Loss 0.0719415545463562\n",
            "Train step - Step 0, Loss 0.07094674557447433\n",
            "Train step - Step 0, Loss 0.07107187807559967\n",
            "Train step - Step 0, Loss 0.06925749033689499\n",
            "Train step - Step 0, Loss 0.07214891910552979\n",
            "Train step - Step 0, Loss 0.07033824175596237\n",
            "Train step - Step 0, Loss 0.06741128116846085\n",
            "Train step - Step 0, Loss 0.07224667072296143\n",
            "Train step - Step 0, Loss 0.07041730731725693\n",
            "Train step - Step 0, Loss 0.07029491662979126\n",
            "Train step - Step 0, Loss 0.06824540346860886\n",
            "Train step - Step 0, Loss 0.07245519757270813\n",
            "Train epoch - Accuracy: 0.24625 Loss: 0.07135320782661438 Corrects: 2955\n",
            "Starting epoch 9/50\n",
            "Train step - Step 0, Loss 0.06842336058616638\n",
            "Train step - Step 0, Loss 0.07097583264112473\n",
            "Train step - Step 0, Loss 0.06868540495634079\n",
            "Train step - Step 0, Loss 0.07022597640752792\n",
            "Train step - Step 0, Loss 0.06979628652334213\n",
            "Train step - Step 0, Loss 0.07304373383522034\n",
            "Train step - Step 0, Loss 0.06887738406658173\n",
            "Train step - Step 0, Loss 0.07274683564901352\n",
            "Train step - Step 0, Loss 0.07228048145771027\n",
            "Train step - Step 0, Loss 0.07059478759765625\n",
            "Train step - Step 0, Loss 0.0697508156299591\n",
            "Train step - Step 0, Loss 0.07030580937862396\n",
            "Train step - Step 0, Loss 0.06876970082521439\n",
            "Train step - Step 0, Loss 0.07246711850166321\n",
            "Train step - Step 0, Loss 0.07129310071468353\n",
            "Train step - Step 0, Loss 0.07140116393566132\n",
            "Train epoch - Accuracy: 0.24791666666666667 Loss: 0.07058319079875947 Corrects: 2975\n",
            "Starting epoch 10/50\n",
            "Train step - Step 0, Loss 0.07186663150787354\n",
            "Train step - Step 0, Loss 0.07166595757007599\n",
            "Train step - Step 0, Loss 0.07311590015888214\n",
            "Train step - Step 0, Loss 0.07360587269067764\n",
            "Train step - Step 0, Loss 0.0691257119178772\n",
            "Train step - Step 0, Loss 0.07265666127204895\n",
            "Train step - Step 0, Loss 0.07226362079381943\n",
            "Train step - Step 0, Loss 0.07053688168525696\n",
            "Train step - Step 0, Loss 0.06961724907159805\n",
            "Train step - Step 0, Loss 0.06941299140453339\n",
            "Train step - Step 0, Loss 0.07057934254407883\n",
            "Train step - Step 0, Loss 0.07013575732707977\n",
            "Train step - Step 0, Loss 0.07010705769062042\n",
            "Train step - Step 0, Loss 0.07213694602251053\n",
            "Train step - Step 0, Loss 0.07023929059505463\n",
            "Train step - Step 0, Loss 0.07127195596694946\n",
            "Train epoch - Accuracy: 0.24816666666666667 Loss: 0.07114309406280518 Corrects: 2978\n",
            "Starting epoch 11/50\n",
            "Train step - Step 0, Loss 0.06787613779306412\n",
            "Train step - Step 0, Loss 0.07220783084630966\n",
            "Train step - Step 0, Loss 0.0723244696855545\n",
            "Train step - Step 0, Loss 0.06651493161916733\n",
            "Train step - Step 0, Loss 0.07158996164798737\n",
            "Train step - Step 0, Loss 0.06743239611387253\n",
            "Train step - Step 0, Loss 0.06877385079860687\n",
            "Train step - Step 0, Loss 0.07311329245567322\n",
            "Train step - Step 0, Loss 0.07176003605127335\n",
            "Train step - Step 0, Loss 0.07307618856430054\n",
            "Train step - Step 0, Loss 0.07149307429790497\n",
            "Train step - Step 0, Loss 0.06902777403593063\n",
            "Train step - Step 0, Loss 0.07279987633228302\n",
            "Train step - Step 0, Loss 0.06794778257608414\n",
            "Train step - Step 0, Loss 0.07401106506586075\n",
            "Train step - Step 0, Loss 0.07181879878044128\n",
            "Train epoch - Accuracy: 0.246 Loss: 0.07070946669578553 Corrects: 2952\n",
            "Starting epoch 12/50\n",
            "Train step - Step 0, Loss 0.07401146739721298\n",
            "Train step - Step 0, Loss 0.07084055989980698\n",
            "Train step - Step 0, Loss 0.0724521055817604\n",
            "Train step - Step 0, Loss 0.06983354687690735\n",
            "Train step - Step 0, Loss 0.06680253893136978\n",
            "Train step - Step 0, Loss 0.0665176659822464\n",
            "Train step - Step 0, Loss 0.06950299441814423\n",
            "Train step - Step 0, Loss 0.06924811005592346\n",
            "Train step - Step 0, Loss 0.07046132534742355\n",
            "Train step - Step 0, Loss 0.0687495619058609\n",
            "Train step - Step 0, Loss 0.07329541444778442\n",
            "Train step - Step 0, Loss 0.07356080412864685\n",
            "Train step - Step 0, Loss 0.0741310864686966\n",
            "Train step - Step 0, Loss 0.0726381465792656\n",
            "Train step - Step 0, Loss 0.07072453945875168\n",
            "Train step - Step 0, Loss 0.07182757556438446\n",
            "Train epoch - Accuracy: 0.2435 Loss: 0.07089037454128265 Corrects: 2922\n",
            "Starting epoch 13/50\n",
            "Train step - Step 0, Loss 0.07098209112882614\n",
            "Train step - Step 0, Loss 0.06933911889791489\n",
            "Train step - Step 0, Loss 0.07281044125556946\n",
            "Train step - Step 0, Loss 0.0702904760837555\n",
            "Train step - Step 0, Loss 0.07091374695301056\n",
            "Train step - Step 0, Loss 0.07069139927625656\n",
            "Train step - Step 0, Loss 0.0712321326136589\n",
            "Train step - Step 0, Loss 0.07088974863290787\n",
            "Train step - Step 0, Loss 0.06810399889945984\n",
            "Train step - Step 0, Loss 0.0721496120095253\n",
            "Train step - Step 0, Loss 0.06950803101062775\n",
            "Train step - Step 0, Loss 0.07584270089864731\n",
            "Train step - Step 0, Loss 0.0670364499092102\n",
            "Train step - Step 0, Loss 0.07242684811353683\n",
            "Train step - Step 0, Loss 0.0727640688419342\n",
            "Train step - Step 0, Loss 0.0701887309551239\n",
            "Train epoch - Accuracy: 0.24858333333333332 Loss: 0.0709663245677948 Corrects: 2983\n",
            "Starting epoch 14/50\n",
            "Train step - Step 0, Loss 0.06950116157531738\n",
            "Train step - Step 0, Loss 0.07041558623313904\n",
            "Train step - Step 0, Loss 0.07321946322917938\n",
            "Train step - Step 0, Loss 0.06846045702695847\n",
            "Train step - Step 0, Loss 0.07110298424959183\n",
            "Train step - Step 0, Loss 0.0688435286283493\n",
            "Train step - Step 0, Loss 0.07364799827337265\n",
            "Train step - Step 0, Loss 0.0718364343047142\n",
            "Train step - Step 0, Loss 0.07231585681438446\n",
            "Train step - Step 0, Loss 0.07121095061302185\n",
            "Train step - Step 0, Loss 0.07052074372768402\n",
            "Train step - Step 0, Loss 0.06801900267601013\n",
            "Train step - Step 0, Loss 0.07207690179347992\n",
            "Train step - Step 0, Loss 0.06933575123548508\n",
            "Train step - Step 0, Loss 0.06931858509778976\n",
            "Train step - Step 0, Loss 0.07065383344888687\n",
            "Train epoch - Accuracy: 0.24683333333333332 Loss: 0.07065497928857803 Corrects: 2962\n",
            "Starting epoch 15/50\n",
            "Train step - Step 0, Loss 0.07368499040603638\n",
            "Train step - Step 0, Loss 0.0662773922085762\n",
            "Train step - Step 0, Loss 0.07080009579658508\n",
            "Train step - Step 0, Loss 0.0700148493051529\n",
            "Train step - Step 0, Loss 0.06713191419839859\n",
            "Train step - Step 0, Loss 0.06920360773801804\n",
            "Train step - Step 0, Loss 0.07283651828765869\n",
            "Train step - Step 0, Loss 0.07363231480121613\n",
            "Train step - Step 0, Loss 0.06915783137083054\n",
            "Train step - Step 0, Loss 0.0717954933643341\n",
            "Train step - Step 0, Loss 0.06827149540185928\n",
            "Train step - Step 0, Loss 0.07118833065032959\n",
            "Train step - Step 0, Loss 0.07255136966705322\n",
            "Train step - Step 0, Loss 0.07120256870985031\n",
            "Train step - Step 0, Loss 0.07068376243114471\n",
            "Train step - Step 0, Loss 0.06935935467481613\n",
            "Train epoch - Accuracy: 0.2515 Loss: 0.07051405638456344 Corrects: 3018\n",
            "Starting epoch 16/50\n",
            "Train step - Step 0, Loss 0.0712420865893364\n",
            "Train step - Step 0, Loss 0.07290766388177872\n",
            "Train step - Step 0, Loss 0.07008232176303864\n",
            "Train step - Step 0, Loss 0.07144062221050262\n",
            "Train step - Step 0, Loss 0.07055498659610748\n",
            "Train step - Step 0, Loss 0.07133040577173233\n",
            "Train step - Step 0, Loss 0.06862941384315491\n",
            "Train step - Step 0, Loss 0.06989417970180511\n",
            "Train step - Step 0, Loss 0.06885343044996262\n",
            "Train step - Step 0, Loss 0.0695798397064209\n",
            "Train step - Step 0, Loss 0.07292287051677704\n",
            "Train step - Step 0, Loss 0.07112176716327667\n",
            "Train step - Step 0, Loss 0.06969898194074631\n",
            "Train step - Step 0, Loss 0.06685381382703781\n",
            "Train step - Step 0, Loss 0.07024724781513214\n",
            "Train step - Step 0, Loss 0.075381338596344\n",
            "Train epoch - Accuracy: 0.24425 Loss: 0.07055826997756957 Corrects: 2931\n",
            "Starting epoch 17/50\n",
            "Train step - Step 0, Loss 0.06986693292856216\n",
            "Train step - Step 0, Loss 0.07111848890781403\n",
            "Train step - Step 0, Loss 0.07609698176383972\n",
            "Train step - Step 0, Loss 0.07048539817333221\n",
            "Train step - Step 0, Loss 0.07196350395679474\n",
            "Train step - Step 0, Loss 0.06957397609949112\n",
            "Train step - Step 0, Loss 0.07148642092943192\n",
            "Train step - Step 0, Loss 0.07074496150016785\n",
            "Train step - Step 0, Loss 0.0666281133890152\n",
            "Train step - Step 0, Loss 0.06873653084039688\n",
            "Train step - Step 0, Loss 0.0670156180858612\n",
            "Train step - Step 0, Loss 0.0698113739490509\n",
            "Train step - Step 0, Loss 0.07166934013366699\n",
            "Train step - Step 0, Loss 0.06844907253980637\n",
            "Train step - Step 0, Loss 0.07266928255558014\n",
            "Train step - Step 0, Loss 0.07418536394834518\n",
            "Train epoch - Accuracy: 0.252 Loss: 0.07057163828611374 Corrects: 3024\n",
            "Starting epoch 18/50\n",
            "Train step - Step 0, Loss 0.07103340327739716\n",
            "Train step - Step 0, Loss 0.07156706601381302\n",
            "Train step - Step 0, Loss 0.06975311785936356\n",
            "Train step - Step 0, Loss 0.07146655023097992\n",
            "Train step - Step 0, Loss 0.07126739621162415\n",
            "Train step - Step 0, Loss 0.06888622790575027\n",
            "Train step - Step 0, Loss 0.07464764267206192\n",
            "Train step - Step 0, Loss 0.06522238254547119\n",
            "Train step - Step 0, Loss 0.06854129582643509\n",
            "Train step - Step 0, Loss 0.07034634798765182\n",
            "Train step - Step 0, Loss 0.06568560749292374\n",
            "Train step - Step 0, Loss 0.06999238580465317\n",
            "Train step - Step 0, Loss 0.07127942889928818\n",
            "Train step - Step 0, Loss 0.06817585229873657\n",
            "Train step - Step 0, Loss 0.07232698053121567\n",
            "Train step - Step 0, Loss 0.07479775696992874\n",
            "Train epoch - Accuracy: 0.25083333333333335 Loss: 0.07020417815446854 Corrects: 3010\n",
            "Starting epoch 19/50\n",
            "Train step - Step 0, Loss 0.07277438044548035\n",
            "Train step - Step 0, Loss 0.06899693608283997\n",
            "Train step - Step 0, Loss 0.07251822203397751\n",
            "Train step - Step 0, Loss 0.0731750875711441\n",
            "Train step - Step 0, Loss 0.06951379776000977\n",
            "Train step - Step 0, Loss 0.0695987194776535\n",
            "Train step - Step 0, Loss 0.06778193265199661\n",
            "Train step - Step 0, Loss 0.07370729744434357\n",
            "Train step - Step 0, Loss 0.07074320316314697\n",
            "Train step - Step 0, Loss 0.06797897815704346\n",
            "Train step - Step 0, Loss 0.06784453243017197\n",
            "Train step - Step 0, Loss 0.07209451496601105\n",
            "Train step - Step 0, Loss 0.06978654116392136\n",
            "Train step - Step 0, Loss 0.07242944091558456\n",
            "Train step - Step 0, Loss 0.07179082185029984\n",
            "Train step - Step 0, Loss 0.07022590190172195\n",
            "Train epoch - Accuracy: 0.24816666666666667 Loss: 0.07069603806734084 Corrects: 2978\n",
            "Starting epoch 20/50\n",
            "Train step - Step 0, Loss 0.06824857741594315\n",
            "Train step - Step 0, Loss 0.07387574762105942\n",
            "Train step - Step 0, Loss 0.07165175676345825\n",
            "Train step - Step 0, Loss 0.07000095397233963\n",
            "Train step - Step 0, Loss 0.07208805531263351\n",
            "Train step - Step 0, Loss 0.06961539387702942\n",
            "Train step - Step 0, Loss 0.06916318088769913\n",
            "Train step - Step 0, Loss 0.07065251469612122\n",
            "Train step - Step 0, Loss 0.07361245900392532\n",
            "Train step - Step 0, Loss 0.07252904772758484\n",
            "Train step - Step 0, Loss 0.07098329812288284\n",
            "Train step - Step 0, Loss 0.07354066520929337\n",
            "Train step - Step 0, Loss 0.07257938385009766\n",
            "Train step - Step 0, Loss 0.06863375753164291\n",
            "Train step - Step 0, Loss 0.07038642466068268\n",
            "Train step - Step 0, Loss 0.07002445310354233\n",
            "Train epoch - Accuracy: 0.24858333333333332 Loss: 0.07112489598989487 Corrects: 2983\n",
            "Starting epoch 21/50\n",
            "Train step - Step 0, Loss 0.0715336948633194\n",
            "Train step - Step 0, Loss 0.07111310213804245\n",
            "Train step - Step 0, Loss 0.06915932148694992\n",
            "Train step - Step 0, Loss 0.07076122611761093\n",
            "Train step - Step 0, Loss 0.07043850421905518\n",
            "Train step - Step 0, Loss 0.07168026268482208\n",
            "Train step - Step 0, Loss 0.07060448825359344\n",
            "Train step - Step 0, Loss 0.06627032160758972\n",
            "Train step - Step 0, Loss 0.07319362461566925\n",
            "Train step - Step 0, Loss 0.06947405636310577\n",
            "Train step - Step 0, Loss 0.07017187774181366\n",
            "Train step - Step 0, Loss 0.06906487792730331\n",
            "Train step - Step 0, Loss 0.06732171773910522\n",
            "Train step - Step 0, Loss 0.07430163025856018\n",
            "Train step - Step 0, Loss 0.07033247500658035\n",
            "Train step - Step 0, Loss 0.06796799600124359\n",
            "Train epoch - Accuracy: 0.24175 Loss: 0.07026567542552949 Corrects: 2901\n",
            "Starting epoch 22/50\n",
            "Train step - Step 0, Loss 0.06901974231004715\n",
            "Train step - Step 0, Loss 0.06976784020662308\n",
            "Train step - Step 0, Loss 0.06876570731401443\n",
            "Train step - Step 0, Loss 0.07036280632019043\n",
            "Train step - Step 0, Loss 0.07172016054391861\n",
            "Train step - Step 0, Loss 0.06837031245231628\n",
            "Train step - Step 0, Loss 0.06961579620838165\n",
            "Train step - Step 0, Loss 0.07058749347925186\n",
            "Train step - Step 0, Loss 0.07076474279165268\n",
            "Train step - Step 0, Loss 0.07002793252468109\n",
            "Train step - Step 0, Loss 0.07309762388467789\n",
            "Train step - Step 0, Loss 0.07146279513835907\n",
            "Train step - Step 0, Loss 0.07071764022111893\n",
            "Train step - Step 0, Loss 0.07270187884569168\n",
            "Train step - Step 0, Loss 0.07046155631542206\n",
            "Train step - Step 0, Loss 0.07337157428264618\n",
            "Train epoch - Accuracy: 0.24791666666666667 Loss: 0.07061128079891205 Corrects: 2975\n",
            "Starting epoch 23/50\n",
            "Train step - Step 0, Loss 0.07168582826852798\n",
            "Train step - Step 0, Loss 0.0679917186498642\n",
            "Train step - Step 0, Loss 0.07064492255449295\n",
            "Train step - Step 0, Loss 0.06885197758674622\n",
            "Train step - Step 0, Loss 0.07310384511947632\n",
            "Train step - Step 0, Loss 0.06969159096479416\n",
            "Train step - Step 0, Loss 0.06990916281938553\n",
            "Train step - Step 0, Loss 0.06831040978431702\n",
            "Train step - Step 0, Loss 0.06757986545562744\n",
            "Train step - Step 0, Loss 0.07152341306209564\n",
            "Train step - Step 0, Loss 0.07166535407304764\n",
            "Train step - Step 0, Loss 0.07304484397172928\n",
            "Train step - Step 0, Loss 0.06776590645313263\n",
            "Train step - Step 0, Loss 0.06764024496078491\n",
            "Train step - Step 0, Loss 0.07212428003549576\n",
            "Train step - Step 0, Loss 0.07003382593393326\n",
            "Train epoch - Accuracy: 0.25083333333333335 Loss: 0.07009948831796646 Corrects: 3010\n",
            "Starting epoch 24/50\n",
            "Train step - Step 0, Loss 0.07235413789749146\n",
            "Train step - Step 0, Loss 0.0701933354139328\n",
            "Train step - Step 0, Loss 0.06990083307027817\n",
            "Train step - Step 0, Loss 0.0721098855137825\n",
            "Train step - Step 0, Loss 0.06983459740877151\n",
            "Train step - Step 0, Loss 0.0713006928563118\n",
            "Train step - Step 0, Loss 0.06795283406972885\n",
            "Train step - Step 0, Loss 0.0724540427327156\n",
            "Train step - Step 0, Loss 0.07234469056129456\n",
            "Train step - Step 0, Loss 0.06994210928678513\n",
            "Train step - Step 0, Loss 0.06806357204914093\n",
            "Train step - Step 0, Loss 0.06953677535057068\n",
            "Train step - Step 0, Loss 0.07197576016187668\n",
            "Train step - Step 0, Loss 0.06796783953905106\n",
            "Train step - Step 0, Loss 0.06777076423168182\n",
            "Train step - Step 0, Loss 0.06833347678184509\n",
            "Train epoch - Accuracy: 0.253 Loss: 0.07017025876045227 Corrects: 3036\n",
            "Starting epoch 25/50\n",
            "Train step - Step 0, Loss 0.06943324953317642\n",
            "Train step - Step 0, Loss 0.07004251331090927\n",
            "Train step - Step 0, Loss 0.07133811712265015\n",
            "Train step - Step 0, Loss 0.068824402987957\n",
            "Train step - Step 0, Loss 0.07354013621807098\n",
            "Train step - Step 0, Loss 0.07037238031625748\n",
            "Train step - Step 0, Loss 0.0723942443728447\n",
            "Train step - Step 0, Loss 0.07105505466461182\n",
            "Train step - Step 0, Loss 0.06886663287878036\n",
            "Train step - Step 0, Loss 0.07231080532073975\n",
            "Train step - Step 0, Loss 0.06985719501972198\n",
            "Train step - Step 0, Loss 0.06840097904205322\n",
            "Train step - Step 0, Loss 0.06901352107524872\n",
            "Train step - Step 0, Loss 0.06775248050689697\n",
            "Train step - Step 0, Loss 0.0703263208270073\n",
            "Train step - Step 0, Loss 0.06888176500797272\n",
            "Train epoch - Accuracy: 0.24891666666666667 Loss: 0.07018106472492218 Corrects: 2987\n",
            "Starting epoch 26/50\n",
            "Train step - Step 0, Loss 0.06957675516605377\n",
            "Train step - Step 0, Loss 0.06801635771989822\n",
            "Train step - Step 0, Loss 0.07089518755674362\n",
            "Train step - Step 0, Loss 0.07241000235080719\n",
            "Train step - Step 0, Loss 0.07126384973526001\n",
            "Train step - Step 0, Loss 0.07292696833610535\n",
            "Train step - Step 0, Loss 0.07290457934141159\n",
            "Train step - Step 0, Loss 0.07329060882329941\n",
            "Train step - Step 0, Loss 0.07028525322675705\n",
            "Train step - Step 0, Loss 0.06816697865724564\n",
            "Train step - Step 0, Loss 0.0699315145611763\n",
            "Train step - Step 0, Loss 0.07245515286922455\n",
            "Train step - Step 0, Loss 0.0665842816233635\n",
            "Train step - Step 0, Loss 0.0695229098200798\n",
            "Train step - Step 0, Loss 0.06873199343681335\n",
            "Train step - Step 0, Loss 0.07208908349275589\n",
            "Train epoch - Accuracy: 0.24133333333333334 Loss: 0.07052915650606155 Corrects: 2896\n",
            "Starting epoch 27/50\n",
            "Train step - Step 0, Loss 0.07201465964317322\n",
            "Train step - Step 0, Loss 0.06939404457807541\n",
            "Train step - Step 0, Loss 0.07134539633989334\n",
            "Train step - Step 0, Loss 0.06812595576047897\n",
            "Train step - Step 0, Loss 0.07289127260446548\n",
            "Train step - Step 0, Loss 0.06881900876760483\n",
            "Train step - Step 0, Loss 0.06864748895168304\n",
            "Train step - Step 0, Loss 0.07267118990421295\n",
            "Train step - Step 0, Loss 0.06840319186449051\n",
            "Train step - Step 0, Loss 0.07001442462205887\n",
            "Train step - Step 0, Loss 0.07141634076833725\n",
            "Train step - Step 0, Loss 0.07357477396726608\n",
            "Train step - Step 0, Loss 0.06850030273199081\n",
            "Train step - Step 0, Loss 0.07041867822408676\n",
            "Train step - Step 0, Loss 0.07201369106769562\n",
            "Train step - Step 0, Loss 0.07343871146440506\n",
            "Train epoch - Accuracy: 0.2435 Loss: 0.07066557532548905 Corrects: 2922\n",
            "Starting epoch 28/50\n",
            "Train step - Step 0, Loss 0.07201937586069107\n",
            "Train step - Step 0, Loss 0.07345270365476608\n",
            "Train step - Step 0, Loss 0.07149510830640793\n",
            "Train step - Step 0, Loss 0.07133109122514725\n",
            "Train step - Step 0, Loss 0.07029116153717041\n",
            "Train step - Step 0, Loss 0.07039918750524521\n",
            "Train step - Step 0, Loss 0.06662343442440033\n",
            "Train step - Step 0, Loss 0.06878215819597244\n",
            "Train step - Step 0, Loss 0.07087714970111847\n",
            "Train step - Step 0, Loss 0.06914155185222626\n",
            "Train step - Step 0, Loss 0.06908515095710754\n",
            "Train step - Step 0, Loss 0.06660544872283936\n",
            "Train step - Step 0, Loss 0.07260143756866455\n",
            "Train step - Step 0, Loss 0.07002511620521545\n",
            "Train step - Step 0, Loss 0.06941016018390656\n",
            "Train step - Step 0, Loss 0.07017278671264648\n",
            "Train epoch - Accuracy: 0.2455 Loss: 0.0701438865661621 Corrects: 2946\n",
            "Starting epoch 29/50\n",
            "Train step - Step 0, Loss 0.07216537743806839\n",
            "Train step - Step 0, Loss 0.0698188990354538\n",
            "Train step - Step 0, Loss 0.07006744295358658\n",
            "Train step - Step 0, Loss 0.07063010334968567\n",
            "Train step - Step 0, Loss 0.07151351869106293\n",
            "Train step - Step 0, Loss 0.0677168220281601\n",
            "Train step - Step 0, Loss 0.06864582747220993\n",
            "Train step - Step 0, Loss 0.07262033224105835\n",
            "Train step - Step 0, Loss 0.06913227587938309\n",
            "Train step - Step 0, Loss 0.07049360126256943\n",
            "Train step - Step 0, Loss 0.07081043720245361\n",
            "Train step - Step 0, Loss 0.07420311123132706\n",
            "Train step - Step 0, Loss 0.06765138357877731\n",
            "Train step - Step 0, Loss 0.06926319003105164\n",
            "Train step - Step 0, Loss 0.067750945687294\n",
            "Train step - Step 0, Loss 0.06909187883138657\n",
            "Train epoch - Accuracy: 0.24908333333333332 Loss: 0.07012260431051254 Corrects: 2989\n",
            "Starting epoch 30/50\n",
            "Train step - Step 0, Loss 0.07144367694854736\n",
            "Train step - Step 0, Loss 0.06820250302553177\n",
            "Train step - Step 0, Loss 0.07193629443645477\n",
            "Train step - Step 0, Loss 0.07315100729465485\n",
            "Train step - Step 0, Loss 0.07160857319831848\n",
            "Train step - Step 0, Loss 0.06874112039804459\n",
            "Train step - Step 0, Loss 0.0703229010105133\n",
            "Train step - Step 0, Loss 0.07047674059867859\n",
            "Train step - Step 0, Loss 0.07106225192546844\n",
            "Train step - Step 0, Loss 0.07221309095621109\n",
            "Train step - Step 0, Loss 0.06779627501964569\n",
            "Train step - Step 0, Loss 0.06878046691417694\n",
            "Train step - Step 0, Loss 0.06965713948011398\n",
            "Train step - Step 0, Loss 0.06966814398765564\n",
            "Train step - Step 0, Loss 0.0690499022603035\n",
            "Train step - Step 0, Loss 0.06789273768663406\n",
            "Train epoch - Accuracy: 0.2504166666666667 Loss: 0.07017875510454177 Corrects: 3005\n",
            "Starting epoch 31/50\n",
            "Train step - Step 0, Loss 0.07075467705726624\n",
            "Train step - Step 0, Loss 0.07313398271799088\n",
            "Train step - Step 0, Loss 0.07325349003076553\n",
            "Train step - Step 0, Loss 0.07138489931821823\n",
            "Train step - Step 0, Loss 0.06976594030857086\n",
            "Train step - Step 0, Loss 0.07030099630355835\n",
            "Train step - Step 0, Loss 0.06932060420513153\n",
            "Train step - Step 0, Loss 0.06997701525688171\n",
            "Train step - Step 0, Loss 0.07061584293842316\n",
            "Train step - Step 0, Loss 0.06854632496833801\n",
            "Train step - Step 0, Loss 0.06982667744159698\n",
            "Train step - Step 0, Loss 0.0690147876739502\n",
            "Train step - Step 0, Loss 0.06920275837182999\n",
            "Train step - Step 0, Loss 0.06603394448757172\n",
            "Train step - Step 0, Loss 0.07080734521150589\n",
            "Train step - Step 0, Loss 0.06979072093963623\n",
            "Train epoch - Accuracy: 0.24816666666666667 Loss: 0.07011574316024781 Corrects: 2978\n",
            "Starting epoch 32/50\n",
            "Train step - Step 0, Loss 0.07040560245513916\n",
            "Train step - Step 0, Loss 0.07174310088157654\n",
            "Train step - Step 0, Loss 0.06809529662132263\n",
            "Train step - Step 0, Loss 0.07368169724941254\n",
            "Train step - Step 0, Loss 0.06991150230169296\n",
            "Train step - Step 0, Loss 0.06782279908657074\n",
            "Train step - Step 0, Loss 0.07066141068935394\n",
            "Train step - Step 0, Loss 0.06865197420120239\n",
            "Train step - Step 0, Loss 0.07106023281812668\n",
            "Train step - Step 0, Loss 0.06837281584739685\n",
            "Train step - Step 0, Loss 0.07208051532506943\n",
            "Train step - Step 0, Loss 0.07179970294237137\n",
            "Train step - Step 0, Loss 0.07234884053468704\n",
            "Train step - Step 0, Loss 0.06810013204813004\n",
            "Train step - Step 0, Loss 0.06924479454755783\n",
            "Train step - Step 0, Loss 0.0711585059762001\n",
            "Train epoch - Accuracy: 0.24416666666666667 Loss: 0.07030108696222305 Corrects: 2930\n",
            "Starting epoch 33/50\n",
            "Train step - Step 0, Loss 0.07313040643930435\n",
            "Train step - Step 0, Loss 0.07086503505706787\n",
            "Train step - Step 0, Loss 0.06885169446468353\n",
            "Train step - Step 0, Loss 0.06728153675794601\n",
            "Train step - Step 0, Loss 0.06840311735868454\n",
            "Train step - Step 0, Loss 0.07159166038036346\n",
            "Train step - Step 0, Loss 0.07360415905714035\n",
            "Train step - Step 0, Loss 0.06953074038028717\n",
            "Train step - Step 0, Loss 0.07056740671396255\n",
            "Train step - Step 0, Loss 0.07279329746961594\n",
            "Train step - Step 0, Loss 0.0739254429936409\n",
            "Train step - Step 0, Loss 0.07163310050964355\n",
            "Train step - Step 0, Loss 0.07064518332481384\n",
            "Train step - Step 0, Loss 0.06975476443767548\n",
            "Train step - Step 0, Loss 0.06841034442186356\n",
            "Train step - Step 0, Loss 0.07427722960710526\n",
            "Train epoch - Accuracy: 0.25166666666666665 Loss: 0.07087431412935256 Corrects: 3020\n",
            "Starting epoch 34/50\n",
            "Train step - Step 0, Loss 0.0699428990483284\n",
            "Train step - Step 0, Loss 0.0708470270037651\n",
            "Train step - Step 0, Loss 0.07224056124687195\n",
            "Train step - Step 0, Loss 0.07153046876192093\n",
            "Train step - Step 0, Loss 0.06991497427225113\n",
            "Train step - Step 0, Loss 0.06834403425455093\n",
            "Train step - Step 0, Loss 0.07183264195919037\n",
            "Train step - Step 0, Loss 0.06878409534692764\n",
            "Train step - Step 0, Loss 0.07169362157583237\n",
            "Train step - Step 0, Loss 0.07015067338943481\n",
            "Train step - Step 0, Loss 0.06748364120721817\n",
            "Train step - Step 0, Loss 0.07023321837186813\n",
            "Train step - Step 0, Loss 0.07111450284719467\n",
            "Train step - Step 0, Loss 0.06909608095884323\n",
            "Train step - Step 0, Loss 0.07259201258420944\n",
            "Train step - Step 0, Loss 0.07230489701032639\n",
            "Train epoch - Accuracy: 0.24883333333333332 Loss: 0.07046342486143112 Corrects: 2986\n",
            "Starting epoch 35/50\n",
            "Train step - Step 0, Loss 0.06990070641040802\n",
            "Train step - Step 0, Loss 0.06941206753253937\n",
            "Train step - Step 0, Loss 0.07128103077411652\n",
            "Train step - Step 0, Loss 0.0676688551902771\n",
            "Train step - Step 0, Loss 0.07297690957784653\n",
            "Train step - Step 0, Loss 0.06831357628107071\n",
            "Train step - Step 0, Loss 0.06854716688394547\n",
            "Train step - Step 0, Loss 0.0710207000374794\n",
            "Train step - Step 0, Loss 0.07119808346033096\n",
            "Train step - Step 0, Loss 0.07065834105014801\n",
            "Train step - Step 0, Loss 0.06864474713802338\n",
            "Train step - Step 0, Loss 0.06935136020183563\n",
            "Train step - Step 0, Loss 0.0710315927863121\n",
            "Train step - Step 0, Loss 0.06974301487207413\n",
            "Train step - Step 0, Loss 0.06959611922502518\n",
            "Train step - Step 0, Loss 0.06498326361179352\n",
            "Train epoch - Accuracy: 0.24775 Loss: 0.06975736391544342 Corrects: 2973\n",
            "Starting epoch 36/50\n",
            "Train step - Step 0, Loss 0.07236473262310028\n",
            "Train step - Step 0, Loss 0.07264856994152069\n",
            "Train step - Step 0, Loss 0.06840259581804276\n",
            "Train step - Step 0, Loss 0.07031130790710449\n",
            "Train step - Step 0, Loss 0.0706515833735466\n",
            "Train step - Step 0, Loss 0.06772086024284363\n",
            "Train step - Step 0, Loss 0.07362251728773117\n",
            "Train step - Step 0, Loss 0.0717015191912651\n",
            "Train step - Step 0, Loss 0.06761669367551804\n",
            "Train step - Step 0, Loss 0.0711575597524643\n",
            "Train step - Step 0, Loss 0.068998783826828\n",
            "Train step - Step 0, Loss 0.07080677896738052\n",
            "Train step - Step 0, Loss 0.06988832354545593\n",
            "Train step - Step 0, Loss 0.06763838976621628\n",
            "Train step - Step 0, Loss 0.07384969294071198\n",
            "Train step - Step 0, Loss 0.06904134154319763\n",
            "Train epoch - Accuracy: 0.24316666666666667 Loss: 0.07043396782875061 Corrects: 2918\n",
            "Starting epoch 37/50\n",
            "Train step - Step 0, Loss 0.06726604700088501\n",
            "Train step - Step 0, Loss 0.06809977442026138\n",
            "Train step - Step 0, Loss 0.06869443506002426\n",
            "Train step - Step 0, Loss 0.07143912464380264\n",
            "Train step - Step 0, Loss 0.07231932133436203\n",
            "Train step - Step 0, Loss 0.06888967007398605\n",
            "Train step - Step 0, Loss 0.071888767182827\n",
            "Train step - Step 0, Loss 0.0689903125166893\n",
            "Train step - Step 0, Loss 0.07093220949172974\n",
            "Train step - Step 0, Loss 0.06813994795084\n",
            "Train step - Step 0, Loss 0.07019888609647751\n",
            "Train step - Step 0, Loss 0.07128030061721802\n",
            "Train step - Step 0, Loss 0.07383611798286438\n",
            "Train step - Step 0, Loss 0.07326387614011765\n",
            "Train step - Step 0, Loss 0.06951020658016205\n",
            "Train step - Step 0, Loss 0.06911583244800568\n",
            "Train epoch - Accuracy: 0.24775 Loss: 0.07026856911182404 Corrects: 2973\n",
            "Starting epoch 38/50\n",
            "Train step - Step 0, Loss 0.06962613761425018\n",
            "Train step - Step 0, Loss 0.0684233009815216\n",
            "Train step - Step 0, Loss 0.07113971561193466\n",
            "Train step - Step 0, Loss 0.0694161206483841\n",
            "Train step - Step 0, Loss 0.0721849724650383\n",
            "Train step - Step 0, Loss 0.06908775866031647\n",
            "Train step - Step 0, Loss 0.07036671787500381\n",
            "Train step - Step 0, Loss 0.07292503118515015\n",
            "Train step - Step 0, Loss 0.0696694552898407\n",
            "Train step - Step 0, Loss 0.0724439024925232\n",
            "Train step - Step 0, Loss 0.06885062158107758\n",
            "Train step - Step 0, Loss 0.06704264134168625\n",
            "Train step - Step 0, Loss 0.06953699886798859\n",
            "Train step - Step 0, Loss 0.06952837854623795\n",
            "Train step - Step 0, Loss 0.0714370533823967\n",
            "Train step - Step 0, Loss 0.07273297756910324\n",
            "Train epoch - Accuracy: 0.24833333333333332 Loss: 0.07021676272153854 Corrects: 2980\n",
            "Starting epoch 39/50\n",
            "Train step - Step 0, Loss 0.06691078841686249\n",
            "Train step - Step 0, Loss 0.06952540576457977\n",
            "Train step - Step 0, Loss 0.07030672580003738\n",
            "Train step - Step 0, Loss 0.07141010463237762\n",
            "Train step - Step 0, Loss 0.06950783729553223\n",
            "Train step - Step 0, Loss 0.06964228302240372\n",
            "Train step - Step 0, Loss 0.06804554164409637\n",
            "Train step - Step 0, Loss 0.06939436495304108\n",
            "Train step - Step 0, Loss 0.06882495433092117\n",
            "Train step - Step 0, Loss 0.06860191375017166\n",
            "Train step - Step 0, Loss 0.06837663799524307\n",
            "Train step - Step 0, Loss 0.0731314867734909\n",
            "Train step - Step 0, Loss 0.07486085593700409\n",
            "Train step - Step 0, Loss 0.07038964331150055\n",
            "Train step - Step 0, Loss 0.07138323038816452\n",
            "Train step - Step 0, Loss 0.0705321729183197\n",
            "Train epoch - Accuracy: 0.2465 Loss: 0.0700412404537201 Corrects: 2958\n",
            "Starting epoch 40/50\n",
            "Train step - Step 0, Loss 0.07228817045688629\n",
            "Train step - Step 0, Loss 0.06751074641942978\n",
            "Train step - Step 0, Loss 0.06884310394525528\n",
            "Train step - Step 0, Loss 0.07003818452358246\n",
            "Train step - Step 0, Loss 0.06763537973165512\n",
            "Train step - Step 0, Loss 0.07037109136581421\n",
            "Train step - Step 0, Loss 0.06962861865758896\n",
            "Train step - Step 0, Loss 0.07007092982530594\n",
            "Train step - Step 0, Loss 0.06981123983860016\n",
            "Train step - Step 0, Loss 0.07024215161800385\n",
            "Train step - Step 0, Loss 0.07131385058164597\n",
            "Train step - Step 0, Loss 0.07174947112798691\n",
            "Train step - Step 0, Loss 0.06819512695074081\n",
            "Train step - Step 0, Loss 0.06981906294822693\n",
            "Train step - Step 0, Loss 0.06803098320960999\n",
            "Train step - Step 0, Loss 0.07301948964595795\n",
            "Train epoch - Accuracy: 0.244 Loss: 0.06983585870265961 Corrects: 2928\n",
            "Starting epoch 41/50\n",
            "Train step - Step 0, Loss 0.07159031182527542\n",
            "Train step - Step 0, Loss 0.06921278685331345\n",
            "Train step - Step 0, Loss 0.06982531398534775\n",
            "Train step - Step 0, Loss 0.0703553557395935\n",
            "Train step - Step 0, Loss 0.06998410820960999\n",
            "Train step - Step 0, Loss 0.0670885518193245\n",
            "Train step - Step 0, Loss 0.06947830319404602\n",
            "Train step - Step 0, Loss 0.07165703177452087\n",
            "Train step - Step 0, Loss 0.07315313816070557\n",
            "Train step - Step 0, Loss 0.06965586543083191\n",
            "Train step - Step 0, Loss 0.06950686126947403\n",
            "Train step - Step 0, Loss 0.06920819729566574\n",
            "Train step - Step 0, Loss 0.06908778101205826\n",
            "Train step - Step 0, Loss 0.06909634917974472\n",
            "Train step - Step 0, Loss 0.07015641778707504\n",
            "Train step - Step 0, Loss 0.07648497819900513\n",
            "Train epoch - Accuracy: 0.24675 Loss: 0.07019900703430176 Corrects: 2961\n",
            "Starting epoch 42/50\n",
            "Train step - Step 0, Loss 0.0688743069767952\n",
            "Train step - Step 0, Loss 0.07019965350627899\n",
            "Train step - Step 0, Loss 0.06881716102361679\n",
            "Train step - Step 0, Loss 0.06804835051298141\n",
            "Train step - Step 0, Loss 0.07047316431999207\n",
            "Train step - Step 0, Loss 0.0677613839507103\n",
            "Train step - Step 0, Loss 0.06793459504842758\n",
            "Train step - Step 0, Loss 0.07055201381444931\n",
            "Train step - Step 0, Loss 0.07233241945505142\n",
            "Train step - Step 0, Loss 0.07168154418468475\n",
            "Train step - Step 0, Loss 0.07208959013223648\n",
            "Train step - Step 0, Loss 0.07279951870441437\n",
            "Train step - Step 0, Loss 0.0693923607468605\n",
            "Train step - Step 0, Loss 0.06917102634906769\n",
            "Train step - Step 0, Loss 0.06935489177703857\n",
            "Train step - Step 0, Loss 0.07165370881557465\n",
            "Train epoch - Accuracy: 0.2520833333333333 Loss: 0.07003299510478973 Corrects: 3025\n",
            "Starting epoch 43/50\n",
            "Train step - Step 0, Loss 0.07255280017852783\n",
            "Train step - Step 0, Loss 0.07128677517175674\n",
            "Train step - Step 0, Loss 0.06904225796461105\n",
            "Train step - Step 0, Loss 0.07260335236787796\n",
            "Train step - Step 0, Loss 0.06961992383003235\n",
            "Train step - Step 0, Loss 0.06939644366502762\n",
            "Train step - Step 0, Loss 0.06850966066122055\n",
            "Train step - Step 0, Loss 0.07003003358840942\n",
            "Train step - Step 0, Loss 0.06745020300149918\n",
            "Train step - Step 0, Loss 0.06614254415035248\n",
            "Train step - Step 0, Loss 0.07055070251226425\n",
            "Train step - Step 0, Loss 0.07281561195850372\n",
            "Train step - Step 0, Loss 0.07163029164075851\n",
            "Train step - Step 0, Loss 0.06866241991519928\n",
            "Train step - Step 0, Loss 0.07155457884073257\n",
            "Train step - Step 0, Loss 0.06977894902229309\n",
            "Train epoch - Accuracy: 0.24091666666666667 Loss: 0.07010940432548524 Corrects: 2891\n",
            "Starting epoch 44/50\n",
            "Train step - Step 0, Loss 0.07143639773130417\n",
            "Train step - Step 0, Loss 0.0705975666642189\n",
            "Train step - Step 0, Loss 0.07231437414884567\n",
            "Train step - Step 0, Loss 0.07078290730714798\n",
            "Train step - Step 0, Loss 0.07054904103279114\n",
            "Train step - Step 0, Loss 0.07112454622983932\n",
            "Train step - Step 0, Loss 0.06941722333431244\n",
            "Train step - Step 0, Loss 0.0711335763335228\n",
            "Train step - Step 0, Loss 0.06750939041376114\n",
            "Train step - Step 0, Loss 0.0681370422244072\n",
            "Train step - Step 0, Loss 0.07355599850416183\n",
            "Train step - Step 0, Loss 0.06704681366682053\n",
            "Train step - Step 0, Loss 0.06858053058385849\n",
            "Train step - Step 0, Loss 0.06728000938892365\n",
            "Train step - Step 0, Loss 0.07148786634206772\n",
            "Train step - Step 0, Loss 0.06932235509157181\n",
            "Train epoch - Accuracy: 0.2510833333333333 Loss: 0.07003390437364579 Corrects: 3013\n",
            "Starting epoch 45/50\n",
            "Train step - Step 0, Loss 0.06839339435100555\n",
            "Train step - Step 0, Loss 0.06765482574701309\n",
            "Train step - Step 0, Loss 0.07052633911371231\n",
            "Train step - Step 0, Loss 0.07101208716630936\n",
            "Train step - Step 0, Loss 0.07207264751195908\n",
            "Train step - Step 0, Loss 0.06845176964998245\n",
            "Train step - Step 0, Loss 0.06998346000909805\n",
            "Train step - Step 0, Loss 0.06859390437602997\n",
            "Train step - Step 0, Loss 0.06837955862283707\n",
            "Train step - Step 0, Loss 0.07077139616012573\n",
            "Train step - Step 0, Loss 0.07221965491771698\n",
            "Train step - Step 0, Loss 0.07124441117048264\n",
            "Train step - Step 0, Loss 0.07298068702220917\n",
            "Train step - Step 0, Loss 0.07095471769571304\n",
            "Train step - Step 0, Loss 0.07046452909708023\n",
            "Train step - Step 0, Loss 0.06977447122335434\n",
            "Train epoch - Accuracy: 0.24208333333333334 Loss: 0.07022799533605575 Corrects: 2905\n",
            "Starting epoch 46/50\n",
            "Train step - Step 0, Loss 0.06922001391649246\n",
            "Train step - Step 0, Loss 0.07249041646718979\n",
            "Train step - Step 0, Loss 0.06829461455345154\n",
            "Train step - Step 0, Loss 0.0731317475438118\n",
            "Train step - Step 0, Loss 0.07009012997150421\n",
            "Train step - Step 0, Loss 0.06974079459905624\n",
            "Train step - Step 0, Loss 0.07016000896692276\n",
            "Train step - Step 0, Loss 0.0683073103427887\n",
            "Train step - Step 0, Loss 0.06764739751815796\n",
            "Train step - Step 0, Loss 0.071924589574337\n",
            "Train step - Step 0, Loss 0.07186923921108246\n",
            "Train step - Step 0, Loss 0.07106169313192368\n",
            "Train step - Step 0, Loss 0.06673810631036758\n",
            "Train step - Step 0, Loss 0.07245531678199768\n",
            "Train step - Step 0, Loss 0.06845198571681976\n",
            "Train step - Step 0, Loss 0.06649519503116608\n",
            "Train epoch - Accuracy: 0.24616666666666667 Loss: 0.06996114313602447 Corrects: 2954\n",
            "Starting epoch 47/50\n",
            "Train step - Step 0, Loss 0.07213225960731506\n",
            "Train step - Step 0, Loss 0.06817537546157837\n",
            "Train step - Step 0, Loss 0.07086259126663208\n",
            "Train step - Step 0, Loss 0.07091595232486725\n",
            "Train step - Step 0, Loss 0.07016679644584656\n",
            "Train step - Step 0, Loss 0.068971648812294\n",
            "Train step - Step 0, Loss 0.0675988644361496\n",
            "Train step - Step 0, Loss 0.06951205432415009\n",
            "Train step - Step 0, Loss 0.0680006816983223\n",
            "Train step - Step 0, Loss 0.06869661808013916\n",
            "Train step - Step 0, Loss 0.07212457060813904\n",
            "Train step - Step 0, Loss 0.07002515345811844\n",
            "Train step - Step 0, Loss 0.07341086864471436\n",
            "Train step - Step 0, Loss 0.06965422630310059\n",
            "Train step - Step 0, Loss 0.07218573987483978\n",
            "Train step - Step 0, Loss 0.06880266219377518\n",
            "Train epoch - Accuracy: 0.24916666666666668 Loss: 0.07010784417390824 Corrects: 2990\n",
            "Starting epoch 48/50\n",
            "Train step - Step 0, Loss 0.06833676993846893\n",
            "Train step - Step 0, Loss 0.07271305471658707\n",
            "Train step - Step 0, Loss 0.06798477470874786\n",
            "Train step - Step 0, Loss 0.06786969304084778\n",
            "Train step - Step 0, Loss 0.07234103977680206\n",
            "Train step - Step 0, Loss 0.07025250792503357\n",
            "Train step - Step 0, Loss 0.06859856098890305\n",
            "Train step - Step 0, Loss 0.06882461905479431\n",
            "Train step - Step 0, Loss 0.07022106647491455\n",
            "Train step - Step 0, Loss 0.07006367295980453\n",
            "Train step - Step 0, Loss 0.0698818489909172\n",
            "Train step - Step 0, Loss 0.07564698904752731\n",
            "Train step - Step 0, Loss 0.0696074441075325\n",
            "Train step - Step 0, Loss 0.06621372699737549\n",
            "Train step - Step 0, Loss 0.07010828703641891\n",
            "Train step - Step 0, Loss 0.07043805718421936\n",
            "Train epoch - Accuracy: 0.2535 Loss: 0.06993202185630798 Corrects: 3042\n",
            "Starting epoch 49/50\n",
            "Train step - Step 0, Loss 0.06889881193637848\n",
            "Train step - Step 0, Loss 0.07096339017152786\n",
            "Train step - Step 0, Loss 0.07119527459144592\n",
            "Train step - Step 0, Loss 0.07298178225755692\n",
            "Train step - Step 0, Loss 0.07159317284822464\n",
            "Train step - Step 0, Loss 0.07189454883337021\n",
            "Train step - Step 0, Loss 0.06606483459472656\n",
            "Train step - Step 0, Loss 0.06709080189466476\n",
            "Train step - Step 0, Loss 0.07302166521549225\n",
            "Train step - Step 0, Loss 0.07233993709087372\n",
            "Train step - Step 0, Loss 0.06752967834472656\n",
            "Train step - Step 0, Loss 0.07338275015354156\n",
            "Train step - Step 0, Loss 0.07074988633394241\n",
            "Train step - Step 0, Loss 0.0719616562128067\n",
            "Train step - Step 0, Loss 0.07277682423591614\n",
            "Train step - Step 0, Loss 0.06882527470588684\n",
            "Train epoch - Accuracy: 0.24725 Loss: 0.07074949193000793 Corrects: 2967\n",
            "Starting epoch 50/50\n",
            "Train step - Step 0, Loss 0.07087912410497665\n",
            "Train step - Step 0, Loss 0.07002656906843185\n",
            "Train step - Step 0, Loss 0.06876970827579498\n",
            "Train step - Step 0, Loss 0.06982915103435516\n",
            "Train step - Step 0, Loss 0.06875032931566238\n",
            "Train step - Step 0, Loss 0.07326886057853699\n",
            "Train step - Step 0, Loss 0.07188425213098526\n",
            "Train step - Step 0, Loss 0.07040508091449738\n",
            "Train step - Step 0, Loss 0.0733514279127121\n",
            "Train step - Step 0, Loss 0.06527861952781677\n",
            "Train step - Step 0, Loss 0.07230185717344284\n",
            "Train step - Step 0, Loss 0.06764357537031174\n",
            "Train step - Step 0, Loss 0.06870587170124054\n",
            "Train step - Step 0, Loss 0.06802048534154892\n",
            "Train step - Step 0, Loss 0.06989741325378418\n",
            "Train step - Step 0, Loss 0.06912576407194138\n",
            "Train epoch - Accuracy: 0.24608333333333332 Loss: 0.06990181940793991 Corrects: 2953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.52 0.04793258383870125\n",
            "TEST GROUP:  0.482\n",
            "TEST ALL:  0.3475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-o1n4skl-77"
      },
      "source": [
        "##CLOSED AND OPEN WORLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lUUjCewmNLo"
      },
      "source": [
        "#Dataset divided into 2 halves, 50 for closed 50 for open (choose five different random division)\n",
        "#1) closed world\n",
        "#  1.1)without rejection -> standard incremental scenario (train and test using selected 10 classes) but with 50 classes\n",
        "#      iter = 0 -> 10 or 20 (he does so in BDOC) classes ? ask Dario\n",
        "#      next iters -> add 10 until 50\n",
        "#      result expected -> equal to incremental \n",
        "#\n",
        "#  1.2)with rejection -> same procedure of above but we implement a rejection technique that \n",
        "#      classify as unknown an object that doesn't belong to the classes seen in the training (for the alg follow BDOC)\n",
        "#      result expected -> idealistic the model should not reject any of the object because we've tested the model with classes seen in the training\n",
        "#\n",
        "#2) open world\n",
        "#    at each step -> test the model only on unknown samples (the second half of dataset)\n",
        "#    \n",
        "#    result expected -> idealist the model should reject all of the test objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFHiLXyLmaWu"
      },
      "source": [
        "###download and dividing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OJxXhGZmdDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82cd843-93c1-44a3-94af-91409429452e"
      },
      "source": [
        "# Import dataset and apply transformations \n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# Check datasets length \n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFLVy0Tmt3G"
      },
      "source": [
        "#closed and open world\n",
        "splits_of_10 = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "#first 5 splits to closed world\n",
        "closed_data = {k:splits_of_10[k] for k in range(5)}\n",
        "\n",
        "#last 5 to open (removing the train val splits)\n",
        "open = []\n",
        "for k in range(5,10):\n",
        "  for j in[\"train\", \"val\"]:\n",
        "    open += splits_of_10[k][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQKnRMfjEaA-"
      },
      "source": [
        "### Modified iCaRL for closed/open"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fIvHXxhzwNI"
      },
      "source": [
        "def updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes, group_id, K, exemplars_set_tot, old_net, rejection=False, closed=True):\n",
        "  #exemplars_set_tot contiene tutti gli exemplars set ottenuti fino ad ora\n",
        "  #train_iter contiene tutti i dati (immagini + labels) delle classi nuove (s, .., t)\n",
        "  exemplars_subset = []\n",
        "  exemplars_indices = []\n",
        "  total_exemplars = []\n",
        "  labels_tot = []\n",
        "\n",
        "  for k, exemplar_set_class_k in exemplars_set_tot.items():\n",
        "    # exemplar_set_class_k is the list of indices of images that belongs to the exemplar set selected for class k \n",
        "    if (exemplar_set_class_k != []):\n",
        "      exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "      total_exemplars = torch.utils.data.ConcatDataset([total_exemplars, exemplars_subset])\n",
        "\n",
        "  if group_id > 1:\n",
        "    train_subset_total = torch.utils.data.ConcatDataset([train_subset, total_exemplars])\n",
        "  else:\n",
        "    train_subset_total = train_subset\n",
        "    \n",
        "  print(\"Len TOTAL train susbset: \", len(train_subset_total))\n",
        "  train_loader = torch.utils.data.DataLoader(train_subset_total, shuffle = True, batch_size=BATCH_SIZE, num_workers=2)\n",
        "  # train_loader è la concatenazione delle nuove classi con gli exemplar_sets calcolati fino a questo punto \n",
        "  print(\"training\")\n",
        "  train(net, train_loader, criterion, optimizer, scheduler, num_classes, group_id, old_net, rejection = rejection, closed = closed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAJtrUjIzqz-"
      },
      "source": [
        "import copy\n",
        "def incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_until_now, rejection=False, closed=True):\n",
        "  print(\"Starting the update representation\")\n",
        "  exemplar_indices = None\n",
        "  num_classes = 10\n",
        "  new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "  print(\"NEW CLASSES: \", new_classes_examined)\n",
        "\n",
        "  updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, rejection=rejection, closed=closed)\n",
        "                \n",
        "  iteration = group_id - 1\n",
        "  t = (num_classes * iteration) + num_classes # num_classes ricevute fino a questo momento \n",
        "  m = int(K/t) #casto ad intero ? per difetto o eccesso?\n",
        "  #s = num_classes * iteration\n",
        "\n",
        "  # REDUCING EXEMPLAR SET FOR EXISTING CLASSES\n",
        "  print(\"reducing exemplars for each class\")\n",
        "  print(total_classes_until_now)\n",
        "  for y in total_classes_until_now: #ci serve un set con tutte le classi fino ad ora viste\n",
        "    exemplar_y_new = reduceExemplarSet(m, exemplars_set_tot[y]) # valore associato alla chiave y che rappresenta il label della classe \n",
        "    print(\"REDUCED EXEMPLAR: \", len(exemplar_y_new))\n",
        "    exemplars_set_tot[y] = exemplar_y_new\n",
        "\n",
        "  \n",
        "  # CONSTRUCTION EXEMPLAR SET FOR NEW CLASSES\n",
        "  for y in new_classes_examined: # nuovi classi in arrivo di cui vogliamo costruire il set rappresentativo\n",
        "    images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data']\n",
        "    imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "    class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "    print(\"class train: \", class_train_subset)\n",
        "    print(\"Constructing exemplars of class\", y)\n",
        "    exemplars_set = constructExemplarSet(net, class_train_subset, m) # exemplar set è un set di indici\n",
        "    #devo recuperare dal dataset iniziale l'indice delle immagini dell'exemplar set creato \n",
        "    #for image in exemplars_set:\n",
        "     # exemplars_set = train_dataset.df.index[train_dataset.df['data'] == image].tolist()\n",
        "    exemplars_set_tot[y] = exemplars_set\n",
        "    print(\"exemplar set: \", exemplars_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkpzD3lazndM"
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes_till_now, group_id, old_net, num_epochs=NUM_EPOCHS, rejection=False, closed=True, threshold=THRESHOLD):    \n",
        "\n",
        "      \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "    print(\"num classes till now: \", num_classes_till_now)\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    print(num_epochs)\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        if rejection == True:\n",
        "          n_sample_known = 0\n",
        "          n_sample_unknown = 0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes_till_now, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            #if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            if (group_id > 1):\n",
        "              old_features = old_net.forward(images)\n",
        "              old_outputs = old_net.predict(old_features)\n",
        "              labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            if rejection == True:\n",
        "              prediction_batch = outputs.data.cpu().numpy()\n",
        "              for i in range(len(prediction_batch)):\n",
        "                current_softmax = softmax(prediction_batch[i])\n",
        "                if max(current_softmax)>THRESHOLD:\n",
        "                  n_sample_known += 1\n",
        "                else:\n",
        "                  n_sample_unknown += 1\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        if rejection == True:\n",
        "          if closed == True:\n",
        "            epoch_acc = n_sample_known / float(len(train_dataloader.dataset))\n",
        "            numb = n_sample_known\n",
        "          else:\n",
        "            epoch_acc = n_sample_unknown / float(len(train_dataloader.dataset))\n",
        "            numb = n_sample_unknown\n",
        "        else:\n",
        "          epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, numb))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0xrVtFyzj75"
      },
      "source": [
        "def validate(net, val_dataloader, criterion, num_classes, rejection = False, closed = False):\n",
        "    #counter for rejection part, known and unknown\n",
        "    if rejection==True:\n",
        "      n_sample_known = 0\n",
        "      n_sample_unknown = 0\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        if rejection == True:\n",
        "          prediction_batch = outputs.data.cpu().numpy()\n",
        "          print(len(prediction_batch))\n",
        "          for i in range(len(prediction_batch)):\n",
        "            current_softmax = softmax(prediction_batch[i])\n",
        "            if max(current_softmax)>THRESHOLD:\n",
        "              n_sample_known += 1\n",
        "            else:\n",
        "              n_sample_unknown += 1\n",
        "        else:\n",
        "          #_, preds = classify(images, )\n",
        "          running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "          all_preds_cm.extend(preds.tolist())\n",
        "          all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    if rejection == True:\n",
        "      if closed == True:\n",
        "        acc = n_sample_known / float(len(val_dataloader.dataset))\n",
        "      else:\n",
        "        acc = n_sample_unknown / float(len(val_dataloader.dataset))\n",
        "    else:\n",
        "      acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes, rejection = False, closed = True):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes, rejection, closed)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcN9P3Gr1ICR"
      },
      "source": [
        "def sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets, rejection = False, closed = True):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    K = 2000\n",
        "    iterations = 5\n",
        "    num_classes = 10\n",
        "    exemplars_set_tot = {new_list: [] for new_list in range(100)}\n",
        "    labels_train = []\n",
        "    total_classes_seen = []\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "\n",
        "      print(\"TRAIN: \", len(train_subset))\n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      print(\"TEST SET LENGHT: \", len(test_set))\n",
        "      print(\"TEST CURRENT GROUP SET LENGHT: \", len(test_subset))\n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      test_classes = list(test_dataset.df.loc[test_set.indices, 'labels'].value_counts().index)\n",
        "      train_classes = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "      validation_classes = list(train_dataset.df.loc[val_subset.indices, 'labels'].value_counts().index)\n",
        "      for i in train_classes:\n",
        "        total_classes_seen.append(i)\n",
        "      print(\"TEST_SET CLASSES: \", test_classes)\n",
        "      print(\"TRAIN_SET CLASSES: \", train_classes)\n",
        "      print(\"VALIDATION CLASSES: \", validation_classes)\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "\n",
        "      incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_seen, rejection=rejection, closed=closed) # Train the network with 10 classes at a time\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen, rejection=rejection, closed=closed)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen, rejection=rejection, closed=closed)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLViwIa2_bY"
      },
      "source": [
        "### Closed World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyhNorNImn9E",
        "outputId": "1776b744-6f19-411b-bdcc-0f30e83aa373"
      },
      "source": [
        "# Reverse indexing for closed and open world\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, splits_of_10)\n",
        "print(outputs_labels_mapping.getGroups())\n",
        "\n",
        "# TEST split\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)\n",
        "#above are 10 splits but I want 5 for closed and 5 for open\n",
        "test_splits_closed = {i:test_splits[i] for i in range(5)}\n",
        "test_splits_open = []\n",
        "for i in range(5,10):\n",
        "  test_splits_open += test_splits[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akWuYU2cB1j9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae096af-7681-46ee-ab59-d374248f4e0d"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "for i in outputs_labels_mapping.getGroups():\n",
        "  print(outputs_labels_mapping.getLabelsOfGroup(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    67\n",
            "1    59\n",
            "2    39\n",
            "3    22\n",
            "4    18\n",
            "5    65\n",
            "6    49\n",
            "7    56\n",
            "8    20\n",
            "9     4\n",
            "Name: labels, dtype: object\n",
            "10    79\n",
            "11    47\n",
            "12     7\n",
            "13    82\n",
            "14    34\n",
            "15    81\n",
            "16    21\n",
            "17    80\n",
            "18    68\n",
            "19    16\n",
            "Name: labels, dtype: object\n",
            "20    75\n",
            "21    23\n",
            "22    90\n",
            "23    10\n",
            "24    61\n",
            "25    76\n",
            "26    64\n",
            "27    32\n",
            "28    24\n",
            "29     0\n",
            "Name: labels, dtype: object\n",
            "30    95\n",
            "31    83\n",
            "32    63\n",
            "33    42\n",
            "34    30\n",
            "35     6\n",
            "36     2\n",
            "37    97\n",
            "38    72\n",
            "39    36\n",
            "Name: labels, dtype: object\n",
            "40    55\n",
            "41    31\n",
            "42    19\n",
            "43    98\n",
            "44    94\n",
            "45    54\n",
            "46    93\n",
            "47    85\n",
            "48     9\n",
            "49    96\n",
            "Name: labels, dtype: object\n",
            "50    99\n",
            "51    15\n",
            "52    14\n",
            "53    57\n",
            "54    45\n",
            "55    13\n",
            "56    88\n",
            "57    60\n",
            "58    40\n",
            "59     8\n",
            "Name: labels, dtype: object\n",
            "60    35\n",
            "61    27\n",
            "62    86\n",
            "63    70\n",
            "64    50\n",
            "65    69\n",
            "66    53\n",
            "67    17\n",
            "68    84\n",
            "69    52\n",
            "Name: labels, dtype: object\n",
            "70    71\n",
            "71    51\n",
            "72    43\n",
            "73    78\n",
            "74    74\n",
            "75    38\n",
            "76    37\n",
            "77    29\n",
            "78    48\n",
            "79    44\n",
            "Name: labels, dtype: object\n",
            "80    87\n",
            "81    58\n",
            "82    46\n",
            "83    26\n",
            "84    77\n",
            "85    41\n",
            "86     5\n",
            "87    92\n",
            "88    28\n",
            "89    12\n",
            "Name: labels, dtype: object\n",
            "90    91\n",
            "91    11\n",
            "92     3\n",
            "93    66\n",
            "94    62\n",
            "95    89\n",
            "96    73\n",
            "97    33\n",
            "98    25\n",
            "99     1\n",
            "Name: labels, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W6-U42kmn9F"
      },
      "source": [
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in closed_data.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,5):\n",
        "    v=test_splits_closed[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDPGgRJCtJe4"
      },
      "source": [
        "#for the test of open world\n",
        "open_test = Subset(test_dataset, test_splits_open)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgnJSvjtKYfS"
      },
      "source": [
        "targets_open = set()\n",
        "for i in range(len(open_test.indices)):\n",
        "  targets_open.add(test_dataset.__getitem__(open_test.indices[i])[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P76U7RxfLoxo"
      },
      "source": [
        "targets_closed = set()\n",
        "for k in test_splits_closed:\n",
        "  for j in range(len(test_splits_closed[k])):\n",
        "    targets_closed.add(test_dataset.__getitem__(test_splits_closed[k][j])[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gp8L6LONeqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a5912e-d6cb-4f77-93c6-a9cc1b30e264"
      },
      "source": [
        "#verifing that there aren't objects of the same class\n",
        "list(targets_closed.intersection(targets_open))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMyXZhVemn8q"
      },
      "source": [
        "### Closed world without rejection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl8IKzFsocw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "ba9679d3-86f9-484f-e886-230833cf7a56"
      },
      "source": [
        "#without rejection\n",
        "rejection = False\n",
        "closed = True\n",
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN:  4950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-31167443351d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclosed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequentialLearningiCaRL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-fc68f2ed3622>\u001b[0m in \u001b[0;36msequentialLearningiCaRL\u001b[0;34m(train_subsets, val_subsets, test_subsets, rejection, closed)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mold_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mold_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0maddOutputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI36G5hjodD8"
      },
      "source": [
        "method = \"Closed world without Rejection\"\n",
        "print(\"metrics ClosedWord for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,5):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFSAonO0mgQ"
      },
      "source": [
        "### Closed world with rejection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Dv40KK1ICR",
        "outputId": "f69af6cc-849f-4ab4-a9e2-1a058929e8ed"
      },
      "source": [
        "# train closed world with rejection\n",
        "rejection = True\n",
        "closed = True\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets, rejection=rejection, closed=closed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  1000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [67, 65, 59, 56, 49, 39, 22, 20, 18, 4]\n",
            "TRAIN_SET CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "VALIDATION CLASSES:  [59, 56, 49, 39, 22, 20, 18, 4, 67, 65]\n",
            "GROUP:  1\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "Len TOTAL train susbset:  4950\n",
            "training\n",
            "num classes till now:  10\n",
            "5\n",
            "Starting epoch 1/5, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.6994286775588989\n",
            "Train step - Step 10, Loss 0.30136817693710327\n",
            "Train step - Step 20, Loss 0.2911085784435272\n",
            "Train step - Step 30, Loss 0.26708194613456726\n",
            "Train epoch - Accuracy: 0.14585858585858585 Loss: 0.35155493756135303 Corrects: 1489\n",
            "Starting epoch 2/5, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.27089643478393555\n",
            "Train step - Step 50, Loss 0.2680715024471283\n",
            "Train step - Step 60, Loss 0.2523084878921509\n",
            "Train step - Step 70, Loss 0.2466038018465042\n",
            "Train epoch - Accuracy: 0.31555555555555553 Loss: 0.24956819676389597 Corrects: 2074\n",
            "Starting epoch 3/5, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.2362622767686844\n",
            "Train step - Step 90, Loss 0.24306665360927582\n",
            "Train step - Step 100, Loss 0.23924599587917328\n",
            "Train step - Step 110, Loss 0.1914578527212143\n",
            "Train epoch - Accuracy: 0.4163636363636364 Loss: 0.23055763977946658 Corrects: 2346\n",
            "Starting epoch 4/5, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.21142147481441498\n",
            "Train step - Step 130, Loss 0.2643110156059265\n",
            "Train step - Step 140, Loss 0.21732209622859955\n",
            "Train step - Step 150, Loss 0.20671935379505157\n",
            "Train epoch - Accuracy: 0.4624242424242424 Loss: 0.22319907110748868 Corrects: 2468\n",
            "Starting epoch 5/5, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.1971411406993866\n",
            "Train step - Step 170, Loss 0.2160784751176834\n",
            "Train step - Step 180, Loss 0.20748233795166016\n",
            "Train step - Step 190, Loss 0.1985824704170227\n",
            "Train epoch - Accuracy: 0.5115151515151515 Loss: 0.2116549697548452 Corrects: 2601\n",
            "Training finished in 13.8569917678833 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3d7f90>\n",
            "Constructing exemplars of class 67\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [2493, 27223, 4863, 13909, 3847, 46588, 49104, 28814, 29434, 38330, 49439, 20414, 9853, 36337, 5730, 12995, 37065, 26856, 17396, 45668, 41907, 42180, 9791, 25966, 16820, 1027, 37188, 42128, 22892, 9034, 33991, 37012, 11412, 37583, 5825, 37145, 4362, 9034, 8825, 37065, 40581, 6455, 4076, 18015, 6815, 16047, 33264, 6373, 8176, 1392, 965, 28814, 41706, 20414, 41648, 43635, 9174, 20057, 15332, 13905, 18423, 46553, 5825, 38422, 10194, 23836, 13704, 12575, 40782, 30805, 14515, 40906, 38671, 6928, 20452, 6036, 49244, 13704, 6036, 49104, 39931, 27380, 41648, 1088, 49407, 24092, 965, 30890, 41643, 9653, 37700, 27071, 23836, 20995, 19900, 46574, 35757, 36337, 46644, 2816, 30890, 41643, 34036, 39844, 26266, 11412, 19621, 24720, 43781, 11435, 32687, 11435, 2860, 39931, 9174, 10630, 46608, 1392, 5825, 11761, 36337, 35749, 44900, 16047, 7768, 22218, 47514, 4516, 2785, 30805, 25145, 27223, 1973, 27612, 12575, 10948, 22714, 19621, 14604, 15270, 25356, 18901, 11571, 27183, 40521, 30830, 24336, 12995, 4609, 9791, 6413, 10988, 9653, 40581, 36337, 6413, 14843, 40521, 15268, 37012, 16111, 38671, 27157, 41392, 34679, 36003, 35199, 49458, 37583, 13208, 25011, 35749, 12149, 46608, 1027, 49340, 38366, 49153, 284, 17163, 38671, 20422, 10194, 36938, 39243, 49407, 34679, 47229, 32224, 10630, 47386, 37145, 12908, 26351, 25463, 15465, 13704, 32655, 24336, 42572]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3d66d0>\n",
            "Constructing exemplars of class 59\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [24261, 37987, 15381, 9026, 10920, 42912, 12832, 26977, 19092, 2834, 1270, 12082, 15810, 16001, 14004, 13465, 1571, 11260, 24255, 6973, 34779, 48359, 1160, 11254, 38279, 32614, 35676, 35501, 16738, 24236, 32372, 10073, 17507, 10111, 12254, 47967, 3711, 42912, 47226, 19949, 20713, 25553, 3165, 12054, 3500, 33020, 16001, 15810, 26849, 3165, 30109, 16650, 10087, 13249, 32077, 6973, 37987, 7065, 10919, 27587, 10064, 2987, 16650, 17427, 28218, 27167, 16001, 16777, 36223, 34455, 11004, 10103, 47372, 46093, 15381, 9981, 19949, 33062, 38279, 32264, 30471, 34455, 41109, 1562, 5504, 25930, 30328, 35811, 10111, 4708, 30883, 37676, 37719, 27167, 10920, 35811, 27489, 1048, 22988, 47809, 7093, 35676, 30055, 32264, 5277, 42060, 19474, 41678, 35136, 30109, 38195, 47618, 29305, 18985, 28218, 29872, 40007, 17567, 15810, 6571, 20207, 28860, 25566, 21649, 32192, 973, 20713, 30828, 22130, 36945, 14671, 14376, 13873, 30109, 16738, 26977, 37533, 23210, 38064, 16001, 13178, 13420, 35920, 11260, 16709, 14004, 36637, 6283, 16189, 31388, 12082, 35811, 16250, 20491, 23044, 25142, 48441, 567, 11637, 2688, 34455, 29873, 23044, 26200, 35811, 3488, 30787, 10919, 4560, 40007, 18467, 43463, 16650, 24308, 34799, 28258, 13249, 12082, 7980, 24627, 34779, 8081, 7037, 34799, 25012, 26213, 3995, 18938, 10073, 30817, 2290, 48359, 1160, 30828, 11587, 34779, 33418, 20216, 10064, 34163]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c676a10>\n",
            "Constructing exemplars of class 39\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [49423, 32037, 38905, 25386, 18143, 23943, 218, 24067, 20430, 6574, 41688, 42644, 7493, 13811, 12184, 22599, 42224, 45131, 7060, 17307, 25467, 24442, 6795, 13489, 14383, 44582, 18624, 25177, 1446, 28001, 35244, 47632, 46877, 5752, 44790, 31843, 7060, 3495, 18637, 32758, 32620, 45674, 19268, 29457, 44596, 20453, 25252, 49897, 5752, 13219, 8415, 15132, 34011, 38041, 37857, 15156, 18147, 15148, 30788, 11597, 5021, 32802, 36418, 32758, 41736, 41565, 29450, 17018, 6776, 11597, 5344, 37881, 47366, 200, 49899, 18206, 6696, 32305, 24205, 22776, 20919, 6776, 18147, 15156, 13825, 11169, 21397, 46764, 23492, 11179, 16816, 1062, 48671, 15148, 37727, 11427, 34507, 16816, 2214, 45886, 35280, 5930, 13489, 6124, 26365, 46877, 9660, 46089, 19637, 10125, 5405, 22175, 25252, 36766, 45884, 15098, 13489, 19080, 1446, 14670, 27895, 25704, 27868, 33518, 17472, 32835, 35777, 11179, 20763, 49920, 33238, 30686, 12025, 10953, 11822, 15580, 48448, 49064, 37727, 5930, 43077, 49155, 40098, 11427, 14172, 31970, 46368, 47014, 45385, 7493, 6542, 19725, 23668, 36418, 5688, 35268, 5414, 25537, 42628, 37062, 45674, 19268, 36912, 23011, 28986, 44596, 17437, 5752, 28163, 41383, 37881, 16475, 41688, 3965, 48544, 24369, 47593, 2213, 39279, 7639, 38449, 21409, 101, 29050, 22175, 5021, 37919, 19725, 45146, 19637, 3758, 1446, 38905, 31502, 32439, 12263, 25126, 10340, 13745, 6542]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c23e990>\n",
            "Constructing exemplars of class 22\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [48379, 25457, 22774, 30469, 17596, 30764, 632, 33877, 14862, 15329, 15804, 8411, 38235, 44433, 44520, 27911, 17623, 4915, 14507, 31767, 38016, 45986, 36375, 27012, 37478, 34873, 6544, 26696, 25300, 13977, 8656, 36122, 9305, 28257, 42014, 34912, 4522, 6526, 6376, 11635, 17251, 7341, 35337, 33853, 2053, 38451, 11429, 8088, 44433, 21510, 45561, 20180, 39111, 36675, 31053, 46837, 37861, 40034, 5766, 7341, 16612, 22156, 46552, 13630, 30411, 7761, 8389, 9681, 42949, 12726, 8126, 26982, 21790, 19004, 36397, 2503, 8706, 19813, 41161, 23454, 24970, 44529, 22156, 7678, 28109, 1442, 42949, 5402, 40972, 5293, 4688, 5725, 12872, 8638, 24262, 26696, 11693, 40431, 36844, 8656, 6300, 17599, 19765, 40431, 39621, 44557, 24165, 15667, 40349, 18163, 48818, 19462, 6369, 16472, 46230, 11002, 4647, 35638, 5293, 632, 22036, 28257, 20024, 8389, 24415, 6300, 7761, 25186, 35194, 6090, 26778, 48995, 35732, 31767, 2584, 7761, 30411, 37554, 21333, 40292, 747, 36977, 34912, 29999, 19765, 30472, 5102, 36314, 10826, 13150, 7888, 1442, 5885, 38901, 33527, 6762, 12675, 30505, 17326, 43175, 19004, 19020, 33886, 8638, 37382, 35337, 424, 36204, 3004, 31767, 7784, 14862, 18614, 42949, 27820, 32505, 12670, 9828, 7784, 945, 48818, 11443, 10936, 27911, 31223, 22156, 47193, 9681, 3293, 11203, 9104, 46552, 9038, 46426, 20024, 17646, 36093, 44704, 10656, 48995]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c676fd0>\n",
            "Constructing exemplars of class 18\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [25395, 49145, 17430, 38092, 27799, 8405, 31736, 13477, 43832, 10419, 20720, 32258, 9782, 29034, 31962, 29210, 12968, 15174, 13417, 7557, 29811, 13606, 33465, 11999, 46367, 35442, 15969, 36385, 5060, 43832, 16017, 10829, 12008, 35061, 13030, 1273, 21078, 44655, 30043, 2778, 18176, 22390, 2434, 24328, 27613, 34561, 4107, 440, 2811, 49759, 10144, 4461, 22438, 9144, 5477, 20174, 16929, 23573, 10693, 39132, 7149, 3343, 19596, 29926, 36385, 38118, 2003, 43749, 7908, 22976, 6431, 28528, 46925, 20261, 32963, 43156, 18683, 22115, 47407, 9605, 2435, 40615, 38379, 30216, 4461, 14811, 38976, 41532, 30092, 40085, 35968, 31961, 10693, 13269, 24271, 42724, 30043, 39149, 27698, 46367, 35442, 2554, 30092, 13785, 33465, 14776, 35917, 14102, 45162, 2692, 10693, 27981, 38719, 16819, 13269, 17232, 27981, 46622, 43870, 38974, 32122, 13417, 20584, 21650, 14283, 36802, 41949, 49433, 22390, 47407, 42420, 7649, 31530, 31962, 21960, 35004, 1597, 13172, 18541, 45817, 38776, 2434, 4461, 19077, 30092, 18932, 38379, 49129, 26439, 21078, 41005, 35442, 22397, 9774, 27981, 32431, 25531, 27221, 5189, 27169, 17134, 4646, 24795, 14102, 18503, 19596, 37924, 25982, 24601, 27981, 24252, 33606, 22322, 3570, 36761, 2778, 3114, 39521, 1005, 14279, 37016, 1273, 41094, 21442, 5060, 17561, 21078, 4786, 35637, 21348, 38170, 20386, 27343, 33465, 11808, 10419, 25395, 19921, 3114, 37638]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c966790>\n",
            "Constructing exemplars of class 65\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [47299, 23560, 32485, 39587, 3602, 36020, 14986, 37153, 16237, 47616, 20321, 33367, 23464, 432, 22801, 6254, 26205, 21279, 26586, 16041, 35284, 15499, 28135, 28375, 17685, 8531, 8338, 6708, 45893, 22195, 39396, 7322, 46170, 17480, 18570, 10962, 10704, 19734, 35631, 35284, 2972, 28962, 983, 18720, 7973, 8225, 34105, 22729, 22801, 3206, 18709, 44985, 24955, 4158, 18691, 463, 31718, 33835, 17044, 3576, 22123, 9040, 29000, 16779, 45287, 27400, 12674, 14941, 22498, 7010, 42091, 13805, 3807, 21354, 49493, 21353, 432, 29924, 29675, 44923, 8009, 24955, 4158, 25387, 15499, 18252, 35425, 27376, 42091, 18498, 34695, 11441, 645, 44002, 13399, 22720, 21975, 42353, 38680, 14712, 48711, 49572, 22720, 17268, 29952, 6255, 33781, 43135, 14200, 21639, 365, 39308, 18709, 44985, 13533, 22720, 19895, 48164, 39714, 36776, 3206, 3602, 2424, 31883, 3799, 23825, 16679, 41727, 7762, 6157, 33366, 10177, 35407, 1814, 16039, 30950, 32583, 17044, 36547, 44836, 7354, 41417, 33043, 28962, 24847, 36076, 19220, 10704, 44459, 34695, 7777, 16986, 21279, 37662, 28962, 32987, 45463, 29364, 47616, 33597, 19199, 7323, 34559, 39188, 39587, 18315, 34695, 49493, 23819, 12674, 42643, 36076, 4158, 15789, 11836, 47845, 46475, 39714, 13152, 21347, 15296, 3576, 32585, 26757, 28855, 4603, 49003, 21639, 8531, 8338, 49752, 594, 4158, 22729, 18720, 21366, 8526, 44985, 16505, 43574]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c226510>\n",
            "Constructing exemplars of class 49\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [38251, 30220, 25633, 30522, 23821, 30826, 1542, 16668, 34270, 39979, 38402, 21727, 17272, 46044, 14890, 37237, 8515, 10421, 15401, 8856, 6758, 23625, 6117, 16363, 49043, 46569, 19075, 35671, 19911, 29350, 28201, 38236, 34270, 4264, 30826, 14536, 43512, 31401, 39644, 23169, 30549, 46931, 6144, 30821, 36373, 11308, 15491, 39780, 38404, 18456, 45722, 30522, 6622, 17524, 34224, 23625, 29777, 29526, 43512, 515, 13859, 35949, 34303, 1147, 19676, 25127, 46767, 40890, 28201, 14536, 8301, 27143, 14929, 34951, 6117, 42740, 28054, 2265, 46044, 617, 43738, 1147, 23913, 17099, 31146, 31350, 28691, 31975, 2265, 39780, 30549, 36009, 36373, 1434, 18112, 5061, 45718, 18001, 45095, 24785, 42325, 19812, 40890, 13859, 2920, 43337, 42904, 4047, 41037, 34224, 49659, 11736, 16421, 27170, 9824, 31721, 43512, 17896, 17790, 45945, 19812, 47186, 6809, 11919, 20211, 46044, 49412, 48754, 33433, 40747, 1140, 30522, 12722, 32735, 31003, 46075, 31578, 45633, 48987, 45650, 2236, 2219, 37546, 423, 35911, 18136, 41320, 21923, 5662, 43049, 22725, 43017, 15100, 34801, 20532, 33744, 15544, 11517, 29706, 15958, 21727, 1147, 34270, 49080, 23169, 31975, 1298, 9020, 16251, 45762, 43738, 34951, 17272, 17576, 44670, 27143, 8301, 6351, 11652, 19911, 467, 2262, 48987, 17524, 5908, 38209, 14929, 37546, 14804, 34270, 30821, 34111, 25633, 4351, 37546, 17229, 40191, 2444, 36373, 45762]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c2267d0>\n",
            "Constructing exemplars of class 56\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [34146, 1822, 21594, 26410, 6509, 26150, 22623, 29297, 30691, 9632, 39945, 8914, 12499, 40994, 22971, 47438, 10856, 41541, 48466, 4387, 21613, 7289, 13025, 14392, 11843, 108, 10239, 27809, 25826, 43671, 6766, 43311, 47662, 18867, 39221, 25059, 29639, 30715, 17919, 42473, 40733, 37352, 25780, 47805, 27676, 8628, 49001, 24037, 31891, 46451, 21522, 2762, 629, 26393, 39054, 20305, 48478, 27001, 9102, 31644, 49875, 9542, 39591, 38889, 49633, 14841, 1468, 43671, 5954, 25519, 48484, 48820, 33660, 14392, 33586, 46633, 19681, 16238, 27200, 45142, 43308, 41946, 39314, 31671, 15432, 37299, 34304, 39436, 45836, 6486, 17754, 269, 7751, 6595, 3044, 36898, 19240, 9491, 4493, 6290, 43633, 26544, 16420, 8063, 12564, 11376, 2764, 34304, 34183, 12571, 13189, 3044, 31427, 27876, 29454, 1529, 6486, 42019, 25059, 31574, 48478, 39500, 7125, 14906, 40710, 31644, 26153, 45142, 689, 12499, 32266, 40003, 48788, 21613, 5316, 15000, 42786, 7619, 9452, 7289, 23839, 36137, 6829, 44068, 42473, 7492, 13045, 1701, 35579, 30758, 48440, 44808, 4387, 20305, 43308, 47956, 1468, 26765, 24599, 40710, 49638, 31465, 41268, 34378, 26289, 25059, 26150, 31891, 26765, 1529, 40710, 14752, 19144, 14392, 18192, 5233, 37809, 17822, 47423, 8266, 4657, 28823, 19718, 47662, 29524, 35565, 41663, 43212, 45845, 1918, 39500, 24037, 24599, 26765, 44416, 43011, 7751, 43308, 37281, 48440]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c226150>\n",
            "Constructing exemplars of class 20\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [15166, 34159, 46547, 11785, 10219, 16438, 32921, 42719, 25513, 6728, 14139, 11001, 2747, 26111, 2020, 48170, 25513, 26973, 27424, 4586, 23321, 3158, 48567, 9289, 46677, 6072, 24084, 41466, 11958, 18131, 11488, 5401, 3033, 41209, 4586, 45453, 23976, 57, 23000, 134, 44379, 1827, 34122, 30460, 13794, 49986, 46897, 3033, 28851, 30824, 18453, 118, 5284, 18320, 49354, 29519, 39758, 19539, 15654, 41924, 44861, 36039, 3117, 26407, 5231, 9289, 29259, 44861, 14029, 47829, 25136, 3197, 46108, 30827, 5284, 9507, 14207, 16301, 16649, 30383, 27548, 26613, 41209, 4768, 49657, 38013, 32955, 34493, 16302, 18453, 47829, 44177, 22230, 48340, 26405, 10985, 29591, 5284, 23045, 19132, 20210, 7285, 37657, 37732, 13760, 39849, 2020, 28391, 25513, 9289, 5940, 29591, 27548, 42123, 7038, 12253, 49855, 43736, 40494, 45704, 24084, 7205, 908, 13794, 31785, 46001, 44111, 25504, 32672, 45453, 47798, 9374, 17318, 6279, 14207, 34122, 32955, 12314, 17446, 1819, 32262, 19763, 37898, 41924, 39151, 42719, 31197, 32262, 44914, 47829, 134, 46898, 36514, 10335, 16774, 25015, 32705, 46015, 47108, 49630, 46108, 30827, 32955, 22320, 3158, 30383, 26830, 40989, 4623, 24829, 33829, 5846, 34663, 20631, 49657, 27649, 15143, 26572, 1768, 48324, 1819, 47921, 5643, 37332, 6307, 48767, 46677, 49855, 39401, 1827, 46008, 19855, 33153, 1383, 44839, 636, 39022, 21572, 26768, 23654]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c980210>\n",
            "Constructing exemplars of class 4\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [8616, 19191, 36030, 11074, 13211, 40009, 4813, 36339, 21645, 28584, 40386, 7015, 33312, 44200, 9380, 33880, 4021, 37055, 42042, 24046, 26580, 32837, 28628, 25099, 46992, 49250, 13442, 17304, 48414, 33850, 27056, 46937, 43490, 35690, 6591, 12963, 13422, 43490, 38272, 6834, 30288, 2769, 12526, 46335, 37645, 33791, 21103, 20735, 23505, 42042, 24046, 33174, 10243, 38272, 31321, 37030, 18449, 20446, 39400, 28584, 42727, 20583, 3230, 45367, 21645, 20078, 40753, 2711, 32866, 6993, 21069, 12963, 30683, 5542, 24154, 14436, 33329, 46589, 44162, 12802, 41403, 36124, 24046, 33793, 27902, 25134, 6993, 4851, 4865, 3470, 16148, 12526, 20804, 47355, 32185, 43786, 9833, 825, 36241, 37057, 1308, 6051, 24619, 7083, 20970, 34433, 26476, 7015, 27514, 12122, 46589, 7819, 18449, 5677, 30185, 44872, 12526, 30683, 27884, 18449, 33791, 145, 10417, 3423, 3230, 41403, 11798, 32771, 4449, 18449, 12897, 5139, 45465, 8946, 3423, 12526, 6591, 35390, 21109, 10983, 20446, 24619, 4899, 43786, 8292, 42050, 40230, 44629, 1636, 47109, 3865, 49483, 389, 35649, 29495, 12122, 31043, 44104, 4449, 19181, 12963, 39748, 15063, 3310, 4449, 113, 25099, 42842, 8179, 14826, 23270, 13454, 20699, 12802, 20970, 3801, 1302, 8008, 42842, 7682, 19118, 42349, 3470, 2139, 2866, 3865, 14865, 3779, 15812, 43490, 25090, 8946, 49483, 44237, 2866, 30853, 18400, 32771, 33880, 24046]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.56 0.2094002068042755\n",
            "TEST GROUP:  0.612\n",
            "TEST ALL:  0.508\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  2000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [82, 81, 7, 16, 18, 20, 21, 22, 34, 39, 47, 49, 56, 59, 65, 67, 68, 79, 80, 4]\n",
            "TRAIN_SET CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "VALIDATION CLASSES:  [47, 34, 21, 16, 82, 81, 80, 79, 7, 68]\n",
            "GROUP:  2\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  20\n",
            "5\n",
            "Starting epoch 1/5, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.4786575734615326\n",
            "Train step - Step 10, Loss 0.2408965677022934\n",
            "Train step - Step 20, Loss 0.2520991265773773\n",
            "Train step - Step 30, Loss 0.22044594585895538\n",
            "Train step - Step 40, Loss 0.21477492153644562\n",
            "Train step - Step 50, Loss 0.21496336162090302\n",
            "Train epoch - Accuracy: 0.25625899280575537 Loss: 0.24712913065076733 Corrects: 1403\n",
            "Starting epoch 2/5, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.21163992583751678\n",
            "Train step - Step 70, Loss 0.2167361080646515\n",
            "Train step - Step 80, Loss 0.21134009957313538\n",
            "Train step - Step 90, Loss 0.20694971084594727\n",
            "Train step - Step 100, Loss 0.21117554605007172\n",
            "Train epoch - Accuracy: 0.28647482014388487 Loss: 0.20996199115145978 Corrects: 1962\n",
            "Starting epoch 3/5, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.20255409181118011\n",
            "Train step - Step 120, Loss 0.21074318885803223\n",
            "Train step - Step 130, Loss 0.2090960592031479\n",
            "Train step - Step 140, Loss 0.2045198529958725\n",
            "Train step - Step 150, Loss 0.22030936181545258\n",
            "Train step - Step 160, Loss 0.19820432364940643\n",
            "Train epoch - Accuracy: 0.33323741007194246 Loss: 0.2043877715729981 Corrects: 2244\n",
            "Starting epoch 4/5, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.19694355130195618\n",
            "Train step - Step 180, Loss 0.20370490849018097\n",
            "Train step - Step 190, Loss 0.20076122879981995\n",
            "Train step - Step 200, Loss 0.19872407615184784\n",
            "Train step - Step 210, Loss 0.19086265563964844\n",
            "Train epoch - Accuracy: 0.3601438848920863 Loss: 0.19970232619227266 Corrects: 2456\n",
            "Starting epoch 5/5, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.2055506706237793\n",
            "Train step - Step 230, Loss 0.18172195553779602\n",
            "Train step - Step 240, Loss 0.19336792826652527\n",
            "Train step - Step 250, Loss 0.1985117644071579\n",
            "Train step - Step 260, Loss 0.20734453201293945\n",
            "Train step - Step 270, Loss 0.2019658088684082\n",
            "Train epoch - Accuracy: 0.378705035971223 Loss: 0.19654389035358705 Corrects: 2578\n",
            "Training finished in 32.25327444076538 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c366650>\n",
            "Constructing exemplars of class 79\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [32829, 27602, 1977, 23535, 46033, 16341, 29605, 8586, 24098, 7140, 47938, 5404, 49095, 36438, 37142, 38156, 35165, 9793, 4744, 23535, 16517, 47158, 29031, 24260, 25718, 38926, 49072, 36145, 14441, 26446, 40781, 41564, 11310, 8223, 25004, 6211, 5485, 6513, 13555, 33252, 3139, 46745, 22362, 21378, 34943, 28188, 20711, 31813, 24493, 7775, 11310, 9378, 29504, 39947, 41078, 28063, 6211, 35258, 30418, 16514, 13846, 28435, 23381, 363, 42823, 34273, 5804, 29059, 7016, 10556, 30124, 29504, 6494, 12495, 29243, 45237, 11123, 47739, 38175, 24547, 38515, 8336, 13555, 6513, 23272, 48012, 37245, 6842, 7133, 40565, 42723, 26188, 7016, 640, 38725, 38926, 18378, 12646, 40529, 10996]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c369c90>\n",
            "Constructing exemplars of class 47\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [17416, 23245, 33168, 33014, 13857, 39354, 38323, 33273, 18652, 44843, 25483, 22234, 36842, 24080, 38500, 3281, 5134, 19937, 43570, 14964, 1786, 26618, 4240, 49031, 34456, 9555, 2667, 38536, 17620, 38536, 14038, 27133, 23407, 19927, 8878, 13301, 24422, 5345, 3327, 59, 39661, 10799, 1670, 16654, 9644, 59, 49764, 7059, 36230, 16873, 41073, 25576, 6429, 22234, 19824, 7121, 25313, 19157, 5020, 15845, 6704, 43269, 24646, 45364, 44251, 31892, 47802, 44779, 45783, 38536, 49526, 26642, 56, 45979, 31553, 8653, 26632, 42412, 1786, 26618, 45800, 22234, 16937, 14666, 34621, 33168, 31025, 29029, 30680, 8193, 44779, 10245, 21027, 43570, 1786, 8185, 9704, 28601, 34532, 1864]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c7d2810>\n",
            "Constructing exemplars of class 7\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [18920, 9862, 34285, 24978, 24869, 44096, 13986, 23354, 5279, 19980, 15748, 18207, 21893, 20596, 32730, 16035, 31764, 47924, 8110, 38438, 36670, 26002, 11767, 15496, 37815, 42898, 27018, 3810, 43273, 39511, 32909, 22759, 15748, 6367, 9118, 23354, 40476, 41605, 25806, 29293, 13962, 38690, 28243, 29732, 482, 46051, 42288, 377, 40128, 40805, 36892, 26640, 49282, 47435, 28363, 8444, 40805, 26593, 14762, 20596, 8716, 12202, 44860, 38876, 4978, 12293, 12134, 15042, 24869, 23752, 45508, 6367, 6679, 15243, 7910, 4275, 25806, 40734, 35841, 8110, 20569, 44096, 4884, 7110, 2161, 36222, 35960, 11540, 13286, 14701, 37565, 7002, 377, 29697, 45809, 36934, 13986, 30814, 31942, 39511]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f340b95fad0>\n",
            "Constructing exemplars of class 82\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [36301, 36327, 7586, 21064, 40409, 4037, 32449, 26501, 37521, 37189, 37510, 32741, 28265, 12210, 12252, 20686, 35369, 18202, 18702, 26852, 41977, 44523, 30528, 40655, 274, 23719, 5904, 31729, 28164, 40082, 18937, 871, 36690, 36727, 34612, 5454, 15304, 42693, 47534, 23130, 16467, 6277, 6227, 40367, 9111, 41900, 37521, 6141, 32106, 324, 44213, 10381, 30911, 28164, 29650, 4037, 38355, 34412, 27709, 27053, 32644, 6761, 16228, 12518, 15113, 13309, 49631, 19060, 29229, 16897, 18644, 34673, 44928, 25265, 11901, 9637, 45373, 42250, 19839, 7471, 32602, 8061, 43699, 46768, 26562, 5578, 33931, 18937, 6057, 10519, 3842, 3340, 16791, 16838, 33522, 31815, 14807, 11714, 23130, 45482]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c35e150>\n",
            "Constructing exemplars of class 34\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [41684, 49918, 28754, 36335, 48048, 28310, 31864, 42407, 8555, 15671, 5308, 21337, 3773, 15614, 30618, 47152, 5552, 39095, 10216, 35278, 43775, 2382, 13272, 8396, 40019, 31864, 29853, 5379, 35762, 120, 42093, 2324, 16611, 1472, 9108, 4091, 48286, 32312, 4556, 44854, 47241, 24571, 5308, 27664, 27630, 29129, 12329, 29468, 6096, 14310, 14859, 36177, 48940, 45766, 35325, 36330, 45900, 7853, 49605, 7368, 40597, 11646, 48783, 17608, 10940, 27028, 41972, 2648, 21197, 31833, 49111, 24459, 45766, 39095, 37038, 8406, 23411, 46887, 28868, 25510, 40438, 29468, 1125, 6849, 4681, 13335, 37038, 8824, 33386, 47241, 48286, 46124, 13038, 12459, 20892, 16193, 15179, 1076, 25110, 16944]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c35b990>\n",
            "Constructing exemplars of class 81\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [12751, 186, 45181, 23159, 20226, 2097, 30409, 503, 39819, 1943, 43532, 40790, 19383, 4925, 8321, 25857, 47627, 49830, 14183, 34026, 9696, 186, 13014, 38079, 9789, 41277, 8668, 5539, 35648, 40177, 22076, 14183, 20504, 43892, 10584, 16503, 6997, 11223, 47237, 42338, 37290, 49232, 22308, 2841, 20278, 31655, 23159, 10180, 18708, 41277, 45736, 21021, 42418, 35097, 36296, 32821, 37894, 9281, 27129, 18389, 41549, 49742, 24532, 20504, 45736, 7554, 23171, 49102, 19095, 49830, 45157, 31655, 22260, 5539, 8276, 6172, 40631, 32141, 35119, 40965, 39790, 43447, 11223, 48066, 34460, 33201, 12746, 40369, 18325, 14648, 28000, 38528, 49309, 25500, 18037, 42926, 36296, 15149, 15119, 23286]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c23aa10>\n",
            "Constructing exemplars of class 21\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [6133, 40466, 12355, 32641, 10676, 35819, 2495, 12998, 7991, 7314, 21562, 16105, 46760, 49609, 30804, 42398, 12998, 3277, 14427, 48058, 16826, 19339, 27524, 41054, 44316, 45390, 13912, 40270, 15874, 42236, 8700, 30132, 41092, 1902, 38040, 21758, 13788, 17657, 46251, 11367, 13806, 1672, 15256, 35619, 3737, 17263, 23559, 49609, 37353, 30904, 12784, 42398, 5713, 2406, 23522, 3900, 3043, 4610, 22795, 35176, 42679, 172, 11712, 4455, 3900, 36549, 49390, 14101, 25784, 36592, 35619, 18764, 11210, 9433, 6357, 21043, 39688, 43491, 2193, 17386, 8725, 24099, 38201, 1794, 37128, 9177, 39688, 37046, 10284, 2695, 49014, 23328, 37120, 13806, 26004, 48668, 40995, 41431, 14419, 21043]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3ecdd0>\n",
            "Constructing exemplars of class 80\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [8851, 16681, 15026, 684, 361, 30281, 41023, 41504, 42914, 7599, 3095, 31568, 18078, 2586, 7191, 37506, 28931, 30641, 40423, 33526, 6320, 43266, 40896, 17949, 18, 40095, 15106, 21740, 192, 13998, 33526, 19750, 43009, 25878, 7771, 18375, 43204, 28928, 34262, 1404, 37298, 24057, 3095, 28406, 36788, 20875, 17441, 7523, 41504, 45254, 28406, 42529, 37374, 25878, 30112, 39656, 43266, 48245, 46302, 45959, 44870, 4924, 19563, 1212, 25749, 39537, 42210, 28299, 3514, 33392, 42206, 42529, 37298, 18021, 17990, 39496, 9302, 40844, 49357, 19346, 28931, 2045, 35914, 33348, 4380, 1124, 38931, 47146, 340, 37506, 1090, 29240, 22392, 32587, 11142, 15974, 34060, 16519, 697, 35914]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3d7e50>\n",
            "Constructing exemplars of class 68\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [27599, 31919, 31044, 46739, 36879, 36099, 49932, 26793, 44804, 10921, 14817, 37785, 45021, 11225, 41493, 10028, 38288, 22453, 49464, 28443, 35328, 9294, 932, 1245, 17077, 30341, 9441, 18331, 46517, 37234, 47074, 24727, 45714, 35058, 29473, 24338, 39701, 18690, 30834, 36856, 4080, 22345, 5462, 320, 46401, 19562, 44458, 35625, 20816, 4342, 40435, 33990, 2815, 46591, 29117, 22905, 37246, 37785, 3836, 17859, 32979, 44652, 47696, 2116, 13212, 8399, 43263, 22453, 34184, 38822, 15046, 15022, 4342, 9591, 49013, 3918, 47868, 7915, 6378, 9723, 25899, 31434, 20014, 22591, 36099, 26793, 9196, 15573, 24524, 18740, 1831, 20325, 28450, 40017, 41928, 32181, 46739, 21729, 2754, 36856]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c22ab90>\n",
            "Constructing exemplars of class 16\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [13543, 22380, 18738, 6305, 34239, 1414, 40901, 34895, 24199, 20465, 15396, 41484, 32487, 22297, 26710, 7513, 7930, 14309, 36935, 15439, 23953, 11817, 12859, 5810, 19097, 2868, 22451, 4542, 23692, 37111, 10619, 35546, 27967, 46976, 11166, 44380, 38554, 12643, 29271, 37324, 13725, 35745, 16965, 1898, 13689, 47601, 38519, 25632, 29373, 10616, 28550, 49991, 26400, 43035, 7930, 20019, 30494, 22825, 48907, 45065, 18348, 24721, 35320, 39606, 20240, 4567, 24132, 35005, 596, 41771, 699, 13792, 7826, 36421, 40527, 8702, 41823, 26484, 29271, 16534, 30251, 4551, 40313, 13689, 30331, 38743, 49055, 3350, 5867, 25137, 36935, 14182, 45983, 39201, 3869, 22549, 41865, 9864, 29901, 5511]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.2 0.1707935631275177\n",
            "TEST GROUP:  0.391\n",
            "TEST ALL:  0.406\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  3000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [81, 79, 4, 10, 16, 18, 20, 22, 24, 32, 34, 56, 64, 68, 76, 80, 82, 90, 7, 21, 23, 39, 47, 49, 59, 61, 65, 67, 75, 0]\n",
            "TRAIN_SET CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "VALIDATION CLASSES:  [61, 32, 90, 24, 23, 76, 75, 10, 0, 64]\n",
            "GROUP:  3\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  30\n",
            "5\n",
            "Starting epoch 1/5, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.4100273847579956\n",
            "Train step - Step 10, Loss 0.22518660128116608\n",
            "Train step - Step 20, Loss 0.2127355933189392\n",
            "Train step - Step 30, Loss 0.204080268740654\n",
            "Train step - Step 40, Loss 0.20063260197639465\n",
            "Train step - Step 50, Loss 0.19907277822494507\n",
            "Train epoch - Accuracy: 0.1776978417266187 Loss: 0.22165248812531396 Corrects: 1164\n",
            "Starting epoch 2/5, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.19283218681812286\n",
            "Train step - Step 70, Loss 0.19041304290294647\n",
            "Train step - Step 80, Loss 0.1957685351371765\n",
            "Train step - Step 90, Loss 0.19302868843078613\n",
            "Train step - Step 100, Loss 0.19334523379802704\n",
            "Train epoch - Accuracy: 0.20014388489208634 Loss: 0.19164166227090274 Corrects: 1844\n",
            "Starting epoch 3/5, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.1907123327255249\n",
            "Train step - Step 120, Loss 0.18456396460533142\n",
            "Train step - Step 130, Loss 0.1883639097213745\n",
            "Train step - Step 140, Loss 0.193313866853714\n",
            "Train step - Step 150, Loss 0.18746034801006317\n",
            "Train step - Step 160, Loss 0.18368922173976898\n",
            "Train epoch - Accuracy: 0.23568345323741008 Loss: 0.18805720366162362 Corrects: 2148\n",
            "Starting epoch 4/5, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.18554319441318512\n",
            "Train step - Step 180, Loss 0.1876971274614334\n",
            "Train step - Step 190, Loss 0.18833711743354797\n",
            "Train step - Step 200, Loss 0.18500302731990814\n",
            "Train step - Step 210, Loss 0.1818116307258606\n",
            "Train epoch - Accuracy: 0.26402877697841726 Loss: 0.1862017927752982 Corrects: 2327\n",
            "Starting epoch 5/5, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.18272311985492706\n",
            "Train step - Step 230, Loss 0.18316835165023804\n",
            "Train step - Step 240, Loss 0.1806299090385437\n",
            "Train step - Step 250, Loss 0.18698008358478546\n",
            "Train step - Step 260, Loss 0.18355143070220947\n",
            "Train step - Step 270, Loss 0.18932068347930908\n",
            "Train epoch - Accuracy: 0.28949640287769784 Loss: 0.1841672743696103 Corrects: 2517\n",
            "Training finished in 32.54950284957886 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3b6250>\n",
            "Constructing exemplars of class 75\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [36676, 19729, 4358, 49346, 43454, 19926, 25325, 15616, 26802, 36510, 48685, 42320, 3022, 30564, 30295, 49346, 48685, 46180, 18908, 2672, 37294, 44017, 11393, 16112, 32982, 33100, 8446, 15984, 2571, 31392, 49868, 42096, 46180, 38077, 30895, 9825, 14355, 9778, 12573, 35128, 14259, 40843, 27180, 25608, 14236, 1625, 39461, 9869, 96, 38527, 1221, 11235, 34141, 33079, 2968, 23138, 10321, 35682, 8446, 15984, 17148, 39246, 46843, 36115, 16990, 37702]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3993d0>\n",
            "Constructing exemplars of class 23\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [901, 26570, 32865, 29128, 4436, 23635, 47380, 42614, 16680, 12494, 44638, 10659, 13380, 27392, 16151, 17152, 31426, 29111, 31830, 31679, 21890, 28100, 11755, 41940, 47077, 33888, 25497, 14482, 22597, 12213, 22703, 42455, 5463, 33316, 36855, 29128, 36377, 18542, 35170, 12213, 31878, 40130, 47216, 37707, 38385, 11418, 43328, 42483, 31329, 23575, 42959, 37869, 17475, 31129, 10461, 26110, 24790, 44940, 31167, 37792, 19910, 19732, 25073, 40523, 7018, 24898]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c399dd0>\n",
            "Constructing exemplars of class 90\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [24007, 22740, 40599, 1476, 23291, 9687, 25809, 46249, 49099, 39540, 15349, 20518, 14321, 27016, 32719, 42217, 10879, 7369, 5222, 34976, 47, 3442, 28622, 45708, 47140, 14866, 20896, 28312, 5304, 21114, 13515, 22385, 37367, 24580, 44748, 22638, 18880, 10482, 22122, 29355, 40811, 9241, 39115, 49712, 26282, 10960, 1956, 34171, 25837, 49313, 28929, 46835, 10960, 49313, 45818, 27734, 21610, 26196, 10106, 746, 41601, 3736, 10174, 791, 4581, 14866]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c35c310>\n",
            "Constructing exemplars of class 10\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [36971, 49077, 30717, 35787, 32162, 30225, 27957, 41961, 22586, 2237, 39855, 17980, 24639, 42813, 7941, 18361, 5193, 18346, 47288, 8048, 13343, 17344, 7406, 42371, 45942, 30498, 13766, 8456, 2127, 42493, 40883, 30225, 11858, 26744, 30042, 23295, 12547, 49516, 14231, 7476, 39040, 26742, 41451, 19503, 7299, 36528, 48795, 28748, 47936, 35241, 26550, 11486, 49415, 28091, 35434, 20233, 1587, 47240, 26106, 44786, 22387, 29045, 15693, 43599, 11486, 1579]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c99f350>\n",
            "Constructing exemplars of class 61\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [20826, 9804, 36734, 25017, 25187, 16330, 16273, 24139, 12562, 22836, 11591, 24156, 22651, 26660, 30244, 19790, 10268, 1552, 6864, 6869, 29425, 39329, 5120, 10392, 29475, 13844, 48512, 44155, 36796, 34818, 24139, 19121, 8709, 104, 49553, 544, 8980, 31935, 44144, 10277, 43495, 7377, 32226, 39247, 6614, 49581, 13110, 41364, 2513, 26601, 32360, 33262, 41422, 26660, 30334, 10277, 37139, 17650, 25239, 12029, 2789, 8865, 48512, 34237, 34475, 49725]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339e772310>\n",
            "Constructing exemplars of class 76\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [1475, 358, 34067, 40173, 18298, 44414, 38736, 18218, 39405, 48023, 36220, 37394, 29227, 44168, 20688, 4781, 5842, 19983, 48571, 34764, 18689, 20640, 14403, 34758, 34811, 41442, 27484, 48023, 44610, 40745, 31940, 3075, 40000, 5515, 4129, 23601, 9263, 18689, 35418, 15619, 49028, 44692, 12586, 14446, 40580, 28912, 20728, 10426, 3245, 34898, 40305, 22767, 30071, 41197, 49443, 10148, 32418, 4129, 5939, 38020, 4111, 32042, 4793, 45873, 10779, 10209]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c98d610>\n",
            "Constructing exemplars of class 64\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [14868, 41783, 44603, 15622, 14009, 17871, 3260, 6185, 46704, 26806, 18505, 173, 25533, 3220, 31797, 20255, 30513, 38436, 37690, 11190, 34409, 32467, 12769, 19318, 29860, 6366, 1373, 49819, 18354, 26611, 13657, 47076, 43917, 19458, 42025, 30209, 14271, 19439, 13835, 5917, 30209, 45275, 42840, 21703, 16397, 33172, 1376, 9474, 39317, 46759, 173, 46299, 10418, 12325, 1810, 10418, 27049, 22931, 12451, 23156, 19811, 10576, 46562, 21417, 17249, 11217]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c366a10>\n",
            "Constructing exemplars of class 32\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [38820, 40870, 16745, 39872, 24938, 26328, 29881, 9818, 26386, 1145, 3322, 42160, 25369, 42928, 9456, 26534, 12804, 29001, 12612, 23846, 48637, 25816, 48706, 22172, 20556, 12612, 13682, 7872, 25991, 27689, 549, 25067, 17680, 33534, 38454, 39950, 4306, 33263, 39019, 40185, 38754, 14494, 32960, 4048, 7455, 13648, 36306, 31411, 9886, 31879, 28059, 23088, 46813, 29195, 48183, 33187, 45661, 31175, 39382, 24837, 48706, 33705, 24010, 25369, 14405, 9133]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339d864a50>\n",
            "Constructing exemplars of class 24\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [17159, 30278, 46602, 5501, 4668, 20144, 23997, 25306, 35318, 18040, 7315, 1110, 6783, 21507, 21175, 24647, 25256, 39052, 44835, 16008, 23202, 17638, 32878, 45410, 35808, 24949, 3518, 21255, 32878, 37247, 31689, 32956, 21844, 48096, 43439, 47898, 37327, 34263, 6482, 37040, 35139, 24177, 49776, 41463, 17584, 19633, 42638, 20718, 1506, 37576, 5574, 8516, 21507, 8440, 1651, 27859, 31960, 41351, 957, 37130, 20144, 31342, 4308, 14595, 44831, 15147]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c226a50>\n",
            "Constructing exemplars of class 0\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [32233, 36817, 32128, 27576, 45171, 3780, 11048, 14513, 15085, 26702, 30731, 30172, 16996, 2640, 40715, 11314, 40607, 15105, 37056, 28648, 39949, 42631, 29405, 26247, 39303, 32826, 23780, 33773, 26819, 2126, 27350, 6851, 21781, 44364, 15085, 40598, 43575, 21870, 33950, 29582, 15701, 40486, 6241, 9236, 7155, 46274, 16353, 5239, 17727, 7234, 6851, 10037, 44429, 2936, 41259, 176, 38525, 31252, 44972, 35389, 29399, 1979, 39318, 8065, 45682, 35137]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.4 0.1220754086971283\n",
            "TEST GROUP:  0.369\n",
            "TEST ALL:  0.3416666666666667\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  4000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [97, 95, 68, 64, 56, 42, 36, 34, 32, 30, 24, 22, 20, 18, 16, 10, 6, 4, 2, 72, 76, 80, 61, 83, 81, 79, 75, 67, 65, 63, 59, 82, 49, 47, 39, 23, 21, 7, 90, 0]\n",
            "TRAIN_SET CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "VALIDATION CLASSES:  [63, 42, 36, 97, 95, 30, 83, 72, 6, 2]\n",
            "GROUP:  4\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  40\n",
            "5\n",
            "Starting epoch 1/5, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.3499222695827484\n",
            "Train step - Step 10, Loss 0.2216702699661255\n",
            "Train step - Step 20, Loss 0.19988541305065155\n",
            "Train step - Step 30, Loss 0.20837430655956268\n",
            "Train step - Step 40, Loss 0.19468402862548828\n",
            "Train step - Step 50, Loss 0.19027912616729736\n",
            "Train epoch - Accuracy: 0.1645021645021645 Loss: 0.21463244940553391 Corrects: 862\n",
            "Starting epoch 2/5, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.19487030804157257\n",
            "Train step - Step 70, Loss 0.19478575885295868\n",
            "Train step - Step 80, Loss 0.19605349004268646\n",
            "Train step - Step 90, Loss 0.1974085420370102\n",
            "Train step - Step 100, Loss 0.1901780217885971\n",
            "Train epoch - Accuracy: 0.172005772005772 Loss: 0.1922725366608577 Corrects: 1148\n",
            "Starting epoch 3/5, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.18605127930641174\n",
            "Train step - Step 120, Loss 0.19892483949661255\n",
            "Train step - Step 130, Loss 0.1892576664686203\n",
            "Train step - Step 140, Loss 0.18869681656360626\n",
            "Train step - Step 150, Loss 0.1864238977432251\n",
            "Train step - Step 160, Loss 0.19479778409004211\n",
            "Train epoch - Accuracy: 0.173015873015873 Loss: 0.19051059945923254 Corrects: 1310\n",
            "Starting epoch 4/5, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.18930546939373016\n",
            "Train step - Step 180, Loss 0.18660981953144073\n",
            "Train step - Step 190, Loss 0.18613505363464355\n",
            "Train step - Step 200, Loss 0.1814662665128708\n",
            "Train step - Step 210, Loss 0.1858462244272232\n",
            "Train epoch - Accuracy: 0.1795093795093795 Loss: 0.19006205088906475 Corrects: 1416\n",
            "Starting epoch 5/5, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1842668056488037\n",
            "Train step - Step 230, Loss 0.18505416810512543\n",
            "Train step - Step 240, Loss 0.19522976875305176\n",
            "Train step - Step 250, Loss 0.1819898933172226\n",
            "Train step - Step 260, Loss 0.18817420303821564\n",
            "Train step - Step 270, Loss 0.19249795377254486\n",
            "Train epoch - Accuracy: 0.17763347763347764 Loss: 0.1888795723044683 Corrects: 1594\n",
            "Training finished in 32.481855630874634 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c375f10>\n",
            "Constructing exemplars of class 95\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [45444, 13801, 35178, 46247, 43747, 44254, 16793, 46078, 24033, 47375, 33380, 31795, 29012, 11454, 43508, 5756, 94, 29681, 38855, 44573, 18052, 39789, 5657, 32897, 49681, 23225, 42567, 40371, 34057, 27842, 49256, 35440, 38447, 29194, 23873, 32805, 29648, 46276, 23030, 22169, 17231, 49508, 38952, 37946, 19111, 33847, 48605, 46247, 10805, 46111]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3664d0>\n",
            "Constructing exemplars of class 83\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [37432, 46671, 25416, 29197, 43615, 49471, 9298, 3688, 32150, 48064, 44727, 24713, 971, 21707, 41531, 21496, 1413, 19207, 23548, 42564, 24160, 36933, 38110, 25370, 49484, 43867, 10886, 41423, 22583, 48996, 11283, 38610, 29306, 34101, 48996, 21054, 13342, 27531, 41231, 49226, 21485, 27481, 49905, 14723, 29306, 27481, 46833, 23627, 15223, 21182]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339e7e1f90>\n",
            "Constructing exemplars of class 63\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [23674, 1181, 41040, 16862, 21062, 17225, 15298, 9447, 31587, 2887, 16004, 24060, 37307, 3091, 41334, 28707, 30491, 3027, 435, 25606, 8625, 16980, 19904, 48411, 40347, 10791, 2735, 12717, 18299, 5167, 30401, 15860, 38634, 36402, 46509, 5076, 6099, 49781, 26508, 11426, 30735, 47321, 35602, 21524, 4112, 6562, 4073, 28025, 38067, 39850]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339e741450>\n",
            "Constructing exemplars of class 42\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [22053, 36859, 46380, 28464, 40394, 14935, 35924, 4503, 10621, 18259, 11685, 12191, 25388, 23981, 30417, 39810, 4530, 32697, 35375, 49660, 3855, 4258, 28650, 20907, 22346, 29014, 12681, 24445, 33425, 33165, 12191, 39713, 49864, 12595, 42517, 3531, 250, 15152, 8426, 36214, 33280, 24445, 8426, 34760, 33917, 26098, 41036, 5035, 44048, 18459]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3511d0>\n",
            "Constructing exemplars of class 30\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [32574, 3959, 135, 41012, 18584, 4101, 30650, 8459, 33540, 45711, 36293, 21345, 11894, 31757, 39992, 40787, 23345, 41622, 33600, 45293, 35567, 35939, 29049, 40572, 28309, 9300, 3792, 47630, 48982, 20394, 33061, 6071, 2511, 46979, 6103, 43818, 17433, 35592, 48233, 15711, 42261, 33295, 42265, 42267, 6694, 32574, 18087, 42208, 40217, 13131]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c958f90>\n",
            "Constructing exemplars of class 6\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [27434, 31184, 17784, 38111, 34323, 27369, 47600, 25473, 17226, 19897, 34169, 40694, 15264, 22809, 12257, 714, 21415, 11982, 23470, 38520, 20433, 7856, 19195, 30004, 14373, 46365, 7096, 46016, 42130, 24253, 30398, 33064, 48240, 19313, 37621, 5535, 29127, 25257, 28017, 49107, 35216, 49856, 15269, 26366, 4739, 46065, 39127, 40740, 6226, 16601]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f33a2151090>\n",
            "Constructing exemplars of class 2\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [13261, 12762, 14499, 7802, 20415, 30742, 37797, 41119, 24149, 1804, 38345, 22121, 41309, 49862, 29307, 14048, 580, 19076, 22171, 16587, 31873, 37557, 9192, 30289, 17767, 35886, 8681, 42518, 20891, 10320, 14499, 5390, 16187, 11833, 40800, 22417, 18277, 40643, 33194, 27394, 14642, 25496, 41473, 15134, 27771, 20257, 11139, 2858, 18124, 18527]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c399f10>\n",
            "Constructing exemplars of class 97\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [13507, 28256, 15793, 22433, 14228, 15643, 44415, 20723, 16954, 8317, 11464, 3614, 16054, 19057, 22743, 40829, 20341, 43400, 11948, 40894, 27738, 16693, 1720, 15542, 46154, 13942, 16559, 18898, 8985, 5204, 19263, 48530, 48673, 6930, 31714, 29788, 15666, 34705, 16498, 10128, 45029, 41545, 45262, 12075, 39785, 46630, 44149, 22001, 32104, 36439]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c3e6710>\n",
            "Constructing exemplars of class 72\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [43893, 2463, 32996, 38358, 8662, 34074, 39313, 10555, 26513, 43501, 33192, 41207, 15650, 43989, 12090, 27203, 42269, 49124, 41289, 29124, 41205, 34748, 14080, 33944, 26087, 15371, 48930, 33192, 11779, 26513, 32064, 30264, 7909, 3644, 21839, 45617, 37995, 28591, 9011, 23013, 3632, 23323, 49124, 19155, 14114, 45538, 13102, 26283, 6532, 19463]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c65f890>\n",
            "Constructing exemplars of class 36\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [5518, 45214, 30117, 31740, 32402, 24960, 34791, 13607, 34243, 24767, 31599, 7818, 10506, 835, 35932, 37215, 3985, 15161, 34600, 16292, 42753, 20989, 31784, 39190, 5223, 33183, 49552, 12063, 356, 31867, 25775, 15368, 48846, 20508, 8859, 15266, 21898, 16090, 21085, 214, 12339, 21375, 25772, 25601, 9307, 36365, 12969, 36033, 4288, 44451]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.16 0.12240724265575409\n",
            "TEST GROUP:  0.174\n",
            "TEST ALL:  0.29875\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  5000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 80, 97, 93, 85, 81, 65, 61, 49, 21, 9, 96, 76, 83, 72, 68, 64, 56, 36, 32, 24, 20, 16, 4, 2, 6, 10, 18, 79, 75, 67, 63, 59, 55, 47, 39, 31, 23, 19, 7, 98, 94, 90, 82, 54, 42, 34, 30, 22, 0]\n",
            "TRAIN_SET CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "VALIDATION CLASSES:  [55, 54, 98, 96, 31, 94, 93, 85, 19, 9]\n",
            "GROUP:  5\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  50\n",
            "5\n",
            "Starting epoch 1/5, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.2794016897678375\n",
            "Train step - Step 10, Loss 0.21458066999912262\n",
            "Train step - Step 20, Loss 0.2031850516796112\n",
            "Train step - Step 30, Loss 0.19893676042556763\n",
            "Train step - Step 40, Loss 0.19937297701835632\n",
            "Train step - Step 50, Loss 0.19884933531284332\n",
            "Train epoch - Accuracy: 0.09237410071942447 Loss: 0.2110676847601966 Corrects: 731\n",
            "Starting epoch 2/5, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.19256888329982758\n",
            "Train step - Step 70, Loss 0.19802996516227722\n",
            "Train step - Step 80, Loss 0.1936100870370865\n",
            "Train step - Step 90, Loss 0.20041754841804504\n",
            "Train step - Step 100, Loss 0.19804838299751282\n",
            "Train epoch - Accuracy: 0.10201438848920863 Loss: 0.19540657784012583 Corrects: 1136\n",
            "Starting epoch 3/5, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.1958869844675064\n",
            "Train step - Step 120, Loss 0.1944384127855301\n",
            "Train step - Step 130, Loss 0.19657917320728302\n",
            "Train step - Step 140, Loss 0.19930724799633026\n",
            "Train step - Step 150, Loss 0.19343560934066772\n",
            "Train step - Step 160, Loss 0.1909271627664566\n",
            "Train epoch - Accuracy: 0.11381294964028776 Loss: 0.19398411812970964 Corrects: 1287\n",
            "Starting epoch 4/5, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.19960711896419525\n",
            "Train step - Step 180, Loss 0.19213896989822388\n",
            "Train step - Step 190, Loss 0.19631388783454895\n",
            "Train step - Step 200, Loss 0.19276291131973267\n",
            "Train step - Step 210, Loss 0.19064150750637054\n",
            "Train epoch - Accuracy: 0.1227338129496403 Loss: 0.1928003161459518 Corrects: 1477\n",
            "Starting epoch 5/5, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.18779638409614563\n",
            "Train step - Step 230, Loss 0.18812400102615356\n",
            "Train step - Step 240, Loss 0.1887567788362503\n",
            "Train step - Step 250, Loss 0.1945568025112152\n",
            "Train step - Step 260, Loss 0.19487348198890686\n",
            "Train step - Step 270, Loss 0.19303111732006073\n",
            "Train epoch - Accuracy: 0.13223021582733813 Loss: 0.19220137341416996 Corrects: 1617\n",
            "Training finished in 33.01742148399353 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c399dd0>\n",
            "Constructing exemplars of class 55\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [24446, 45731, 1905, 38765, 40120, 23475, 48683, 46844, 21760, 30568, 1544, 24096, 42574, 29596, 46872, 45582, 2993, 9693, 11539, 19309, 24018, 37251, 39217, 3052, 23798, 43894, 36424, 31734, 17697, 8060, 41597, 4544, 27388, 7394, 38832, 4383, 29490, 49779, 38423, 24096]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c375650>\n",
            "Constructing exemplars of class 31\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [47198, 11256, 14564, 30859, 20503, 26056, 16115, 9730, 39085, 15461, 29317, 48911, 32374, 14450, 38882, 48403, 8073, 19931, 4946, 11777, 21784, 42090, 32948, 31113, 30862, 593, 8068, 31845, 46812, 14777, 44187, 1826, 19078, 32318, 30013, 21061, 520, 17696, 9753, 38083]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c980950>\n",
            "Constructing exemplars of class 19\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [4283, 23503, 7821, 48061, 15104, 33564, 351, 31384, 3607, 28983, 45169, 24816, 48937, 20664, 19498, 9878, 27752, 32415, 43221, 5783, 683, 6075, 38116, 43244, 19519, 15495, 40751, 25627, 24350, 25173, 49945, 49974, 32427, 39609, 16807, 4403, 10093, 18457, 35912, 11148]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339bb07bd0>\n",
            "Constructing exemplars of class 98\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [20046, 14930, 6657, 32017, 3677, 20881, 3624, 49923, 888, 49135, 39579, 5738, 12567, 42683, 33067, 12170, 31312, 18876, 29028, 5039, 2106, 41402, 6692, 9787, 40227, 27498, 43239, 40633, 33973, 45343, 7108, 29121, 2103, 41829, 25630, 47339, 6692, 45929, 12792, 14675]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339c966190>\n",
            "Constructing exemplars of class 94\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [13563, 23885, 39985, 39092, 21745, 21693, 11233, 6536, 20653, 49023, 16046, 15527, 1297, 5106, 2309, 9445, 46995, 47196, 44067, 29644, 29636, 1435, 27796, 5888, 31910, 9917, 45494, 31429, 43548, 41748, 45955, 7828, 9056, 41133, 12073, 23246, 27762, 31780, 39617, 48746]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339d8c0e10>\n",
            "Constructing exemplars of class 54\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [33810, 14713, 34847, 26599, 40826, 14184, 22238, 22496, 37779, 41410, 19730, 1104, 21722, 36591, 22573, 22588, 10893, 2642, 34910, 10385, 34648, 26899, 9239, 27603, 16372, 11851, 8433, 1295, 45211, 18311, 27243, 1577, 47082, 29281, 33653, 12468, 10229, 43546, 15914, 330]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339ca1a650>\n",
            "Constructing exemplars of class 93\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [5045, 16669, 12516, 31114, 47219, 17283, 45996, 10663, 12110, 45899, 29109, 34989, 10649, 31441, 23520, 3687, 28438, 8410, 36779, 2064, 13042, 45075, 23935, 99, 26905, 4822, 33055, 35432, 12776, 770, 32695, 35786, 27117, 14657, 31633, 29068, 2142, 49709, 17355, 10471]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339d8c0f10>\n",
            "Constructing exemplars of class 85\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [41809, 21627, 19128, 5445, 1372, 48883, 26079, 35358, 44349, 35933, 47574, 20228, 31055, 41943, 3862, 22154, 38961, 36440, 33290, 38121, 26698, 5799, 16156, 26533, 15001, 20927, 26242, 6620, 16640, 21233, 45654, 39362, 23388, 38502, 11559, 43708, 46360, 2221, 43283, 48161]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339bb07bd0>\n",
            "Constructing exemplars of class 9\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [41539, 33879, 35537, 9138, 32516, 24419, 41168, 4355, 3752, 5047, 44810, 16619, 14188, 1876, 43924, 21977, 41376, 15112, 31703, 36678, 13668, 20726, 40717, 13145, 20702, 47368, 8590, 7555, 41610, 24185, 9547, 34658, 8111, 35410, 1962, 9131, 2921, 32659, 19600, 4425]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f339ca2ff90>\n",
            "Constructing exemplars of class 96\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [26096, 3681, 24249, 2145, 4177, 44424, 12292, 6839, 38465, 704, 29855, 10348, 2700, 19661, 22207, 4195, 8274, 20531, 47690, 39951, 6839, 28599, 15599, 3575, 2638, 38465, 2552, 28717, 20700, 21935, 25183, 18578, 8769, 18967, 12677, 33085, 46017, 15123, 13491, 18529]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.06 0.10472306609153748\n",
            "TEST GROUP:  0.152\n",
            "TEST ALL:  0.2636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KRvNYlfO1ICS",
        "outputId": "0227b47b-3ccc-4add-f379-05c74153e5c2"
      },
      "source": [
        "method = \"Closed world with Rejection\"\n",
        "print(\"metrics ClosedWord for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,5):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        " #writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "metrics ClosedWord for seed 66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Wc2tTMTlFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1c6484-fa39-4c2b-f675-aa6d6c5710ae"
      },
      "source": [
        "closed_with_rej_acc = new_accuracies\n",
        "print(closed_with_rej_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.508, 0.406, 0.3416666666666667, 0.29875, 0.2636]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pXLJaU3CtVQ"
      },
      "source": [
        "### open world with rejection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNW9TdvxHEl2"
      },
      "source": [
        "def sequentialLearningiCaRLOpen(train_subsets, val_subsets, open_dataset, rejection = False, closed = True):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    K = 2000\n",
        "    iterations = 5\n",
        "    num_classes = 10\n",
        "    exemplars_set_tot = {new_list: [] for new_list in range(100)}\n",
        "    labels_train = []\n",
        "    total_classes_seen = []\n",
        "\n",
        "    for train_subset, val_subset in zip(train_subsets, val_subsets):\n",
        "      \n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      print(\"BATCH SIZE: \", BATCH_SIZE )\n",
        "      print(\"TRAIN: \", len(train_subset))\n",
        "      old_net = copy.deepcopy(net)\n",
        "      old_net.to(DEVICE)\n",
        "      addOutputs(net,10)\n",
        "    \n",
        "    \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      train_classes = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "      validation_classes = list(train_dataset.df.loc[val_subset.indices, 'labels'].value_counts().index)\n",
        "      for i in train_classes:\n",
        "        total_classes_seen.append(i)\n",
        "      print(\"TRAIN_SET CLASSES: \", train_classes)\n",
        "      print(\"VALIDATION CLASSES: \", validation_classes)\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "\n",
        "      incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_seen, rejection=rejection, closed=closed) # Train the network with 10 classes at a time\n",
        "\n",
        "      # Validate on current group\n",
        "      \n",
        "      # val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      # acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen, rejection=rejection, closed=closed)\n",
        "      # print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      if(group_id ==5):\n",
        "        \"\"\" modify batch size for the variation \"\"\"\n",
        "        num_classes_seen=100\n",
        "        test_loader = DataLoader(open_dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen, exemplars_set_tot, rejection, closed)\n",
        "        all_accuracies.append(acc_all)\n",
        "        print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, all_accuracies, all_preds_cm, all_labels_cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tY3UJjmjPji"
      },
      "source": [
        "import gc\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes, exemplar_set, rejection = False, closed = False):\n",
        "    #counter for rejection part, known and unknown\n",
        "    rejection = True\n",
        "    if rejection==True:\n",
        "      n_sample_known = 0\n",
        "      n_sample_unknown = 0\n",
        "    net.eval()\n",
        "    exemplars_subset = []\n",
        "    exemplar_loader = None \n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    print(len(val_dataloader))\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, image, labels in val_dataloader:\n",
        "        print('ciclo immagini')\n",
        "        # Bring images and labels to GPU\n",
        "        image = image.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(image)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * image.size(0)\n",
        "            \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "       \n",
        "        if rejection == True:\n",
        "          print('1')\n",
        "          #passare exemplar_set_tot\n",
        "          reject = True\n",
        "          feature = net.forward(image)\n",
        "          # 128 * 64\n",
        "          #print(feature.shape)\n",
        "          mean_image = []\n",
        "          cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "          for k, exemplar_set_class_k in exemplar_set.items():\n",
        "            distances = []\n",
        "          # exemplar_set_class_k is the list of indices of images that belongs to the exemplar set selected for class k \n",
        "            if (exemplar_set_class_k != []):\n",
        "              exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "              exemplar_loader = torch.utils.data.DataLoader(exemplars_subset, shuffle = True, batch_size=1, num_workers=2)\n",
        "            dist = 0\n",
        "            # 40 volte\n",
        "            for _, exemplars, labels  in exemplar_loader:\n",
        "              # print('exemplar: ', exemplar)\n",
        "              exemplars = exemplars.to(DEVICE)  \n",
        "              feature_exemplar = net.forward(exemplars)\n",
        "              del exemplars #delete unnecessary variables \n",
        "              gc.collect()  \n",
        "              #print(feature_exemplar.shape) #1 * 64\n",
        "              output = (cos(feature_exemplar, feature)) # ex1 128distanze \n",
        "              output = output.detach().cpu().numpy() #128x1\n",
        "              distances.append(output) # 128x40 \n",
        "            #print('DISTANZE: ', distances) # 128x40\n",
        "            # 128 * 40 media orizzontale per ottenere 128x1\n",
        "            mean = np.mean(distances, axis = 0) # 128x1\n",
        "            mean_image.append(mean)\n",
        "          print(\"mean_image (128x50): \", mean_image) #128x50 \n",
        "          normalized_vector = ( mean_image- np.mean(mean_image, axis = 0) ) / np.std(mean_image, axis = 0)\n",
        "          #print(normalized_vector)\n",
        "          \n",
        "          for value in normalized_vector:\n",
        "            if (value < 0.5):\n",
        "              reject = False\n",
        "          if (reject == False):\n",
        "            n_sample_known += 1\n",
        "          else:\n",
        "            n_sample_unknown += 1\n",
        "        # if rejection == True:\n",
        "        #   prediction_batch = outputs.data.cpu().numpy()\n",
        "        #   print(\"OUTPUTS shape: \", outputs.data.shape)\n",
        "        #   print(\"LEN PRED BATCH:\", len(prediction_batch))\n",
        "        #   for i in range(len(prediction_batch)):\n",
        "        #     current_softmax = softmax(prediction_batch[i])\n",
        "        #     #print(max(current_softmax))\n",
        "        #     if max(current_softmax)>THRESHOLD:\n",
        "        #       n_sample_known += 1\n",
        "        #     else:\n",
        "        #       n_sample_unknown += 1\n",
        "        else:\n",
        "          #_, preds = classify(images, )\n",
        "          running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "          all_preds_cm.extend(preds.tolist())\n",
        "          all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    if rejection == True:\n",
        "      if closed == True:\n",
        "        acc = n_sample_known / float(len(val_dataloader.dataset))\n",
        "      else:\n",
        "        acc = n_sample_unknown / float(len(val_dataloader.dataset))\n",
        "    else:\n",
        "      acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes, exemplar_set, rejection = False, closed = True):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes, exemplar_set, rejection, closed)\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes, exemplar_set, rejection, closed)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs9uww-HEu08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dac819-1d8c-4f38-e325-9492182e6c06"
      },
      "source": [
        "#open with rejection\n",
        "rejection = True\n",
        "closed = False\n",
        "# train\n",
        "net, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningiCaRLOpen(train_subsets, val_subsets, open_test, rejection=rejection, closed=closed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BATCH SIZE:  128\n",
            "TRAIN:  4950\n",
            "TRAIN_SET CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "VALIDATION CLASSES:  [59, 56, 49, 39, 22, 20, 18, 4, 67, 65]\n",
            "GROUP:  1\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "Len TOTAL train susbset:  4950\n",
            "training\n",
            "num classes till now:  10\n",
            "1\n",
            "Starting epoch 1/1, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7201578617095947\n",
            "Train step - Step 10, Loss 0.30925440788269043\n",
            "Train step - Step 20, Loss 0.2873806059360504\n",
            "Train step - Step 30, Loss 0.2768387496471405\n",
            "Train epoch - Accuracy: 0.8547474747474747 Loss: 0.3545821268510337 Corrects: 4231\n",
            "Training finished in 5.665836334228516 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3259533d0>\n",
            "Constructing exemplars of class 67\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [18314, 47266, 42180, 23457, 40782, 49153, 26453, 25145, 1973, 7786, 12437, 35749, 26910, 27071, 23517, 11435, 26294, 15628, 42128, 13341, 6455, 6380, 27043, 6928, 33169, 45433, 46666, 25966, 9653, 36708, 426, 965, 37255, 23633, 27948, 32541, 41907, 23517, 43844, 43781, 2860, 37700, 18540, 18324, 25938, 22335, 11050, 41648, 35433, 20707, 49783, 11683, 6455, 41907, 34679, 7279, 17163, 508, 1088, 25938, 1014, 39193, 25966, 39682, 32655, 25938, 37700, 14882, 40906, 44094, 47104, 21363, 26294, 48252, 33742, 46443, 49244, 36337, 27036, 27948, 13905, 26856, 14717, 1973, 24855, 7430, 1247, 33761, 43164, 14914, 47266, 49407, 39931, 2742, 28494, 1014, 39953, 10630, 9483, 2860, 30391, 10947, 21813, 29434, 6928, 13909, 29022, 20145, 11761, 5415, 10630, 11234, 10630, 30391, 23517, 28625, 5730, 35429, 25138, 49795, 23836, 8484, 40875, 3847, 20253, 48574, 5807, 4076, 7768, 49104, 42399, 29022, 34036, 48076, 508, 36508, 28403, 32400, 44900, 26266, 17514, 27043, 16592, 13704, 6455, 6380, 44686, 1025, 32224, 45433, 9331, 44009, 10946, 35749, 13208, 20452, 29006, 39243, 41907, 30184, 26975, 38326, 40605, 37255, 16616, 20614, 30184, 29674, 14157, 7768, 17411, 24498, 13704, 5399, 11234, 20422, 22239, 37583, 17514, 5730, 26671, 42945, 18812, 21917, 28625, 32082, 11571, 20614, 20646, 10336, 20414, 21663, 39311, 21031, 8484, 25966, 47057, 40782, 40906, 39311]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3261f8a50>\n",
            "Constructing exemplars of class 59\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [8081, 46599, 14052, 44993, 8241, 13328, 11306, 4649, 21144, 32778, 34852, 25012, 42060, 4113, 34536, 18250, 49401, 2987, 49931, 41316, 45267, 10103, 21537, 34504, 38195, 13656, 10087, 42330, 28860, 10073, 7093, 1844, 24503, 12907, 24627, 8578, 29804, 8578, 18193, 30055, 16167, 30615, 26688, 33062, 36945, 22130, 39641, 12907, 1237, 38216, 28258, 33173, 18512, 44993, 30553, 27489, 16446, 10073, 4560, 29804, 8014, 36223, 16709, 12318, 41316, 44581, 38061, 46093, 25142, 40178, 22866, 4649, 13656, 19384, 1270, 4018, 11555, 28258, 25142, 3316, 31559, 30109, 11016, 41971, 36945, 4113, 23210, 15989, 20812, 6571, 16244, 46536, 2688, 29352, 24021, 7980, 8113, 33062, 27541, 21269, 982, 44993, 10111, 24261, 4010, 45659, 28279, 47614, 3711, 22988, 32136, 44335, 36312, 32022, 39993, 13656, 3740, 4113, 849, 34852, 32778, 8918, 10111, 25774, 4936, 19709, 9026, 30883, 35136, 28526, 9677, 30055, 10020, 16650, 25553, 31501, 18512, 28218, 34779, 41678, 13249, 28660, 27587, 17427, 11306, 13328, 35676, 29870, 4560, 43881, 27536, 18467, 25629, 17943, 45339, 36223, 9677, 12907, 14758, 29628, 21624, 5504, 2000, 23247, 30817, 47618, 17507, 30615, 18250, 8324, 34536, 13656, 14091, 16167, 12318, 30883, 31501, 29164, 20864, 1048, 14004, 1927, 7061, 13465, 24308, 1562, 30471, 3165, 43881, 6283, 41307, 11306, 20491, 35190, 12006, 36223, 14671, 6283, 31678, 7061]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32595aa10>\n",
            "Constructing exemplars of class 39\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [12168, 18147, 2311, 32758, 22685, 39225, 41688, 32685, 36766, 2757, 45744, 30268, 44266, 14383, 3524, 18785, 16816, 29734, 5021, 18749, 18143, 40488, 8031, 11427, 35009, 32439, 44453, 13077, 49860, 32307, 34352, 18206, 18522, 18034, 36793, 18624, 735, 25467, 27672, 43859, 29734, 22654, 5320, 22737, 28004, 26139, 49899, 14383, 38861, 12412, 35634, 44596, 46634, 42032, 49899, 47084, 6006, 18147, 12168, 10125, 28649, 4922, 34507, 1494, 49423, 7295, 41455, 36369, 36766, 166, 47632, 11883, 22737, 5340, 13077, 28472, 18143, 19303, 46231, 41688, 45072, 3745, 19522, 6407, 37929, 42224, 12135, 46104, 45388, 32307, 19899, 39280, 11775, 31593, 1062, 39225, 32620, 42552, 49097, 27672, 33368, 5451, 13077, 36418, 16816, 34507, 19357, 5930, 22227, 27895, 18143, 18624, 13489, 31964, 45388, 10125, 21575, 21343, 25887, 18206, 5340, 27250, 226, 44285, 46368, 19522, 7493, 35009, 42032, 24067, 38834, 37794, 49074, 44582, 14383, 43777, 14527, 47788, 46962, 14096, 30686, 38041, 12697, 22227, 8683, 20687, 3307, 47340, 27250, 44509, 21409, 5021, 26139, 3970, 10125, 21575, 30307, 40856, 34160, 38449, 5405, 23370, 45131, 35009, 46661, 44453, 2311, 18522, 18034, 5320, 12697, 48671, 15098, 33859, 20997, 34507, 15156, 30268, 29503, 30268, 14659, 15730, 31403, 21997, 166, 28649, 5673, 25467, 28986, 28001, 49064, 45884, 18522, 42637, 41852, 1062, 39225, 17472, 10340, 13387]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb328221690>\n",
            "Constructing exemplars of class 22\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [14023, 6968, 36897, 32169, 49084, 38054, 10992, 16458, 43175, 40972, 41014, 9171, 47463, 24165, 46837, 21219, 23414, 45265, 48592, 8117, 34912, 39070, 945, 37382, 47785, 43564, 21578, 10251, 14594, 47145, 3004, 47317, 12872, 17646, 9221, 41791, 44714, 35616, 35892, 44721, 27497, 45671, 22367, 32047, 12994, 31976, 36093, 47463, 30469, 37754, 44557, 48676, 33877, 42014, 11972, 48379, 10936, 11002, 7888, 12994, 21578, 10251, 36314, 46552, 26982, 16753, 24352, 3352, 37219, 32505, 10936, 45265, 22036, 7784, 15318, 31931, 21557, 44433, 25457, 41981, 31292, 19131, 34912, 34082, 36204, 11850, 48592, 13209, 24042, 37754, 779, 15329, 18718, 37915, 36093, 30254, 2251, 15804, 27012, 14507, 19813, 32169, 4915, 7678, 17599, 36314, 35840, 34154, 35732, 10817, 519, 7705, 22367, 40206, 23664, 44529, 24311, 6544, 3941, 4228, 8341, 40431, 38235, 29380, 41791, 17313, 48870, 8117, 39395, 45561, 8603, 38451, 45671, 28968, 40206, 34723, 21481, 19813, 16272, 22566, 31292, 35250, 37250, 29930, 5885, 24204, 519, 35935, 30411, 41791, 27820, 35616, 1851, 8126, 7678, 19004, 26461, 36977, 6090, 45478, 40206, 8117, 9322, 12627, 36314, 38451, 18902, 39852, 872, 21200, 12648, 6771, 35674, 35840, 16552, 36069, 18905, 24262, 26767, 17326, 20525, 21200, 21510, 36310, 24448, 46649, 39621, 2135, 49069, 49821, 17623, 7696, 36367, 19020, 24042, 21913, 25693, 8117, 48870, 24147]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32595c590>\n",
            "Constructing exemplars of class 18\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [47884, 48761, 13477, 31340, 18683, 10359, 32203, 32101, 20386, 45833, 13277, 43749, 49759, 44118, 2807, 32500, 4107, 18541, 11385, 5189, 47098, 41949, 43059, 35637, 37129, 39571, 39583, 21348, 12968, 13030, 2435, 23725, 13100, 27830, 31959, 38776, 20871, 18500, 13148, 13030, 20261, 4646, 37843, 35004, 47407, 12530, 36152, 46367, 27989, 19596, 21650, 22017, 18031, 35793, 31800, 7908, 28389, 41094, 23725, 32191, 19627, 13785, 16819, 40363, 3556, 21770, 3570, 27120, 49145, 49342, 7955, 24472, 3343, 33848, 47192, 14128, 14512, 29811, 8004, 45162, 9645, 27748, 13477, 37181, 13030, 35247, 11159, 12585, 46500, 37129, 9670, 12662, 32209, 32203, 46329, 14977, 11523, 37638, 11523, 18889, 8936, 14102, 3114, 14776, 36037, 33465, 19077, 40946, 28047, 32963, 36802, 11061, 9605, 4461, 22017, 21371, 10829, 2811, 38379, 21335, 39149, 32258, 15174, 18847, 31959, 38776, 42573, 9654, 24472, 46712, 12619, 43287, 30885, 12660, 23573, 14085, 4461, 6605, 13100, 12541, 45730, 42969, 22467, 22115, 1242, 28829, 17430, 44489, 36259, 38676, 26711, 1597, 9622, 20939, 13292, 44530, 13030, 11159, 35247, 19492, 37129, 30654, 13269, 34175, 6764, 9654, 47098, 24271, 6431, 32952, 9705, 27371, 14102, 31961, 47407, 48232, 10065, 18932, 10168, 16527, 14107, 5060, 4798, 4384, 8004, 21552, 27799, 17232, 22322, 5477, 43832, 35442, 20871, 18847, 13148, 46386, 27799, 41949, 4386, 440]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326203fd0>\n",
            "Constructing exemplars of class 65\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [39954, 43135, 7762, 17959, 9040, 28614, 23560, 7024, 21873, 10704, 16121, 33043, 12943, 42353, 7973, 48625, 24775, 21771, 34962, 11441, 21902, 38833, 44708, 23766, 48625, 49003, 38489, 2424, 18805, 170, 29737, 37992, 16101, 3206, 19912, 21347, 18805, 14361, 28375, 17681, 17959, 22820, 3734, 38262, 19956, 28362, 19199, 39308, 30661, 24050, 48476, 46771, 36020, 26193, 848, 21684, 33597, 41212, 6714, 33367, 33366, 29091, 30303, 33364, 30351, 20215, 43365, 37992, 45707, 36248, 3361, 1982, 33056, 32987, 16057, 22447, 210, 7762, 21726, 1814, 21771, 48449, 37662, 25046, 1691, 5103, 37671, 22118, 11925, 6411, 1175, 170, 37205, 16003, 45425, 30712, 1313, 11632, 49003, 26757, 11149, 21639, 10177, 34371, 6398, 49140, 19912, 7973, 36547, 4185, 16041, 21835, 10333, 9777, 33367, 35969, 42643, 18658, 21975, 1982, 20321, 37105, 24955, 36248, 47161, 33056, 22746, 25655, 24955, 21366, 17959, 15296, 37635, 47616, 23819, 7973, 18570, 17388, 30303, 40426, 23560, 27493, 16003, 22195, 14712, 40512, 48126, 15842, 33364, 49735, 48174, 33043, 5331, 39714, 47709, 46475, 19648, 30303, 23942, 23649, 4550, 15020, 46475, 6255, 30661, 21353, 38799, 18550, 38115, 10704, 38560, 25046, 29364, 34260, 29000, 14941, 19895, 25843, 19294, 15657, 34962, 20396, 43785, 2972, 17905, 36020, 43396, 35503, 46848, 32767, 27562, 38262, 6254, 19294, 34654, 28261, 46771, 49210, 27378, 34302]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb328221f10>\n",
            "Constructing exemplars of class 49\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [47041, 46595, 44525, 24630, 31992, 18189, 15215, 38938, 34963, 34228, 19486, 10680, 37168, 8515, 23742, 45848, 8025, 29893, 28827, 5576, 8997, 5662, 30821, 41037, 12345, 515, 18001, 11652, 31146, 43524, 45236, 9798, 2612, 29706, 13797, 43305, 33271, 33031, 1298, 28691, 30522, 10055, 16888, 31747, 15544, 37168, 43858, 34940, 17790, 33136, 20532, 14533, 42, 17896, 2181, 5444, 35550, 35400, 39644, 6403, 13859, 1147, 15089, 8997, 34951, 42531, 31992, 11122, 34963, 38581, 6094, 25621, 34982, 28384, 31080, 3127, 13797, 43305, 49922, 23342, 45722, 46041, 42642, 36778, 39004, 42740, 6554, 32592, 43738, 34303, 16363, 36563, 34111, 31350, 14611, 4869, 88, 36235, 4047, 2920, 12189, 1542, 18112, 28355, 21962, 17524, 11736, 24630, 45624, 22247, 41817, 22074, 12713, 35949, 49043, 31992, 35731, 22164, 35911, 2612, 20532, 15958, 39780, 15401, 24785, 15089, 5529, 10680, 6809, 33409, 27303, 3127, 38404, 9463, 5471, 41320, 45722, 21976, 22074, 45624, 2233, 41836, 31299, 5444, 35492, 42339, 18996, 26063, 16888, 32592, 5061, 41817, 45597, 2233, 46508, 40974, 11652, 15544, 41037, 15342, 17272, 11442, 40747, 22074, 6117, 30052, 40611, 25068, 33562, 38851, 3638, 23966, 16421, 49043, 19048, 15401, 47029, 27289, 42531, 18112, 43738, 28844, 10995, 30826, 25737, 43524, 19316, 29051, 9824, 14018, 11397, 37363, 19676, 37363, 40318, 4351, 43713, 8987, 39991, 42531]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326289e50>\n",
            "Constructing exemplars of class 56\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [5954, 42345, 1468, 6290, 49475, 22401, 36578, 18984, 27964, 34146, 16233, 9452, 27718, 41541, 43011, 34892, 6916, 30635, 11857, 34212, 16915, 49875, 42697, 43813, 14972, 4845, 23949, 22829, 26544, 37544, 10070, 9102, 471, 629, 776, 47761, 442, 48788, 25519, 27200, 37622, 1167, 19886, 23949, 16924, 23461, 20305, 8914, 31574, 27075, 47179, 35565, 16420, 4868, 44, 37544, 787, 10469, 39054, 33738, 7289, 13189, 47423, 27676, 18867, 28791, 1468, 16915, 6486, 42697, 47662, 269, 11023, 14906, 36374, 15536, 45911, 15432, 5233, 37426, 776, 4319, 17751, 37440, 18183, 8378, 22829, 39675, 18192, 41899, 629, 26517, 26410, 11756, 37809, 36898, 14167, 37089, 30966, 30145, 30262, 29375, 49475, 28131, 39543, 15511, 39945, 44068, 37090, 2255, 26349, 1822, 49626, 13908, 16068, 39314, 30635, 7125, 47106, 269, 42019, 27814, 30079, 15636, 23839, 11843, 1529, 47455, 24629, 13189, 6766, 47151, 28828, 10390, 38415, 11023, 38960, 24037, 644, 39940, 19144, 35792, 4656, 21642, 45311, 49549, 27588, 4657, 10982, 19246, 269, 40710, 34378, 15536, 4857, 37023, 41264, 26349, 9632, 26150, 34212, 38459, 8063, 40003, 40271, 12819, 39500, 31671, 33586, 37090, 26153, 9491, 39945, 35186, 776, 43650, 12603, 42758, 16420, 43813, 29454, 37809, 36898, 26544, 2196, 8663, 43311, 39054, 9452, 49633, 32266, 49476, 39350, 26825, 49549, 39221, 49638, 37426, 38889, 49837]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325d2c150>\n",
            "Constructing exemplars of class 20\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [34447, 31968, 26613, 44455, 39084, 15330, 325, 12903, 46108, 39022, 49604, 26058, 764, 48239, 12599, 4833, 42039, 25511, 15716, 37138, 30383, 2758, 33814, 4213, 1768, 29303, 34596, 46897, 10252, 10269, 18382, 6728, 2060, 3197, 49630, 45573, 24540, 47846, 32672, 5722, 49222, 22230, 28240, 31478, 16649, 39370, 49792, 15166, 25504, 30704, 49986, 4768, 20210, 31967, 40989, 6728, 9500, 48767, 31785, 34336, 40770, 41924, 6072, 34189, 5940, 2587, 41767, 35391, 764, 22251, 41732, 44408, 35705, 36039, 5080, 17936, 2747, 28391, 49604, 11001, 17299, 8767, 15716, 27649, 5722, 19444, 48227, 39622, 6072, 41449, 12198, 49733, 43013, 44839, 32921, 19539, 2627, 18349, 47846, 42561, 16774, 46212, 10985, 23045, 4989, 31967, 25890, 13794, 4768, 5560, 28851, 30069, 49604, 17299, 37149, 2587, 2653, 34596, 10716, 22520, 13382, 34797, 6937, 48234, 18115, 18167, 24829, 21572, 31197, 30136, 20089, 39151, 22230, 1210, 46015, 47391, 26768, 41499, 35384, 32955, 14710, 17285, 29303, 25507, 36986, 45704, 17082, 43710, 49081, 5002, 19763, 32522, 388, 26615, 44209, 18768, 6072, 47391, 44177, 31785, 17446, 40989, 6728, 26094, 30460, 15378, 42963, 3033, 40989, 23321, 7813, 37808, 24533, 40770, 636, 6279, 9289, 5560, 24864, 8685, 5284, 26405, 35508, 10563, 16724, 8279, 34663, 19132, 29303, 17483, 10269, 45518, 7606, 37138, 24533, 30425, 19222, 37149, 2587, 23530]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32595ab10>\n",
            "Constructing exemplars of class 4\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [44413, 35882, 10058, 48971, 19801, 2601, 10417, 17802, 42333, 31801, 27417, 47133, 35649, 28527, 7017, 10243, 24619, 1148, 23853, 36232, 20446, 11074, 26646, 48172, 17147, 10104, 32331, 3423, 49186, 33996, 1205, 993, 36472, 35641, 4851, 42042, 36232, 41796, 488, 12963, 33004, 20332, 33880, 36063, 46335, 47355, 17693, 19967, 7015, 28116, 45292, 38786, 25413, 23505, 23361, 35576, 43420, 3230, 36395, 36241, 19967, 1729, 40009, 37434, 3875, 35775, 14826, 47133, 916, 30683, 25099, 12078, 35006, 24809, 32117, 27678, 29225, 20039, 28529, 3822, 44237, 40296, 26580, 27514, 11038, 3865, 49186, 2711, 638, 5519, 42333, 28116, 20039, 39730, 4588, 17903, 37381, 37057, 40736, 45436, 42727, 46992, 46937, 7083, 7372, 4846, 1892, 26580, 995, 13253, 40386, 32866, 43260, 3310, 45934, 15766, 40048, 10518, 9380, 7031, 12122, 40806, 11038, 15117, 1148, 13693, 45664, 3779, 24358, 28116, 41995, 3423, 1308, 3107, 42869, 46589, 40296, 30288, 41403, 46743, 26809, 40753, 46335, 28584, 31043, 4899, 46155, 35641, 35576, 6854, 35006, 951, 12078, 36715, 38272, 24545, 38786, 20039, 6051, 21951, 7524, 16016, 9833, 13836, 48926, 32771, 9579, 22782, 48332, 46743, 49483, 15073, 34784, 19967, 47355, 32837, 24228, 49250, 49483, 49252, 41542, 43786, 17903, 11182, 19554, 2429, 18449, 42937, 32066, 39730, 44104, 34743, 27342, 29036, 145, 28139, 6925, 19597, 17802, 19597]\n",
            "BATCH SIZE:  128\n",
            "TRAIN:  4950\n",
            "TRAIN_SET CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "VALIDATION CLASSES:  [47, 34, 21, 16, 82, 81, 80, 79, 7, 68]\n",
            "GROUP:  2\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  20\n",
            "1\n",
            "Starting epoch 1/1, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.5417094230651855\n",
            "Train step - Step 10, Loss 0.23697905242443085\n",
            "Train step - Step 20, Loss 0.2361215204000473\n",
            "Train step - Step 30, Loss 0.2317582666873932\n",
            "Train step - Step 40, Loss 0.22931471467018127\n",
            "Train step - Step 50, Loss 0.21129079163074493\n",
            "Train epoch - Accuracy: 0.9031654676258993 Loss: 0.2589032570663974 Corrects: 6277\n",
            "Training finished in 13.2768235206604 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326289e50>\n",
            "Constructing exemplars of class 79\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [43794, 4517, 1317, 8336, 31950, 42215, 17492, 16868, 39611, 8033, 16341, 2104, 34943, 19875, 30418, 8007, 18433, 42516, 20820, 863, 33519, 7072, 23535, 21825, 35035, 20345, 4517, 38479, 42723, 42275, 18041, 38515, 44563, 44576, 31258, 28157, 48347, 29525, 35165, 35307, 18210, 16868, 6731, 23272, 16069, 36864, 504, 19584, 18041, 36864, 16868, 17351, 4237, 13021, 39774, 26456, 20012, 46033, 35598, 26811, 4307, 1317, 11692, 12973, 38711, 29058, 14661, 31258, 35060, 35307, 19584, 26236, 37186, 21378, 38273, 20202, 40258, 34970, 49095, 12336, 11123, 14904, 45394, 42215, 17492, 14468, 18433, 3269, 7072, 10996, 39774, 32127, 48218, 41118, 14628, 25172, 43687, 39830, 1317, 13846]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32621e210>\n",
            "Constructing exemplars of class 47\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [36872, 44341, 23245, 28027, 33001, 6429, 35751, 23810, 36013, 3797, 19157, 21601, 36181, 23629, 43224, 46217, 14110, 49392, 19927, 42591, 40884, 3659, 16329, 25313, 36657, 557, 37848, 2400, 16873, 10428, 41300, 2836, 18803, 8862, 6681, 11263, 12913, 3189, 33733, 1683, 23326, 8185, 5860, 32853, 28481, 45403, 24315, 28027, 26342, 6429, 30493, 34438, 42584, 43090, 8047, 20277, 1121, 1980, 36131, 42557, 24179, 43269, 32293, 44214, 49392, 28346, 10905, 14166, 20906, 47491, 38137, 31553, 49526, 23229, 47283, 40197, 22837, 49569, 15845, 43061, 43570, 48800, 21654, 47992, 10799, 35751, 3659, 5901, 30852, 40205, 7830, 8037, 25483, 1196, 6460, 10841, 42713, 12913, 44214, 43381]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326410d90>\n",
            "Constructing exemplars of class 7\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [42560, 26640, 27520, 43201, 35781, 7376, 1409, 15243, 7910, 178, 13986, 36487, 34285, 22007, 1981, 43273, 26593, 18896, 31134, 3476, 49220, 40476, 16463, 12293, 7420, 26064, 27749, 47136, 25690, 35626, 49808, 3476, 44080, 45889, 49567, 13476, 42870, 26967, 40357, 46073, 29590, 28351, 23752, 10072, 482, 26886, 15099, 9816, 31650, 4572, 46307, 40820, 19233, 25681, 6367, 19272, 43668, 44823, 40343, 34181, 32339, 28778, 27940, 25539, 17286, 15042, 48087, 11197, 6367, 19272, 13162, 14352, 26640, 47924, 43201, 37445, 25231, 3375, 41017, 35841, 26573, 18009, 27940, 25690, 42870, 44860, 18432, 43201, 5440, 43273, 45889, 4966, 3618, 48087, 32339, 46073, 7110, 5718, 29789, 7226]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325948b10>\n",
            "Constructing exemplars of class 82\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [42250, 44417, 17503, 27297, 32847, 164, 20824, 42519, 39262, 33090, 7334, 32368, 11600, 25817, 8573, 49838, 38738, 8078, 15113, 7671, 12866, 18626, 33298, 26440, 9111, 1296, 11600, 31210, 41181, 22835, 12252, 29650, 13318, 49368, 31169, 43453, 45852, 44697, 45076, 3833, 23681, 22681, 36327, 32299, 30639, 7334, 36194, 43765, 11600, 49832, 16838, 41895, 10283, 20824, 29650, 13204, 49906, 30049, 35774, 36688, 13546, 10909, 11544, 42656, 17455, 40367, 31169, 6057, 39514, 41547, 324, 33382, 19839, 44928, 31555, 25724, 31249, 43442, 8257, 466, 44697, 42833, 4419, 23071, 20824, 8553, 9541, 37781, 36690, 44213, 49832, 27709, 32277, 16791, 43765, 37781, 164, 25139, 23071, 5454]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32595cc50>\n",
            "Constructing exemplars of class 34\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [14198, 13481, 36335, 8396, 10238, 32312, 49987, 12228, 15291, 48783, 46124, 9845, 31833, 19311, 8643, 32916, 49973, 17105, 16735, 42463, 19826, 43022, 23636, 31511, 43683, 18275, 39042, 48745, 20904, 23884, 46887, 29853, 2648, 31323, 4312, 31750, 34859, 20590, 18632, 38200, 49605, 3499, 5932, 43839, 33256, 41992, 36177, 49724, 46555, 31750, 5124, 27234, 27241, 4875, 15359, 4577, 11706, 42463, 25221, 11706, 1394, 29129, 42158, 26022, 49724, 14619, 38906, 7399, 28339, 34214, 17550, 24559, 12636, 3515, 18632, 5124, 34757, 21337, 8406, 5552, 27234, 15087, 20767, 15310, 36973, 4875, 28339, 39626, 16662, 40428, 16944, 49721, 33411, 5601, 30393, 10911, 20861, 31783, 26314, 1938]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb328245c10>\n",
            "Constructing exemplars of class 81\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [37465, 12523, 41277, 32625, 45143, 9916, 1241, 2156, 48461, 11566, 49742, 13603, 25894, 14621, 37917, 20783, 39604, 30920, 39498, 29807, 22504, 19400, 2596, 39408, 37260, 49102, 39569, 5709, 29483, 14600, 44761, 41707, 8622, 28000, 9780, 43827, 12480, 12661, 24640, 25894, 12751, 45143, 5633, 48948, 26025, 3009, 48461, 20185, 14338, 47237, 6997, 34398, 20081, 16318, 36, 31655, 31611, 29408, 20578, 38982, 12751, 20392, 44891, 2132, 8622, 23331, 18330, 39790, 46119, 14621, 24801, 14006, 783, 10897, 43537, 27776, 654, 48815, 37969, 31655, 45157, 9281, 21463, 48461, 43892, 8276, 14660, 37849, 26928, 27776, 6209, 39790, 25283, 22260, 40930, 9535, 33428, 11885, 37741, 7428]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32645c510>\n",
            "Constructing exemplars of class 21\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [11981, 19339, 3983, 38444, 14262, 25730, 15874, 42053, 8922, 43392, 25309, 4372, 7092, 9087, 25124, 5943, 27007, 43714, 31866, 25784, 34947, 33967, 12272, 11319, 21611, 24099, 19569, 27211, 44059, 35819, 6432, 41589, 28967, 1361, 19147, 12272, 44754, 30927, 6133, 7358, 31866, 13788, 1794, 46315, 9544, 28841, 33785, 26707, 14282, 3082, 13358, 47958, 5849, 34870, 16783, 15196, 37883, 27211, 38611, 13191, 3277, 17564, 17263, 37079, 40977, 46772, 15256, 30372, 49014, 22629, 41054, 2695, 46760, 33785, 38141, 26876, 5286, 19576, 30927, 35819, 4372, 29589, 7702, 33982, 39655, 37883, 41054, 37079, 12355, 33052, 25397, 25205, 2555, 32240, 5943, 21562, 18399, 44955, 42274, 28909]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32621ea90>\n",
            "Constructing exemplars of class 80\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [40755, 48318, 15026, 20105, 5829, 37393, 35871, 25878, 39365, 43009, 11991, 43266, 38932, 4777, 1646, 192, 2437, 3641, 31171, 10725, 30641, 16315, 10149, 2603, 697, 33526, 16953, 28709, 41023, 32152, 9302, 30641, 38825, 1090, 15339, 40844, 40823, 8851, 33348, 16948, 38972, 16625, 3026, 10721, 24684, 38931, 25263, 32587, 15669, 25666, 41098, 12081, 48082, 19429, 35871, 3331, 40014, 43900, 28246, 37506, 3641, 41620, 29136, 648, 15026, 10984, 10721, 31171, 5422, 31533, 31244, 29365, 16681, 10816, 24111, 3331, 48082, 12081, 41023, 25999, 44454, 15387, 30135, 25105, 28767, 17990, 36436, 5735, 47220, 24057, 20442, 11461, 47546, 25666, 29136, 19750, 12119, 18078, 28246, 49506]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32621ecd0>\n",
            "Constructing exemplars of class 68\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [41441, 2670, 43333, 47885, 8173, 19380, 38643, 34339, 15322, 12647, 48177, 30341, 5121, 13854, 38288, 5680, 30169, 32918, 16762, 3660, 27599, 26591, 2572, 11225, 10673, 11153, 23877, 17868, 33398, 18662, 46401, 7073, 38288, 37234, 29117, 15322, 30695, 5680, 40926, 24727, 6458, 7521, 10028, 9742, 45993, 40435, 29233, 8864, 45020, 37548, 10867, 44639, 34339, 18662, 16742, 31919, 12777, 45020, 20501, 36808, 38213, 38643, 8660, 26939, 7836, 10921, 47074, 13461, 24365, 41493, 5680, 29487, 18662, 22188, 717, 33529, 11225, 39255, 1855, 10361, 30336, 27599, 32979, 33068, 46610, 33189, 48206, 43778, 39098, 12920, 2815, 18711, 9347, 21535, 4063, 34589, 45714, 1120, 28955, 28655]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32824cc10>\n",
            "Constructing exemplars of class 16\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [37111, 27097, 47939, 34812, 48455, 4502, 41281, 18608, 18607, 44130, 20797, 42335, 47531, 2676, 20459, 46083, 2616, 39942, 19388, 39592, 4046, 19097, 15273, 6965, 12044, 22084, 30175, 40653, 39606, 33479, 48588, 13689, 12709, 39942, 38789, 12966, 31069, 38148, 39851, 11699, 46929, 37757, 31581, 12834, 47233, 14924, 14509, 16091, 15221, 18013, 5004, 37388, 34895, 7930, 1252, 19052, 32613, 35299, 27967, 49055, 11284, 26400, 2676, 27220, 40773, 16091, 19141, 49863, 22549, 3698, 37586, 12909, 12966, 31049, 46293, 33118, 18945, 1781, 31620, 23067, 43401, 40313, 19388, 46580, 34886, 4687, 19724, 33489, 36032, 39331, 44758, 35111, 36421, 40254, 8157, 24132, 26789, 20240, 15360, 30114]\n",
            "BATCH SIZE:  128\n",
            "TRAIN:  4950\n",
            "TRAIN_SET CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "VALIDATION CLASSES:  [61, 32, 90, 24, 23, 76, 75, 10, 0, 64]\n",
            "GROUP:  3\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  30\n",
            "1\n",
            "Starting epoch 1/1, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.3794572949409485\n",
            "Train step - Step 10, Loss 0.21821501851081848\n",
            "Train step - Step 20, Loss 0.21837572753429413\n",
            "Train step - Step 30, Loss 0.21101343631744385\n",
            "Train step - Step 40, Loss 0.20947399735450745\n",
            "Train step - Step 50, Loss 0.20467664301395416\n",
            "Train epoch - Accuracy: 0.9440287769784173 Loss: 0.23036658257031611 Corrects: 6561\n",
            "Training finished in 13.362017631530762 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326073c10>\n",
            "Constructing exemplars of class 75\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [46953, 13120, 19896, 11650, 2571, 7099, 44265, 47329, 20065, 3256, 14165, 46006, 31135, 8312, 31322, 39495, 37880, 45610, 30086, 36506, 11650, 28588, 42397, 25965, 27322, 8160, 9472, 38066, 41578, 13330, 9869, 49054, 10592, 4358, 24553, 7028, 16692, 19342, 38225, 46259, 2968, 5978, 37574, 42822, 17148, 11650, 9604, 16990, 22309, 29712, 17901, 11163, 42320, 329, 9825, 27322, 3428, 7099, 37472, 25009, 44235, 39169, 39495, 7446, 31890, 1045]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326297f90>\n",
            "Constructing exemplars of class 23\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [26568, 46262, 30257, 28534, 27727, 29725, 652, 5561, 36855, 43328, 37442, 10539, 2245, 28100, 42614, 15823, 10627, 49382, 18055, 13667, 16151, 652, 4464, 31167, 13770, 39444, 43037, 12403, 43498, 28118, 3858, 39458, 9999, 15386, 27754, 2119, 2606, 44880, 19252, 49566, 41241, 29128, 901, 46682, 45446, 27970, 29533, 25542, 41211, 33803, 26666, 11703, 47424, 19848, 9485, 11755, 17892, 43351, 3288, 41839, 28118, 28186, 39191, 36855, 41940, 4464]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325cf2250>\n",
            "Constructing exemplars of class 90\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [11108, 4214, 21114, 20429, 10842, 46249, 33154, 19408, 40282, 13480, 13834, 34463, 41784, 7726, 22638, 10082, 43282, 6796, 7504, 43218, 46770, 27319, 41835, 3974, 11861, 10082, 10871, 36372, 30091, 7934, 49313, 2314, 17921, 47333, 41397, 30027, 23291, 231, 49099, 6999, 1685, 40811, 44748, 40657, 44146, 10879, 452, 13892, 15590, 1108, 41601, 27064, 3736, 42781, 27016, 27516, 46977, 25760, 1074, 24384, 42620, 6452, 4025, 40282, 30198, 42381]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325d12650>\n",
            "Constructing exemplars of class 10\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [18361, 37726, 25111, 15286, 39263, 46313, 39503, 37647, 46530, 8707, 32907, 41296, 42496, 22611, 32162, 40788, 40354, 45740, 2127, 22107, 13554, 28091, 3682, 40585, 33315, 39263, 30637, 40662, 36896, 14231, 6427, 37726, 28748, 19042, 385, 23651, 7429, 42371, 5745, 46800, 40830, 30791, 328, 22934, 14149, 21720, 37277, 33399, 48927, 30101, 10742, 16740, 40203, 9044, 29819, 43599, 39342, 30791, 44165, 17207, 37486, 47644, 4064, 12402, 34647, 43754]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260de4d0>\n",
            "Constructing exemplars of class 61\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [10623, 15259, 26660, 45110, 41422, 27414, 35511, 30626, 13591, 31525, 49846, 21225, 33262, 32360, 3950, 45168, 28245, 2682, 14463, 5120, 39065, 11980, 7187, 44182, 6621, 37052, 2833, 22836, 28304, 24789, 36394, 29957, 17053, 6869, 13844, 41183, 6166, 14079, 8280, 45527, 44555, 9804, 44022, 37874, 3914, 33262, 1742, 39065, 45110, 27389, 12562, 10675, 33984, 19934, 39044, 21542, 32035, 19893, 22019, 21261, 31406, 27503, 43284, 20884, 5120, 23306]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325d22290>\n",
            "Constructing exemplars of class 76\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [24324, 40150, 15619, 45374, 26669, 44414, 28095, 608, 44691, 22488, 42003, 827, 44168, 27862, 17878, 30768, 14286, 8923, 3123, 9628, 27662, 32418, 19641, 14284, 34394, 6145, 5939, 28994, 7190, 13467, 12192, 7681, 46689, 20529, 7053, 7834, 40915, 9263, 19135, 35857, 24215, 4129, 49728, 27673, 1022, 17523, 1475, 44414, 27033, 25164, 37394, 22233, 10456, 3233, 36555, 44692, 41342, 20632, 22767, 25394, 44692, 15619, 37631, 49369, 46241, 36490]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326410210>\n",
            "Constructing exemplars of class 64\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [42744, 16404, 11190, 9922, 31500, 5917, 18417, 43427, 38320, 38549, 48596, 39338, 15622, 39220, 29372, 30197, 33219, 26148, 41837, 11484, 46422, 10576, 42744, 41292, 46137, 27856, 44366, 22350, 4134, 16404, 38038, 3968, 30606, 27815, 2305, 32467, 11000, 127, 24844, 26582, 36455, 21107, 45275, 30841, 36035, 1058, 42922, 25533, 29974, 44366, 2837, 35131, 3220, 36035, 36726, 16308, 18214, 3968, 43028, 27246, 21006, 2837, 2180, 45677, 44078, 829]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326298190>\n",
            "Constructing exemplars of class 32\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [33857, 13719, 27088, 43613, 31407, 15446, 33534, 2535, 42392, 42603, 42746, 27892, 39533, 4209, 7249, 42237, 15446, 41353, 36127, 11831, 24927, 48742, 20356, 43169, 23088, 20799, 20519, 19286, 16546, 5509, 33763, 12725, 2365, 49253, 21743, 19249, 25369, 23738, 24938, 15916, 7904, 9537, 27892, 15282, 39242, 4048, 7346, 33187, 28687, 33705, 9456, 1968, 22624, 36186, 20124, 36236, 40807, 12505, 23585, 10724, 26328, 39831, 2230, 2994, 691, 49146]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325d22290>\n",
            "Constructing exemplars of class 24\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [7401, 15197, 42760, 19823, 9944, 42106, 20682, 33616, 4308, 3261, 12028, 41965, 3143, 24914, 36228, 28679, 36997, 7749, 42585, 15815, 1921, 16361, 46174, 42655, 43926, 14595, 12687, 45952, 23022, 19787, 17137, 17638, 38344, 23506, 1397, 16214, 27317, 27626, 38506, 13361, 413, 11463, 44782, 47356, 7315, 37173, 36888, 49410, 30234, 46359, 6828, 1921, 34767, 8950, 42031, 31888, 11015, 8867, 45952, 7175, 47532, 44782, 36752, 1921, 7558, 34001]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326203090>\n",
            "Constructing exemplars of class 0\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [17390, 36817, 39278, 35230, 42957, 27636, 49748, 20339, 10382, 8106, 24382, 37763, 9426, 30631, 3708, 31252, 5077, 38950, 14082, 30026, 21099, 14869, 45317, 22165, 44364, 43202, 1828, 30442, 587, 36693, 5129, 6416, 20738, 20155, 42162, 26819, 26418, 8045, 41819, 21823, 36535, 32826, 27440, 4055, 32124, 16520, 35204, 48395, 16352, 38420, 47676, 317, 45375, 43691, 2640, 19002, 42957, 13971, 14444, 12286, 19218, 19037, 39278, 26320, 38100, 6241]\n",
            "BATCH SIZE:  128\n",
            "TRAIN:  4950\n",
            "TRAIN_SET CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "VALIDATION CLASSES:  [63, 42, 36, 97, 95, 30, 83, 72, 6, 2]\n",
            "GROUP:  4\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  40\n",
            "1\n",
            "Starting epoch 1/1, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.3489232659339905\n",
            "Train step - Step 10, Loss 0.22502465546131134\n",
            "Train step - Step 20, Loss 0.2071315050125122\n",
            "Train step - Step 30, Loss 0.2082352638244629\n",
            "Train step - Step 40, Loss 0.1994708776473999\n",
            "Train step - Step 50, Loss 0.20731286704540253\n",
            "Train epoch - Accuracy: 0.9577200577200577 Loss: 0.22288345802483964 Corrects: 6637\n",
            "Training finished in 13.385721921920776 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260755d0>\n",
            "Constructing exemplars of class 95\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [49508, 49406, 1838, 44573, 48729, 41872, 16793, 10916, 1714, 1046, 934, 10195, 44573, 45887, 29648, 25996, 13643, 33731, 9422, 19756, 7551, 30394, 49681, 42176, 13798, 10223, 46503, 6109, 934, 11673, 8935, 31795, 16180, 34057, 28003, 31028, 45887, 41872, 16946, 28993, 25678, 10854, 31590, 8739, 6236, 34010, 4145, 14838, 5648, 36117]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32c612ed0>\n",
            "Constructing exemplars of class 83\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [48135, 30476, 27248, 21753, 43773, 38622, 20158, 49905, 44727, 32070, 12226, 36728, 4939, 47209, 41124, 22554, 21485, 43867, 43773, 6067, 43361, 11440, 12126, 13968, 29197, 19757, 14458, 32394, 32676, 26681, 3688, 23110, 31275, 46671, 21485, 34372, 2829, 38375, 42556, 44535, 47910, 95, 44998, 3265, 20858, 10096, 8952, 44151, 48115, 21159]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32607f750>\n",
            "Constructing exemplars of class 63\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [40190, 20932, 24622, 7592, 1049, 3027, 11064, 8717, 30809, 31986, 13390, 28441, 49011, 45912, 435, 40153, 23379, 4963, 12221, 1182, 44922, 27506, 11064, 42504, 6787, 36006, 9385, 11372, 1044, 31246, 24763, 13390, 41482, 10791, 42935, 19815, 22552, 45041, 31570, 33774, 6009, 34112, 11448, 48246, 47713, 41790, 19974, 2089, 10979, 21524]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260772d0>\n",
            "Constructing exemplars of class 42\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [16060, 11847, 2594, 44048, 28573, 42517, 16269, 22063, 33794, 20282, 14697, 36202, 42027, 49016, 46424, 42816, 6120, 10030, 18259, 37986, 23981, 21430, 16322, 250, 9858, 36362, 32542, 36362, 5311, 29066, 812, 2468, 19455, 33076, 37323, 42309, 987, 32818, 7171, 7162, 1515, 8426, 25562, 10580, 4258, 29014, 36932, 523, 36711, 31141]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325953f90>\n",
            "Constructing exemplars of class 30\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [26243, 1214, 41012, 42369, 31127, 13267, 32252, 34766, 22415, 34766, 25100, 702, 28309, 23793, 6922, 48612, 29360, 7413, 21636, 23642, 19509, 49204, 9760, 22379, 5095, 25100, 20071, 5355, 5127, 30360, 17504, 6936, 3794, 35489, 23490, 31757, 13529, 30490, 12343, 45273, 4352, 10671, 505, 10002, 10690, 1012, 10973, 47776, 17424, 41247]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260c2f90>\n",
            "Constructing exemplars of class 6\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [21577, 31877, 48919, 49329, 38848, 48981, 42630, 37106, 12432, 22537, 34256, 39806, 44477, 30004, 19068, 33077, 6237, 31817, 28255, 22877, 20916, 48589, 25174, 49592, 38670, 21716, 24620, 45078, 48351, 30670, 49592, 31156, 31351, 38304, 21456, 23387, 55, 11557, 33505, 47011, 13680, 21604, 34872, 48981, 23387, 2518, 45078, 19068, 18887, 17457]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260c2990>\n",
            "Constructing exemplars of class 2\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [17767, 18527, 1837, 20257, 13261, 30200, 35883, 10227, 23678, 18763, 13469, 44740, 11364, 41632, 46991, 19216, 12605, 7877, 45815, 27478, 260, 43003, 46974, 18297, 46974, 18026, 26310, 2352, 35886, 7474, 41309, 33304, 25014, 15620, 5661, 33218, 12852, 47621, 47937, 30289, 19072, 12363, 28215, 15134, 20257, 1195, 2192, 13524, 39783, 36119]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260cfd90>\n",
            "Constructing exemplars of class 97\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [44012, 49994, 12927, 37047, 15655, 46225, 22094, 2976, 44677, 16498, 9712, 32991, 8551, 14861, 37409, 21924, 26290, 26451, 39897, 28467, 23369, 3463, 14465, 26479, 19607, 38377, 31281, 48042, 20373, 17068, 12069, 29039, 17320, 28463, 19113, 22452, 28977, 39501, 23281, 43400, 46009, 37541, 26239, 39014, 34705, 22812, 30807, 24013, 37032, 20592]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb325cf28d0>\n",
            "Constructing exemplars of class 72\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [32275, 32773, 30720, 32962, 20955, 23455, 43912, 34281, 21350, 7962, 19314, 25901, 34576, 1424, 5114, 7661, 28972, 46721, 26512, 11807, 30837, 32773, 32650, 28554, 34839, 45337, 28976, 3938, 2782, 17805, 17983, 33127, 40234, 28591, 15309, 17951, 38034, 28514, 2849, 10715, 3606, 10594, 46511, 29361, 38462, 15652, 7985, 14519, 171, 40143]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb32645ca10>\n",
            "Constructing exemplars of class 36\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [38349, 29335, 214, 5170, 15458, 32742, 33097, 19413, 35932, 36087, 21761, 3210, 3610, 16292, 48029, 7859, 21606, 1024, 38605, 34124, 48424, 9143, 37822, 13833, 37555, 36034, 44878, 47195, 49859, 32742, 32086, 25209, 17102, 13013, 841, 31632, 2059, 3985, 15763, 13083, 37125, 25209, 29981, 14164, 44878, 27352, 15368, 30256, 2756, 38917]\n",
            "BATCH SIZE:  128\n",
            "TRAIN:  4950\n",
            "TRAIN_SET CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "VALIDATION CLASSES:  [55, 54, 98, 96, 31, 94, 93, 85, 19, 9]\n",
            "GROUP:  5\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  50\n",
            "1\n",
            "Starting epoch 1/1, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.3376277983188629\n",
            "Train step - Step 10, Loss 0.229234978556633\n",
            "Train step - Step 20, Loss 0.21059942245483398\n",
            "Train step - Step 30, Loss 0.21688327193260193\n",
            "Train step - Step 40, Loss 0.20810475945472717\n",
            "Train step - Step 50, Loss 0.20898741483688354\n",
            "Train epoch - Accuracy: 0.9784172661870504 Loss: 0.22357994300427197 Corrects: 6800\n",
            "Training finished in 13.44616174697876 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260759d0>\n",
            "Constructing exemplars of class 55\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [40885, 12581, 20251, 25445, 44942, 7394, 19592, 42365, 12723, 38453, 10495, 46861, 27793, 25464, 32997, 2457, 39377, 30945, 43894, 19887, 32399, 46421, 33756, 5808, 48119, 45166, 26332, 2743, 10438, 15484, 19032, 31734, 30719, 1715, 21819, 45183, 37165, 49235, 21019, 2239]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb326297f90>\n",
            "Constructing exemplars of class 31\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [36831, 15529, 5691, 41840, 2266, 17696, 32514, 36189, 11726, 44232, 48626, 11801, 15337, 32206, 8073, 49727, 17028, 31762, 39326, 26118, 14450, 48014, 15461, 15794, 2257, 28433, 48499, 33135, 33430, 29081, 46812, 41495, 27652, 26286, 306, 27076, 14211, 33313, 3830, 23628]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3264234d0>\n",
            "Constructing exemplars of class 19\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [48620, 46468, 45169, 22482, 16162, 46467, 35184, 42182, 26011, 33181, 30947, 15495, 22482, 21314, 29780, 31229, 13983, 38037, 19932, 44640, 9405, 27589, 29230, 40121, 26861, 19605, 683, 20121, 25588, 22153, 15918, 48937, 22034, 18686, 29433, 24350, 32427, 29592, 39961, 14616]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7fb3260b2fd0>\n",
            "Constructing exemplars of class 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51XqBQsXogw4"
      },
      "source": [
        "## Variation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEg6pKOSomU6"
      },
      "source": [
        "### Data Augmentation\n",
        "\n",
        "\n",
        "*   **brightness**: the intensity of the original image is altered by adding a random intensity value in the range [-63,63]\n",
        "*   **contrast normalization**: the contrast of the original image is altered by a random value in the range [0.2,1.8]\n",
        "*   **random cropping**: all the images (original, brightness and costrast) are randomly cropped\n",
        "*   **mirroring**: a mirror image is computed for all images (original, brightness, contrast and crops)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f5Osm7B45nd"
      },
      "source": [
        "HOW TO USE\n",
        "\n",
        "    for _, images, labels in train_dataloader: \n",
        "  \n",
        "        \"\"\"  \n",
        "        perform data augmentation \n",
        "        \"\"\" \n",
        "        # print(\"Dimension before data augmentation: \", images.shape) \n",
        "        # print(\"...performing data augmentation...\") \n",
        "        images, labels = data_augmentation_e2e(images,labels) \n",
        "  \n",
        "        # print(\"Dimension after data augmentation: \", images.shape) \n",
        "  \n",
        "  \n",
        "        images = torch.from_numpy(images) \n",
        "        labels = torch.from_numpy(labels) \n",
        "  \n",
        "  \n",
        "  \n",
        "        # Bring images and labels to GPU \n",
        "        images = images.to(DEVICE,dtype=torch.float32) \n",
        "        labels = labels.to(DEVICE,dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5j7CevMoisq"
      },
      "source": [
        "import tensorflow as tf\n",
        "def data_augmentation_e2e(img, lab):\n",
        "    \"\"\"\n",
        "        Realize the data augmentation in End-to-End paper\n",
        "        Parameters\n",
        "        ----------\n",
        "        img: the original images, size = (n, c, w, h)\n",
        "        lab: the original labels, size = (n)\n",
        "        Returns\n",
        "        ----------\n",
        "        img_aug: the original images, size = (n * 12, c, w, h)\n",
        "        lab_aug: the original labels, size = (n * 12)\n",
        "    \"\"\"\n",
        "    \n",
        "    shape = np.shape(img)\n",
        "    # print(\"IMG is: \",img)\n",
        "    # print(shape[0], 1, shape[1], shape[2], shape[3])\n",
        "    img_aug = np.zeros((shape[0], 6, shape[1], shape[2], shape[3]))\n",
        "    img_aug[:, 0, :, :, :] = img\n",
        "    lab_aug = np.zeros((shape[0], 6))\n",
        "    # print(\"IMG_AUG is: \", img_aug)\n",
        "\n",
        "    for i in range(shape[0]):\n",
        "        # np.random.seed(int(time.time()) % 1000)\n",
        "\n",
        "        # convert image from tensor to numpy\n",
        "        image=img.numpy()\n",
        "        im = image[i]\n",
        "      \n",
        "        # # brightness\n",
        "        brightness = (np.random.rand(1)-0.5)*2*63\n",
        "        im_temp = im + brightness\n",
        "\n",
        "        img_aug[i, 1] = im_temp\n",
        "\n",
        "\n",
        "        # constrast\n",
        "        constrast = (np.random.rand(1)-0.5)*2*0.8+1\n",
        "        m0 = np.mean(im[0])\n",
        "        m1 = np.mean(im[1])\n",
        "        m2 = np.mean(im[2])\n",
        "        im_temp = im\n",
        "        im_temp[0] = (im_temp[0]-m0)*constrast + m0\n",
        "        im_temp[1] = (im_temp[1]-m1)*constrast + m1\n",
        "        im_temp[2] = (im_temp[2]-m2)*constrast + m2\n",
        "        img_aug[i, 2] = im_temp\n",
        "\n",
        "        # crop\n",
        "        im_temp = img_aug[i, :3]\n",
        "        for j in range(3):\n",
        "            x_ = int(np.random.rand(1)*1000)%8\n",
        "            y_ = int(np.random.rand(1)*1000)%8\n",
        "            im_temp = np.zeros(shape=(shape[1], shape[2]+8, shape[3]+8))\n",
        "            im_temp[:, 4:-4, 4:-4] = img_aug[i, j]\n",
        "            img_aug[i, 3+j] = im_temp[:, x_:x_+shape[2], y_:y_+shape[3]]\n",
        "\n",
        "\n",
        "\n",
        "        # mirror\n",
        "        # for j in range(6):\n",
        "        #     im_temp = img_aug[i, j]\n",
        "        #     img_aug[i, 6 + j] = im_temp[:,-1::-1,:]\n",
        "\n",
        "        lab_aug[i, :] = lab[i]\n",
        "\n",
        "    # idx = np.where(img_aug>255)\n",
        "    # img_aug[idx] = 255\n",
        "    # idx = np.where(img_aug<0)\n",
        "    # img_aug[idx] = 0\n",
        "\n",
        "    img_aug = np.reshape(img_aug, newshape=(shape[0]*6, shape[1], shape[2], shape[3]))\n",
        "    img_aug = np.array(img_aug, dtype=np.float64)\n",
        "    lab_aug = np.reshape(lab_aug, newshape=(shape[0]*6))\n",
        "    lab_aug = np.array(lab_aug, dtype=np.float64)\n",
        "    return img_aug, lab_aug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nn5U7dCoygv"
      },
      "source": [
        "### prova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NK2S4Xaozyd"
      },
      "source": [
        "train_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, drop_last=False)\n",
        "n = 1\n",
        "i = 0\n",
        "for _, images, labels in train_loader:\n",
        "  if i == 0:\n",
        "    print(images.shape, labels.shape)\n",
        "    print(images, labels)\n",
        "    images_combined, labels_combined = data_augmentation_e2e(images,labels)\n",
        "    print(images_combined.shape, labels_combined.shape)\n",
        "    print(images_combined, labels_combined)\n",
        "    i = 2\n",
        "  else:\n",
        "    break\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeUV-v0GW7yA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9knD34-NXADG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229ba67d-0d2e-4db7-b645-c544568a41ff"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "input1 = torch.randn(100,64)\n",
        "print(input1.shape)\n",
        "input2 = torch.randn(1,64)\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "output = cos(input1, input2)\n",
        "print(output.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 64])\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}