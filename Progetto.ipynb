{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LWF funzionante.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfp19qRVa7l"
      },
      "source": [
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2iq0PaVWC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121ff75a-7e26-4843-b2de-9314711ad2a4"
      },
      "source": [
        "# Check GPU assigned\n",
        "!nvidia-smi"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 09:33:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    32W /  70W |   1560MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OWtqytyzmMF"
      },
      "source": [
        "## Network, dataset, functions and parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itMjhanGVTUp"
      },
      "source": [
        "### LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nHVORYbiZRx"
      },
      "source": [
        "### Resnet32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIdSy6PnibZA"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\"\"\"\n",
        "Credits to @hshustc\n",
        "Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "from torch.nn import init\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_relu=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.stride = stride\n",
        "        self.use_relu = use_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        if self.use_relu:\n",
        "            out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, nIn, nOut, stride):\n",
        "        super(Downsample, self).__init__()\n",
        "        assert stride == 2\n",
        "        self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        return torch.cat((x, x.mul(0)), 1)\n",
        "\n",
        "\n",
        "class CifarResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block=BasicBlock, depth=32, num_classes=0, channels=3):\n",
        "\n",
        "        super(CifarResNet, self).__init__()\n",
        "\n",
        "        # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be one of 20, 32, 44, 56, 110'\n",
        "        layer_blocks = (depth - 2) // 6\n",
        "        bn = nn.BatchNorm2d\n",
        "        self.inplanes = 16\n",
        "\n",
        "        self.conv_1_3x3 = nn.Conv2d(channels, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn_1 = bn(self.inplanes)\n",
        "\n",
        "        self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n",
        "        self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n",
        "        self.stage_3 = self._make_layer(block, 64, layer_blocks, 2, last=True)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.relu = nn.ReLU()\n",
        "        #self.linear = nn.Linear(64, num_classes)\n",
        "        self.fcs = nn.ModuleList([nn.Linear(64, num_classes)])\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, math.sqrt(1. / 64.))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, last=False):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = Downsample(self.\n",
        "inplanes, planes * block.expansion, stride)\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
        "\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        if last:\n",
        "            for i in range(1, blocks - 1):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "            layers.append(block(self.inplanes, planes, use_relu=False))\n",
        "\n",
        "        else:\n",
        "            for i in range(1, blocks):\n",
        "                layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_1_3x3(x)\n",
        "\n",
        "        x = self.bn_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.stage_1(x)\n",
        "        x = self.stage_2(x)\n",
        "        x = self.stage_3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = []\n",
        "        for fc in self.fcs:\n",
        "            out.append(fc(x))\n",
        "        out = torch.cat(out, dim=1)\n",
        "        return out\n",
        "\n",
        "    def addOutputNodes(self, num_classes):\n",
        "        self.fcs.append(nn.Linear(64, num_classes))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ga-SaCsjkYV"
      },
      "source": [
        "### Cifar100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHAyljuejmkd"
      },
      "source": [
        "# ref:\n",
        "# https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py\n",
        "# https://pytorch.org/docs/stable/_modules/torchvision/datasets/cifar.html#CIFAR10\n",
        "# homework2 (caltech)\n",
        "\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# This is an handler class for the Cifar dataset\n",
        "class CIFAR100(VisionDataset):\n",
        "    \"\"\"\n",
        "    `CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "    This is a subclass of the `CIFAR100` Dataset.\n",
        "    \"\"\"\n",
        "    base_folder = 'cifar-100-python'\n",
        "    train_file = 'train'\n",
        "    test_file = 'test'\n",
        "    meta_file = 'meta'\n",
        "\n",
        "    def __init__(self, root, split = 'train', transform = None):\n",
        "        \"\"\"\n",
        "          Args:\n",
        "              root (string): Root directory of the dataset where directory\n",
        "                  cifar-100-python exists.\n",
        "              split (string, optional): If 'train', creates dataset from training\n",
        "                  set, otherwise creates from test set.\n",
        "              transform (callable, optional): A function/transform that takes in a\n",
        "                  PIL image and returns a transformed version.\n",
        "        \"\"\"\n",
        "        super(CIFAR100, self).__init__(root, transform=transform)\n",
        "\n",
        "        self.split = split\n",
        "        if split == 'train':\n",
        "            filename = self.train_file\n",
        "        else:\n",
        "            filename = self.test_file\n",
        "\n",
        "        data_path = os.path.join(self.root, self.base_folder, filename)\n",
        "        data = None\n",
        "        labels = None\n",
        "\n",
        "        with open(data_path, 'rb') as f:\n",
        "            entry = pickle.load(f, encoding='latin1')\n",
        "            data = entry['data']\n",
        "            labels = entry['fine_labels']\n",
        "        \n",
        "        data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
        "        data = data.transpose((0, 2, 3, 1))  # Convert to HWC\n",
        "        \n",
        "        labels = np.array(labels)\n",
        "\n",
        "        self.df = pd.DataFrame()\n",
        "        self.df['data'] = pd.Series(list(data))\n",
        "        self.df['labels'] = labels\n",
        "\n",
        "        self.data = self.df['data']\n",
        "        self.labels = self.df['labels']\n",
        "\n",
        "        self._load_meta()\n",
        "\n",
        "    def _load_meta(self):\n",
        "        meta_path = os.path.join(self.root, self.base_folder, self.meta_file)\n",
        "        with open(meta_path, 'rb') as f:\n",
        "            meta = pickle.load(f, encoding='latin1')\n",
        "            self.label_names = meta['fine_label_names']\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.df.loc[index, 'data'], self.df.loc[index, 'labels']\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img) # Return a PIL image\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return index, img, target\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def getTargets(self):\n",
        "        return set(self.labels)\n",
        "     \n",
        "    # test\n",
        "    def get_indices(self, labels):\n",
        "        return list(self.df[self.df['labels'].isin(labels)].index)\n",
        "\n",
        "    def split_classes(self, n_splits=10, seed=None, dictionary_of='dataframes'):\n",
        "        if dictionary_of not in ['dataframes','indices']:\n",
        "            raise ValueError(\"'dictionary_of' must be equal to 'dataframes' or 'indices'\")\n",
        "\n",
        "        all_classes = list(self.df['labels'].value_counts().index)\n",
        "        dictionary = {}\n",
        "        random.seed(seed)\n",
        "        random.shuffle(all_classes)\n",
        "        split_size = int(len(all_classes)/n_splits)\n",
        "        for j in range(n_splits):\n",
        "            if ((j+1)*split_size < len(all_classes)):\n",
        "                split_end = (j+1)*split_size\n",
        "            else:\n",
        "                split_end = None\n",
        "            subgroup = all_classes[j*split_size:split_end]\n",
        "            if dictionary_of == 'dataframes':\n",
        "                dictionary[j] = self.df[self.df['labels'].isin(subgroup)]\n",
        "            elif dictionary_of == 'indices':\n",
        "                dictionary[j] = list(self.df[self.df['labels'].isin(subgroup)].index)\n",
        "        return dictionary\n",
        "\n",
        "    def split_groups_in_train_validation(self, groups, ratio=0.5, seed=None):\n",
        "        groups_train_val = dict()\n",
        "        for k, subdf in groups.items():\n",
        "            train_indexes = []\n",
        "            val_indexes = []\n",
        "            split_labels = list(subdf['labels'].value_counts().index)\n",
        "            for l in split_labels:\n",
        "                indexes_to_sample = list(subdf[subdf['labels'] == l].index)\n",
        "                random.seed(seed)\n",
        "                train_samples = random.sample(indexes_to_sample, int(len(indexes_to_sample)*ratio))\n",
        "                train_indexes = train_indexes + train_samples\n",
        "                val_indexes = val_indexes + list(set(indexes_to_sample).difference(set(train_samples)))\n",
        "            groups_train_val[k] = {\n",
        "                'train': train_indexes,\n",
        "                'val': val_indexes\n",
        "            }\n",
        "        return groups_train_val\n",
        "    \n",
        "    def split_in_train_val_groups(self, n_splits=10, ratio=0.5, seed=None):\n",
        "        groups = self.split_classes(n_splits=n_splits, seed=seed)\n",
        "        return self.split_groups_in_train_validation(groups, ratio=ratio, seed=seed)\n",
        "\n",
        "    # given a tensors returns an image (used in exemplars)\n",
        "    #def tensorToImg(self, tensor):\n",
        "    #   return Variable(transform(Image.fromarray(img)), volatile=True)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_M1anVYkRnF"
      },
      "source": [
        "### Reverse Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j66mUOXekTlM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "__all__ = ['ReverseIndex']\n",
        "\n",
        "class ReverseIndex():\n",
        "\n",
        "    def __init__(self, dataset, splits, device='cuda'):\n",
        "\n",
        "        self.df = pd.DataFrame(columns=['group', 'labels'])\n",
        "\n",
        "        for k in splits.keys():\n",
        "            labels = list(dataset.df.loc[splits[k]['train'],'labels'].value_counts().index)\n",
        "            group = [k for i in range(len(labels))]\n",
        "            data = pd.DataFrame(np.array([group, labels]).T, columns=['group', 'labels'])\n",
        "            self.df = self.df.append(data, ignore_index=True)\n",
        "\n",
        "        self.df['nodes'] = self.df.index\n",
        "        self.device = device\n",
        "    \n",
        "    def _changeIndex(self, reverse_index, column):\n",
        "        reverse_index = reverse_index.set_index(column)\n",
        "        reverse_index[column] = reverse_index.index\n",
        "        return reverse_index\n",
        "\n",
        "    def getLabels(self, outputs):\n",
        "        outs = outputs.cpu().numpy()\n",
        "        reverse_index = self._changeIndex(self.df, 'nodes')\n",
        "        labels = reverse_index.loc[outs, 'labels']\n",
        "\n",
        "        labels = torch.tensor(list(labels))\n",
        "        return labels.to(self.device)\n",
        "\n",
        "    def getNodes(self, labels):\n",
        "        labels = labels.cpu().numpy()\n",
        "       \n",
        "        reverse_index = self._changeIndex(self.df, 'labels')\n",
        "\n",
        "        nodes = reverse_index.loc[labels, 'nodes']\n",
        "\n",
        "        nodes = torch.tensor(list(nodes))\n",
        "        return nodes.to(self.device)\n",
        "\n",
        "    def getGroups(self, distinct=True):\n",
        "        return self.df['group'].value_counts().index.sort_values()\n",
        "    \n",
        "    def getLabelsOfGroup(self, group):\n",
        "        return self.df.loc[self.df['group'] == group, 'labels']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVfOeOCuknB8"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4QpAHzFkoW0"
      },
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import Module\n",
        "\n",
        "# These are the default iCaRL hyper-parameters\n",
        "def getHyperparams():\n",
        "\tdictHyperparams = {\n",
        "\t\t\"LR\": 2,\n",
        "\t\t\"MOMENTUM\": 0.9,\n",
        "\t\t\"WEIGHT_DECAY\": 1e-5,\n",
        "\t\t\"NUM_EPOCHS\": 70,\n",
        "\t\t\"MILESTONES\": [49, 63],\n",
        "\t\t\"BATCH_SIZE\": 128,\n",
        "\t\t\"DEVICE\": 'cuda',\n",
        "\t\t\"GAMMA\": 0.2,\n",
        "\t\t\"SEED\": 66, #use 30, 42, 16\n",
        "\t\t\"LOG_FREQUENCY\": 10,\n",
        "\t\t\"NUM_CLASSES\": 100\n",
        "\t}\n",
        "\treturn dictHyperparams\n",
        "\n",
        "def getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize):\n",
        "\toptimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\tscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA, last_epoch=-1) \n",
        "\treturn optimizer, scheduler\n",
        "\n",
        "# the mean and the std have been found on the web as mean and std of cifar100\n",
        "# alternative (realistic): compute mean and std for the dataset\n",
        "def getTransformations():\n",
        "\t# Define transforms for training phase\n",
        "\ttrain_transform = transforms.Compose([transforms.RandomHorizontalFlip(), # Randomly flip the image with probability of 0.5\n",
        "\t                                      transforms.Pad(4), # Add padding\n",
        "\t                                      transforms.RandomCrop(32),# Crops a random squares of the image\n",
        "\t                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "\t                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
        "\t])\n",
        "\t# Define transforms for the evaluation phase\n",
        "\teval_transform = transforms.Compose([\n",
        "\t                                      transforms.ToTensor(),\n",
        "\t                                      transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
        "\t])\n",
        "\treturn train_transform, eval_transform\n",
        "\n",
        "# BCEWithLogits = Sigmoid + BCE, is the loss used in iCaRL\n",
        "def getLossCriterion():\n",
        "\tcriterion = nn.BCEWithLogitsLoss(reduction = 'mean') # for classification: Cross Entropy\n",
        "\treturn criterion\n",
        "\n",
        "def computeLoss(criterion, outputs, labels):\n",
        "\treturn criterion(outputs, labels)\n",
        "\n",
        "# support BCE\n",
        "def _one_hot_encode(labels, n_classes, reverse_index, dtype=None, device='cuda'):\n",
        "\tbatch_size = len(labels)\n",
        "\tenconded = torch.zeros(batch_size, n_classes, dtype=dtype, device=device)\n",
        "\tlabels=map_to_outputs(labels, reverse_index)\n",
        "\tfor i, l in enumerate(labels):\n",
        "\t  enconded[i, l] = 1\n",
        "\treturn enconded\n",
        "\n",
        "def map_to_outputs(labels, reverse_index):\n",
        "\tif reverse_index is None:\n",
        "\t  return labels\n",
        "\tif type(labels) == int:\n",
        "\t  return int(reverse_index.getNodes(torch.tensor([labels])))\n",
        "\telif type(labels) == torch.Tensor:\n",
        "\t\treturn reverse_index.getNodes(labels)\n",
        "\n",
        "\n",
        "def plotAccuracyTrend(method, data_plot_line, seed):\n",
        "\tplt.figure(figsize=(20,7))\n",
        "\taccuracyDF=pd.DataFrame(data_plot_line, columns = ['Classes','Accuracy'])\n",
        "\tax = sns.lineplot(x=\"Classes\", y=\"Accuracy\",data=accuracyDF, marker = 'o')\n",
        "\tax.minorticks_on()\n",
        "\tax.set_xticks(np.arange(10,110,10))\n",
        "\tax.set_xlim(xmin=9, xmax=101)\n",
        "\tax.set_ylim(ymin=0, ymax=1)\n",
        "\tplt.legend(['Accuracy {}'.format(method)])\n",
        "\tax.grid(axis='y')\n",
        "\tplt.title(\"Accuracies against seen classes {} - seed: {}\".format(method, seed))\n",
        "\t\n",
        "\tfilename = \"acc_{}_{}.jpg\".format(method, seed) # ex. acc_lwf_30\n",
        "\tplt.savefig(filename, format='png', dpi=300)\n",
        "\tplt.show()\n",
        "\n",
        "def plotConfusionMatrix(method, confusionMatrixData, seed):\n",
        "\tfig,ax=plt.subplots(figsize=(10,10))\n",
        "\tsns.heatmap(confusionMatrixData,cmap='terrain',ax=ax)\n",
        "\tplt.ylabel('True label')\n",
        "\tplt.xlabel('Predicted label')\n",
        "\tplt.title(\"Confusion Matrix {} - seed: {}\".format(method, seed))\n",
        "\n",
        "\tfilename = \"cm_{}_{}.jpg\".format(method, seed) # ex. cm_lwf_30\n",
        "\tplt.savefig(filename, format='png', dpi=300)\n",
        "\tplt.show()\n",
        "\n",
        "# Write down the metrics (accuracy trand and confusion matrix)\n",
        "# this method is a shortcut when perfoming multiple tests with different splits (random_seed)\n",
        "# and allow us to plot on the same graph the data from multiple models (accuracy)\n",
        "def writeMetrics(method, seed, accuracies, confusionMatrixData):\n",
        "  data = {}\n",
        "  data['accuracies'] = []\n",
        "  data['cm'] = [] #cm line\n",
        "  i = 0\n",
        "  for classes_seen in range(10, 110, 10): #x axis on the plot\n",
        "    data['accuracies'].append({classes_seen : accuracies[i]}) \n",
        "    i += 1\n",
        "\n",
        "  i = 0\n",
        "  for class_num in range(0,len(confusionMatrixData)): #rows of the cm\n",
        "    data['cm'].append({class_num : confusionMatrixData[i].tolist()}) \n",
        "    i += 1\n",
        "  \n",
        "  # dump to file\n",
        "  aus = method + '_' + str(seed)\n",
        "  filename = 'data_{}.json'.format(aus)\n",
        "  with open(filename, 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "\n",
        "# Functions\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = CifarResNet()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfJj1z2LSxp0"
      },
      "source": [
        "### DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3a29fb-aec8-416c-ecc4-13c4dd5f6661"
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 09:33:05--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  41.4MB/s    in 4.4s    \n",
            "\n",
            "2021-06-08 09:33:09 (36.8 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "mv: cannot move 'cifar-100-python' to 'DATA/cifar-100-python/cifar-100-python': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY10HfpTS1lq"
      },
      "source": [
        "### HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "NUM_CLASSES = 100\n",
        "BATCH_SIZE = 128 \n",
        "LR = 0.1         \n",
        "MOMENTUM = 0.9     \n",
        "WEIGHT_DECAY = 1e-05\n",
        "NUM_EPOCHS = 70\n",
        "GAMMA = 0.2\n",
        "LOG_FREQUENCY = 10\n",
        "MILESTONES = [49,63]\n",
        "RANDOM_SEED = 66"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW7WxV_QS4re"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk"
      },
      "source": [
        "train_transform, eval_transform = getTransformations()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPrwhTcIqUbA"
      },
      "source": [
        "### train & test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJKwvGljJj2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36eb24f6-1d30-4a26-d22e-b77815cb7fd6"
      },
      "source": [
        "# Import dataset and apply transformations \n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# Check datasets length \n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnooWwcyS_YN"
      },
      "source": [
        "### SPLIT DATA IN CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckn3H69iJj2X"
      },
      "source": [
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60885231-c821-4de3-85ef-b8308e29f626"
      },
      "source": [
        "# TRAIN / VAL split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "print(outputs_labels_mapping)\n",
        "\n",
        "# TEST split\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.ReverseIndex object at 0x7f672307e650>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn"
      },
      "source": [
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpWv5ZkhxTPJ"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NQa-wNxWL1"
      },
      "source": [
        "### train, validate, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pisadUTPxcRP"
      },
      "source": [
        "import copy\n",
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "  \n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            # # if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            # if (group_id > 1):\n",
        "            #   old_features = old_net.forward(images)\n",
        "            #   old_outputs = old_net.predict(old_features)\n",
        "            #   labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX_61nSuxh3v"
      },
      "source": [
        "### sequential learning fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM0GysHZxk1B"
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearningFineTuning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    old_net = None\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen, group_id, old_net)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    #confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2X2IVZ-xrVT"
      },
      "source": [
        "### execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DGpd8lslxtUW",
        "outputId": "2a7a5171-8688-4b1f-fe52-f88f4b532a6a"
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningFineTuning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7173749208450317\n",
            "Train step - Step 10, Loss 0.31387636065483093\n",
            "Train step - Step 20, Loss 0.2874338626861572\n",
            "Train step - Step 30, Loss 0.2654590606689453\n",
            "Train epoch - Accuracy: 0.318989898989899 Loss: 0.34560690457772725 Corrects: 1579\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.26789265871047974\n",
            "Train step - Step 50, Loss 0.258944034576416\n",
            "Train step - Step 60, Loss 0.2350231260061264\n",
            "Train step - Step 70, Loss 0.23865528404712677\n",
            "Train epoch - Accuracy: 0.44363636363636366 Loss: 0.24301170718790305 Corrects: 2196\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.23784291744232178\n",
            "Train step - Step 90, Loss 0.22167158126831055\n",
            "Train step - Step 100, Loss 0.22836807370185852\n",
            "Train step - Step 110, Loss 0.21694694459438324\n",
            "Train epoch - Accuracy: 0.48707070707070704 Loss: 0.22610946089330344 Corrects: 2411\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.21196965873241425\n",
            "Train step - Step 130, Loss 0.20575585961341858\n",
            "Train step - Step 140, Loss 0.22211872041225433\n",
            "Train step - Step 150, Loss 0.20619133114814758\n",
            "Train epoch - Accuracy: 0.5016161616161616 Loss: 0.21912972303954037 Corrects: 2483\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.2055768072605133\n",
            "Train step - Step 170, Loss 0.20553207397460938\n",
            "Train step - Step 180, Loss 0.22383907437324524\n",
            "Train step - Step 190, Loss 0.19269728660583496\n",
            "Train epoch - Accuracy: 0.5418181818181819 Loss: 0.20608459960932685 Corrects: 2682\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.19962547719478607\n",
            "Train step - Step 210, Loss 0.1956397444009781\n",
            "Train step - Step 220, Loss 0.23317204415798187\n",
            "Train step - Step 230, Loss 0.1870502084493637\n",
            "Train epoch - Accuracy: 0.5523232323232323 Loss: 0.19966931800047558 Corrects: 2734\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.19728612899780273\n",
            "Train step - Step 250, Loss 0.17967957258224487\n",
            "Train step - Step 260, Loss 0.1929226964712143\n",
            "Train step - Step 270, Loss 0.19188766181468964\n",
            "Train epoch - Accuracy: 0.5834343434343434 Loss: 0.19277908541939476 Corrects: 2888\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.1998911201953888\n",
            "Train step - Step 290, Loss 0.18329913914203644\n",
            "Train step - Step 300, Loss 0.16586630046367645\n",
            "Train step - Step 310, Loss 0.17675089836120605\n",
            "Train epoch - Accuracy: 0.598989898989899 Loss: 0.1864176897809963 Corrects: 2965\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.17738604545593262\n",
            "Train step - Step 330, Loss 0.18055176734924316\n",
            "Train step - Step 340, Loss 0.17641305923461914\n",
            "Train step - Step 350, Loss 0.14969894289970398\n",
            "Train epoch - Accuracy: 0.6155555555555555 Loss: 0.17903075204955207 Corrects: 3047\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.1671830266714096\n",
            "Train step - Step 370, Loss 0.1687958985567093\n",
            "Train step - Step 380, Loss 0.159011110663414\n",
            "Train epoch - Accuracy: 0.6309090909090909 Loss: 0.1738420210462628 Corrects: 3123\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.15419088304042816\n",
            "Train step - Step 400, Loss 0.14775967597961426\n",
            "Train step - Step 410, Loss 0.16979841887950897\n",
            "Train step - Step 420, Loss 0.1525963395833969\n",
            "Train epoch - Accuracy: 0.6539393939393939 Loss: 0.1639658623993999 Corrects: 3237\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.19196446239948273\n",
            "Train step - Step 440, Loss 0.1466265171766281\n",
            "Train step - Step 450, Loss 0.17056730389595032\n",
            "Train step - Step 460, Loss 0.18163080513477325\n",
            "Train epoch - Accuracy: 0.6608080808080808 Loss: 0.16202940798167026 Corrects: 3271\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.176211878657341\n",
            "Train step - Step 480, Loss 0.1588747799396515\n",
            "Train step - Step 490, Loss 0.1342204362154007\n",
            "Train step - Step 500, Loss 0.14058950543403625\n",
            "Train epoch - Accuracy: 0.6767676767676768 Loss: 0.15383696049752862 Corrects: 3350\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.1555892676115036\n",
            "Train step - Step 520, Loss 0.13571906089782715\n",
            "Train step - Step 530, Loss 0.1515876054763794\n",
            "Train step - Step 540, Loss 0.1359780877828598\n",
            "Train epoch - Accuracy: 0.702020202020202 Loss: 0.14594818502363532 Corrects: 3475\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.15486030280590057\n",
            "Train step - Step 560, Loss 0.13412602245807648\n",
            "Train step - Step 570, Loss 0.15869688987731934\n",
            "Train step - Step 580, Loss 0.13754160702228546\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.14330182038172326 Corrects: 3482\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 590, Loss 0.13797789812088013\n",
            "Train step - Step 600, Loss 0.14471013844013214\n",
            "Train step - Step 610, Loss 0.1659015417098999\n",
            "Train step - Step 620, Loss 0.13035106658935547\n",
            "Train epoch - Accuracy: 0.712929292929293 Loss: 0.1402043603164981 Corrects: 3529\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 630, Loss 0.10688119381666183\n",
            "Train step - Step 640, Loss 0.10551120340824127\n",
            "Train step - Step 650, Loss 0.11231940239667892\n",
            "Train step - Step 660, Loss 0.12159333378076553\n",
            "Train epoch - Accuracy: 0.7434343434343434 Loss: 0.1296956703397963 Corrects: 3680\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 670, Loss 0.13172531127929688\n",
            "Train step - Step 680, Loss 0.142404243350029\n",
            "Train step - Step 690, Loss 0.12234494835138321\n",
            "Train step - Step 700, Loss 0.14414963126182556\n",
            "Train epoch - Accuracy: 0.756969696969697 Loss: 0.12469814313180519 Corrects: 3747\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.1333446353673935\n",
            "Train step - Step 720, Loss 0.15927483141422272\n",
            "Train step - Step 730, Loss 0.11001887172460556\n",
            "Train step - Step 740, Loss 0.12100914865732193\n",
            "Train epoch - Accuracy: 0.7450505050505051 Loss: 0.12714890332836093 Corrects: 3688\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 750, Loss 0.11506552994251251\n",
            "Train step - Step 760, Loss 0.10524898767471313\n",
            "Train step - Step 770, Loss 0.0984029471874237\n",
            "Train epoch - Accuracy: 0.7668686868686869 Loss: 0.11733168877435453 Corrects: 3796\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 780, Loss 0.12441835552453995\n",
            "Train step - Step 790, Loss 0.11353017389774323\n",
            "Train step - Step 800, Loss 0.13449843227863312\n",
            "Train step - Step 810, Loss 0.12670955061912537\n",
            "Train epoch - Accuracy: 0.7739393939393939 Loss: 0.11266988289175611 Corrects: 3831\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 820, Loss 0.10420570522546768\n",
            "Train step - Step 830, Loss 0.10050588846206665\n",
            "Train step - Step 840, Loss 0.09052333980798721\n",
            "Train step - Step 850, Loss 0.07840898633003235\n",
            "Train epoch - Accuracy: 0.7808080808080808 Loss: 0.11037116950509523 Corrects: 3865\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 860, Loss 0.13141851127147675\n",
            "Train step - Step 870, Loss 0.11617157608270645\n",
            "Train step - Step 880, Loss 0.11001942306756973\n",
            "Train step - Step 890, Loss 0.08741968870162964\n",
            "Train epoch - Accuracy: 0.7844444444444445 Loss: 0.10794938291564132 Corrects: 3883\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 900, Loss 0.11431687325239182\n",
            "Train step - Step 910, Loss 0.0919078066945076\n",
            "Train step - Step 920, Loss 0.1131000742316246\n",
            "Train step - Step 930, Loss 0.12487182766199112\n",
            "Train epoch - Accuracy: 0.7935353535353535 Loss: 0.10410453104310566 Corrects: 3928\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.0851389467716217\n",
            "Train step - Step 950, Loss 0.10327544063329697\n",
            "Train step - Step 960, Loss 0.09313042461872101\n",
            "Train step - Step 970, Loss 0.12224413454532623\n",
            "Train epoch - Accuracy: 0.8014141414141415 Loss: 0.10208582940125706 Corrects: 3967\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.10216508060693741\n",
            "Train step - Step 990, Loss 0.10625173896551132\n",
            "Train step - Step 1000, Loss 0.12439626455307007\n",
            "Train step - Step 1010, Loss 0.09492490440607071\n",
            "Train epoch - Accuracy: 0.805050505050505 Loss: 0.10121105768764863 Corrects: 3985\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1020, Loss 0.1075296625494957\n",
            "Train step - Step 1030, Loss 0.08558668196201324\n",
            "Train step - Step 1040, Loss 0.10448060184717178\n",
            "Train step - Step 1050, Loss 0.0987623855471611\n",
            "Train epoch - Accuracy: 0.8115151515151515 Loss: 0.09598487866647316 Corrects: 4017\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1060, Loss 0.11706822365522385\n",
            "Train step - Step 1070, Loss 0.08957835286855698\n",
            "Train step - Step 1080, Loss 0.1004997119307518\n",
            "Train step - Step 1090, Loss 0.10269360989332199\n",
            "Train epoch - Accuracy: 0.8151515151515152 Loss: 0.093790872918837 Corrects: 4035\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10780717432498932\n",
            "Train step - Step 1110, Loss 0.0829559937119484\n",
            "Train step - Step 1120, Loss 0.06946247071027756\n",
            "Train step - Step 1130, Loss 0.08679612725973129\n",
            "Train epoch - Accuracy: 0.8232323232323232 Loss: 0.09224864899811118 Corrects: 4075\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.0877915769815445\n",
            "Train step - Step 1150, Loss 0.07081689685583115\n",
            "Train step - Step 1160, Loss 0.09684779495000839\n",
            "Train epoch - Accuracy: 0.8305050505050505 Loss: 0.08737428996298048 Corrects: 4111\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1170, Loss 0.08674424141645432\n",
            "Train step - Step 1180, Loss 0.08422601222991943\n",
            "Train step - Step 1190, Loss 0.09191498905420303\n",
            "Train step - Step 1200, Loss 0.09191594272851944\n",
            "Train epoch - Accuracy: 0.834949494949495 Loss: 0.08547621402174535 Corrects: 4133\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.07304417341947556\n",
            "Train step - Step 1220, Loss 0.09637052565813065\n",
            "Train step - Step 1230, Loss 0.08423800766468048\n",
            "Train step - Step 1240, Loss 0.09754743427038193\n",
            "Train epoch - Accuracy: 0.8418181818181818 Loss: 0.0811596822106477 Corrects: 4167\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.08752617239952087\n",
            "Train step - Step 1260, Loss 0.08612791448831558\n",
            "Train step - Step 1270, Loss 0.09345199167728424\n",
            "Train step - Step 1280, Loss 0.06988094002008438\n",
            "Train epoch - Accuracy: 0.8432323232323232 Loss: 0.08195995536717501 Corrects: 4174\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1290, Loss 0.063926100730896\n",
            "Train step - Step 1300, Loss 0.09519979357719421\n",
            "Train step - Step 1310, Loss 0.0794561430811882\n",
            "Train step - Step 1320, Loss 0.09330239146947861\n",
            "Train epoch - Accuracy: 0.8434343434343434 Loss: 0.08210123597973525 Corrects: 4175\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1330, Loss 0.06706669181585312\n",
            "Train step - Step 1340, Loss 0.07936250418424606\n",
            "Train step - Step 1350, Loss 0.08014490455389023\n",
            "Train step - Step 1360, Loss 0.08957503736019135\n",
            "Train epoch - Accuracy: 0.8488888888888889 Loss: 0.07934777613541093 Corrects: 4202\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1370, Loss 0.08020991086959839\n",
            "Train step - Step 1380, Loss 0.09724964946508408\n",
            "Train step - Step 1390, Loss 0.06381719559431076\n",
            "Train step - Step 1400, Loss 0.06528539955615997\n",
            "Train epoch - Accuracy: 0.8549494949494949 Loss: 0.07585879642855037 Corrects: 4232\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.07746966183185577\n",
            "Train step - Step 1420, Loss 0.08617367595434189\n",
            "Train step - Step 1430, Loss 0.06970410794019699\n",
            "Train step - Step 1440, Loss 0.08160582929849625\n",
            "Train epoch - Accuracy: 0.8527272727272728 Loss: 0.07876499318715298 Corrects: 4221\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 1450, Loss 0.06916437298059464\n",
            "Train step - Step 1460, Loss 0.06720501184463501\n",
            "Train step - Step 1470, Loss 0.06595558673143387\n",
            "Train step - Step 1480, Loss 0.0707656592130661\n",
            "Train epoch - Accuracy: 0.8654545454545455 Loss: 0.07132082007449082 Corrects: 4284\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.05659304931759834\n",
            "Train step - Step 1500, Loss 0.06974741071462631\n",
            "Train step - Step 1510, Loss 0.0784800574183464\n",
            "Train step - Step 1520, Loss 0.06901217252016068\n",
            "Train epoch - Accuracy: 0.8672727272727273 Loss: 0.07315080337753199 Corrects: 4293\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 1530, Loss 0.07148046046495438\n",
            "Train step - Step 1540, Loss 0.08015324175357819\n",
            "Train step - Step 1550, Loss 0.07519340515136719\n",
            "Train epoch - Accuracy: 0.8682828282828283 Loss: 0.06976768631826748 Corrects: 4298\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 1560, Loss 0.061872996389865875\n",
            "Train step - Step 1570, Loss 0.08952672779560089\n",
            "Train step - Step 1580, Loss 0.0770217701792717\n",
            "Train step - Step 1590, Loss 0.06781128793954849\n",
            "Train epoch - Accuracy: 0.8719191919191919 Loss: 0.06902587638659911 Corrects: 4316\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.0734851062297821\n",
            "Train step - Step 1610, Loss 0.055662430822849274\n",
            "Train step - Step 1620, Loss 0.08112241327762604\n",
            "Train step - Step 1630, Loss 0.07834818959236145\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.06590250587222551 Corrects: 4326\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 1640, Loss 0.05307411774992943\n",
            "Train step - Step 1650, Loss 0.04475534334778786\n",
            "Train step - Step 1660, Loss 0.06450628489255905\n",
            "Train step - Step 1670, Loss 0.06469791382551193\n",
            "Train epoch - Accuracy: 0.8838383838383839 Loss: 0.06405000432874217 Corrects: 4375\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.055307772010564804\n",
            "Train step - Step 1690, Loss 0.06018352508544922\n",
            "Train step - Step 1700, Loss 0.05738571286201477\n",
            "Train step - Step 1710, Loss 0.07564640045166016\n",
            "Train epoch - Accuracy: 0.883030303030303 Loss: 0.06291912011124871 Corrects: 4371\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 1720, Loss 0.0579797700047493\n",
            "Train step - Step 1730, Loss 0.05599530413746834\n",
            "Train step - Step 1740, Loss 0.07791357487440109\n",
            "Train step - Step 1750, Loss 0.07570113986730576\n",
            "Train epoch - Accuracy: 0.8860606060606061 Loss: 0.06122048602411241 Corrects: 4386\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.046970587223768234\n",
            "Train step - Step 1770, Loss 0.05448814854025841\n",
            "Train step - Step 1780, Loss 0.0570836178958416\n",
            "Train step - Step 1790, Loss 0.052846431732177734\n",
            "Train epoch - Accuracy: 0.8921212121212121 Loss: 0.05948092536342264 Corrects: 4416\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 1800, Loss 0.0464363619685173\n",
            "Train step - Step 1810, Loss 0.056273628026247025\n",
            "Train step - Step 1820, Loss 0.0658160001039505\n",
            "Train step - Step 1830, Loss 0.0690997764468193\n",
            "Train epoch - Accuracy: 0.8955555555555555 Loss: 0.05688923456151076 Corrects: 4433\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.059149112552404404\n",
            "Train step - Step 1850, Loss 0.05253974348306656\n",
            "Train step - Step 1860, Loss 0.07070215791463852\n",
            "Train step - Step 1870, Loss 0.05269395932555199\n",
            "Train epoch - Accuracy: 0.8927272727272727 Loss: 0.05812157820571553 Corrects: 4419\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 1880, Loss 0.04611649736762047\n",
            "Train step - Step 1890, Loss 0.06521129608154297\n",
            "Train step - Step 1900, Loss 0.0597667470574379\n",
            "Train step - Step 1910, Loss 0.07057886570692062\n",
            "Train epoch - Accuracy: 0.9002020202020202 Loss: 0.05608734115506663 Corrects: 4456\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 1920, Loss 0.042010191828012466\n",
            "Train step - Step 1930, Loss 0.043184537440538406\n",
            "Train step - Step 1940, Loss 0.0397011898458004\n",
            "Train epoch - Accuracy: 0.9242424242424242 Loss: 0.04325935698518849 Corrects: 4575\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1950, Loss 0.039822064340114594\n",
            "Train step - Step 1960, Loss 0.036546554416418076\n",
            "Train step - Step 1970, Loss 0.04635452851653099\n",
            "Train step - Step 1980, Loss 0.033635109663009644\n",
            "Train epoch - Accuracy: 0.9432323232323232 Loss: 0.037418713830035144 Corrects: 4669\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1990, Loss 0.03440694510936737\n",
            "Train step - Step 2000, Loss 0.04546314477920532\n",
            "Train step - Step 2010, Loss 0.03715860843658447\n",
            "Train step - Step 2020, Loss 0.050867773592472076\n",
            "Train epoch - Accuracy: 0.9412121212121212 Loss: 0.03600090804876703 Corrects: 4659\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2030, Loss 0.02928098477423191\n",
            "Train step - Step 2040, Loss 0.03901729732751846\n",
            "Train step - Step 2050, Loss 0.037106212228536606\n",
            "Train step - Step 2060, Loss 0.03669671341776848\n",
            "Train epoch - Accuracy: 0.9452525252525252 Loss: 0.03400145272564406 Corrects: 4679\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2070, Loss 0.0314776748418808\n",
            "Train step - Step 2080, Loss 0.031674575060606\n",
            "Train step - Step 2090, Loss 0.018039535731077194\n",
            "Train step - Step 2100, Loss 0.0348820686340332\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.033380321872354755 Corrects: 4687\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2110, Loss 0.02144073322415352\n",
            "Train step - Step 2120, Loss 0.029142146930098534\n",
            "Train step - Step 2130, Loss 0.03788841888308525\n",
            "Train step - Step 2140, Loss 0.032097745686769485\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.03260654991022264 Corrects: 4701\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2150, Loss 0.027982238680124283\n",
            "Train step - Step 2160, Loss 0.020777106285095215\n",
            "Train step - Step 2170, Loss 0.030742371454834938\n",
            "Train step - Step 2180, Loss 0.0357779823243618\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.03025592699345916 Corrects: 4724\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2190, Loss 0.031895961612463\n",
            "Train step - Step 2200, Loss 0.025660132989287376\n",
            "Train step - Step 2210, Loss 0.038197994232177734\n",
            "Train step - Step 2220, Loss 0.025359375402331352\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.03145596713730783 Corrects: 4715\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2230, Loss 0.03523494675755501\n",
            "Train step - Step 2240, Loss 0.02871292270720005\n",
            "Train step - Step 2250, Loss 0.028518855571746826\n",
            "Train step - Step 2260, Loss 0.028394445776939392\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.031200148419599342 Corrects: 4703\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2270, Loss 0.026044586673378944\n",
            "Train step - Step 2280, Loss 0.03078872337937355\n",
            "Train step - Step 2290, Loss 0.03193800523877144\n",
            "Train step - Step 2300, Loss 0.05611391365528107\n",
            "Train epoch - Accuracy: 0.9555555555555556 Loss: 0.030103796654277377 Corrects: 4730\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2310, Loss 0.02573627233505249\n",
            "Train step - Step 2320, Loss 0.026890838518738747\n",
            "Train step - Step 2330, Loss 0.03133704885840416\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.0305143504032884 Corrects: 4722\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2340, Loss 0.029058242216706276\n",
            "Train step - Step 2350, Loss 0.02426040545105934\n",
            "Train step - Step 2360, Loss 0.03160322457551956\n",
            "Train step - Step 2370, Loss 0.04511835798621178\n",
            "Train epoch - Accuracy: 0.9563636363636364 Loss: 0.029337084354324774 Corrects: 4734\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2380, Loss 0.031107379123568535\n",
            "Train step - Step 2390, Loss 0.029924381524324417\n",
            "Train step - Step 2400, Loss 0.024590641260147095\n",
            "Train step - Step 2410, Loss 0.020830800756812096\n",
            "Train epoch - Accuracy: 0.961010101010101 Loss: 0.02768125159346094 Corrects: 4757\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2420, Loss 0.02306819148361683\n",
            "Train step - Step 2430, Loss 0.05020679160952568\n",
            "Train step - Step 2440, Loss 0.032019324600696564\n",
            "Train step - Step 2450, Loss 0.035698115825653076\n",
            "Train epoch - Accuracy: 0.9587878787878787 Loss: 0.028257839812172784 Corrects: 4746\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 2460, Loss 0.03360297158360481\n",
            "Train step - Step 2470, Loss 0.02808537892997265\n",
            "Train step - Step 2480, Loss 0.01882505789399147\n",
            "Train step - Step 2490, Loss 0.01958288811147213\n",
            "Train epoch - Accuracy: 0.96 Loss: 0.026811572033347504 Corrects: 4752\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2500, Loss 0.024240998551249504\n",
            "Train step - Step 2510, Loss 0.015550089068710804\n",
            "Train step - Step 2520, Loss 0.01995779201388359\n",
            "Train step - Step 2530, Loss 0.02513287402689457\n",
            "Train epoch - Accuracy: 0.962020202020202 Loss: 0.025361865840174934 Corrects: 4762\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2540, Loss 0.021166345104575157\n",
            "Train step - Step 2550, Loss 0.018641367554664612\n",
            "Train step - Step 2560, Loss 0.021410910412669182\n",
            "Train step - Step 2570, Loss 0.03057834319770336\n",
            "Train epoch - Accuracy: 0.9646464646464646 Loss: 0.023534335130167127 Corrects: 4775\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2580, Loss 0.029833734035491943\n",
            "Train step - Step 2590, Loss 0.018363453447818756\n",
            "Train step - Step 2600, Loss 0.026480138301849365\n",
            "Train step - Step 2610, Loss 0.028178563341498375\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.024363452725187695 Corrects: 4782\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2620, Loss 0.0342327281832695\n",
            "Train step - Step 2630, Loss 0.02055048942565918\n",
            "Train step - Step 2640, Loss 0.020426509901881218\n",
            "Train step - Step 2650, Loss 0.021581510081887245\n",
            "Train epoch - Accuracy: 0.9648484848484848 Loss: 0.025252315486320343 Corrects: 4776\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2660, Loss 0.03008689358830452\n",
            "Train step - Step 2670, Loss 0.0230241846293211\n",
            "Train step - Step 2680, Loss 0.019735518842935562\n",
            "Train step - Step 2690, Loss 0.01372586376965046\n",
            "Train epoch - Accuracy: 0.9644444444444444 Loss: 0.024579011685769966 Corrects: 4774\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.02005911059677601\n",
            "Train step - Step 2710, Loss 0.023675382137298584\n",
            "Train step - Step 2720, Loss 0.02118927799165249\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.024567253339772274 Corrects: 4769\n",
            "Training finished in 203.4930591583252 seconds\n",
            "EVALUATION:  0.78 0.12797264754772186\n",
            "TEST GROUP:  0.836\n",
            "TEST ALL:  0.836\n",
            "GROUP:  2\n",
            "Starting epoch 1/70, LR = [0.1]\n",
            "Train step - Step 0, Loss 0.5198947787284851\n",
            "Train step - Step 10, Loss 0.18119554221630096\n",
            "Train step - Step 20, Loss 0.1347174048423767\n",
            "Train step - Step 30, Loss 0.10982789844274521\n",
            "Train epoch - Accuracy: 0.36808080808080806 Loss: 0.17154767145111102 Corrects: 1822\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.09604242444038391\n",
            "Train step - Step 50, Loss 0.09236812591552734\n",
            "Train step - Step 60, Loss 0.08287163078784943\n",
            "Train step - Step 70, Loss 0.08627394586801529\n",
            "Train epoch - Accuracy: 0.6482828282828282 Loss: 0.08684955637563359 Corrects: 3209\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.08100271224975586\n",
            "Train step - Step 90, Loss 0.07603686302900314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-754cea9f07ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequentialLearningFineTuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-31e6b3e7dcf7>\u001b[0m in \u001b[0;36msequentialLearningFineTuning\u001b[0;34m(train_subsets, val_subsets, test_subsets)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSchedulerOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset learning rate and step_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Validate on current group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-20cff53f0192>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Bring images and labels to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aakVopSdyeGr"
      },
      "source": [
        "### plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0VbtGQygRH"
      },
      "source": [
        "method = \"finetuning\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-J8aC_xx-c"
      },
      "source": [
        "## LWF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZBNivOix1FB"
      },
      "source": [
        "### train, validate, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdfIllqBx59v"
      },
      "source": [
        "import copy\n",
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            # if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            if (group_id > 1):\n",
        "              old_features = old_net.forward(images)\n",
        "              old_outputs = old_net.predict(old_features)\n",
        "              labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        features = net.forward(images)\n",
        "        outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkzFiDVDyAm_"
      },
      "source": [
        "### sequential learning LWF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf7REFkIyEiQ"
      },
      "source": [
        "### LWF\n",
        "def sequentialLearningLWF(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen, group_id, old_net)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZTwTS_4TcES"
      },
      "source": [
        "### execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb"
      },
      "source": [
        "# train\n",
        "# net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningLWF(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2qUxVyMTfB4"
      },
      "source": [
        "### plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz"
      },
      "source": [
        "method = \"Learning Without Forgetting\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI"
      },
      "source": [
        "\"\"\"num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjGRIqDtNQP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nX10znUi6qd"
      },
      "source": [
        "## iCaRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKBdrJ8Csy2a"
      },
      "source": [
        "### classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAPTOU9bszTY"
      },
      "source": [
        "def classify(batch_img, net, exemplar_sets):\n",
        "  \"\"\" classify images by nearest mean-of-exemplars \"\"\" \n",
        "  \"\"\" \n",
        "  class1: list_of_indices for images that represent class1\n",
        "  class2: list_of_indices for images that represent class2\n",
        "  ...\n",
        "  class100: list_of_indices for images that represent class 100\n",
        "  with Subset I retrieve the images from the train_dataset\n",
        "  iterate over it to calculate mean for each class\n",
        "  \"\"\"\n",
        "  net.eval()\n",
        "  classes_mean = []\n",
        "  for k, exemplars_indices in exemplar_sets.items():\n",
        "    features = []\n",
        "    class_images_set = Subset(train_dataset, exemplars_indices)\n",
        "    class_images = DataLoader(class_images_set, batch_size=BATCH_SIZE, num_workers=2)\n",
        "    for _, images, labels in class_images:\n",
        "      # for each class (paper from y=1...t) calculate features and then mean\n",
        "      feature = net.forward(images)\n",
        "      features.append(feature)\n",
        "    features_s = torch.cat(features)\n",
        "    class_mean = features_s.mean(0)\n",
        "    classes_mean.append(class_mean)\n",
        "    means_exemplars = torch.cat(classes_mean, dim=0)\n",
        "    means_exemplars = torch.stack([means_exemplars] * BATCH_SIZE)\n",
        "    means_exemplars = means_exemplars.transpose(1,2)\n",
        "  feature_images_to_classify = net.forward(batch_img)\n",
        "  # sono da normalizzare?\n",
        "  feature_images_to_classify = feature_images_to_classify.unsqueeze(2)\n",
        "  feature_images_to_classify = feature_images_to_classify.expand_as(means_exemplars) # expand_as to get the same dimension\n",
        "  preds = torch.argmin((feature_images_to_classify - means_exemplars).pow(2).sum(1), dim=1)\n",
        "  return preds"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5HRagcujHgM"
      },
      "source": [
        "### construct exemplar set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blwBqG6BjNsM"
      },
      "source": [
        "import sys\n",
        "\n",
        "def constructExemplarSet(net, Xclass, m):\n",
        "#Xclass contiene immagini e label della classe X\n",
        "  exemplars_set = []\n",
        "  feature_exemplars = []\n",
        "  indexes = []\n",
        "  features = [] \n",
        "  class_images = []\n",
        "  net.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    XtrainLoader = torch.utils.data.DataLoader(Xclass, shuffle = True, batch_size=1, num_workers=2)\n",
        "    for _, image, labels in XtrainLoader:\n",
        "      image = image.to(DEVICE)\n",
        "      class_images.append(image)\n",
        "      # per ogni immagine della classe x, prendiamo le rispettive feature e le uniamo nel vettore features, che contiene tutte quelle delle immagini della classe x\n",
        "      feature = net.forward(image)\n",
        "      #feature = net.predict(featuretmp)\n",
        "      feature = feature/np.linalg.norm(feature.cpu())\n",
        "      features.append(feature)\n",
        "\n",
        "    features = torch.cat(features, dim=0) #cat solve the problem of inequal size of tensors \n",
        "    current_class_mean = features.mean(0) # mu = media delle features delle immagini della classe\n",
        "\n",
        "    for k in range(1, m+1):\n",
        "      min = 100000\n",
        "      sum = 0\n",
        "      for j in range(k-1):\n",
        "        sum += feature_exemplars[j]\n",
        "      for x in range(len(Xclass)): \n",
        "        if (x not in indexes):\n",
        "          phiX = features[x]\n",
        "          val = current_class_mean - ((phiX + sum)/k)\n",
        "          val = np.linalg.norm(val.cpu().numpy()) ## NORMA \n",
        "          if (val < min):\n",
        "            min = val\n",
        "            feature_min = phiX\n",
        "            index_min = x\n",
        "      feature_exemplars.append(feature_min)\n",
        "      exemplars_set.append(Xclass[index_min][0])\n",
        "\n",
        "    print(\"lunghezza exemplar set: \", len(exemplars_set))\n",
        "    return exemplars_set"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy_HVL-tjZcb"
      },
      "source": [
        "### reduce exemplar set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7kuQ5DnjcCP"
      },
      "source": [
        "# DA CHIAMARE PER OGNI CLASSE k: riduce il numero di exemplars all'interno dell'exemplar_set della classe k \n",
        "# EXEMPLAR SET è una lista di indici che rappresentano la posizione dell'immagine selezionata per l'exemplar della classe corrente nel dataset di partenza\n",
        "def reduceExemplarSet(m, exemplars_set):\n",
        "  exemplars_new = []\n",
        "  for i in range(m):\n",
        "    if (exemplars_set != []):\n",
        "      exemplars_new.append(exemplars_set[i])\n",
        "\n",
        "  return exemplars_new"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMMlEpLsjfaj"
      },
      "source": [
        "### update representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRdA9RtDjhak"
      },
      "source": [
        "def updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes, group_id, K, exemplars_set_tot, old_net):\n",
        "  #exemplars_set_tot contiene tutti gli exemplars set ottenuti fino ad ora\n",
        "  #train_iter contiene tutti i dati (immagini + labels) delle classi nuove (s, .., t)\n",
        "  exemplars_subset = []\n",
        "  exemplars_indices = []\n",
        "  total_exemplars = []\n",
        "  labels_tot = []\n",
        "\n",
        "  for k, exemplar_set_class_k in exemplars_set_tot.items():\n",
        "    # exemplar_set_class_k is the list of indices of images that belongs to the exemplar set selected for class k \n",
        "    if (exemplar_set_class_k != []):\n",
        "      exemplars_subset = Subset(train_dataset, exemplar_set_class_k)\n",
        "      total_exemplars = torch.utils.data.ConcatDataset([total_exemplars, exemplars_subset])\n",
        "\n",
        "  if group_id > 1:\n",
        "    train_subset_total = torch.utils.data.ConcatDataset([train_subset, total_exemplars])\n",
        "  else:\n",
        "    train_subset_total = train_subset\n",
        "    \n",
        "  print(\"Len TOTAL train susbset: \", len(train_subset_total))\n",
        "  train_loader = torch.utils.data.DataLoader(train_subset_total, shuffle = True, batch_size=BATCH_SIZE, num_workers=2)\n",
        "  # train_loader è la concatenazione delle nuove classi con gli exemplar_sets calcolati fino a questo punto \n",
        "  print(\"training\")\n",
        "  train(net, train_loader, criterion, optimizer, scheduler, num_classes, group_id, old_net)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac65-6QGjm9O"
      },
      "source": [
        "### incremental train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPU_32ArjpPH"
      },
      "source": [
        "import copy\n",
        "def incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_until_now):\n",
        "  print(\"Starting the update representation\")\n",
        "  exemplar_indices = None\n",
        "  num_classes = 10\n",
        "  new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "  print(\"NEW CLASSES: \", new_classes_examined)\n",
        "\n",
        "  updateRepresentation(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net)\n",
        "                \n",
        "  iteration = group_id - 1\n",
        "  t = (num_classes * iteration) + num_classes # num_classes ricevute fino a questo momento \n",
        "  m = int(K/t) #casto ad intero ? per difetto o eccesso?\n",
        "  #s = num_classes * iteration\n",
        "\n",
        "  # REDUCING EXEMPLAR SET FOR EXISTING CLASSES\n",
        "  print(\"reducing exemplars for each class\")\n",
        "  print(total_classes_until_now)\n",
        "  for y in total_classes_until_now: #ci serve un set con tutte le classi fino ad ora viste\n",
        "    exemplar_y_new = reduceExemplarSet(m, exemplars_set_tot[y]) # valore associato alla chiave y che rappresenta il label della classe \n",
        "    print(\"REDUCED EXEMPLAR: \", len(exemplar_y_new))\n",
        "    exemplars_set_tot[y] = exemplar_y_new\n",
        "\n",
        "  \n",
        "  # CONSTRUCTION EXEMPLAR SET FOR NEW CLASSES\n",
        "  for y in new_classes_examined: # nuovi classi in arrivo di cui vogliamo costruire il set rappresentativo\n",
        "    images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data']\n",
        "    imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "    class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "    print(\"class train: \", class_train_subset)\n",
        "    print(\"Constructing exemplars of class\", y)\n",
        "    exemplars_set = constructExemplarSet(net, class_train_subset, m) # exemplar set è un set di indici\n",
        "    #devo recuperare dal dataset iniziale l'indice delle immagini dell'exemplar set creato \n",
        "    #for image in exemplars_set:\n",
        "     # exemplars_set = train_dataset.df.index[train_dataset.df['data'] == image].tolist()\n",
        "    exemplars_set_tot[y] = exemplars_set\n",
        "    print(\"exemplar set: \", exemplars_set)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDxmsQlWjp5D"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dQznGoEju9J"
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes_till_now, group_id, old_net, num_epochs=NUM_EPOCHS):    \n",
        "    num_classes_till_previous_step = group_id * 10 - 10\n",
        "    print(\"num classes till now: \", num_classes_till_now)\n",
        "    # network to GPU\n",
        "    net = net.to(DEVICE) \n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "\n",
        "            # Bring images and labels to GPU\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            # Labels encoding \n",
        "            labels_enc = _one_hot_encode(labels, num_classes_till_now, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            features = net.forward(images)\n",
        "            outputs = net.predict(features)\n",
        "\n",
        "            #if iteration > 0, loss is the combination between the classification loss on new classes and the distillation loss on old classes\n",
        "            if (group_id > 1):\n",
        "              old_features = old_net.forward(images)\n",
        "              old_outputs = old_net.predict(old_features)\n",
        "              labels_enc[:,0:num_classes_till_previous_step] = torch.sigmoid(old_outputs)\n",
        "\n",
        "            loss = computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHpi410ljzWD"
      },
      "source": [
        "### test and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQYB0-cLj0sP"
      },
      "source": [
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    getLossCriterion()\n",
        "\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "\n",
        "        # Bring images and labels to GPU\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "       \n",
        "        # Labels encoding \n",
        "        labels_enc = _one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        #features = net.forward(images)\n",
        "        #outputs = net.predict(features)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        #if criterion is not None:\n",
        "         #   loss = computeLoss(criterion, outputs, labels_enc)\n",
        "          #  running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = classify(images, )\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    #Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTv6zBetj3Cb"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_cnELYdkap4"
      },
      "source": [
        "def sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "    K = 2000\n",
        "    iterations = 10\n",
        "    num_classes = 10\n",
        "    exemplars_set_tot = {new_list: [] for new_list in range(100)}\n",
        "    labels_train = []\n",
        "    total_classes_seen = []\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "\n",
        "      print(\"TRAIN: \", len(train_subset))\n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        old_net = copy.deepcopy(net)\n",
        "        old_net.to(DEVICE)\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      print(\"TEST SET LENGHT: \", len(test_set))\n",
        "      print(\"TEST CURRENT GROUP SET LENGHT: \", len(test_subset))\n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      test_classes = list(test_dataset.df.loc[test_set.indices, 'labels'].value_counts().index)\n",
        "      train_classes = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "      validation_classes = list(train_dataset.df.loc[val_subset.indices, 'labels'].value_counts().index)\n",
        "      for i in train_classes:\n",
        "        total_classes_seen.append(i)\n",
        "      print(\"TEST_SET CLASSES: \", test_classes)\n",
        "      print(\"TRAIN_SET CLASSES: \", train_classes)\n",
        "      print(\"VALIDATION CLASSES: \", validation_classes)\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "\n",
        "      incrementalTrain(net, train_subset, criterion, optimizer, scheduler, num_classes_seen, group_id, K, exemplars_set_tot, old_net, total_classes_seen) # Train the network with 10 classes at a time\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTV1Gxq6yF5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4c5aa7-6544-4aa2-eda6-1330fcfc3f20"
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearningiCaRL(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  1000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [67, 65, 59, 56, 49, 39, 22, 20, 18, 4]\n",
            "TRAIN_SET CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "VALIDATION CLASSES:  [59, 56, 49, 39, 22, 20, 18, 4, 67, 65]\n",
            "GROUP:  1\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "Len TOTAL train susbset:  4950\n",
            "training\n",
            "num classes till now:  10\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7142981886863708\n",
            "Train step - Step 10, Loss 0.31953832507133484\n",
            "Train step - Step 20, Loss 0.2948654294013977\n",
            "Train step - Step 30, Loss 0.26296573877334595\n",
            "Train epoch - Accuracy: 0.2737373737373737 Loss: 0.3504807402630045 Corrects: 1355\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.2608111798763275\n",
            "Train step - Step 50, Loss 0.26669788360595703\n",
            "Train step - Step 60, Loss 0.27732422947883606\n",
            "Train step - Step 70, Loss 0.24007593095302582\n",
            "Train epoch - Accuracy: 0.4175757575757576 Loss: 0.25167836442740277 Corrects: 2067\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.24393489956855774\n",
            "Train step - Step 90, Loss 0.2226618379354477\n",
            "Train step - Step 100, Loss 0.2382979393005371\n",
            "Train step - Step 110, Loss 0.2209840565919876\n",
            "Train epoch - Accuracy: 0.4713131313131313 Loss: 0.2306337677469157 Corrects: 2333\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.2240050584077835\n",
            "Train step - Step 130, Loss 0.22028625011444092\n",
            "Train step - Step 140, Loss 0.224601611495018\n",
            "Train step - Step 150, Loss 0.22539018094539642\n",
            "Train epoch - Accuracy: 0.5036363636363637 Loss: 0.22071308197999243 Corrects: 2493\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.2099609225988388\n",
            "Train step - Step 170, Loss 0.20564711093902588\n",
            "Train step - Step 180, Loss 0.18527816236019135\n",
            "Train step - Step 190, Loss 0.2166523039340973\n",
            "Train epoch - Accuracy: 0.5404040404040404 Loss: 0.20914029076243892 Corrects: 2675\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.18623016774654388\n",
            "Train step - Step 210, Loss 0.17793606221675873\n",
            "Train step - Step 220, Loss 0.2047453671693802\n",
            "Train step - Step 230, Loss 0.19628676772117615\n",
            "Train epoch - Accuracy: 0.5602020202020203 Loss: 0.20131403349264704 Corrects: 2773\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.2019999772310257\n",
            "Train step - Step 250, Loss 0.18941724300384521\n",
            "Train step - Step 260, Loss 0.18728883564472198\n",
            "Train step - Step 270, Loss 0.19446147978305817\n",
            "Train epoch - Accuracy: 0.5727272727272728 Loss: 0.19290381955980052 Corrects: 2835\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.1641668826341629\n",
            "Train step - Step 290, Loss 0.17897231876850128\n",
            "Train step - Step 300, Loss 0.186049222946167\n",
            "Train step - Step 310, Loss 0.1762353926897049\n",
            "Train epoch - Accuracy: 0.5961616161616161 Loss: 0.18596365136931642 Corrects: 2951\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.17429156601428986\n",
            "Train step - Step 330, Loss 0.19222870469093323\n",
            "Train step - Step 340, Loss 0.16956691443920135\n",
            "Train step - Step 350, Loss 0.1836668998003006\n",
            "Train epoch - Accuracy: 0.6018181818181818 Loss: 0.18291535897086364 Corrects: 2979\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.19730736315250397\n",
            "Train step - Step 370, Loss 0.15704496204853058\n",
            "Train step - Step 380, Loss 0.1739930361509323\n",
            "Train epoch - Accuracy: 0.617979797979798 Loss: 0.17571306138327628 Corrects: 3059\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.17416667938232422\n",
            "Train step - Step 400, Loss 0.17818644642829895\n",
            "Train step - Step 410, Loss 0.1637457013130188\n",
            "Train step - Step 420, Loss 0.15695157647132874\n",
            "Train epoch - Accuracy: 0.6486868686868686 Loss: 0.16717306639208937 Corrects: 3211\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.1857634335756302\n",
            "Train step - Step 440, Loss 0.14677587151527405\n",
            "Train step - Step 450, Loss 0.15717272460460663\n",
            "Train step - Step 460, Loss 0.16053393483161926\n",
            "Train epoch - Accuracy: 0.657979797979798 Loss: 0.16235040786290408 Corrects: 3257\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.16962586343288422\n",
            "Train step - Step 480, Loss 0.1341588944196701\n",
            "Train step - Step 490, Loss 0.13822288811206818\n",
            "Train step - Step 500, Loss 0.13651375472545624\n",
            "Train epoch - Accuracy: 0.6775757575757576 Loss: 0.15319704646413976 Corrects: 3354\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.13137903809547424\n",
            "Train step - Step 520, Loss 0.14567093551158905\n",
            "Train step - Step 530, Loss 0.1481725126504898\n",
            "Train step - Step 540, Loss 0.15124188363552094\n",
            "Train epoch - Accuracy: 0.7090909090909091 Loss: 0.14748164579723821 Corrects: 3510\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.13214440643787384\n",
            "Train step - Step 560, Loss 0.1520310640335083\n",
            "Train step - Step 570, Loss 0.14354537427425385\n",
            "Train step - Step 580, Loss 0.1277085840702057\n",
            "Train epoch - Accuracy: 0.702020202020202 Loss: 0.14348890140803172 Corrects: 3475\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 590, Loss 0.14833597838878632\n",
            "Train step - Step 600, Loss 0.13714127242565155\n",
            "Train step - Step 610, Loss 0.13602964580059052\n",
            "Train step - Step 620, Loss 0.15040583908557892\n",
            "Train epoch - Accuracy: 0.724040404040404 Loss: 0.1391956524174623 Corrects: 3584\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 630, Loss 0.11559491604566574\n",
            "Train step - Step 640, Loss 0.12414492666721344\n",
            "Train step - Step 650, Loss 0.143685981631279\n",
            "Train step - Step 660, Loss 0.15561257302761078\n",
            "Train epoch - Accuracy: 0.7268686868686869 Loss: 0.1342410941497244 Corrects: 3598\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 670, Loss 0.13206514716148376\n",
            "Train step - Step 680, Loss 0.1077275276184082\n",
            "Train step - Step 690, Loss 0.13146553933620453\n",
            "Train step - Step 700, Loss 0.12071537971496582\n",
            "Train epoch - Accuracy: 0.7393939393939394 Loss: 0.12767183866765763 Corrects: 3660\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.11481297016143799\n",
            "Train step - Step 720, Loss 0.13845831155776978\n",
            "Train step - Step 730, Loss 0.13953207433223724\n",
            "Train step - Step 740, Loss 0.13204176723957062\n",
            "Train epoch - Accuracy: 0.7456565656565657 Loss: 0.12519765048918097 Corrects: 3691\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 750, Loss 0.1189693734049797\n",
            "Train step - Step 760, Loss 0.12551073729991913\n",
            "Train step - Step 770, Loss 0.11239498108625412\n",
            "Train epoch - Accuracy: 0.7640404040404041 Loss: 0.12103354843878987 Corrects: 3782\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 780, Loss 0.12064075469970703\n",
            "Train step - Step 790, Loss 0.10181528329849243\n",
            "Train step - Step 800, Loss 0.12107100337743759\n",
            "Train step - Step 810, Loss 0.11150243133306503\n",
            "Train epoch - Accuracy: 0.7775757575757576 Loss: 0.11593149099687133 Corrects: 3849\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 820, Loss 0.1131710633635521\n",
            "Train step - Step 830, Loss 0.1350727081298828\n",
            "Train step - Step 840, Loss 0.09780275076627731\n",
            "Train step - Step 850, Loss 0.09126550704240799\n",
            "Train epoch - Accuracy: 0.7711111111111111 Loss: 0.11450429115632568 Corrects: 3817\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 860, Loss 0.12204638868570328\n",
            "Train step - Step 870, Loss 0.09956871718168259\n",
            "Train step - Step 880, Loss 0.1170239970088005\n",
            "Train step - Step 890, Loss 0.1172175407409668\n",
            "Train epoch - Accuracy: 0.7747474747474747 Loss: 0.11213072525431411 Corrects: 3835\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 900, Loss 0.12256436794996262\n",
            "Train step - Step 910, Loss 0.1093367338180542\n",
            "Train step - Step 920, Loss 0.11127763241529465\n",
            "Train step - Step 930, Loss 0.1111595630645752\n",
            "Train epoch - Accuracy: 0.7874747474747474 Loss: 0.10688280686284557 Corrects: 3898\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.10424071550369263\n",
            "Train step - Step 950, Loss 0.08496402949094772\n",
            "Train step - Step 960, Loss 0.1393619030714035\n",
            "Train step - Step 970, Loss 0.09706928580999374\n",
            "Train epoch - Accuracy: 0.7927272727272727 Loss: 0.10350099721942285 Corrects: 3924\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.0882105827331543\n",
            "Train step - Step 990, Loss 0.09044227749109268\n",
            "Train step - Step 1000, Loss 0.11302664130926132\n",
            "Train step - Step 1010, Loss 0.10894284397363663\n",
            "Train epoch - Accuracy: 0.8092929292929293 Loss: 0.10122579740153419 Corrects: 4006\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1020, Loss 0.09669698774814606\n",
            "Train step - Step 1030, Loss 0.1122705489397049\n",
            "Train step - Step 1040, Loss 0.09006695449352264\n",
            "Train step - Step 1050, Loss 0.1196027547121048\n",
            "Train epoch - Accuracy: 0.8135353535353536 Loss: 0.09767952231746731 Corrects: 4027\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1060, Loss 0.0917796716094017\n",
            "Train step - Step 1070, Loss 0.12501025199890137\n",
            "Train step - Step 1080, Loss 0.07775226980447769\n",
            "Train step - Step 1090, Loss 0.09317629784345627\n",
            "Train epoch - Accuracy: 0.8242424242424242 Loss: 0.09290492799546983 Corrects: 4080\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.08597459644079208\n",
            "Train step - Step 1110, Loss 0.08479618281126022\n",
            "Train step - Step 1120, Loss 0.08501679450273514\n",
            "Train step - Step 1130, Loss 0.08972848951816559\n",
            "Train epoch - Accuracy: 0.8218181818181818 Loss: 0.09143187380198277 Corrects: 4068\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.08455716818571091\n",
            "Train step - Step 1150, Loss 0.10891564935445786\n",
            "Train step - Step 1160, Loss 0.062174320220947266\n",
            "Train epoch - Accuracy: 0.8157575757575758 Loss: 0.09557259802866463 Corrects: 4038\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1170, Loss 0.09800087660551071\n",
            "Train step - Step 1180, Loss 0.08237981051206589\n",
            "Train step - Step 1190, Loss 0.08996433019638062\n",
            "Train step - Step 1200, Loss 0.09667046368122101\n",
            "Train epoch - Accuracy: 0.8284848484848485 Loss: 0.08933716342605726 Corrects: 4101\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.09460969269275665\n",
            "Train step - Step 1220, Loss 0.08313318341970444\n",
            "Train step - Step 1230, Loss 0.08948428928852081\n",
            "Train step - Step 1240, Loss 0.07561980932950974\n",
            "Train epoch - Accuracy: 0.835959595959596 Loss: 0.08510196384456423 Corrects: 4138\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.07982213795185089\n",
            "Train step - Step 1260, Loss 0.08700376749038696\n",
            "Train step - Step 1270, Loss 0.08719893544912338\n",
            "Train step - Step 1280, Loss 0.07465513050556183\n",
            "Train epoch - Accuracy: 0.8466666666666667 Loss: 0.08037082874413692 Corrects: 4191\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1290, Loss 0.08318748325109482\n",
            "Train step - Step 1300, Loss 0.08893243223428726\n",
            "Train step - Step 1310, Loss 0.08875247091054916\n",
            "Train step - Step 1320, Loss 0.0706259235739708\n",
            "Train epoch - Accuracy: 0.8402020202020202 Loss: 0.08475759999017522 Corrects: 4159\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1330, Loss 0.08326909691095352\n",
            "Train step - Step 1340, Loss 0.11331937462091446\n",
            "Train step - Step 1350, Loss 0.09438225626945496\n",
            "Train step - Step 1360, Loss 0.07677818834781647\n",
            "Train epoch - Accuracy: 0.8460606060606061 Loss: 0.08135982395121545 Corrects: 4188\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1370, Loss 0.07054115831851959\n",
            "Train step - Step 1380, Loss 0.0810464546084404\n",
            "Train step - Step 1390, Loss 0.05486828088760376\n",
            "Train step - Step 1400, Loss 0.10138358175754547\n",
            "Train epoch - Accuracy: 0.8478787878787879 Loss: 0.07796519019989052 Corrects: 4197\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.09654366225004196\n",
            "Train step - Step 1420, Loss 0.07668643444776535\n",
            "Train step - Step 1430, Loss 0.061875440180301666\n",
            "Train step - Step 1440, Loss 0.07632805407047272\n",
            "Train epoch - Accuracy: 0.8537373737373737 Loss: 0.07652936380017887 Corrects: 4226\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 1450, Loss 0.10377459973096848\n",
            "Train step - Step 1460, Loss 0.07422473281621933\n",
            "Train step - Step 1470, Loss 0.08929788321256638\n",
            "Train step - Step 1480, Loss 0.08230884373188019\n",
            "Train epoch - Accuracy: 0.8561616161616161 Loss: 0.07443096831290409 Corrects: 4238\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.075603187084198\n",
            "Train step - Step 1500, Loss 0.07411854714155197\n",
            "Train step - Step 1510, Loss 0.0782000944018364\n",
            "Train step - Step 1520, Loss 0.08375955373048782\n",
            "Train epoch - Accuracy: 0.8674747474747475 Loss: 0.07044718379625166 Corrects: 4294\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 1530, Loss 0.07515352964401245\n",
            "Train step - Step 1540, Loss 0.07778837531805038\n",
            "Train step - Step 1550, Loss 0.055123865604400635\n",
            "Train epoch - Accuracy: 0.8604040404040404 Loss: 0.0745756068765515 Corrects: 4259\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 1560, Loss 0.06563730537891388\n",
            "Train step - Step 1570, Loss 0.06453675031661987\n",
            "Train step - Step 1580, Loss 0.05958933383226395\n",
            "Train step - Step 1590, Loss 0.08461932092905045\n",
            "Train epoch - Accuracy: 0.8713131313131313 Loss: 0.06765472172787695 Corrects: 4313\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.060770995914936066\n",
            "Train step - Step 1610, Loss 0.06066869571805\n",
            "Train step - Step 1620, Loss 0.07133632153272629\n",
            "Train step - Step 1630, Loss 0.08196890354156494\n",
            "Train epoch - Accuracy: 0.8783838383838384 Loss: 0.06741846062619276 Corrects: 4348\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 1640, Loss 0.05050243064761162\n",
            "Train step - Step 1650, Loss 0.06642284244298935\n",
            "Train step - Step 1660, Loss 0.05352221801877022\n",
            "Train step - Step 1670, Loss 0.05324338749051094\n",
            "Train epoch - Accuracy: 0.882020202020202 Loss: 0.0649447727534506 Corrects: 4366\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.057130634784698486\n",
            "Train step - Step 1690, Loss 0.07484056800603867\n",
            "Train step - Step 1700, Loss 0.06050152704119682\n",
            "Train step - Step 1710, Loss 0.07444947212934494\n",
            "Train epoch - Accuracy: 0.8812121212121212 Loss: 0.06378526650444426 Corrects: 4362\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 1720, Loss 0.055838461965322495\n",
            "Train step - Step 1730, Loss 0.06162933260202408\n",
            "Train step - Step 1740, Loss 0.06462614983320236\n",
            "Train step - Step 1750, Loss 0.05974100902676582\n",
            "Train epoch - Accuracy: 0.8858585858585859 Loss: 0.062022218421252086 Corrects: 4385\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.0596819631755352\n",
            "Train step - Step 1770, Loss 0.061052680015563965\n",
            "Train step - Step 1780, Loss 0.07143459469079971\n",
            "Train step - Step 1790, Loss 0.06124916300177574\n",
            "Train epoch - Accuracy: 0.8935353535353535 Loss: 0.0588405172451578 Corrects: 4423\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 1800, Loss 0.04882241040468216\n",
            "Train step - Step 1810, Loss 0.055668868124485016\n",
            "Train step - Step 1820, Loss 0.059455957263708115\n",
            "Train step - Step 1830, Loss 0.05828921124339104\n",
            "Train epoch - Accuracy: 0.8860606060606061 Loss: 0.062244682330073735 Corrects: 4386\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.06143311411142349\n",
            "Train step - Step 1850, Loss 0.05230377987027168\n",
            "Train step - Step 1860, Loss 0.06775718927383423\n",
            "Train step - Step 1870, Loss 0.05996842309832573\n",
            "Train epoch - Accuracy: 0.8901010101010101 Loss: 0.058850349019272157 Corrects: 4406\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 1880, Loss 0.049757812172174454\n",
            "Train step - Step 1890, Loss 0.07347660511732101\n",
            "Train step - Step 1900, Loss 0.06278938055038452\n",
            "Train step - Step 1910, Loss 0.053924668580293655\n",
            "Train epoch - Accuracy: 0.8856565656565657 Loss: 0.059629946957633954 Corrects: 4384\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 1920, Loss 0.04277403652667999\n",
            "Train step - Step 1930, Loss 0.03828004375100136\n",
            "Train step - Step 1940, Loss 0.03980689123272896\n",
            "Train epoch - Accuracy: 0.9187878787878788 Loss: 0.0459460833939639 Corrects: 4548\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1950, Loss 0.04175686836242676\n",
            "Train step - Step 1960, Loss 0.03769885376095772\n",
            "Train step - Step 1970, Loss 0.031818732619285583\n",
            "Train step - Step 1980, Loss 0.048518355935811996\n",
            "Train epoch - Accuracy: 0.935959595959596 Loss: 0.0387587347024619 Corrects: 4633\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 1990, Loss 0.0475020632147789\n",
            "Train step - Step 2000, Loss 0.03851538151502609\n",
            "Train step - Step 2010, Loss 0.03568258509039879\n",
            "Train step - Step 2020, Loss 0.020591599866747856\n",
            "Train epoch - Accuracy: 0.943030303030303 Loss: 0.03604115625975108 Corrects: 4668\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2030, Loss 0.03556221351027489\n",
            "Train step - Step 2040, Loss 0.030464887619018555\n",
            "Train step - Step 2050, Loss 0.026035761460661888\n",
            "Train step - Step 2060, Loss 0.043632932007312775\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.03434549716837478 Corrects: 4683\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2070, Loss 0.03375213220715523\n",
            "Train step - Step 2080, Loss 0.03605068847537041\n",
            "Train step - Step 2090, Loss 0.04675016924738884\n",
            "Train step - Step 2100, Loss 0.042568035423755646\n",
            "Train epoch - Accuracy: 0.9478787878787879 Loss: 0.033592711113619084 Corrects: 4692\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2110, Loss 0.039320725947618484\n",
            "Train step - Step 2120, Loss 0.0400443971157074\n",
            "Train step - Step 2130, Loss 0.034380193799734116\n",
            "Train step - Step 2140, Loss 0.04101353511214256\n",
            "Train epoch - Accuracy: 0.944040404040404 Loss: 0.03363805299982278 Corrects: 4673\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2150, Loss 0.02139139547944069\n",
            "Train step - Step 2160, Loss 0.02144126407802105\n",
            "Train step - Step 2170, Loss 0.03289608284831047\n",
            "Train step - Step 2180, Loss 0.02711847424507141\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.032620769900203954 Corrects: 4715\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2190, Loss 0.0366511233150959\n",
            "Train step - Step 2200, Loss 0.0302578154951334\n",
            "Train step - Step 2210, Loss 0.03397226333618164\n",
            "Train step - Step 2220, Loss 0.03215285763144493\n",
            "Train epoch - Accuracy: 0.9535353535353536 Loss: 0.03131436201508599 Corrects: 4720\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2230, Loss 0.021973781287670135\n",
            "Train step - Step 2240, Loss 0.03962681069970131\n",
            "Train step - Step 2250, Loss 0.03601308539509773\n",
            "Train step - Step 2260, Loss 0.0517682246863842\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.031384160392212146 Corrects: 4708\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2270, Loss 0.02213471382856369\n",
            "Train step - Step 2280, Loss 0.028661752119660378\n",
            "Train step - Step 2290, Loss 0.03748664632439613\n",
            "Train step - Step 2300, Loss 0.02934454008936882\n",
            "Train epoch - Accuracy: 0.9547474747474748 Loss: 0.030714495123335808 Corrects: 4726\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2310, Loss 0.015140515752136707\n",
            "Train step - Step 2320, Loss 0.02208586409687996\n",
            "Train step - Step 2330, Loss 0.026200076565146446\n",
            "Train epoch - Accuracy: 0.9533333333333334 Loss: 0.029752900254244756 Corrects: 4719\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2340, Loss 0.022474918514490128\n",
            "Train step - Step 2350, Loss 0.036273181438446045\n",
            "Train step - Step 2360, Loss 0.02811289392411709\n",
            "Train step - Step 2370, Loss 0.026353154331445694\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.029524138605955874 Corrects: 4723\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2380, Loss 0.022360704839229584\n",
            "Train step - Step 2390, Loss 0.021185507997870445\n",
            "Train step - Step 2400, Loss 0.03528032824397087\n",
            "Train step - Step 2410, Loss 0.037594784051179886\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.029326232072680886 Corrects: 4738\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2420, Loss 0.028486967086791992\n",
            "Train step - Step 2430, Loss 0.02288452349603176\n",
            "Train step - Step 2440, Loss 0.019950469955801964\n",
            "Train step - Step 2450, Loss 0.032160017639398575\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.02910686623267453 Corrects: 4725\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 2460, Loss 0.025166690349578857\n",
            "Train step - Step 2470, Loss 0.022977208718657494\n",
            "Train step - Step 2480, Loss 0.021154511719942093\n",
            "Train step - Step 2490, Loss 0.030879193916916847\n",
            "Train epoch - Accuracy: 0.9618181818181818 Loss: 0.027135962092063644 Corrects: 4761\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2500, Loss 0.015368628315627575\n",
            "Train step - Step 2510, Loss 0.02804390899837017\n",
            "Train step - Step 2520, Loss 0.02024829387664795\n",
            "Train step - Step 2530, Loss 0.035143960267305374\n",
            "Train epoch - Accuracy: 0.9636363636363636 Loss: 0.024700769540486913 Corrects: 4770\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2540, Loss 0.02473190240561962\n",
            "Train step - Step 2550, Loss 0.01961803250014782\n",
            "Train step - Step 2560, Loss 0.03362078592181206\n",
            "Train step - Step 2570, Loss 0.041119348257780075\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.025666201426224274 Corrects: 4772\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2580, Loss 0.01840662583708763\n",
            "Train step - Step 2590, Loss 0.026443306356668472\n",
            "Train step - Step 2600, Loss 0.038777101784944534\n",
            "Train step - Step 2610, Loss 0.02030714973807335\n",
            "Train epoch - Accuracy: 0.9652525252525253 Loss: 0.024555352511580544 Corrects: 4778\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2620, Loss 0.02050783857703209\n",
            "Train step - Step 2630, Loss 0.018282661214470863\n",
            "Train step - Step 2640, Loss 0.033863235265016556\n",
            "Train step - Step 2650, Loss 0.032185111194849014\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.024038326884761003 Corrects: 4787\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2660, Loss 0.02332996018230915\n",
            "Train step - Step 2670, Loss 0.01761564426124096\n",
            "Train step - Step 2680, Loss 0.017593158408999443\n",
            "Train step - Step 2690, Loss 0.013954918831586838\n",
            "Train epoch - Accuracy: 0.9668686868686869 Loss: 0.024457199827890203 Corrects: 4786\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.023947762325406075\n",
            "Train step - Step 2710, Loss 0.022283626720309258\n",
            "Train step - Step 2720, Loss 0.02404911071062088\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.024721435712593973 Corrects: 4772\n",
            "Training finished in 192.51440453529358 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4]\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103df910>\n",
            "Constructing exemplars of class 67\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [31039, 41609, 29006, 49104, 35749, 31732, 39682, 21143, 44900, 33169, 45668, 4293, 22085, 38052, 18901, 47266, 21582, 426, 7961, 48038, 42399, 18981, 4680, 48250, 3540, 41760, 22714, 19621, 22239, 28625, 24241, 48251, 18295, 426, 9174, 48076, 1973, 4609, 7739, 1025, 18488, 14249, 6928, 7279, 2785, 16863, 40605, 9092, 32655, 17612, 4411, 5399, 6413, 26910, 49153, 13995, 37065, 21903, 2798, 20707, 14999, 37145, 7430, 14637, 39768, 2155, 28060, 23223, 5825, 26351, 12149, 37561, 9181, 36708, 18015, 30949, 42295, 9853, 41648, 45719, 47057, 40570, 41927, 28060, 48251, 30115, 11234, 6413, 4752, 20414, 17411, 8345, 26351, 16863, 9181, 40285, 7029, 8323, 47229, 39953, 21031, 38422, 17411, 32687, 39844, 20253, 10194, 21286, 46619, 12241, 27642, 47314, 28403, 29006, 20995, 13341, 15596, 5385, 18701, 18314, 28814, 15465, 48038, 35298, 23070, 35298, 4752, 30890, 24720, 21363, 34332, 27223, 49391, 14249, 45635, 49153, 13886, 1627, 17514, 15111, 25011, 49458, 36810, 23572, 30991, 21903, 45516, 4226, 43250, 18577, 42572, 2816, 23633, 32541, 35429, 19621, 36337, 6186, 13886, 45516, 18901, 25938, 8692, 15324, 48250, 6036, 29674, 17422, 24855, 17612, 15332, 27223, 31580, 24241, 23985, 45668, 9702, 21663, 18812, 8475, 2798, 46574, 14637, 41721, 18314, 18324, 15465, 35174, 19621, 9174, 47514, 18488, 2062, 44094, 14249, 11234, 14843, 4609, 23223, 16863]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710450d50>\n",
            "Constructing exemplars of class 59\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [610, 28279, 1562, 21269, 21624, 21649, 4010, 15381, 42192, 9679, 18757, 30470, 32648, 19183, 46093, 13420, 27341, 45838, 33936, 27587, 32022, 7065, 40396, 27858, 18938, 27950, 15950, 16244, 2530, 42912, 34163, 11016, 23289, 6746, 30471, 6045, 36701, 41861, 14671, 2834, 48148, 12711, 29352, 7320, 35811, 23044, 7980, 29872, 47809, 28258, 17831, 28660, 41861, 8081, 4113, 25142, 26213, 10919, 7664, 7093, 849, 43881, 32372, 30828, 33173, 15798, 49931, 27858, 22866, 1341, 30553, 14956, 17567, 23247, 41109, 39867, 38957, 36637, 40723, 17090, 11075, 10920, 16167, 6065, 41861, 37676, 25629, 31097, 44367, 15798, 48169, 7037, 24627, 26560, 22436, 43534, 3500, 38279, 26430, 45339, 14956, 33062, 46599, 7093, 8241, 1341, 41931, 26379, 49789, 8918, 5672, 14358, 7390, 38061, 11004, 37719, 19335, 25553, 43881, 18828, 8271, 45747, 15079, 10092, 27341, 28526, 30817, 19261, 48359, 13004, 40922, 19384, 38957, 27824, 44244, 15138, 26560, 14478, 27167, 25891, 4649, 15381, 31150, 29352, 9026, 27536, 19136, 28218, 22797, 30328, 45448, 23044, 16001, 30055, 28806, 13830, 14376, 14413, 25930, 13105, 30553, 42060, 18985, 33062, 39034, 26113, 23695, 17090, 406, 47372, 19677, 24503, 27858, 31150, 39481, 10103, 41434, 35279, 16608, 15079, 44244, 15950, 27950, 15950, 30109, 41971, 11710, 2000, 49663, 34779, 731, 3995, 1616, 4936, 19335, 4708, 18985, 22797, 45339, 4560]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722aa6290>\n",
            "Constructing exemplars of class 39\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [22556, 18143, 26139, 45674, 19357, 7060, 48544, 18253, 15098, 4457, 14374, 11883, 40488, 17931, 22737, 32037, 39348, 23215, 45631, 15263, 30725, 46764, 13219, 19522, 5711, 13387, 40525, 41565, 29160, 1062, 9660, 49155, 13745, 38592, 6124, 11797, 23668, 45285, 44046, 1494, 41736, 48671, 37628, 45744, 41688, 23828, 2830, 13219, 15098, 11117, 48209, 30000, 32620, 11867, 44315, 156, 36793, 32307, 30788, 39279, 32685, 32039, 30940, 27868, 38041, 32634, 47788, 29050, 25467, 27032, 2830, 36336, 41688, 24427, 19080, 45631, 32439, 36369, 47788, 12931, 3991, 24768, 10386, 46104, 46661, 33241, 14527, 39279, 5632, 36656, 49155, 35772, 46634, 41876, 21506, 18637, 39280, 38592, 30307, 28986, 25177, 21506, 31502, 2808, 11797, 36656, 48671, 7060, 32848, 33368, 37727, 11082, 42644, 27640, 33518, 46877, 19080, 2300, 45631, 28524, 34352, 33859, 5320, 43859, 41688, 20997, 34501, 42129, 23610, 46661, 42628, 36581, 34501, 10340, 4999, 34070, 19899, 32758, 46513, 16211, 12786, 30229, 17472, 8683, 39358, 11265, 13811, 1734, 13825, 31970, 18749, 45886, 12386, 27805, 3745, 5405, 25887, 46764, 223, 12135, 13724, 36581, 29620, 37727, 1494, 33942, 24442, 19725, 101, 22663, 49064, 49729, 19268, 8082, 5344, 22599, 16682, 47014, 28001, 34011, 46368, 48209, 22227, 38834, 17467, 12697, 44582, 25126, 45285, 27672, 8031, 32037, 7295, 18637, 14670, 21409, 40098, 2757, 38893, 18785]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671076b650>\n",
            "Constructing exemplars of class 22\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [37219, 21171, 6771, 8920, 35069, 2584, 39395, 3004, 48737, 13977, 32438, 49084, 19434, 44959, 35732, 21712, 15318, 45265, 16135, 43824, 25379, 32169, 1442, 39621, 15708, 7678, 10291, 3530, 46817, 10476, 20137, 11429, 46754, 4522, 9204, 17464, 6881, 4228, 24311, 47110, 25693, 6526, 5088, 24415, 21557, 8942, 32505, 8411, 32199, 8436, 5885, 7678, 44472, 6369, 36397, 26070, 10976, 35935, 6771, 29999, 6669, 632, 29172, 39093, 16552, 8429, 4916, 48737, 13977, 25990, 46915, 24147, 36489, 27012, 45561, 8117, 6019, 5641, 35674, 9204, 3352, 5102, 34723, 12317, 34154, 39070, 48107, 43471, 41014, 48818, 29153, 46754, 18902, 44918, 7888, 17464, 49821, 17313, 40026, 44721, 22774, 12670, 7057, 7610, 47463, 2148, 44714, 10826, 28244, 18636, 9828, 42668, 5293, 22222, 26532, 37754, 14867, 49084, 34817, 17251, 34634, 632, 14023, 42949, 47317, 8088, 17464, 17611, 39070, 23414, 36954, 12317, 37554, 24415, 2752, 6762, 3530, 25457, 32438, 26441, 40206, 36314, 39093, 41981, 8429, 29021, 12675, 2503, 20180, 31931, 49320, 10976, 632, 46754, 36897, 48737, 42062, 40092, 31976, 6544, 26555, 24311, 7341, 33853, 23664, 42949, 31767, 39070, 49498, 2752, 9038, 3941, 17313, 49821, 20372, 3530, 28665, 5828, 13630, 18821, 21578, 35194, 27728, 23414, 28257, 12994, 29999, 16612, 25379, 12317, 9681, 36310, 32438, 35674, 26441, 3293, 44529, 43849, 29950, 14460]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103c5850>\n",
            "Constructing exemplars of class 18\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [36689, 40615, 12585, 48761, 35395, 40207, 13148, 9654, 32209, 21942, 14811, 7104, 36707, 29926, 3343, 14512, 36886, 4386, 5470, 20174, 14650, 5060, 21650, 26792, 46035, 13403, 42969, 39571, 18889, 17907, 10065, 31539, 37924, 49342, 38974, 19627, 39521, 27221, 33288, 6605, 38776, 40498, 75, 13148, 43059, 31962, 13292, 43586, 36687, 38170, 42406, 22981, 31961, 17228, 45188, 10359, 36037, 25982, 10829, 49129, 22976, 24328, 20584, 47750, 21078, 35267, 40207, 41949, 4764, 14102, 38676, 32191, 44368, 12009, 25714, 2557, 32952, 40443, 41219, 44655, 43870, 38716, 9100, 13172, 41302, 14128, 20543, 10696, 14431, 6484, 25182, 31961, 49759, 26101, 21335, 36347, 24795, 11999, 11061, 5520, 49243, 31722, 42310, 36791, 21078, 27799, 13172, 26711, 11574, 28378, 33980, 38716, 32122, 10829, 30306, 38379, 24328, 4798, 36347, 24271, 34175, 42724, 11523, 25182, 75, 39571, 40363, 31753, 22438, 8218, 5205, 31736, 22397, 46753, 44591, 47090, 27120, 38719, 24825, 32779, 1273, 9605, 48346, 41532, 20261, 89, 38118, 22438, 24795, 13403, 32792, 19921, 17146, 27169, 17907, 29811, 47098, 22467, 46884, 17561, 45162, 37961, 39440, 2811, 9645, 42724, 31961, 4798, 39460, 34023, 14283, 30885, 13269, 47987, 36280, 10127, 40363, 27799, 8346, 7908, 37638, 10829, 20174, 7557, 30092, 32209, 33432, 6431, 25982, 4107, 11893, 7386, 35793, 46925, 44368, 12009, 19077, 38448, 38118, 8959]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710450d50>\n",
            "Constructing exemplars of class 65\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [7762, 11569, 13022, 37635, 18805, 7777, 21726, 22123, 9040, 27400, 37992, 14676, 36020, 30223, 21339, 19648, 35969, 7024, 44459, 23942, 21450, 29091, 39396, 40984, 34695, 26376, 19564, 21279, 6695, 49140, 2972, 12479, 25365, 3206, 38115, 46170, 16237, 20016, 365, 170, 12674, 37635, 47616, 5820, 9715, 33597, 2175, 43176, 29067, 10962, 23825, 40512, 11837, 30020, 47161, 17388, 5103, 21684, 5024, 7365, 19199, 23819, 36248, 17959, 35425, 3904, 7024, 35007, 33366, 31883, 41321, 43296, 34559, 21771, 49845, 17480, 21684, 5331, 9460, 3838, 42332, 16505, 8123, 6255, 7354, 30950, 48829, 23560, 43574, 32485, 11569, 6714, 27378, 4755, 21835, 45893, 48164, 22801, 44283, 18570, 40973, 3799, 13533, 21354, 1738, 31693, 37018, 9777, 1934, 35631, 21339, 27358, 29675, 22447, 31693, 8338, 23330, 45287, 36877, 18720, 15296, 9979, 11176, 48464, 45632, 19667, 11925, 16875, 37662, 24955, 26182, 49170, 26627, 8666, 23560, 1814, 26241, 15842, 16057, 1835, 23565, 6411, 22720, 38833, 20934, 31718, 1934, 34962, 1917, 12674, 32928, 38308, 38907, 34695, 43574, 44708, 45229, 7010, 14200, 23649, 20009, 25077, 33056, 43356, 23565, 18658, 41727, 16099, 40502, 1917, 432, 26586, 27376, 9040, 10962, 23825, 21639, 45893, 48625, 18498, 27493, 18720, 38833, 514, 42353, 28544, 24997, 21639, 32987, 18805, 43296, 33367, 396, 17044, 29000, 34559, 5505, 42091, 31756, 45255]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234fcb10>\n",
            "Constructing exemplars of class 49\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [38909, 34224, 24785, 2361, 36778, 33409, 8721, 34446, 9142, 6351, 28973, 46041, 19812, 17272, 25822, 33988, 46973, 4998, 36643, 22292, 6117, 2862, 12011, 35615, 25068, 13797, 2236, 26204, 31080, 41320, 49043, 39798, 8515, 40318, 1787, 6245, 18797, 22247, 8856, 18731, 31299, 34975, 26777, 36523, 3667, 13957, 45236, 45650, 14823, 2920, 2265, 47253, 23913, 27289, 45945, 19486, 29567, 47186, 18996, 17576, 29350, 10137, 9078, 38236, 47582, 32316, 29491, 15544, 34092, 1591, 19316, 45760, 47688, 11397, 42370, 17272, 38251, 11122, 14018, 14611, 33676, 45650, 23528, 22431, 15491, 43512, 42671, 28691, 14406, 22101, 31401, 24630, 9020, 15544, 49310, 10137, 423, 40974, 14929, 2612, 7587, 27122, 7785, 42622, 13215, 6287, 13957, 42531, 42904, 13215, 3638, 16075, 19316, 32386, 6747, 32352, 9045, 48776, 20532, 45848, 42122, 45650, 6094, 23188, 29567, 22298, 13755, 2862, 23966, 40890, 8267, 47186, 21070, 20532, 12345, 4791, 20894, 42671, 30220, 34963, 31358, 2181, 32239, 43524, 46044, 38851, 19812, 23821, 36585, 12860, 43305, 49966, 47186, 34951, 12011, 18138, 49610, 27170, 29777, 27143, 41037, 16676, 15491, 33332, 20211, 31350, 35518, 4351, 18001, 20485, 35911, 11652, 49972, 12856, 1097, 31439, 13849, 14804, 48987, 18630, 11694, 37168, 31080, 12631, 8515, 28827, 32592, 49610, 28054, 20833, 14823, 34224, 6287, 20485, 20894, 42370, 44670, 4974, 34118, 16251]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103c5d50>\n",
            "Constructing exemplars of class 56\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [2196, 29110, 12972, 39221, 29297, 30678, 46755, 28823, 4092, 12571, 7845, 38988, 17751, 22460, 39531, 32266, 7507, 31772, 48285, 7156, 23949, 30758, 38865, 34378, 12921, 17754, 9892, 471, 24108, 49001, 43671, 6243, 27075, 21613, 39892, 41541, 1529, 10394, 39945, 15023, 37910, 26393, 28791, 1822, 9892, 24108, 2762, 14972, 49626, 22829, 17754, 44674, 21570, 31465, 5361, 12564, 46309, 38988, 24138, 12921, 30076, 38889, 26492, 6165, 23863, 49475, 21642, 27588, 24629, 40994, 644, 4314, 47479, 30966, 25780, 4868, 8063, 47761, 43869, 7829, 44068, 4554, 42697, 47360, 9503, 2327, 43813, 38779, 14972, 49626, 29110, 8973, 30691, 18635, 43212, 46688, 6290, 39721, 27964, 35186, 23080, 24535, 44147, 43815, 35186, 36374, 19681, 35305, 26825, 37440, 5316, 27997, 27588, 44808, 14392, 21570, 39531, 18635, 35565, 34892, 45966, 41946, 30758, 19240, 21522, 6595, 3156, 4493, 44068, 776, 38960, 21570, 31574, 39314, 24138, 12921, 42758, 26517, 11843, 3156, 46755, 46451, 23889, 31891, 43311, 31185, 41946, 8914, 19129, 42786, 471, 14825, 30715, 40439, 14972, 10982, 397, 277, 6509, 25926, 48440, 16420, 26303, 4868, 39543, 34018, 4787, 33586, 10654, 27676, 21127, 689, 776, 26349, 19986, 14787, 47179, 40271, 6509, 27075, 1529, 43027, 17754, 47423, 21020, 24138, 48788, 46633, 39054, 27588, 43650, 5316, 4314, 397, 31995, 43374, 30678, 31185, 8973, 38779]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b05310>\n",
            "Constructing exemplars of class 20\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [2747, 15143, 17470, 34819, 44986, 32522, 509, 18723, 16006, 33837, 28825, 12903, 2060, 4831, 48170, 49986, 26407, 36838, 31785, 6137, 44209, 11488, 29137, 46897, 9508, 7800, 13760, 11479, 36986, 17299, 36838, 34819, 49855, 17415, 908, 33677, 13195, 11958, 44209, 31785, 17285, 17470, 3117, 31326, 41466, 18115, 46183, 34420, 5643, 34596, 25185, 6937, 48324, 41520, 34447, 5940, 23976, 40761, 48989, 26572, 28825, 13760, 19855, 9500, 46212, 6279, 17415, 20575, 24829, 18115, 46183, 34420, 22251, 34855, 5401, 13094, 46547, 4774, 31197, 22865, 48340, 13195, 25198, 25185, 25507, 20199, 48133, 44986, 17415, 39483, 21426, 30425, 30025, 19444, 30910, 4768, 19539, 25507, 18382, 16774, 36986, 37694, 14029, 32262, 35508, 39206, 1425, 23976, 26058, 2587, 17318, 26019, 2758, 31197, 25513, 44861, 2271, 20098, 42221, 14029, 12253, 13940, 764, 509, 29137, 41272, 2587, 18911, 46212, 22251, 19305, 45704, 16774, 27004, 9374, 5080, 26094, 36557, 46101, 42039, 18382, 16301, 989, 32955, 11001, 44209, 28980, 30910, 4833, 32262, 19315, 23530, 11488, 34336, 38722, 39720, 49081, 21396, 26572, 19222, 46878, 45022, 24084, 23045, 14269, 36064, 25839, 26830, 18349, 41449, 30824, 41466, 37773, 28825, 28555, 28340, 7800, 3158, 32836, 49222, 6279, 19404, 11785, 18911, 35384, 10234, 31197, 18012, 34663, 22320, 1768, 46001, 18723, 39720, 43657, 11479, 10335, 33837, 36039, 30910]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671076b650>\n",
            "Constructing exemplars of class 4\n",
            "lunghezza exemplar set:  200\n",
            "exemplar set:  [102, 7178, 35690, 44413, 14727, 47125, 33689, 33174, 5542, 43969, 28116, 14996, 113, 34225, 10518, 32876, 41904, 35641, 33880, 22647, 20446, 45436, 33312, 14305, 26299, 36241, 36710, 5493, 8040, 42937, 10650, 13442, 15120, 10983, 27342, 43974, 15812, 17704, 41557, 12053, 17802, 8292, 30378, 30665, 28205, 6834, 32771, 32331, 17304, 43420, 33850, 21951, 49250, 44568, 4021, 27921, 389, 24809, 43260, 35361, 12963, 44258, 37645, 15423, 33003, 44104, 28584, 15073, 24923, 28139, 3107, 25090, 11359, 35641, 43943, 3213, 42869, 13503, 33634, 3779, 29663, 16148, 37055, 3230, 5880, 32771, 35576, 47596, 22450, 47125, 7936, 12963, 20735, 49929, 15442, 33791, 20583, 31043, 19181, 13422, 5490, 7682, 40558, 3801, 35006, 7932, 3213, 10074, 43660, 4021, 17304, 9218, 8946, 21951, 38059, 45934, 21645, 47622, 33004, 40048, 21069, 9579, 4588, 33689, 11257, 34743, 32331, 10058, 32876, 43420, 32866, 36753, 48043, 16974, 19967, 30683, 13503, 14691, 34784, 40048, 2601, 23853, 2866, 1148, 8040, 26319, 43260, 35361, 24923, 33174, 49257, 2711, 29840, 27902, 38364, 8040, 45780, 47596, 44162, 33996, 36371, 41904, 6834, 24358, 38612, 32876, 25399, 44872, 10061, 31822, 15442, 21109, 28527, 12928, 29495, 43897, 22660, 41747, 26714, 5519, 2943, 21103, 13503, 12078, 12928, 33003, 23505, 36371, 24293, 15117, 1767, 35649, 916, 37381, 2949, 39748, 45465, 3230, 488, 5542]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.82 0.11626096069812775\n",
            "TEST GROUP:  0.823\n",
            "TEST ALL:  0.823\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  2000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [82, 81, 7, 16, 18, 20, 21, 22, 34, 39, 47, 49, 56, 59, 65, 67, 68, 79, 80, 4]\n",
            "TRAIN_SET CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "VALIDATION CLASSES:  [47, 34, 21, 16, 82, 81, 80, 79, 7, 68]\n",
            "GROUP:  2\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  20\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.4743521809577942\n",
            "Train step - Step 10, Loss 0.19128087162971497\n",
            "Train step - Step 20, Loss 0.15853504836559296\n",
            "Train step - Step 30, Loss 0.1502845138311386\n",
            "Train step - Step 40, Loss 0.13920561969280243\n",
            "Train step - Step 50, Loss 0.14723920822143555\n",
            "Train epoch - Accuracy: 0.318273381294964 Loss: 0.17468830531020815 Corrects: 2212\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.1215742975473404\n",
            "Train step - Step 70, Loss 0.14103426039218903\n",
            "Train step - Step 80, Loss 0.12930619716644287\n",
            "Train step - Step 90, Loss 0.11195210367441177\n",
            "Train step - Step 100, Loss 0.1103985458612442\n",
            "Train epoch - Accuracy: 0.3939568345323741 Loss: 0.1284312527385547 Corrects: 2738\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.13272729516029358\n",
            "Train step - Step 120, Loss 0.11832413822412491\n",
            "Train step - Step 130, Loss 0.12322764843702316\n",
            "Train step - Step 140, Loss 0.11141163110733032\n",
            "Train step - Step 150, Loss 0.10594375431537628\n",
            "Train step - Step 160, Loss 0.11895948648452759\n",
            "Train epoch - Accuracy: 0.439568345323741 Loss: 0.1196074087928525 Corrects: 3055\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11439984291791916\n",
            "Train step - Step 180, Loss 0.11611800640821457\n",
            "Train step - Step 190, Loss 0.1301484853029251\n",
            "Train step - Step 200, Loss 0.10913649946451187\n",
            "Train step - Step 210, Loss 0.11171829700469971\n",
            "Train epoch - Accuracy: 0.4776978417266187 Loss: 0.11531890684323345 Corrects: 3320\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1108209639787674\n",
            "Train step - Step 230, Loss 0.09834390133619308\n",
            "Train step - Step 240, Loss 0.1157802864909172\n",
            "Train step - Step 250, Loss 0.10703575611114502\n",
            "Train step - Step 260, Loss 0.12352307140827179\n",
            "Train step - Step 270, Loss 0.11270441859960556\n",
            "Train epoch - Accuracy: 0.4902158273381295 Loss: 0.11334025692811116 Corrects: 3407\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.11645694077014923\n",
            "Train step - Step 290, Loss 0.1197509765625\n",
            "Train step - Step 300, Loss 0.11226749420166016\n",
            "Train step - Step 310, Loss 0.11768174171447754\n",
            "Train step - Step 320, Loss 0.11089807748794556\n",
            "Train epoch - Accuracy: 0.5105035971223022 Loss: 0.11137157566041397 Corrects: 3548\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.10345746576786041\n",
            "Train step - Step 340, Loss 0.1076565533876419\n",
            "Train step - Step 350, Loss 0.1098984032869339\n",
            "Train step - Step 360, Loss 0.12189183384180069\n",
            "Train step - Step 370, Loss 0.10268374532461166\n",
            "Train step - Step 380, Loss 0.1118169054389\n",
            "Train epoch - Accuracy: 0.5289208633093525 Loss: 0.10880488161346037 Corrects: 3676\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11083199828863144\n",
            "Train step - Step 400, Loss 0.10235084593296051\n",
            "Train step - Step 410, Loss 0.09867896139621735\n",
            "Train step - Step 420, Loss 0.0980999618768692\n",
            "Train step - Step 430, Loss 0.09775558114051819\n",
            "Train epoch - Accuracy: 0.539568345323741 Loss: 0.1065078880632524 Corrects: 3750\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.1044316217303276\n",
            "Train step - Step 450, Loss 0.11145982891321182\n",
            "Train step - Step 460, Loss 0.10583901405334473\n",
            "Train step - Step 470, Loss 0.09504044055938721\n",
            "Train step - Step 480, Loss 0.13494282960891724\n",
            "Train step - Step 490, Loss 0.10167937725782394\n",
            "Train epoch - Accuracy: 0.5456115107913669 Loss: 0.10612218256476971 Corrects: 3792\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.09896212071180344\n",
            "Train step - Step 510, Loss 0.1080586239695549\n",
            "Train step - Step 520, Loss 0.11249873787164688\n",
            "Train step - Step 530, Loss 0.10605907440185547\n",
            "Train step - Step 540, Loss 0.10662084072828293\n",
            "Train epoch - Accuracy: 0.5602877697841726 Loss: 0.10427589044082079 Corrects: 3894\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.10920443385839462\n",
            "Train step - Step 560, Loss 0.09364330768585205\n",
            "Train step - Step 570, Loss 0.08872803300619125\n",
            "Train step - Step 580, Loss 0.10903503000736237\n",
            "Train step - Step 590, Loss 0.10359156131744385\n",
            "Train step - Step 600, Loss 0.11032233387231827\n",
            "Train epoch - Accuracy: 0.5775539568345324 Loss: 0.10299107109256786 Corrects: 4014\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.09602274000644684\n",
            "Train step - Step 620, Loss 0.09349526464939117\n",
            "Train step - Step 630, Loss 0.11351978033781052\n",
            "Train step - Step 640, Loss 0.10833382606506348\n",
            "Train step - Step 650, Loss 0.09760501235723495\n",
            "Train epoch - Accuracy: 0.5801438848920863 Loss: 0.10228895965668795 Corrects: 4032\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.1102219969034195\n",
            "Train step - Step 670, Loss 0.0987003967165947\n",
            "Train step - Step 680, Loss 0.09573501348495483\n",
            "Train step - Step 690, Loss 0.11302319914102554\n",
            "Train step - Step 700, Loss 0.0972827821969986\n",
            "Train step - Step 710, Loss 0.10119753330945969\n",
            "Train epoch - Accuracy: 0.5884892086330935 Loss: 0.10127679129084237 Corrects: 4090\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.09628414362668991\n",
            "Train step - Step 730, Loss 0.0931716114282608\n",
            "Train step - Step 740, Loss 0.0952124148607254\n",
            "Train step - Step 750, Loss 0.10115724802017212\n",
            "Train step - Step 760, Loss 0.10299041122198105\n",
            "Train epoch - Accuracy: 0.5971223021582733 Loss: 0.0990811574544838 Corrects: 4150\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.09728073328733444\n",
            "Train step - Step 780, Loss 0.1048491969704628\n",
            "Train step - Step 790, Loss 0.10338807106018066\n",
            "Train step - Step 800, Loss 0.09164635092020035\n",
            "Train step - Step 810, Loss 0.09217136353254318\n",
            "Train step - Step 820, Loss 0.09835293143987656\n",
            "Train epoch - Accuracy: 0.6113669064748202 Loss: 0.09912906560323222 Corrects: 4249\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.087366484105587\n",
            "Train step - Step 840, Loss 0.09050413966178894\n",
            "Train step - Step 850, Loss 0.08670592308044434\n",
            "Train step - Step 860, Loss 0.1010250598192215\n",
            "Train step - Step 870, Loss 0.10707779973745346\n",
            "Train epoch - Accuracy: 0.6128057553956835 Loss: 0.09753671861595387 Corrects: 4259\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.0997992530465126\n",
            "Train step - Step 890, Loss 0.09812066704034805\n",
            "Train step - Step 900, Loss 0.08872418850660324\n",
            "Train step - Step 910, Loss 0.09818297624588013\n",
            "Train step - Step 920, Loss 0.10249294340610504\n",
            "Train step - Step 930, Loss 0.09003335237503052\n",
            "Train epoch - Accuracy: 0.6202877697841727 Loss: 0.09645975249705555 Corrects: 4311\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.0897306278347969\n",
            "Train step - Step 950, Loss 0.09465064108371735\n",
            "Train step - Step 960, Loss 0.0957128033041954\n",
            "Train step - Step 970, Loss 0.09067340940237045\n",
            "Train step - Step 980, Loss 0.0978911817073822\n",
            "Train epoch - Accuracy: 0.6312230215827338 Loss: 0.09544306427025967 Corrects: 4387\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.09345412254333496\n",
            "Train step - Step 1000, Loss 0.09115345776081085\n",
            "Train step - Step 1010, Loss 0.1026601791381836\n",
            "Train step - Step 1020, Loss 0.09537120163440704\n",
            "Train step - Step 1030, Loss 0.09019383788108826\n",
            "Train step - Step 1040, Loss 0.0884721502661705\n",
            "Train epoch - Accuracy: 0.6336690647482014 Loss: 0.09559634831526297 Corrects: 4404\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.08647317439317703\n",
            "Train step - Step 1060, Loss 0.09822022914886475\n",
            "Train step - Step 1070, Loss 0.08547431230545044\n",
            "Train step - Step 1080, Loss 0.08167021721601486\n",
            "Train step - Step 1090, Loss 0.10904538631439209\n",
            "Train epoch - Accuracy: 0.6427338129496403 Loss: 0.09387057457896446 Corrects: 4467\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.08944949507713318\n",
            "Train step - Step 1110, Loss 0.0926569476723671\n",
            "Train step - Step 1120, Loss 0.10193324089050293\n",
            "Train step - Step 1130, Loss 0.08657164871692657\n",
            "Train step - Step 1140, Loss 0.08977743238210678\n",
            "Train step - Step 1150, Loss 0.09974085539579391\n",
            "Train epoch - Accuracy: 0.6453237410071943 Loss: 0.09367338925600052 Corrects: 4485\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.09007681906223297\n",
            "Train step - Step 1170, Loss 0.08502957969903946\n",
            "Train step - Step 1180, Loss 0.09328494220972061\n",
            "Train step - Step 1190, Loss 0.09043305367231369\n",
            "Train step - Step 1200, Loss 0.09102600812911987\n",
            "Train epoch - Accuracy: 0.659136690647482 Loss: 0.09231935784327898 Corrects: 4581\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.10193317383527756\n",
            "Train step - Step 1220, Loss 0.09323572367429733\n",
            "Train step - Step 1230, Loss 0.08979206532239914\n",
            "Train step - Step 1240, Loss 0.08484949916601181\n",
            "Train step - Step 1250, Loss 0.09172755479812622\n",
            "Train step - Step 1260, Loss 0.08404278010129929\n",
            "Train epoch - Accuracy: 0.6686330935251799 Loss: 0.09141053159674295 Corrects: 4647\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.09791598469018936\n",
            "Train step - Step 1280, Loss 0.09472659230232239\n",
            "Train step - Step 1290, Loss 0.08696506917476654\n",
            "Train step - Step 1300, Loss 0.0821673795580864\n",
            "Train step - Step 1310, Loss 0.08698699623346329\n",
            "Train epoch - Accuracy: 0.6746762589928058 Loss: 0.09162985503887959 Corrects: 4689\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.09809734672307968\n",
            "Train step - Step 1330, Loss 0.08025498688220978\n",
            "Train step - Step 1340, Loss 0.0933857187628746\n",
            "Train step - Step 1350, Loss 0.08050396293401718\n",
            "Train step - Step 1360, Loss 0.08769525587558746\n",
            "Train step - Step 1370, Loss 0.08618815988302231\n",
            "Train epoch - Accuracy: 0.6725179856115108 Loss: 0.0909906712110094 Corrects: 4674\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.08625107258558273\n",
            "Train step - Step 1390, Loss 0.09218975156545639\n",
            "Train step - Step 1400, Loss 0.09745892137289047\n",
            "Train step - Step 1410, Loss 0.09796484559774399\n",
            "Train step - Step 1420, Loss 0.0895649716258049\n",
            "Train epoch - Accuracy: 0.6807194244604317 Loss: 0.08970672877572423 Corrects: 4731\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.08513667434453964\n",
            "Train step - Step 1440, Loss 0.08850634098052979\n",
            "Train step - Step 1450, Loss 0.09628517180681229\n",
            "Train step - Step 1460, Loss 0.07111789286136627\n",
            "Train step - Step 1470, Loss 0.08493506163358688\n",
            "Train step - Step 1480, Loss 0.08545442670583725\n",
            "Train epoch - Accuracy: 0.6906474820143885 Loss: 0.08787480151910576 Corrects: 4800\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.08818986266851425\n",
            "Train step - Step 1500, Loss 0.0978156104683876\n",
            "Train step - Step 1510, Loss 0.09755945205688477\n",
            "Train step - Step 1520, Loss 0.0827580913901329\n",
            "Train step - Step 1530, Loss 0.08117394894361496\n",
            "Train epoch - Accuracy: 0.6889208633093525 Loss: 0.08890237036797641 Corrects: 4788\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09312368929386139\n",
            "Train step - Step 1550, Loss 0.09007793664932251\n",
            "Train step - Step 1560, Loss 0.09479250758886337\n",
            "Train step - Step 1570, Loss 0.0841621682047844\n",
            "Train step - Step 1580, Loss 0.09157248586416245\n",
            "Train step - Step 1590, Loss 0.10216125100851059\n",
            "Train epoch - Accuracy: 0.6928057553956835 Loss: 0.08802415189768771 Corrects: 4815\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.08583880960941315\n",
            "Train step - Step 1610, Loss 0.09249287098646164\n",
            "Train step - Step 1620, Loss 0.08243361115455627\n",
            "Train step - Step 1630, Loss 0.09090419113636017\n",
            "Train step - Step 1640, Loss 0.08905106782913208\n",
            "Train epoch - Accuracy: 0.7002877697841726 Loss: 0.0876436931816794 Corrects: 4867\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.08867033571004868\n",
            "Train step - Step 1660, Loss 0.0991072878241539\n",
            "Train step - Step 1670, Loss 0.08670403808355331\n",
            "Train step - Step 1680, Loss 0.0917344018816948\n",
            "Train step - Step 1690, Loss 0.09161213785409927\n",
            "Train step - Step 1700, Loss 0.08319039642810822\n",
            "Train epoch - Accuracy: 0.7031654676258993 Loss: 0.08719079511199923 Corrects: 4887\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.07967402040958405\n",
            "Train step - Step 1720, Loss 0.08997463434934616\n",
            "Train step - Step 1730, Loss 0.08340635150671005\n",
            "Train step - Step 1740, Loss 0.08421727269887924\n",
            "Train step - Step 1750, Loss 0.0900859460234642\n",
            "Train epoch - Accuracy: 0.7040287769784173 Loss: 0.0851522861860639 Corrects: 4893\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.07789094001054764\n",
            "Train step - Step 1770, Loss 0.08886964619159698\n",
            "Train step - Step 1780, Loss 0.08715405315160751\n",
            "Train step - Step 1790, Loss 0.08757010847330093\n",
            "Train step - Step 1800, Loss 0.09230105578899384\n",
            "Train step - Step 1810, Loss 0.08154784888029099\n",
            "Train epoch - Accuracy: 0.7149640287769784 Loss: 0.08471883178400479 Corrects: 4969\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.08470320701599121\n",
            "Train step - Step 1830, Loss 0.08863556385040283\n",
            "Train step - Step 1840, Loss 0.0818091332912445\n",
            "Train step - Step 1850, Loss 0.09177007526159286\n",
            "Train step - Step 1860, Loss 0.08181770145893097\n",
            "Train epoch - Accuracy: 0.7223021582733813 Loss: 0.08435002408868117 Corrects: 5020\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.09133332967758179\n",
            "Train step - Step 1880, Loss 0.07700370997190475\n",
            "Train step - Step 1890, Loss 0.08419875800609589\n",
            "Train step - Step 1900, Loss 0.08626766502857208\n",
            "Train step - Step 1910, Loss 0.07783523947000504\n",
            "Train step - Step 1920, Loss 0.079221211373806\n",
            "Train epoch - Accuracy: 0.7231654676258993 Loss: 0.08321380741733442 Corrects: 5026\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.08102162927389145\n",
            "Train step - Step 1940, Loss 0.0736260935664177\n",
            "Train step - Step 1950, Loss 0.08006203174591064\n",
            "Train step - Step 1960, Loss 0.08360089361667633\n",
            "Train step - Step 1970, Loss 0.0849861428141594\n",
            "Train epoch - Accuracy: 0.7276258992805755 Loss: 0.08246077019104854 Corrects: 5057\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.08303462713956833\n",
            "Train step - Step 1990, Loss 0.08483133465051651\n",
            "Train step - Step 2000, Loss 0.0776047334074974\n",
            "Train step - Step 2010, Loss 0.08522987365722656\n",
            "Train step - Step 2020, Loss 0.09608560800552368\n",
            "Train step - Step 2030, Loss 0.08209391683340073\n",
            "Train epoch - Accuracy: 0.7381294964028777 Loss: 0.08259114898151632 Corrects: 5130\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.08830311894416809\n",
            "Train step - Step 2050, Loss 0.07408883422613144\n",
            "Train step - Step 2060, Loss 0.09292998164892197\n",
            "Train step - Step 2070, Loss 0.09308552742004395\n",
            "Train step - Step 2080, Loss 0.08583851903676987\n",
            "Train epoch - Accuracy: 0.7402877697841727 Loss: 0.08357230639929394 Corrects: 5145\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.0743132159113884\n",
            "Train step - Step 2100, Loss 0.09161055088043213\n",
            "Train step - Step 2110, Loss 0.08810538798570633\n",
            "Train step - Step 2120, Loss 0.08326970040798187\n",
            "Train step - Step 2130, Loss 0.08105643838644028\n",
            "Train step - Step 2140, Loss 0.07843183726072311\n",
            "Train epoch - Accuracy: 0.7446043165467626 Loss: 0.08132078922052177 Corrects: 5175\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.07844902575016022\n",
            "Train step - Step 2160, Loss 0.08699387311935425\n",
            "Train step - Step 2170, Loss 0.09245177358388901\n",
            "Train step - Step 2180, Loss 0.08118638396263123\n",
            "Train step - Step 2190, Loss 0.07928546518087387\n",
            "Train epoch - Accuracy: 0.7469064748201439 Loss: 0.08224469575950567 Corrects: 5191\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.07606356590986252\n",
            "Train step - Step 2210, Loss 0.0772818922996521\n",
            "Train step - Step 2220, Loss 0.08379936218261719\n",
            "Train step - Step 2230, Loss 0.08464641869068146\n",
            "Train step - Step 2240, Loss 0.07618295401334763\n",
            "Train step - Step 2250, Loss 0.07610883563756943\n",
            "Train epoch - Accuracy: 0.7520863309352518 Loss: 0.07951289540143322 Corrects: 5227\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.07841842621564865\n",
            "Train step - Step 2270, Loss 0.07562637329101562\n",
            "Train step - Step 2280, Loss 0.07898830622434616\n",
            "Train step - Step 2290, Loss 0.08112528920173645\n",
            "Train step - Step 2300, Loss 0.0801079273223877\n",
            "Train epoch - Accuracy: 0.7579856115107914 Loss: 0.0810613041365747 Corrects: 5268\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.07188000530004501\n",
            "Train step - Step 2320, Loss 0.08159184455871582\n",
            "Train step - Step 2330, Loss 0.08670703321695328\n",
            "Train step - Step 2340, Loss 0.0836402177810669\n",
            "Train step - Step 2350, Loss 0.08067601174116135\n",
            "Train step - Step 2360, Loss 0.08649583160877228\n",
            "Train epoch - Accuracy: 0.7579856115107914 Loss: 0.07887858719491272 Corrects: 5268\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.06969437748193741\n",
            "Train step - Step 2380, Loss 0.07847713679075241\n",
            "Train step - Step 2390, Loss 0.08111704140901566\n",
            "Train step - Step 2400, Loss 0.07200746983289719\n",
            "Train step - Step 2410, Loss 0.07317783683538437\n",
            "Train epoch - Accuracy: 0.7611510791366907 Loss: 0.0789040493514898 Corrects: 5290\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.08684875816106796\n",
            "Train step - Step 2430, Loss 0.07859621196985245\n",
            "Train step - Step 2440, Loss 0.07317996025085449\n",
            "Train step - Step 2450, Loss 0.08195336163043976\n",
            "Train step - Step 2460, Loss 0.07884181290864944\n",
            "Train step - Step 2470, Loss 0.07073567062616348\n",
            "Train epoch - Accuracy: 0.7719424460431654 Loss: 0.07896966556207739 Corrects: 5365\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.07636939734220505\n",
            "Train step - Step 2490, Loss 0.07855691760778427\n",
            "Train step - Step 2500, Loss 0.0798669382929802\n",
            "Train step - Step 2510, Loss 0.07321789115667343\n",
            "Train step - Step 2520, Loss 0.08716956526041031\n",
            "Train epoch - Accuracy: 0.7680575539568345 Loss: 0.0775988291750709 Corrects: 5338\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.06697400659322739\n",
            "Train step - Step 2540, Loss 0.08389300853013992\n",
            "Train step - Step 2550, Loss 0.0687478706240654\n",
            "Train step - Step 2560, Loss 0.0783657655119896\n",
            "Train step - Step 2570, Loss 0.07785002887248993\n",
            "Train step - Step 2580, Loss 0.07430341094732285\n",
            "Train epoch - Accuracy: 0.7728057553956834 Loss: 0.07753785020155872 Corrects: 5371\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.07820087671279907\n",
            "Train step - Step 2600, Loss 0.07849066704511642\n",
            "Train step - Step 2610, Loss 0.08411149680614471\n",
            "Train step - Step 2620, Loss 0.09575015306472778\n",
            "Train step - Step 2630, Loss 0.07609675079584122\n",
            "Train epoch - Accuracy: 0.7635971223021583 Loss: 0.07848372214132075 Corrects: 5307\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.07477510720491409\n",
            "Train step - Step 2650, Loss 0.08134207874536514\n",
            "Train step - Step 2660, Loss 0.0732947438955307\n",
            "Train step - Step 2670, Loss 0.07864028215408325\n",
            "Train step - Step 2680, Loss 0.07147307693958282\n",
            "Train step - Step 2690, Loss 0.06788656860589981\n",
            "Train epoch - Accuracy: 0.779568345323741 Loss: 0.07579870967341841 Corrects: 5418\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.07750822603702545\n",
            "Train step - Step 2710, Loss 0.06844818592071533\n",
            "Train step - Step 2720, Loss 0.06460272520780563\n",
            "Train step - Step 2730, Loss 0.07117803394794464\n",
            "Train step - Step 2740, Loss 0.07598521560430527\n",
            "Train epoch - Accuracy: 0.7992805755395683 Loss: 0.07095399120943152 Corrects: 5555\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.07423200458288193\n",
            "Train step - Step 2760, Loss 0.07238127291202545\n",
            "Train step - Step 2770, Loss 0.06992557644844055\n",
            "Train step - Step 2780, Loss 0.06945379078388214\n",
            "Train step - Step 2790, Loss 0.06746865808963776\n",
            "Train step - Step 2800, Loss 0.07610302418470383\n",
            "Train epoch - Accuracy: 0.8043165467625899 Loss: 0.0699007533415616 Corrects: 5590\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.06465283036231995\n",
            "Train step - Step 2820, Loss 0.0650763213634491\n",
            "Train step - Step 2830, Loss 0.06271997839212418\n",
            "Train step - Step 2840, Loss 0.0654720664024353\n",
            "Train step - Step 2850, Loss 0.06934919208288193\n",
            "Train epoch - Accuracy: 0.8071942446043165 Loss: 0.06834715443978207 Corrects: 5610\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.05856287479400635\n",
            "Train step - Step 2870, Loss 0.06312396377325058\n",
            "Train step - Step 2880, Loss 0.06774598360061646\n",
            "Train step - Step 2890, Loss 0.06349124759435654\n",
            "Train step - Step 2900, Loss 0.07012271136045456\n",
            "Train step - Step 2910, Loss 0.06908047199249268\n",
            "Train epoch - Accuracy: 0.8084892086330935 Loss: 0.06854770457787479 Corrects: 5619\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.06575459986925125\n",
            "Train step - Step 2930, Loss 0.06732499599456787\n",
            "Train step - Step 2940, Loss 0.0692911297082901\n",
            "Train step - Step 2950, Loss 0.07999482750892639\n",
            "Train step - Step 2960, Loss 0.0641644299030304\n",
            "Train epoch - Accuracy: 0.8092086330935252 Loss: 0.06826628792843373 Corrects: 5624\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.06558253616094589\n",
            "Train step - Step 2980, Loss 0.061687495559453964\n",
            "Train step - Step 2990, Loss 0.06372322142124176\n",
            "Train step - Step 3000, Loss 0.06796710938215256\n",
            "Train step - Step 3010, Loss 0.07104261219501495\n",
            "Train step - Step 3020, Loss 0.07268769294023514\n",
            "Train epoch - Accuracy: 0.8145323741007194 Loss: 0.06840056559164748 Corrects: 5661\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.07101383060216904\n",
            "Train step - Step 3040, Loss 0.057972200214862823\n",
            "Train step - Step 3050, Loss 0.07201194763183594\n",
            "Train step - Step 3060, Loss 0.06074795126914978\n",
            "Train step - Step 3070, Loss 0.0746191143989563\n",
            "Train epoch - Accuracy: 0.8172661870503597 Loss: 0.0678599736437523 Corrects: 5680\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.060356177389621735\n",
            "Train step - Step 3090, Loss 0.06626743823289871\n",
            "Train step - Step 3100, Loss 0.07118469476699829\n",
            "Train step - Step 3110, Loss 0.06648870557546616\n",
            "Train step - Step 3120, Loss 0.07069078832864761\n",
            "Train step - Step 3130, Loss 0.06213439628481865\n",
            "Train epoch - Accuracy: 0.8159712230215828 Loss: 0.06778279125904865 Corrects: 5671\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.07424994558095932\n",
            "Train step - Step 3150, Loss 0.06541550904512405\n",
            "Train step - Step 3160, Loss 0.06635861843824387\n",
            "Train step - Step 3170, Loss 0.06651591509580612\n",
            "Train step - Step 3180, Loss 0.08002698421478271\n",
            "Train epoch - Accuracy: 0.8156834532374101 Loss: 0.06730531203017819 Corrects: 5669\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.06424734741449356\n",
            "Train step - Step 3200, Loss 0.07441460341215134\n",
            "Train step - Step 3210, Loss 0.06511198729276657\n",
            "Train step - Step 3220, Loss 0.06526430696249008\n",
            "Train step - Step 3230, Loss 0.0713106021285057\n",
            "Train step - Step 3240, Loss 0.07323458045721054\n",
            "Train epoch - Accuracy: 0.8218705035971223 Loss: 0.06685195200306049 Corrects: 5712\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.06926721334457397\n",
            "Train step - Step 3260, Loss 0.06381057947874069\n",
            "Train step - Step 3270, Loss 0.07590257376432419\n",
            "Train step - Step 3280, Loss 0.07271124422550201\n",
            "Train step - Step 3290, Loss 0.06532203406095505\n",
            "Train epoch - Accuracy: 0.8197122302158273 Loss: 0.06739946644940822 Corrects: 5697\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.06773592531681061\n",
            "Train step - Step 3310, Loss 0.06586019694805145\n",
            "Train step - Step 3320, Loss 0.06029285117983818\n",
            "Train step - Step 3330, Loss 0.06461337953805923\n",
            "Train step - Step 3340, Loss 0.06919544190168381\n",
            "Train step - Step 3350, Loss 0.06532362848520279\n",
            "Train epoch - Accuracy: 0.8211510791366906 Loss: 0.06739989785196113 Corrects: 5707\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.06816557049751282\n",
            "Train step - Step 3370, Loss 0.06540684401988983\n",
            "Train step - Step 3380, Loss 0.06396946310997009\n",
            "Train step - Step 3390, Loss 0.0630120262503624\n",
            "Train step - Step 3400, Loss 0.06271857023239136\n",
            "Train epoch - Accuracy: 0.8153956834532374 Loss: 0.06667114208070495 Corrects: 5667\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.06853705644607544\n",
            "Train step - Step 3420, Loss 0.0650898814201355\n",
            "Train step - Step 3430, Loss 0.07230563461780548\n",
            "Train step - Step 3440, Loss 0.06279322504997253\n",
            "Train step - Step 3450, Loss 0.0724271684885025\n",
            "Train step - Step 3460, Loss 0.06262276321649551\n",
            "Train epoch - Accuracy: 0.8211510791366906 Loss: 0.06674409091258221 Corrects: 5707\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.06968171894550323\n",
            "Train step - Step 3480, Loss 0.0686718001961708\n",
            "Train step - Step 3490, Loss 0.07032584398984909\n",
            "Train step - Step 3500, Loss 0.0670204907655716\n",
            "Train step - Step 3510, Loss 0.06686713546514511\n",
            "Train epoch - Accuracy: 0.8271942446043166 Loss: 0.06620076637902705 Corrects: 5749\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.05819754675030708\n",
            "Train step - Step 3530, Loss 0.0644274652004242\n",
            "Train step - Step 3540, Loss 0.06751081347465515\n",
            "Train step - Step 3550, Loss 0.06048911437392235\n",
            "Train step - Step 3560, Loss 0.06766422092914581\n",
            "Train step - Step 3570, Loss 0.06594592332839966\n",
            "Train epoch - Accuracy: 0.8290647482014388 Loss: 0.06519553962478535 Corrects: 5762\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.06408502906560898\n",
            "Train step - Step 3590, Loss 0.06563837826251984\n",
            "Train step - Step 3600, Loss 0.06697627156972885\n",
            "Train step - Step 3610, Loss 0.06838872283697128\n",
            "Train step - Step 3620, Loss 0.06356824934482574\n",
            "Train epoch - Accuracy: 0.8260431654676259 Loss: 0.065763808743988 Corrects: 5741\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.05880674347281456\n",
            "Train step - Step 3640, Loss 0.06359174102544785\n",
            "Train step - Step 3650, Loss 0.06407752633094788\n",
            "Train step - Step 3660, Loss 0.06817223131656647\n",
            "Train step - Step 3670, Loss 0.06970172375440598\n",
            "Train step - Step 3680, Loss 0.06397707015275955\n",
            "Train epoch - Accuracy: 0.8254676258992806 Loss: 0.06539061366439723 Corrects: 5737\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.06609030812978745\n",
            "Train step - Step 3700, Loss 0.06462076306343079\n",
            "Train step - Step 3710, Loss 0.0636807233095169\n",
            "Train step - Step 3720, Loss 0.06091834232211113\n",
            "Train step - Step 3730, Loss 0.06928621977567673\n",
            "Train epoch - Accuracy: 0.8253237410071942 Loss: 0.06503866654077022 Corrects: 5736\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.060604359954595566\n",
            "Train step - Step 3750, Loss 0.06737404316663742\n",
            "Train step - Step 3760, Loss 0.05941007286310196\n",
            "Train step - Step 3770, Loss 0.06571996212005615\n",
            "Train step - Step 3780, Loss 0.06390087306499481\n",
            "Train step - Step 3790, Loss 0.06828572601079941\n",
            "Train epoch - Accuracy: 0.8227338129496403 Loss: 0.06526829861908508 Corrects: 5718\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.07152523845434189\n",
            "Train step - Step 3810, Loss 0.06667063385248184\n",
            "Train step - Step 3820, Loss 0.07079432159662247\n",
            "Train step - Step 3830, Loss 0.059563010931015015\n",
            "Train step - Step 3840, Loss 0.057845354080200195\n",
            "Train epoch - Accuracy: 0.8323741007194244 Loss: 0.06455218589134354 Corrects: 5785\n",
            "Training finished in 439.93826842308044 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16]\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  100\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710360210>\n",
            "Constructing exemplars of class 79\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [41564, 39830, 39726, 40565, 18210, 40366, 2617, 26936, 34348, 21796, 30696, 33929, 39611, 20202, 184, 38725, 47689, 41846, 35035, 29058, 30418, 5594, 47983, 32281, 46531, 10141, 45237, 37142, 9793, 42616, 49842, 12059, 9716, 18041, 1317, 12646, 35987, 37280, 16069, 8939, 26911, 16517, 5962, 42215, 44563, 22499, 38514, 18041, 36864, 23084, 42616, 47158, 30501, 4237, 21209, 28063, 44087, 48347, 3493, 23672, 28242, 1710, 49648, 25004, 18647, 1667, 9409, 10266, 30021, 34009, 32010, 21411, 504, 42184, 236, 31173, 32726, 48869, 19035, 42275, 6742, 12808, 44350, 49142, 32547, 38515, 6742, 42823, 44724, 19018, 26811, 5404, 11863, 47795, 41497, 47733, 19003, 7016, 10631, 5485]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b30ad0>\n",
            "Constructing exemplars of class 47\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [1620, 19937, 25597, 9529, 41171, 33014, 42584, 45703, 25361, 5369, 45938, 20152, 45130, 28634, 9227, 26618, 32828, 44779, 2470, 4645, 38086, 31553, 27741, 17000, 35751, 36842, 43061, 16867, 37911, 34621, 42078, 11823, 47992, 3659, 14885, 2278, 22837, 30680, 21846, 8037, 25919, 41117, 22837, 6169, 47931, 28346, 22289, 49150, 16253, 43207, 16329, 9876, 26203, 16605, 37911, 48147, 46217, 38231, 29891, 8037, 4240, 9384, 5134, 22495, 13301, 45028, 15074, 20873, 39661, 40763, 4240, 35554, 6704, 20906, 3659, 28400, 41055, 8844, 23326, 28027, 14296, 2800, 7607, 39797, 32268, 3327, 14043, 10245, 24190, 20152, 21317, 36131, 40579, 24080, 1665, 6704, 47598, 47707, 9511, 42902]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671049f350>\n",
            "Constructing exemplars of class 7\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [20284, 21893, 15699, 49939, 4572, 9765, 30918, 28243, 36222, 35960, 35159, 26002, 41071, 44860, 14470, 40343, 37460, 18441, 28079, 11540, 26031, 17791, 41100, 16537, 26394, 45434, 31684, 30772, 6138, 38132, 290, 31829, 44497, 34406, 41650, 10407, 39555, 31134, 10729, 15202, 8238, 2356, 24877, 46051, 42560, 7938, 16260, 24582, 44445, 10755, 3431, 49939, 34078, 22475, 44823, 9226, 7226, 48087, 5718, 2204, 20596, 40820, 4498, 44890, 40040, 5995, 20569, 25681, 19419, 3087, 31764, 7110, 24755, 41017, 19233, 19348, 48696, 42669, 45889, 16260, 47049, 11197, 10271, 28778, 24978, 44801, 46353, 31684, 35960, 29382, 37445, 44445, 1015, 42052, 18111, 15496, 40129, 44823, 30121, 15097]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671040f150>\n",
            "Constructing exemplars of class 82\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [9637, 12543, 48703, 34608, 16897, 24852, 26471, 42693, 6961, 5244, 31210, 24714, 34471, 47982, 29229, 27487, 28783, 44213, 34911, 34612, 31815, 6141, 11470, 41627, 362, 20497, 43442, 4419, 18922, 8581, 13546, 40083, 7959, 7334, 6570, 32449, 36631, 27063, 14398, 318, 49708, 45695, 8078, 362, 20824, 7471, 1136, 14832, 34911, 28488, 49838, 6961, 21973, 27297, 45853, 29348, 34608, 42656, 18922, 42485, 324, 47737, 45064, 34305, 47957, 1402, 42833, 42541, 42656, 29650, 4019, 14992, 26852, 10727, 35774, 22970, 40636, 38738, 26399, 27314, 28164, 35967, 31249, 19657, 10519, 14041, 38486, 38538, 5578, 7415, 16897, 18702, 10901, 30911, 31456, 28347, 22190, 7027, 1919, 34517]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67104f2310>\n",
            "Constructing exemplars of class 34\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [31068, 6188, 15179, 19814, 16944, 19009, 25992, 18745, 31323, 10666, 14233, 4292, 15614, 33735, 10643, 31527, 47121, 42158, 18893, 974, 27238, 22000, 27579, 31783, 41290, 5835, 21205, 31794, 47530, 20904, 31864, 43022, 25251, 24854, 48745, 39585, 40789, 36335, 24376, 34877, 30894, 1951, 49978, 41853, 3680, 13074, 38997, 28310, 29284, 49619, 42112, 19416, 42158, 42020, 16662, 26347, 21102, 24571, 15179, 32901, 26171, 40033, 9108, 13416, 14829, 26628, 8649, 41992, 45164, 34859, 31323, 15972, 34757, 18397, 12267, 15820, 43805, 2382, 48286, 25363, 32312, 33777, 16193, 439, 42093, 49724, 11804, 4901, 41290, 14699, 3773, 20338, 2699, 8949, 45766, 33633, 4001, 4091, 48468, 38997]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67229f6950>\n",
            "Constructing exemplars of class 81\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [45181, 9535, 4904, 12480, 10222, 15624, 49179, 37364, 46697, 14290, 34666, 31466, 17913, 42338, 21157, 24743, 48948, 27099, 12688, 48815, 21905, 2097, 37864, 28820, 36359, 14690, 35097, 40177, 25963, 673, 12246, 11135, 26606, 37917, 17913, 43450, 654, 47568, 24001, 1395, 675, 23360, 489, 44891, 26074, 37917, 33718, 44247, 19599, 6209, 39398, 25857, 36, 24640, 12523, 49742, 43892, 32821, 30920, 48255, 10042, 12195, 1481, 40563, 27886, 3335, 28820, 46366, 33428, 40218, 16336, 28913, 12751, 22025, 15308, 3344, 43537, 14235, 44247, 13014, 14809, 23171, 26045, 40369, 33323, 975, 22025, 14377, 40958, 29516, 11675, 1412, 23286, 48199, 25283, 28838, 35102, 48815, 47807, 25909]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67104500d0>\n",
            "Constructing exemplars of class 21\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [44505, 34948, 19576, 12784, 21686, 26707, 5849, 18479, 26773, 20365, 45167, 21758, 21611, 5105, 37900, 4455, 19977, 14614, 7159, 6991, 20694, 19083, 26790, 42653, 6585, 4610, 19647, 2695, 37378, 44233, 26623, 6432, 11981, 48668, 26154, 27406, 39655, 29113, 11210, 3722, 23522, 22629, 7092, 45710, 16014, 17038, 46760, 33967, 45961, 37128, 14579, 37046, 46315, 33008, 15103, 32344, 2738, 17657, 12272, 46772, 37146, 39490, 42274, 18761, 4765, 35403, 27935, 17038, 44550, 30927, 45356, 22795, 10202, 5381, 46772, 1702, 6663, 34637, 9433, 20031, 32923, 44955, 12784, 3277, 38141, 46014, 25205, 29474, 10284, 19919, 412, 32762, 10171, 37146, 2738, 3737, 35619, 32647, 32825, 45054]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103729d0>\n",
            "Constructing exemplars of class 80\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [41023, 11502, 35914, 43900, 39365, 9935, 38931, 19467, 26008, 15026, 33348, 1253, 28709, 32319, 17990, 1646, 24418, 4924, 39906, 40784, 20037, 22265, 20035, 11199, 42720, 16651, 10575, 26413, 1157, 8240, 22492, 1512, 684, 42206, 45678, 20035, 31568, 40844, 38761, 10175, 35071, 40823, 22336, 48490, 40550, 49357, 49861, 12061, 19563, 10575, 16591, 28987, 15339, 293, 20495, 2385, 24917, 25666, 32319, 22514, 14012, 32587, 27162, 49132, 35871, 17508, 24684, 23042, 20882, 41448, 12512, 12081, 47287, 26467, 23697, 20608, 25105, 30177, 40719, 19368, 45437, 24684, 2938, 30933, 2045, 43939, 10514, 30936, 1629, 42914, 13750, 684, 2364, 15106, 27586, 13998, 10094, 29368, 6459, 14954]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710316250>\n",
            "Constructing exemplars of class 68\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [37042, 2739, 47799, 5934, 43955, 23471, 47074, 8412, 11932, 454, 7963, 8951, 15046, 38288, 31749, 29473, 2956, 40793, 30834, 2740, 36703, 37232, 6929, 5121, 12826, 13880, 17077, 19380, 11225, 3208, 45013, 33270, 279, 3918, 43417, 5462, 26622, 34905, 5090, 41709, 7963, 21087, 47878, 24150, 22824, 24153, 20325, 1185, 38104, 19543, 5486, 42382, 44107, 16762, 5462, 20327, 39811, 43445, 45013, 30803, 19644, 20014, 2116, 41441, 16168, 35394, 13650, 13583, 19892, 43417, 18690, 37548, 13212, 46401, 49013, 27262, 30341, 47206, 32979, 24727, 20659, 13757, 7778, 22100, 9196, 2116, 13299, 9441, 8971, 12103, 2992, 10424, 14511, 11225, 37274, 31522, 37673, 15022, 13757, 46305]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103dfb50>\n",
            "Constructing exemplars of class 16\n",
            "lunghezza exemplar set:  100\n",
            "exemplar set:  [15164, 23122, 21566, 46580, 49045, 18608, 24744, 22451, 1252, 48643, 11699, 7199, 8633, 49045, 11616, 19760, 32995, 33920, 37286, 12909, 20636, 3382, 18042, 14182, 21595, 45932, 37757, 49118, 25118, 33489, 35111, 14785, 8890, 19234, 30569, 38638, 15164, 7514, 6972, 30175, 37198, 40625, 48125, 34670, 21900, 14785, 40815, 23965, 8929, 30078, 1300, 14309, 48907, 49654, 25541, 32613, 4046, 26475, 11595, 41823, 21082, 8120, 6965, 23380, 21953, 1300, 48576, 573, 7513, 781, 47601, 22162, 15979, 40773, 6965, 47939, 34546, 23056, 12256, 22825, 5285, 14447, 24199, 13413, 13543, 46056, 37324, 27967, 38638, 27220, 39815, 49544, 26760, 48125, 9548, 13639, 35798, 21718, 17743, 25135]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.58 0.14015503227710724\n",
            "TEST GROUP:  0.66\n",
            "TEST ALL:  0.7165\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  3000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [81, 79, 4, 10, 16, 18, 20, 22, 24, 32, 34, 56, 64, 68, 76, 80, 82, 90, 7, 21, 23, 39, 47, 49, 59, 61, 65, 67, 75, 0]\n",
            "TRAIN_SET CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "VALIDATION CLASSES:  [61, 32, 90, 24, 23, 76, 75, 10, 0, 64]\n",
            "GROUP:  3\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  30\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.3409467935562134\n",
            "Train step - Step 10, Loss 0.153070330619812\n",
            "Train step - Step 20, Loss 0.14892396330833435\n",
            "Train step - Step 30, Loss 0.12976868450641632\n",
            "Train step - Step 40, Loss 0.1251469999551773\n",
            "Train step - Step 50, Loss 0.12657961249351501\n",
            "Train epoch - Accuracy: 0.2745323741007194 Loss: 0.150538267617603 Corrects: 1908\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.11259935051202774\n",
            "Train step - Step 70, Loss 0.11831434816122055\n",
            "Train step - Step 80, Loss 0.11904024332761765\n",
            "Train step - Step 90, Loss 0.11372874677181244\n",
            "Train step - Step 100, Loss 0.1127871423959732\n",
            "Train epoch - Accuracy: 0.33366906474820146 Loss: 0.11700625240802764 Corrects: 2319\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.11460064351558685\n",
            "Train step - Step 120, Loss 0.10211878269910812\n",
            "Train step - Step 130, Loss 0.11749269813299179\n",
            "Train step - Step 140, Loss 0.12116251140832901\n",
            "Train step - Step 150, Loss 0.10644567757844925\n",
            "Train step - Step 160, Loss 0.10988987982273102\n",
            "Train epoch - Accuracy: 0.36489208633093523 Loss: 0.11370033440830038 Corrects: 2536\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11350405216217041\n",
            "Train step - Step 180, Loss 0.10643943399190903\n",
            "Train step - Step 190, Loss 0.11503305286169052\n",
            "Train step - Step 200, Loss 0.10642337054014206\n",
            "Train step - Step 210, Loss 0.10757850855588913\n",
            "Train epoch - Accuracy: 0.3920863309352518 Loss: 0.11132397944978673 Corrects: 2725\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1084180623292923\n",
            "Train step - Step 230, Loss 0.11619293689727783\n",
            "Train step - Step 240, Loss 0.11086755245923996\n",
            "Train step - Step 250, Loss 0.11032827943563461\n",
            "Train step - Step 260, Loss 0.11046809703111649\n",
            "Train step - Step 270, Loss 0.11201515793800354\n",
            "Train epoch - Accuracy: 0.4112230215827338 Loss: 0.10994824396620552 Corrects: 2858\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.10520680993795395\n",
            "Train step - Step 290, Loss 0.1189066618680954\n",
            "Train step - Step 300, Loss 0.11217261850833893\n",
            "Train step - Step 310, Loss 0.10612546652555466\n",
            "Train step - Step 320, Loss 0.1128220334649086\n",
            "Train epoch - Accuracy: 0.4283453237410072 Loss: 0.10870002591567074 Corrects: 2977\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.09820321202278137\n",
            "Train step - Step 340, Loss 0.10844370722770691\n",
            "Train step - Step 350, Loss 0.1093023344874382\n",
            "Train step - Step 360, Loss 0.1044093519449234\n",
            "Train step - Step 370, Loss 0.1131170392036438\n",
            "Train step - Step 380, Loss 0.10501622408628464\n",
            "Train epoch - Accuracy: 0.44359712230215825 Loss: 0.10709034458982002 Corrects: 3083\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11422382295131683\n",
            "Train step - Step 400, Loss 0.09846704453229904\n",
            "Train step - Step 410, Loss 0.10771044343709946\n",
            "Train step - Step 420, Loss 0.10025864094495773\n",
            "Train step - Step 430, Loss 0.10754399746656418\n",
            "Train epoch - Accuracy: 0.4618705035971223 Loss: 0.10619808524632625 Corrects: 3210\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.10803579539060593\n",
            "Train step - Step 450, Loss 0.10990291088819504\n",
            "Train step - Step 460, Loss 0.10326755046844482\n",
            "Train step - Step 470, Loss 0.10606628656387329\n",
            "Train step - Step 480, Loss 0.10168905556201935\n",
            "Train step - Step 490, Loss 0.1047188937664032\n",
            "Train epoch - Accuracy: 0.4684892086330935 Loss: 0.10576227411091757 Corrects: 3256\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.11604534834623337\n",
            "Train step - Step 510, Loss 0.10210105776786804\n",
            "Train step - Step 520, Loss 0.10857749730348587\n",
            "Train step - Step 530, Loss 0.10287076979875565\n",
            "Train step - Step 540, Loss 0.1093485876917839\n",
            "Train epoch - Accuracy: 0.4833093525179856 Loss: 0.10422920169590189 Corrects: 3359\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.10720892250537872\n",
            "Train step - Step 560, Loss 0.10792643576860428\n",
            "Train step - Step 570, Loss 0.10592001676559448\n",
            "Train step - Step 580, Loss 0.09952408820390701\n",
            "Train step - Step 590, Loss 0.1067153736948967\n",
            "Train step - Step 600, Loss 0.10005053132772446\n",
            "Train epoch - Accuracy: 0.4948201438848921 Loss: 0.10385083526158505 Corrects: 3439\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.10766860842704773\n",
            "Train step - Step 620, Loss 0.10040384531021118\n",
            "Train step - Step 630, Loss 0.09550050646066666\n",
            "Train step - Step 640, Loss 0.10021453350782394\n",
            "Train step - Step 650, Loss 0.10871180146932602\n",
            "Train epoch - Accuracy: 0.5004316546762589 Loss: 0.10353958063417201 Corrects: 3478\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.09426068514585495\n",
            "Train step - Step 670, Loss 0.1053084135055542\n",
            "Train step - Step 680, Loss 0.10786851495504379\n",
            "Train step - Step 690, Loss 0.09771815687417984\n",
            "Train step - Step 700, Loss 0.09602540731430054\n",
            "Train step - Step 710, Loss 0.11469512432813644\n",
            "Train epoch - Accuracy: 0.5133812949640287 Loss: 0.10238391092784113 Corrects: 3568\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.11043563485145569\n",
            "Train step - Step 730, Loss 0.10746344178915024\n",
            "Train step - Step 740, Loss 0.10221481323242188\n",
            "Train step - Step 750, Loss 0.10153763741254807\n",
            "Train step - Step 760, Loss 0.10632812976837158\n",
            "Train epoch - Accuracy: 0.5223021582733813 Loss: 0.1022195346921468 Corrects: 3630\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.10586909204721451\n",
            "Train step - Step 780, Loss 0.10054343938827515\n",
            "Train step - Step 790, Loss 0.0997200533747673\n",
            "Train step - Step 800, Loss 0.0940234363079071\n",
            "Train step - Step 810, Loss 0.11057069152593613\n",
            "Train step - Step 820, Loss 0.10828184336423874\n",
            "Train epoch - Accuracy: 0.5293525179856116 Loss: 0.10062151117290524 Corrects: 3679\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.105894073843956\n",
            "Train step - Step 840, Loss 0.09759275615215302\n",
            "Train step - Step 850, Loss 0.0966937318444252\n",
            "Train step - Step 860, Loss 0.11154953390359879\n",
            "Train step - Step 870, Loss 0.10835661739110947\n",
            "Train epoch - Accuracy: 0.539136690647482 Loss: 0.1009604947022397 Corrects: 3747\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.10360237210988998\n",
            "Train step - Step 890, Loss 0.098972387611866\n",
            "Train step - Step 900, Loss 0.09520029276609421\n",
            "Train step - Step 910, Loss 0.10253294557332993\n",
            "Train step - Step 920, Loss 0.10562191903591156\n",
            "Train step - Step 930, Loss 0.1016276404261589\n",
            "Train epoch - Accuracy: 0.5444604316546763 Loss: 0.10031065046787262 Corrects: 3784\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.0933457612991333\n",
            "Train step - Step 950, Loss 0.09745591878890991\n",
            "Train step - Step 960, Loss 0.09467268735170364\n",
            "Train step - Step 970, Loss 0.09653209894895554\n",
            "Train step - Step 980, Loss 0.0963243693113327\n",
            "Train epoch - Accuracy: 0.5483453237410072 Loss: 0.09970166919257144 Corrects: 3811\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10056944191455841\n",
            "Train step - Step 1000, Loss 0.10168081521987915\n",
            "Train step - Step 1010, Loss 0.09200707077980042\n",
            "Train step - Step 1020, Loss 0.0952792763710022\n",
            "Train step - Step 1030, Loss 0.09874369949102402\n",
            "Train step - Step 1040, Loss 0.095644511282444\n",
            "Train epoch - Accuracy: 0.5548201438848921 Loss: 0.09904812450460393 Corrects: 3856\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.09704276919364929\n",
            "Train step - Step 1060, Loss 0.097834512591362\n",
            "Train step - Step 1070, Loss 0.10363142937421799\n",
            "Train step - Step 1080, Loss 0.0889107957482338\n",
            "Train step - Step 1090, Loss 0.09996850788593292\n",
            "Train epoch - Accuracy: 0.5673381294964028 Loss: 0.09894004810413869 Corrects: 3943\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.09458160400390625\n",
            "Train step - Step 1110, Loss 0.10283287614583969\n",
            "Train step - Step 1120, Loss 0.09435886144638062\n",
            "Train step - Step 1130, Loss 0.10702428221702576\n",
            "Train step - Step 1140, Loss 0.09864599257707596\n",
            "Train step - Step 1150, Loss 0.10366123914718628\n",
            "Train epoch - Accuracy: 0.5657553956834532 Loss: 0.09808571035270211 Corrects: 3932\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.1018456444144249\n",
            "Train step - Step 1170, Loss 0.10464279353618622\n",
            "Train step - Step 1180, Loss 0.10057362914085388\n",
            "Train step - Step 1190, Loss 0.08820896595716476\n",
            "Train step - Step 1200, Loss 0.0917765200138092\n",
            "Train epoch - Accuracy: 0.5742446043165468 Loss: 0.09859135447003001 Corrects: 3991\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.09780175983905792\n",
            "Train step - Step 1220, Loss 0.10189468413591385\n",
            "Train step - Step 1230, Loss 0.09008293598890305\n",
            "Train step - Step 1240, Loss 0.09674493223428726\n",
            "Train step - Step 1250, Loss 0.10019087046384811\n",
            "Train step - Step 1260, Loss 0.0994533821940422\n",
            "Train epoch - Accuracy: 0.5854676258992806 Loss: 0.09773678657176683 Corrects: 4069\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.09687232226133347\n",
            "Train step - Step 1280, Loss 0.0896090418100357\n",
            "Train step - Step 1290, Loss 0.08925309032201767\n",
            "Train step - Step 1300, Loss 0.09763383120298386\n",
            "Train step - Step 1310, Loss 0.0958915501832962\n",
            "Train epoch - Accuracy: 0.5899280575539568 Loss: 0.09672175955429352 Corrects: 4100\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.09521827101707458\n",
            "Train step - Step 1330, Loss 0.09802275896072388\n",
            "Train step - Step 1340, Loss 0.10096019506454468\n",
            "Train step - Step 1350, Loss 0.09394922107458115\n",
            "Train step - Step 1360, Loss 0.08974010497331619\n",
            "Train step - Step 1370, Loss 0.09418753534555435\n",
            "Train epoch - Accuracy: 0.5886330935251799 Loss: 0.09636643111920186 Corrects: 4091\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.0949755385518074\n",
            "Train step - Step 1390, Loss 0.09423132240772247\n",
            "Train step - Step 1400, Loss 0.0977214053273201\n",
            "Train step - Step 1410, Loss 0.09396806359291077\n",
            "Train step - Step 1420, Loss 0.09740562736988068\n",
            "Train epoch - Accuracy: 0.5920863309352518 Loss: 0.09695981617454144 Corrects: 4115\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.09729383140802383\n",
            "Train step - Step 1440, Loss 0.1000463217496872\n",
            "Train step - Step 1450, Loss 0.09069608896970749\n",
            "Train step - Step 1460, Loss 0.09706844389438629\n",
            "Train step - Step 1470, Loss 0.10095620155334473\n",
            "Train step - Step 1480, Loss 0.0914548709988594\n",
            "Train epoch - Accuracy: 0.6046043165467626 Loss: 0.09591510263063925 Corrects: 4202\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.0945138931274414\n",
            "Train step - Step 1500, Loss 0.09573771059513092\n",
            "Train step - Step 1510, Loss 0.09498703479766846\n",
            "Train step - Step 1520, Loss 0.08924487978219986\n",
            "Train step - Step 1530, Loss 0.09400101751089096\n",
            "Train epoch - Accuracy: 0.599568345323741 Loss: 0.0957784480306742 Corrects: 4167\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.09254422783851624\n",
            "Train step - Step 1550, Loss 0.09641727805137634\n",
            "Train step - Step 1560, Loss 0.09505928307771683\n",
            "Train step - Step 1570, Loss 0.09694474190473557\n",
            "Train step - Step 1580, Loss 0.09080925583839417\n",
            "Train step - Step 1590, Loss 0.10084140300750732\n",
            "Train epoch - Accuracy: 0.6133812949640288 Loss: 0.09539351501481996 Corrects: 4263\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.09648875892162323\n",
            "Train step - Step 1610, Loss 0.09127505123615265\n",
            "Train step - Step 1620, Loss 0.0925111323595047\n",
            "Train step - Step 1630, Loss 0.10628456622362137\n",
            "Train step - Step 1640, Loss 0.09831400215625763\n",
            "Train epoch - Accuracy: 0.6132374100719424 Loss: 0.09520942845790506 Corrects: 4262\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.09523618221282959\n",
            "Train step - Step 1660, Loss 0.08946498483419418\n",
            "Train step - Step 1670, Loss 0.09304837137460709\n",
            "Train step - Step 1680, Loss 0.08978328853845596\n",
            "Train step - Step 1690, Loss 0.09445752948522568\n",
            "Train step - Step 1700, Loss 0.09366364777088165\n",
            "Train epoch - Accuracy: 0.6257553956834533 Loss: 0.09461702149334571 Corrects: 4349\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.09546326845884323\n",
            "Train step - Step 1720, Loss 0.10683779418468475\n",
            "Train step - Step 1730, Loss 0.09807473421096802\n",
            "Train step - Step 1740, Loss 0.10030294209718704\n",
            "Train step - Step 1750, Loss 0.09999458491802216\n",
            "Train epoch - Accuracy: 0.623453237410072 Loss: 0.0941597245751525 Corrects: 4333\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.08794412016868591\n",
            "Train step - Step 1770, Loss 0.08693306148052216\n",
            "Train step - Step 1780, Loss 0.09285303205251694\n",
            "Train step - Step 1790, Loss 0.09806106239557266\n",
            "Train step - Step 1800, Loss 0.09047635644674301\n",
            "Train step - Step 1810, Loss 0.09162858128547668\n",
            "Train epoch - Accuracy: 0.6353956834532374 Loss: 0.09335293205093137 Corrects: 4416\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.1002415344119072\n",
            "Train step - Step 1830, Loss 0.08845985680818558\n",
            "Train step - Step 1840, Loss 0.09244389832019806\n",
            "Train step - Step 1850, Loss 0.08396690338850021\n",
            "Train step - Step 1860, Loss 0.09720615297555923\n",
            "Train epoch - Accuracy: 0.6270503597122302 Loss: 0.0944011425650377 Corrects: 4358\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.08733118325471878\n",
            "Train step - Step 1880, Loss 0.09934128075838089\n",
            "Train step - Step 1890, Loss 0.09466733783483505\n",
            "Train step - Step 1900, Loss 0.10015520453453064\n",
            "Train step - Step 1910, Loss 0.09211350232362747\n",
            "Train step - Step 1920, Loss 0.08737093955278397\n",
            "Train epoch - Accuracy: 0.6371223021582734 Loss: 0.09342150056748082 Corrects: 4428\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.09100854396820068\n",
            "Train step - Step 1940, Loss 0.09854273498058319\n",
            "Train step - Step 1950, Loss 0.0913332998752594\n",
            "Train step - Step 1960, Loss 0.0963478833436966\n",
            "Train step - Step 1970, Loss 0.09080161154270172\n",
            "Train epoch - Accuracy: 0.6394244604316547 Loss: 0.09321291053252255 Corrects: 4444\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.08769720047712326\n",
            "Train step - Step 1990, Loss 0.09771998226642609\n",
            "Train step - Step 2000, Loss 0.09914770722389221\n",
            "Train step - Step 2010, Loss 0.08889715373516083\n",
            "Train step - Step 2020, Loss 0.09407368302345276\n",
            "Train step - Step 2030, Loss 0.08668062090873718\n",
            "Train epoch - Accuracy: 0.6502158273381295 Loss: 0.09254370395442564 Corrects: 4519\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.0895816907286644\n",
            "Train step - Step 2050, Loss 0.09040554612874985\n",
            "Train step - Step 2060, Loss 0.08720426261425018\n",
            "Train step - Step 2070, Loss 0.08995255082845688\n",
            "Train step - Step 2080, Loss 0.0966920405626297\n",
            "Train epoch - Accuracy: 0.6496402877697842 Loss: 0.09271009296178817 Corrects: 4515\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.09684057533740997\n",
            "Train step - Step 2100, Loss 0.09798089414834976\n",
            "Train step - Step 2110, Loss 0.08559814095497131\n",
            "Train step - Step 2120, Loss 0.08666975051164627\n",
            "Train step - Step 2130, Loss 0.09219571202993393\n",
            "Train step - Step 2140, Loss 0.08659422397613525\n",
            "Train epoch - Accuracy: 0.6589928057553956 Loss: 0.09230304971873332 Corrects: 4580\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.0971929281949997\n",
            "Train step - Step 2160, Loss 0.0953984260559082\n",
            "Train step - Step 2170, Loss 0.0998692736029625\n",
            "Train step - Step 2180, Loss 0.09989449381828308\n",
            "Train step - Step 2190, Loss 0.09480495750904083\n",
            "Train epoch - Accuracy: 0.6594244604316547 Loss: 0.0927677576147395 Corrects: 4583\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09639255702495575\n",
            "Train step - Step 2210, Loss 0.08685128390789032\n",
            "Train step - Step 2220, Loss 0.09821102023124695\n",
            "Train step - Step 2230, Loss 0.09320520609617233\n",
            "Train step - Step 2240, Loss 0.08526866137981415\n",
            "Train step - Step 2250, Loss 0.09727463871240616\n",
            "Train epoch - Accuracy: 0.6686330935251799 Loss: 0.09157377145916439 Corrects: 4647\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.08477967977523804\n",
            "Train step - Step 2270, Loss 0.08672540634870529\n",
            "Train step - Step 2280, Loss 0.09208159893751144\n",
            "Train step - Step 2290, Loss 0.09516353905200958\n",
            "Train step - Step 2300, Loss 0.08262511342763901\n",
            "Train epoch - Accuracy: 0.6712230215827338 Loss: 0.09131975507564682 Corrects: 4665\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.09373755753040314\n",
            "Train step - Step 2320, Loss 0.0840066522359848\n",
            "Train step - Step 2330, Loss 0.08580611646175385\n",
            "Train step - Step 2340, Loss 0.08510737866163254\n",
            "Train step - Step 2350, Loss 0.0832962617278099\n",
            "Train step - Step 2360, Loss 0.08871528506278992\n",
            "Train epoch - Accuracy: 0.6733812949640288 Loss: 0.09084307215411029 Corrects: 4680\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.08547129482030869\n",
            "Train step - Step 2380, Loss 0.10497505217790604\n",
            "Train step - Step 2390, Loss 0.09594814479351044\n",
            "Train step - Step 2400, Loss 0.0869155079126358\n",
            "Train step - Step 2410, Loss 0.08868437260389328\n",
            "Train epoch - Accuracy: 0.6686330935251799 Loss: 0.09132201020666164 Corrects: 4647\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.08695726096630096\n",
            "Train step - Step 2430, Loss 0.09601904451847076\n",
            "Train step - Step 2440, Loss 0.09159565716981888\n",
            "Train step - Step 2450, Loss 0.09069231897592545\n",
            "Train step - Step 2460, Loss 0.09334859997034073\n",
            "Train step - Step 2470, Loss 0.0943150445818901\n",
            "Train epoch - Accuracy: 0.679136690647482 Loss: 0.0907842176959669 Corrects: 4720\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.09283199906349182\n",
            "Train step - Step 2490, Loss 0.08580261468887329\n",
            "Train step - Step 2500, Loss 0.09380844980478287\n",
            "Train step - Step 2510, Loss 0.08613249659538269\n",
            "Train step - Step 2520, Loss 0.09571930766105652\n",
            "Train epoch - Accuracy: 0.6837410071942446 Loss: 0.09024169328615819 Corrects: 4752\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.08745089173316956\n",
            "Train step - Step 2540, Loss 0.09968645125627518\n",
            "Train step - Step 2550, Loss 0.09582921862602234\n",
            "Train step - Step 2560, Loss 0.08440126478672028\n",
            "Train step - Step 2570, Loss 0.09668870270252228\n",
            "Train step - Step 2580, Loss 0.09098497033119202\n",
            "Train epoch - Accuracy: 0.6792805755395683 Loss: 0.08955877099320185 Corrects: 4721\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.0883491113781929\n",
            "Train step - Step 2600, Loss 0.08459200710058212\n",
            "Train step - Step 2610, Loss 0.08929219841957092\n",
            "Train step - Step 2620, Loss 0.08487842977046967\n",
            "Train step - Step 2630, Loss 0.0846322551369667\n",
            "Train epoch - Accuracy: 0.6792805755395683 Loss: 0.09014680053261544 Corrects: 4721\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.08850856870412827\n",
            "Train step - Step 2650, Loss 0.09517098218202591\n",
            "Train step - Step 2660, Loss 0.0973636731505394\n",
            "Train step - Step 2670, Loss 0.08947452157735825\n",
            "Train step - Step 2680, Loss 0.09582880139350891\n",
            "Train step - Step 2690, Loss 0.08560404926538467\n",
            "Train epoch - Accuracy: 0.6966906474820144 Loss: 0.08990806649271532 Corrects: 4842\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.08534368127584457\n",
            "Train step - Step 2710, Loss 0.08376237004995346\n",
            "Train step - Step 2720, Loss 0.08115004003047943\n",
            "Train step - Step 2730, Loss 0.08487684279680252\n",
            "Train step - Step 2740, Loss 0.08810592442750931\n",
            "Train epoch - Accuracy: 0.7025899280575539 Loss: 0.087273493623562 Corrects: 4883\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.0883171558380127\n",
            "Train step - Step 2760, Loss 0.08238063007593155\n",
            "Train step - Step 2770, Loss 0.08262799680233002\n",
            "Train step - Step 2780, Loss 0.08237393200397491\n",
            "Train step - Step 2790, Loss 0.08768471330404282\n",
            "Train step - Step 2800, Loss 0.08951259404420853\n",
            "Train epoch - Accuracy: 0.7070503597122302 Loss: 0.08590063390971946 Corrects: 4914\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.08073187619447708\n",
            "Train step - Step 2820, Loss 0.09097033739089966\n",
            "Train step - Step 2830, Loss 0.08456700295209885\n",
            "Train step - Step 2840, Loss 0.08257001638412476\n",
            "Train step - Step 2850, Loss 0.09192513674497604\n",
            "Train epoch - Accuracy: 0.7125179856115108 Loss: 0.08606891719342993 Corrects: 4952\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.08151163160800934\n",
            "Train step - Step 2870, Loss 0.08210249990224838\n",
            "Train step - Step 2880, Loss 0.0887710377573967\n",
            "Train step - Step 2890, Loss 0.08944550156593323\n",
            "Train step - Step 2900, Loss 0.07530427724123001\n",
            "Train step - Step 2910, Loss 0.08585970848798752\n",
            "Train epoch - Accuracy: 0.7115107913669064 Loss: 0.08569748369266661 Corrects: 4945\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.0902312770485878\n",
            "Train step - Step 2930, Loss 0.08059888333082199\n",
            "Train step - Step 2940, Loss 0.08414725214242935\n",
            "Train step - Step 2950, Loss 0.08906755596399307\n",
            "Train step - Step 2960, Loss 0.08397037535905838\n",
            "Train epoch - Accuracy: 0.7135251798561151 Loss: 0.08561910612120045 Corrects: 4959\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.08933091163635254\n",
            "Train step - Step 2980, Loss 0.08330123871564865\n",
            "Train step - Step 2990, Loss 0.08195909112691879\n",
            "Train step - Step 3000, Loss 0.08510653674602509\n",
            "Train step - Step 3010, Loss 0.0907910168170929\n",
            "Train step - Step 3020, Loss 0.08407552540302277\n",
            "Train epoch - Accuracy: 0.7117985611510791 Loss: 0.08560928443996169 Corrects: 4947\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.08222973346710205\n",
            "Train step - Step 3040, Loss 0.09486712515354156\n",
            "Train step - Step 3050, Loss 0.08622193336486816\n",
            "Train step - Step 3060, Loss 0.08691368252038956\n",
            "Train step - Step 3070, Loss 0.0834992304444313\n",
            "Train epoch - Accuracy: 0.7185611510791367 Loss: 0.08523131989317832 Corrects: 4994\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.08789122849702835\n",
            "Train step - Step 3090, Loss 0.08044229447841644\n",
            "Train step - Step 3100, Loss 0.08153939247131348\n",
            "Train step - Step 3110, Loss 0.08810923993587494\n",
            "Train step - Step 3120, Loss 0.0864611491560936\n",
            "Train step - Step 3130, Loss 0.08764053136110306\n",
            "Train epoch - Accuracy: 0.7210071942446044 Loss: 0.08497834074840271 Corrects: 5011\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.07964633405208588\n",
            "Train step - Step 3150, Loss 0.07547736912965775\n",
            "Train step - Step 3160, Loss 0.08887890726327896\n",
            "Train step - Step 3170, Loss 0.08724310249090195\n",
            "Train step - Step 3180, Loss 0.08784914761781693\n",
            "Train epoch - Accuracy: 0.7139568345323741 Loss: 0.08496080746110395 Corrects: 4962\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.08180804550647736\n",
            "Train step - Step 3200, Loss 0.08189470320940018\n",
            "Train step - Step 3210, Loss 0.08386509865522385\n",
            "Train step - Step 3220, Loss 0.08395737409591675\n",
            "Train step - Step 3230, Loss 0.08172006905078888\n",
            "Train step - Step 3240, Loss 0.08573101460933685\n",
            "Train epoch - Accuracy: 0.7132374100719424 Loss: 0.08508730203770905 Corrects: 4957\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.08549953252077103\n",
            "Train step - Step 3260, Loss 0.08066074550151825\n",
            "Train step - Step 3270, Loss 0.08929944783449173\n",
            "Train step - Step 3280, Loss 0.07595451921224594\n",
            "Train step - Step 3290, Loss 0.08655548840761185\n",
            "Train epoch - Accuracy: 0.718705035971223 Loss: 0.08519149671141192 Corrects: 4995\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.08912911266088486\n",
            "Train step - Step 3310, Loss 0.08438023924827576\n",
            "Train step - Step 3320, Loss 0.08318652212619781\n",
            "Train step - Step 3330, Loss 0.0839281678199768\n",
            "Train step - Step 3340, Loss 0.08169731497764587\n",
            "Train step - Step 3350, Loss 0.08006218820810318\n",
            "Train epoch - Accuracy: 0.7231654676258993 Loss: 0.08460567245166078 Corrects: 5026\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.08299387991428375\n",
            "Train step - Step 3370, Loss 0.08424121141433716\n",
            "Train step - Step 3380, Loss 0.08567528426647186\n",
            "Train step - Step 3390, Loss 0.082407146692276\n",
            "Train step - Step 3400, Loss 0.08546414971351624\n",
            "Train epoch - Accuracy: 0.720431654676259 Loss: 0.08518051713919468 Corrects: 5007\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.08587692677974701\n",
            "Train step - Step 3420, Loss 0.08777668327093124\n",
            "Train step - Step 3430, Loss 0.08388994634151459\n",
            "Train step - Step 3440, Loss 0.08712343126535416\n",
            "Train step - Step 3450, Loss 0.08617536723613739\n",
            "Train step - Step 3460, Loss 0.08577752858400345\n",
            "Train epoch - Accuracy: 0.7142446043165468 Loss: 0.08502689966623732 Corrects: 4964\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.08066406100988388\n",
            "Train step - Step 3480, Loss 0.08186468482017517\n",
            "Train step - Step 3490, Loss 0.0812549740076065\n",
            "Train step - Step 3500, Loss 0.08322954922914505\n",
            "Train step - Step 3510, Loss 0.08540743589401245\n",
            "Train epoch - Accuracy: 0.7146762589928057 Loss: 0.08446785230216362 Corrects: 4967\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.08740544319152832\n",
            "Train step - Step 3530, Loss 0.08315481245517731\n",
            "Train step - Step 3540, Loss 0.0828205868601799\n",
            "Train step - Step 3550, Loss 0.0791066363453865\n",
            "Train step - Step 3560, Loss 0.08175402134656906\n",
            "Train step - Step 3570, Loss 0.08083445578813553\n",
            "Train epoch - Accuracy: 0.7258992805755395 Loss: 0.084040332082793 Corrects: 5045\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.08379770070314407\n",
            "Train step - Step 3590, Loss 0.08154835551977158\n",
            "Train step - Step 3600, Loss 0.08495683968067169\n",
            "Train step - Step 3610, Loss 0.08990804105997086\n",
            "Train step - Step 3620, Loss 0.08113931119441986\n",
            "Train epoch - Accuracy: 0.7179856115107913 Loss: 0.08423319022861316 Corrects: 4990\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09053841978311539\n",
            "Train step - Step 3640, Loss 0.08295805007219315\n",
            "Train step - Step 3650, Loss 0.08340220898389816\n",
            "Train step - Step 3660, Loss 0.08563349395990372\n",
            "Train step - Step 3670, Loss 0.09024699777364731\n",
            "Train step - Step 3680, Loss 0.08264406770467758\n",
            "Train epoch - Accuracy: 0.7248920863309353 Loss: 0.08437882927681903 Corrects: 5038\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.08010430634021759\n",
            "Train step - Step 3700, Loss 0.08489792048931122\n",
            "Train step - Step 3710, Loss 0.08675914257764816\n",
            "Train step - Step 3720, Loss 0.08354219049215317\n",
            "Train step - Step 3730, Loss 0.08488620072603226\n",
            "Train epoch - Accuracy: 0.7205755395683453 Loss: 0.08390439118412758 Corrects: 5008\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.08620934933423996\n",
            "Train step - Step 3750, Loss 0.09162450581789017\n",
            "Train step - Step 3760, Loss 0.08812040090560913\n",
            "Train step - Step 3770, Loss 0.08245830237865448\n",
            "Train step - Step 3780, Loss 0.07858742773532867\n",
            "Train step - Step 3790, Loss 0.08647608757019043\n",
            "Train epoch - Accuracy: 0.7205755395683453 Loss: 0.08406873194219397 Corrects: 5008\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.08419010043144226\n",
            "Train step - Step 3810, Loss 0.08513304591178894\n",
            "Train step - Step 3820, Loss 0.0817616805434227\n",
            "Train step - Step 3830, Loss 0.08062185347080231\n",
            "Train step - Step 3840, Loss 0.08548856526613235\n",
            "Train epoch - Accuracy: 0.722589928057554 Loss: 0.08392173058266263 Corrects: 5022\n",
            "Training finished in 441.0208601951599 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0]\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  66\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237f8390>\n",
            "Constructing exemplars of class 75\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [33722, 6363, 46843, 15533, 7099, 21163, 17780, 38388, 37476, 5583, 14281, 461, 866, 31135, 41475, 25009, 24985, 24239, 34761, 6503, 40059, 41838, 47263, 46548, 35329, 15509, 38316, 27693, 37419, 24239, 32755, 22946, 25965, 25842, 29712, 9126, 47787, 35359, 36890, 21163, 49022, 9778, 12399, 42449, 36506, 49738, 39999, 34155, 35682, 26250, 14520, 31135, 19896, 37201, 42822, 1086, 32034, 46804, 31392, 24972, 24479, 33100, 24272, 959, 15154, 41838]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6789afce50>\n",
            "Constructing exemplars of class 23\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [11041, 22597, 4035, 40360, 21173, 31673, 9936, 40707, 443, 35753, 46614, 46058, 44880, 37360, 26168, 7436, 43538, 13518, 33316, 13816, 21033, 27017, 39696, 46614, 28911, 27431, 49695, 22597, 5463, 21926, 14230, 14857, 32040, 13290, 7436, 11721, 21797, 14482, 43889, 37243, 28534, 2889, 14234, 8479, 47331, 20602, 35431, 23575, 4242, 34522, 19252, 48501, 40707, 39463, 275, 19301, 43328, 8741, 15386, 46007, 10785, 40266, 3288, 32709, 42916, 38841]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671079add0>\n",
            "Constructing exemplars of class 90\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [4760, 22455, 10082, 44590, 23734, 41835, 26155, 23417, 45572, 45644, 10196, 33154, 12387, 1603, 31595, 25490, 42982, 41784, 46770, 11108, 14708, 7934, 10106, 7726, 1649, 34463, 15550, 26382, 24426, 14125, 10824, 45927, 37963, 42217, 6428, 40599, 18494, 3452, 10173, 38923, 25879, 41630, 27734, 6, 25941, 1074, 49468, 19408, 41835, 20362, 44403, 1074, 35260, 8418, 41330, 29670, 7934, 17339, 29956, 48248, 39041, 34781, 20518, 25809, 16673, 49007]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710388050>\n",
            "Constructing exemplars of class 10\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [11486, 38293, 4776, 13552, 19477, 47644, 7142, 328, 4642, 26126, 13554, 47995, 12703, 48762, 42371, 41459, 6426, 36990, 7142, 44875, 8456, 12759, 26550, 34524, 39855, 31504, 45195, 23112, 47552, 22586, 3198, 7179, 29099, 40448, 35787, 37647, 45216, 39934, 46313, 45942, 244, 14830, 26424, 39752, 17711, 17835, 36971, 29346, 14588, 24296, 40997, 22400, 47712, 41067, 33315, 32932, 46802, 48927, 19864, 17207, 41451, 13628, 30127, 37211, 45053, 39342]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103c5510>\n",
            "Constructing exemplars of class 61\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [14014, 34584, 39775, 44155, 27503, 39913, 35596, 22836, 13729, 48639, 26821, 33588, 21044, 13591, 49388, 30379, 44182, 27389, 8980, 19686, 10439, 30613, 29856, 43826, 45301, 32245, 27870, 37304, 45799, 18340, 39329, 17650, 7658, 10423, 27700, 22651, 6221, 35500, 32286, 6502, 31519, 18425, 40559, 16776, 1130, 12700, 26370, 1742, 47874, 12029, 3950, 15188, 38809, 38311, 34475, 35511, 43700, 30613, 4619, 3462, 13855, 18717, 32624, 24637, 17676, 6864]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671049fd10>\n",
            "Constructing exemplars of class 76\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [48950, 48282, 28994, 37631, 41064, 32418, 16131, 35857, 8999, 6049, 25164, 7190, 37394, 43161, 18579, 30823, 5773, 27027, 18942, 40340, 36458, 16181, 46486, 9014, 17230, 32606, 14176, 4781, 29249, 9750, 30238, 16531, 21013, 40164, 13412, 49606, 978, 40580, 14244, 15861, 36176, 15375, 40331, 20993, 17037, 4129, 14403, 18298, 32529, 21864, 34898, 22299, 49395, 35981, 1475, 13726, 49606, 17051, 20815, 38048, 3245, 39360, 16531, 40340, 6510, 35418]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710388050>\n",
            "Constructing exemplars of class 64\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [15892, 23192, 1810, 11000, 31832, 14718, 43449, 44366, 46137, 25362, 25855, 47856, 40089, 22374, 43028, 32457, 7605, 47777, 36726, 13590, 44394, 26582, 16312, 31708, 6633, 34735, 37856, 19241, 29372, 44105, 42565, 41621, 45957, 39670, 30197, 111, 14577, 6894, 39338, 9042, 34476, 1554, 33211, 13590, 22350, 42452, 45467, 1704, 37935, 1810, 30513, 26934, 43028, 46577, 7783, 2763, 13847, 42025, 4134, 24502, 44603, 38471, 24983, 41769, 26625, 45275]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67104224d0>\n",
            "Constructing exemplars of class 32\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [10492, 15379, 33467, 19262, 38597, 9818, 4520, 48183, 15096, 27883, 11167, 31407, 21854, 33263, 48637, 49272, 42237, 25345, 29140, 10156, 579, 2222, 32090, 121, 17343, 904, 6947, 45612, 39349, 23117, 33507, 33187, 3322, 49272, 14430, 38307, 21436, 4841, 20556, 27374, 23660, 26454, 16140, 40735, 27088, 25345, 33263, 34849, 35948, 4048, 38454, 40113, 7249, 35156, 38389, 26260, 27477, 15489, 23088, 26534, 48180, 23117, 46279, 30153, 14494, 10156]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723067610>\n",
            "Constructing exemplars of class 24\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [27859, 39159, 6615, 27618, 15911, 19633, 47532, 15821, 6083, 31888, 27264, 16435, 47356, 23199, 37376, 23506, 41965, 46602, 20617, 46172, 15815, 17159, 33402, 11374, 44595, 26596, 36083, 11015, 1651, 7558, 23997, 37130, 41351, 4301, 32381, 42103, 38, 47091, 26741, 43409, 47577, 26860, 5274, 21978, 29896, 41177, 34279, 38, 19787, 4308, 48096, 10752, 49189, 34066, 24107, 23802, 37499, 19787, 23997, 37576, 9238, 21178, 20316, 7749, 42550, 13264]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671049f090>\n",
            "Constructing exemplars of class 0\n",
            "lunghezza exemplar set:  66\n",
            "exemplar set:  [11048, 26247, 15701, 30026, 11841, 32233, 40036, 30592, 18746, 17390, 9324, 8065, 45171, 38787, 42285, 26247, 43210, 25898, 17450, 19265, 20339, 14967, 45682, 29275, 28361, 47676, 35908, 4726, 304, 26418, 27440, 19002, 40264, 48154, 21290, 7577, 12738, 43219, 13531, 34871, 44450, 18746, 10958, 22165, 3535, 1979, 2500, 48715, 5914, 30631, 45317, 30026, 14344, 42077, 5077, 15701, 23780, 41819, 38934, 19218, 16353, 48715, 27990, 8847, 12738, 15274]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.62 0.13044852018356323\n",
            "TEST GROUP:  0.581\n",
            "TEST ALL:  0.647\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  4000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [97, 95, 68, 64, 56, 42, 36, 34, 32, 30, 24, 22, 20, 18, 16, 10, 6, 4, 2, 72, 76, 80, 61, 83, 81, 79, 75, 67, 65, 63, 59, 82, 49, 47, 39, 23, 21, 7, 90, 0]\n",
            "TRAIN_SET CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "VALIDATION CLASSES:  [63, 42, 36, 97, 95, 30, 83, 72, 6, 2]\n",
            "GROUP:  4\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  40\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.263184130191803\n",
            "Train step - Step 10, Loss 0.14646269381046295\n",
            "Train step - Step 20, Loss 0.1406106799840927\n",
            "Train step - Step 30, Loss 0.13172221183776855\n",
            "Train step - Step 40, Loss 0.12888920307159424\n",
            "Train step - Step 50, Loss 0.12040694057941437\n",
            "Train epoch - Accuracy: 0.2248196248196248 Loss: 0.14679575229620004 Corrects: 1558\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.12789736688137054\n",
            "Train step - Step 70, Loss 0.1255502551794052\n",
            "Train step - Step 80, Loss 0.11771636456251144\n",
            "Train step - Step 90, Loss 0.12243538349866867\n",
            "Train step - Step 100, Loss 0.13017883896827698\n",
            "Train epoch - Accuracy: 0.25483405483405486 Loss: 0.12324336547872204 Corrects: 1766\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.12328099459409714\n",
            "Train step - Step 120, Loss 0.12554360926151276\n",
            "Train step - Step 130, Loss 0.1187860518693924\n",
            "Train step - Step 140, Loss 0.12342529743909836\n",
            "Train step - Step 150, Loss 0.12136876583099365\n",
            "Train step - Step 160, Loss 0.1163579449057579\n",
            "Train epoch - Accuracy: 0.2854256854256854 Loss: 0.11990082586052442 Corrects: 1978\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11853356659412384\n",
            "Train step - Step 180, Loss 0.11904884874820709\n",
            "Train step - Step 190, Loss 0.1157640814781189\n",
            "Train step - Step 200, Loss 0.11596477031707764\n",
            "Train step - Step 210, Loss 0.12083528190851212\n",
            "Train epoch - Accuracy: 0.2994227994227994 Loss: 0.11817408793674403 Corrects: 2075\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.1177062913775444\n",
            "Train step - Step 230, Loss 0.11335797607898712\n",
            "Train step - Step 240, Loss 0.12060399353504181\n",
            "Train step - Step 250, Loss 0.11638827621936798\n",
            "Train step - Step 260, Loss 0.11657016724348068\n",
            "Train step - Step 270, Loss 0.10702285915613174\n",
            "Train epoch - Accuracy: 0.319047619047619 Loss: 0.11728089828511853 Corrects: 2211\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.11856162548065186\n",
            "Train step - Step 290, Loss 0.12506341934204102\n",
            "Train step - Step 300, Loss 0.11267049610614777\n",
            "Train step - Step 310, Loss 0.12443286180496216\n",
            "Train step - Step 320, Loss 0.11987270414829254\n",
            "Train epoch - Accuracy: 0.3360750360750361 Loss: 0.11597684637292639 Corrects: 2329\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.11470351368188858\n",
            "Train step - Step 340, Loss 0.11226536333560944\n",
            "Train step - Step 350, Loss 0.11259110271930695\n",
            "Train step - Step 360, Loss 0.11872352659702301\n",
            "Train step - Step 370, Loss 0.11895184963941574\n",
            "Train step - Step 380, Loss 0.11158408969640732\n",
            "Train epoch - Accuracy: 0.3414141414141414 Loss: 0.11569253318495565 Corrects: 2366\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.12130308151245117\n",
            "Train step - Step 400, Loss 0.1144261583685875\n",
            "Train step - Step 410, Loss 0.11684849113225937\n",
            "Train step - Step 420, Loss 0.10898218303918839\n",
            "Train step - Step 430, Loss 0.10997941344976425\n",
            "Train epoch - Accuracy: 0.354978354978355 Loss: 0.11479004195758274 Corrects: 2460\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.11016888916492462\n",
            "Train step - Step 450, Loss 0.11641879379749298\n",
            "Train step - Step 460, Loss 0.12149878591299057\n",
            "Train step - Step 470, Loss 0.11566828936338425\n",
            "Train step - Step 480, Loss 0.10632079094648361\n",
            "Train step - Step 490, Loss 0.11745939403772354\n",
            "Train epoch - Accuracy: 0.3665223665223665 Loss: 0.1144724921832697 Corrects: 2540\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.10981971025466919\n",
            "Train step - Step 510, Loss 0.11688530445098877\n",
            "Train step - Step 520, Loss 0.11231397837400436\n",
            "Train step - Step 530, Loss 0.11151538044214249\n",
            "Train step - Step 540, Loss 0.11902590841054916\n",
            "Train epoch - Accuracy: 0.37922077922077924 Loss: 0.11384633146925234 Corrects: 2628\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.10914500057697296\n",
            "Train step - Step 560, Loss 0.1217845231294632\n",
            "Train step - Step 570, Loss 0.11089759320020676\n",
            "Train step - Step 580, Loss 0.11094778031110764\n",
            "Train step - Step 590, Loss 0.10625715553760529\n",
            "Train step - Step 600, Loss 0.12356555461883545\n",
            "Train epoch - Accuracy: 0.3847041847041847 Loss: 0.11383299677919 Corrects: 2666\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.11838465929031372\n",
            "Train step - Step 620, Loss 0.11109646409749985\n",
            "Train step - Step 630, Loss 0.11622947454452515\n",
            "Train step - Step 640, Loss 0.10888268798589706\n",
            "Train step - Step 650, Loss 0.10924816131591797\n",
            "Train epoch - Accuracy: 0.3937950937950938 Loss: 0.1126242376186631 Corrects: 2729\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.11056026071310043\n",
            "Train step - Step 670, Loss 0.1170930415391922\n",
            "Train step - Step 680, Loss 0.11049359291791916\n",
            "Train step - Step 690, Loss 0.11279912292957306\n",
            "Train step - Step 700, Loss 0.11032231152057648\n",
            "Train step - Step 710, Loss 0.11583629995584488\n",
            "Train epoch - Accuracy: 0.39826839826839827 Loss: 0.11257378061612447 Corrects: 2760\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.11595220863819122\n",
            "Train step - Step 730, Loss 0.11189796775579453\n",
            "Train step - Step 740, Loss 0.1046539694070816\n",
            "Train step - Step 750, Loss 0.11391983181238174\n",
            "Train step - Step 760, Loss 0.11126606911420822\n",
            "Train epoch - Accuracy: 0.4103896103896104 Loss: 0.11247145952428401 Corrects: 2844\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.11306276172399521\n",
            "Train step - Step 780, Loss 0.11280255764722824\n",
            "Train step - Step 790, Loss 0.11032213270664215\n",
            "Train step - Step 800, Loss 0.1100759282708168\n",
            "Train step - Step 810, Loss 0.11524952948093414\n",
            "Train step - Step 820, Loss 0.11746951192617416\n",
            "Train epoch - Accuracy: 0.4165945165945166 Loss: 0.1125093580410422 Corrects: 2887\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.10911474376916885\n",
            "Train step - Step 840, Loss 0.11378633975982666\n",
            "Train step - Step 850, Loss 0.10879974812269211\n",
            "Train step - Step 860, Loss 0.11053432524204254\n",
            "Train step - Step 870, Loss 0.10789056122303009\n",
            "Train epoch - Accuracy: 0.4210678210678211 Loss: 0.11128951891676173 Corrects: 2918\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.12227954715490341\n",
            "Train step - Step 890, Loss 0.1134624108672142\n",
            "Train step - Step 900, Loss 0.10674048960208893\n",
            "Train step - Step 910, Loss 0.11256269365549088\n",
            "Train step - Step 920, Loss 0.11186778545379639\n",
            "Train step - Step 930, Loss 0.11535270512104034\n",
            "Train epoch - Accuracy: 0.4326118326118326 Loss: 0.11097001897609252 Corrects: 2998\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.11604874581098557\n",
            "Train step - Step 950, Loss 0.1192849650979042\n",
            "Train step - Step 960, Loss 0.11020975559949875\n",
            "Train step - Step 970, Loss 0.10511348396539688\n",
            "Train step - Step 980, Loss 0.11017067730426788\n",
            "Train epoch - Accuracy: 0.43722943722943725 Loss: 0.11107113046133502 Corrects: 3030\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.11247407644987106\n",
            "Train step - Step 1000, Loss 0.10885236412286758\n",
            "Train step - Step 1010, Loss 0.10983846336603165\n",
            "Train step - Step 1020, Loss 0.11233203858137131\n",
            "Train step - Step 1030, Loss 0.11549999564886093\n",
            "Train step - Step 1040, Loss 0.11016147583723068\n",
            "Train epoch - Accuracy: 0.4443001443001443 Loss: 0.11067042174234362 Corrects: 3079\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10397721827030182\n",
            "Train step - Step 1060, Loss 0.11482208222150803\n",
            "Train step - Step 1070, Loss 0.11073007434606552\n",
            "Train step - Step 1080, Loss 0.11105164140462875\n",
            "Train step - Step 1090, Loss 0.1040981188416481\n",
            "Train epoch - Accuracy: 0.447041847041847 Loss: 0.10984932785641408 Corrects: 3098\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.11478006839752197\n",
            "Train step - Step 1110, Loss 0.11427896469831467\n",
            "Train step - Step 1120, Loss 0.10903825610876083\n",
            "Train step - Step 1130, Loss 0.10492453724145889\n",
            "Train step - Step 1140, Loss 0.09950075298547745\n",
            "Train step - Step 1150, Loss 0.11065074056386948\n",
            "Train epoch - Accuracy: 0.4471861471861472 Loss: 0.10924252880385084 Corrects: 3099\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11904718726873398\n",
            "Train step - Step 1170, Loss 0.11499807983636856\n",
            "Train step - Step 1180, Loss 0.10986824333667755\n",
            "Train step - Step 1190, Loss 0.10544814169406891\n",
            "Train step - Step 1200, Loss 0.11530157178640366\n",
            "Train epoch - Accuracy: 0.4546897546897547 Loss: 0.10991172090839342 Corrects: 3151\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.11305179446935654\n",
            "Train step - Step 1220, Loss 0.11297166347503662\n",
            "Train step - Step 1230, Loss 0.11251676082611084\n",
            "Train step - Step 1240, Loss 0.1152450442314148\n",
            "Train step - Step 1250, Loss 0.11002879589796066\n",
            "Train step - Step 1260, Loss 0.11029323190450668\n",
            "Train epoch - Accuracy: 0.45670995670995673 Loss: 0.10950683896976804 Corrects: 3165\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10606477409601212\n",
            "Train step - Step 1280, Loss 0.11071594059467316\n",
            "Train step - Step 1290, Loss 0.1101255938410759\n",
            "Train step - Step 1300, Loss 0.1057102233171463\n",
            "Train step - Step 1310, Loss 0.10694154351949692\n",
            "Train epoch - Accuracy: 0.4663780663780664 Loss: 0.10856913442778553 Corrects: 3232\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.10713916271924973\n",
            "Train step - Step 1330, Loss 0.11114665120840073\n",
            "Train step - Step 1340, Loss 0.10989425331354141\n",
            "Train step - Step 1350, Loss 0.10748697817325592\n",
            "Train step - Step 1360, Loss 0.1060936227440834\n",
            "Train step - Step 1370, Loss 0.11878102272748947\n",
            "Train epoch - Accuracy: 0.4692640692640693 Loss: 0.1086848867490006 Corrects: 3252\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10560622066259384\n",
            "Train step - Step 1390, Loss 0.11309366673231125\n",
            "Train step - Step 1400, Loss 0.10450682789087296\n",
            "Train step - Step 1410, Loss 0.10959787666797638\n",
            "Train step - Step 1420, Loss 0.11402469128370285\n",
            "Train epoch - Accuracy: 0.48412698412698413 Loss: 0.10823340579587831 Corrects: 3355\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10412044823169708\n",
            "Train step - Step 1440, Loss 0.11201675236225128\n",
            "Train step - Step 1450, Loss 0.11339409649372101\n",
            "Train step - Step 1460, Loss 0.11180415004491806\n",
            "Train step - Step 1470, Loss 0.11008775234222412\n",
            "Train step - Step 1480, Loss 0.106825090944767\n",
            "Train epoch - Accuracy: 0.4823953823953824 Loss: 0.10803243393161768 Corrects: 3343\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10439174622297287\n",
            "Train step - Step 1500, Loss 0.10753121227025986\n",
            "Train step - Step 1510, Loss 0.11231093853712082\n",
            "Train step - Step 1520, Loss 0.1044154167175293\n",
            "Train step - Step 1530, Loss 0.11374711990356445\n",
            "Train epoch - Accuracy: 0.4854256854256854 Loss: 0.1086666826733951 Corrects: 3364\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.11022467911243439\n",
            "Train step - Step 1550, Loss 0.10421551764011383\n",
            "Train step - Step 1560, Loss 0.09949468076229095\n",
            "Train step - Step 1570, Loss 0.10427854210138321\n",
            "Train step - Step 1580, Loss 0.10599364340305328\n",
            "Train step - Step 1590, Loss 0.10312946140766144\n",
            "Train epoch - Accuracy: 0.49826839826839825 Loss: 0.10754649354222877 Corrects: 3453\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10840754956007004\n",
            "Train step - Step 1610, Loss 0.10755350440740585\n",
            "Train step - Step 1620, Loss 0.10861756652593613\n",
            "Train step - Step 1630, Loss 0.10969765484333038\n",
            "Train step - Step 1640, Loss 0.10263154655694962\n",
            "Train epoch - Accuracy: 0.5002886002886003 Loss: 0.10743798477438105 Corrects: 3467\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.10632586479187012\n",
            "Train step - Step 1660, Loss 0.11020909994840622\n",
            "Train step - Step 1670, Loss 0.11092042922973633\n",
            "Train step - Step 1680, Loss 0.1051095724105835\n",
            "Train step - Step 1690, Loss 0.10580503195524216\n",
            "Train step - Step 1700, Loss 0.10573344677686691\n",
            "Train epoch - Accuracy: 0.5057720057720058 Loss: 0.10738314684335287 Corrects: 3505\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.10590236634016037\n",
            "Train step - Step 1720, Loss 0.11373341083526611\n",
            "Train step - Step 1730, Loss 0.11028744280338287\n",
            "Train step - Step 1740, Loss 0.10334217548370361\n",
            "Train step - Step 1750, Loss 0.10452194511890411\n",
            "Train epoch - Accuracy: 0.51010101010101 Loss: 0.10708980046395443 Corrects: 3535\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.1036120280623436\n",
            "Train step - Step 1770, Loss 0.11512990295886993\n",
            "Train step - Step 1780, Loss 0.10577769577503204\n",
            "Train step - Step 1790, Loss 0.10414643585681915\n",
            "Train step - Step 1800, Loss 0.10942064970731735\n",
            "Train step - Step 1810, Loss 0.10282442718744278\n",
            "Train epoch - Accuracy: 0.5115440115440115 Loss: 0.10712910873377306 Corrects: 3545\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.11235373467206955\n",
            "Train step - Step 1830, Loss 0.1080237627029419\n",
            "Train step - Step 1840, Loss 0.10348605364561081\n",
            "Train step - Step 1850, Loss 0.1076943427324295\n",
            "Train step - Step 1860, Loss 0.10610455274581909\n",
            "Train epoch - Accuracy: 0.5151515151515151 Loss: 0.10689516456053198 Corrects: 3570\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10075289011001587\n",
            "Train step - Step 1880, Loss 0.11013918370008469\n",
            "Train step - Step 1890, Loss 0.1039874479174614\n",
            "Train step - Step 1900, Loss 0.11140626668930054\n",
            "Train step - Step 1910, Loss 0.11000116169452667\n",
            "Train step - Step 1920, Loss 0.11231935024261475\n",
            "Train epoch - Accuracy: 0.5197691197691198 Loss: 0.10657002524853097 Corrects: 3602\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10690241307020187\n",
            "Train step - Step 1940, Loss 0.10536129772663116\n",
            "Train step - Step 1950, Loss 0.10090389102697372\n",
            "Train step - Step 1960, Loss 0.1012505516409874\n",
            "Train step - Step 1970, Loss 0.10888867825269699\n",
            "Train epoch - Accuracy: 0.522077922077922 Loss: 0.10603815376285523 Corrects: 3618\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.0981828048825264\n",
            "Train step - Step 1990, Loss 0.10537328571081161\n",
            "Train step - Step 2000, Loss 0.11013396084308624\n",
            "Train step - Step 2010, Loss 0.10479263216257095\n",
            "Train step - Step 2020, Loss 0.11023757606744766\n",
            "Train step - Step 2030, Loss 0.10613031685352325\n",
            "Train epoch - Accuracy: 0.5303030303030303 Loss: 0.10562632030566878 Corrects: 3675\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10895414650440216\n",
            "Train step - Step 2050, Loss 0.10308994352817535\n",
            "Train step - Step 2060, Loss 0.10601954907178879\n",
            "Train step - Step 2070, Loss 0.10232656449079514\n",
            "Train step - Step 2080, Loss 0.10263440757989883\n",
            "Train epoch - Accuracy: 0.5151515151515151 Loss: 0.1061735146037944 Corrects: 3570\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10591896623373032\n",
            "Train step - Step 2100, Loss 0.1042957529425621\n",
            "Train step - Step 2110, Loss 0.11326763778924942\n",
            "Train step - Step 2120, Loss 0.10516639798879623\n",
            "Train step - Step 2130, Loss 0.10469242185354233\n",
            "Train step - Step 2140, Loss 0.10387388616800308\n",
            "Train epoch - Accuracy: 0.5329004329004329 Loss: 0.10562847260100845 Corrects: 3693\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.11221007257699966\n",
            "Train step - Step 2160, Loss 0.1023949608206749\n",
            "Train step - Step 2170, Loss 0.10335566848516464\n",
            "Train step - Step 2180, Loss 0.10101708024740219\n",
            "Train step - Step 2190, Loss 0.11028198152780533\n",
            "Train epoch - Accuracy: 0.5404040404040404 Loss: 0.1057865330194154 Corrects: 3745\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.09819772094488144\n",
            "Train step - Step 2210, Loss 0.10643155872821808\n",
            "Train step - Step 2220, Loss 0.1083914041519165\n",
            "Train step - Step 2230, Loss 0.10466807335615158\n",
            "Train step - Step 2240, Loss 0.11047527939081192\n",
            "Train step - Step 2250, Loss 0.10537084192037582\n",
            "Train epoch - Accuracy: 0.5457431457431458 Loss: 0.10511771948822649 Corrects: 3782\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10577613115310669\n",
            "Train step - Step 2270, Loss 0.10357973724603653\n",
            "Train step - Step 2280, Loss 0.10609664022922516\n",
            "Train step - Step 2290, Loss 0.10378143936395645\n",
            "Train step - Step 2300, Loss 0.10378892719745636\n",
            "Train epoch - Accuracy: 0.5401154401154401 Loss: 0.10518125281017408 Corrects: 3743\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10365164279937744\n",
            "Train step - Step 2320, Loss 0.09871188551187515\n",
            "Train step - Step 2330, Loss 0.09950970858335495\n",
            "Train step - Step 2340, Loss 0.10086970776319504\n",
            "Train step - Step 2350, Loss 0.11014709621667862\n",
            "Train step - Step 2360, Loss 0.11476627737283707\n",
            "Train epoch - Accuracy: 0.5503607503607504 Loss: 0.10488666528231137 Corrects: 3814\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.10728277266025543\n",
            "Train step - Step 2380, Loss 0.10712283104658127\n",
            "Train step - Step 2390, Loss 0.1074526309967041\n",
            "Train step - Step 2400, Loss 0.11622704565525055\n",
            "Train step - Step 2410, Loss 0.09718077629804611\n",
            "Train epoch - Accuracy: 0.5535353535353535 Loss: 0.10468099717195932 Corrects: 3836\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.10300620645284653\n",
            "Train step - Step 2430, Loss 0.10170914977788925\n",
            "Train step - Step 2440, Loss 0.10772013664245605\n",
            "Train step - Step 2450, Loss 0.09901966899633408\n",
            "Train step - Step 2460, Loss 0.10399060696363449\n",
            "Train step - Step 2470, Loss 0.10769205540418625\n",
            "Train epoch - Accuracy: 0.5613275613275613 Loss: 0.10450315566849055 Corrects: 3890\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10523919016122818\n",
            "Train step - Step 2490, Loss 0.1024773120880127\n",
            "Train step - Step 2500, Loss 0.10502723604440689\n",
            "Train step - Step 2510, Loss 0.10257325321435928\n",
            "Train step - Step 2520, Loss 0.09991105645895004\n",
            "Train epoch - Accuracy: 0.5542568542568542 Loss: 0.10427112618480065 Corrects: 3841\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10490154474973679\n",
            "Train step - Step 2540, Loss 0.10920959711074829\n",
            "Train step - Step 2550, Loss 0.10924471914768219\n",
            "Train step - Step 2560, Loss 0.10741498321294785\n",
            "Train step - Step 2570, Loss 0.10925612598657608\n",
            "Train step - Step 2580, Loss 0.10980844497680664\n",
            "Train epoch - Accuracy: 0.5653679653679654 Loss: 0.10440326537318732 Corrects: 3918\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.1063760295510292\n",
            "Train step - Step 2600, Loss 0.0992579236626625\n",
            "Train step - Step 2610, Loss 0.102647565305233\n",
            "Train step - Step 2620, Loss 0.10708494484424591\n",
            "Train step - Step 2630, Loss 0.10368170589208603\n",
            "Train epoch - Accuracy: 0.5686868686868687 Loss: 0.10349033221623942 Corrects: 3941\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10492036491632462\n",
            "Train step - Step 2650, Loss 0.10018592327833176\n",
            "Train step - Step 2660, Loss 0.09727106243371964\n",
            "Train step - Step 2670, Loss 0.10575979202985764\n",
            "Train step - Step 2680, Loss 0.1046537533402443\n",
            "Train step - Step 2690, Loss 0.09386899322271347\n",
            "Train epoch - Accuracy: 0.5701298701298702 Loss: 0.10389304832591639 Corrects: 3951\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10179910808801651\n",
            "Train step - Step 2710, Loss 0.09754589945077896\n",
            "Train step - Step 2720, Loss 0.10229197889566422\n",
            "Train step - Step 2730, Loss 0.10446202754974365\n",
            "Train step - Step 2740, Loss 0.10754628479480743\n",
            "Train epoch - Accuracy: 0.5835497835497836 Loss: 0.10184164080569927 Corrects: 4044\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10473159700632095\n",
            "Train step - Step 2760, Loss 0.10625161230564117\n",
            "Train step - Step 2770, Loss 0.09688284248113632\n",
            "Train step - Step 2780, Loss 0.10217473655939102\n",
            "Train step - Step 2790, Loss 0.10563340038061142\n",
            "Train step - Step 2800, Loss 0.09833550453186035\n",
            "Train epoch - Accuracy: 0.5867243867243868 Loss: 0.10110348658945309 Corrects: 4066\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10407966375350952\n",
            "Train step - Step 2820, Loss 0.09665372222661972\n",
            "Train step - Step 2830, Loss 0.10606225579977036\n",
            "Train step - Step 2840, Loss 0.10112801939249039\n",
            "Train step - Step 2850, Loss 0.09477365016937256\n",
            "Train epoch - Accuracy: 0.5877344877344878 Loss: 0.10098659888576464 Corrects: 4073\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.088893823325634\n",
            "Train step - Step 2870, Loss 0.10077095031738281\n",
            "Train step - Step 2880, Loss 0.10309264808893204\n",
            "Train step - Step 2890, Loss 0.10628560930490494\n",
            "Train step - Step 2900, Loss 0.10867509990930557\n",
            "Train step - Step 2910, Loss 0.10801862925291061\n",
            "Train epoch - Accuracy: 0.5823953823953824 Loss: 0.10111489461097882 Corrects: 4036\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.08852341026067734\n",
            "Train step - Step 2930, Loss 0.1016886755824089\n",
            "Train step - Step 2940, Loss 0.10882618278265\n",
            "Train step - Step 2950, Loss 0.10240612179040909\n",
            "Train step - Step 2960, Loss 0.09724462777376175\n",
            "Train epoch - Accuracy: 0.5898989898989899 Loss: 0.10077030414024644 Corrects: 4088\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.10045748203992844\n",
            "Train step - Step 2980, Loss 0.11002246290445328\n",
            "Train step - Step 2990, Loss 0.10106503218412399\n",
            "Train step - Step 3000, Loss 0.09953852742910385\n",
            "Train step - Step 3010, Loss 0.09594247490167618\n",
            "Train step - Step 3020, Loss 0.09651633352041245\n",
            "Train epoch - Accuracy: 0.5854256854256854 Loss: 0.10074072239804921 Corrects: 4057\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.10057200491428375\n",
            "Train step - Step 3040, Loss 0.09859883040189743\n",
            "Train step - Step 3050, Loss 0.10067444294691086\n",
            "Train step - Step 3060, Loss 0.10121770948171616\n",
            "Train step - Step 3070, Loss 0.1051718220114708\n",
            "Train epoch - Accuracy: 0.5848484848484848 Loss: 0.10068885471139635 Corrects: 4053\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.1026046872138977\n",
            "Train step - Step 3090, Loss 0.1026863232254982\n",
            "Train step - Step 3100, Loss 0.09932943433523178\n",
            "Train step - Step 3110, Loss 0.10249622911214828\n",
            "Train step - Step 3120, Loss 0.09787140786647797\n",
            "Train step - Step 3130, Loss 0.0935189500451088\n",
            "Train epoch - Accuracy: 0.5891774891774891 Loss: 0.10043349267772438 Corrects: 4083\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.09829805046319962\n",
            "Train step - Step 3150, Loss 0.10266901552677155\n",
            "Train step - Step 3160, Loss 0.09892052412033081\n",
            "Train step - Step 3170, Loss 0.09543152898550034\n",
            "Train step - Step 3180, Loss 0.10447268933057785\n",
            "Train epoch - Accuracy: 0.589033189033189 Loss: 0.10052639952985755 Corrects: 4082\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10080325603485107\n",
            "Train step - Step 3200, Loss 0.09845264256000519\n",
            "Train step - Step 3210, Loss 0.09594535827636719\n",
            "Train step - Step 3220, Loss 0.09934914112091064\n",
            "Train step - Step 3230, Loss 0.10074057430028915\n",
            "Train step - Step 3240, Loss 0.0998111218214035\n",
            "Train epoch - Accuracy: 0.5948051948051948 Loss: 0.1000892573190802 Corrects: 4122\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09525882452726364\n",
            "Train step - Step 3260, Loss 0.10356908291578293\n",
            "Train step - Step 3270, Loss 0.10070677846670151\n",
            "Train step - Step 3280, Loss 0.09967219084501266\n",
            "Train step - Step 3290, Loss 0.10684769600629807\n",
            "Train epoch - Accuracy: 0.5971139971139972 Loss: 0.09997573355145613 Corrects: 4138\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.0973227247595787\n",
            "Train step - Step 3310, Loss 0.1154722347855568\n",
            "Train step - Step 3320, Loss 0.09918510168790817\n",
            "Train step - Step 3330, Loss 0.09303610026836395\n",
            "Train step - Step 3340, Loss 0.09438502043485641\n",
            "Train step - Step 3350, Loss 0.10041164606809616\n",
            "Train epoch - Accuracy: 0.5888888888888889 Loss: 0.10025784628731864 Corrects: 4081\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.105321504175663\n",
            "Train step - Step 3370, Loss 0.10873565822839737\n",
            "Train step - Step 3380, Loss 0.09597905725240707\n",
            "Train step - Step 3390, Loss 0.0941535159945488\n",
            "Train step - Step 3400, Loss 0.10504060983657837\n",
            "Train epoch - Accuracy: 0.5955266955266956 Loss: 0.10020535506555356 Corrects: 4127\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.10877422243356705\n",
            "Train step - Step 3420, Loss 0.10136277973651886\n",
            "Train step - Step 3430, Loss 0.09568112343549728\n",
            "Train step - Step 3440, Loss 0.09941829741001129\n",
            "Train step - Step 3450, Loss 0.09989175945520401\n",
            "Train step - Step 3460, Loss 0.09832359105348587\n",
            "Train epoch - Accuracy: 0.6008658008658009 Loss: 0.09973412033541378 Corrects: 4164\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.09602297842502594\n",
            "Train step - Step 3480, Loss 0.10645440965890884\n",
            "Train step - Step 3490, Loss 0.09583026170730591\n",
            "Train step - Step 3500, Loss 0.10715644806623459\n",
            "Train step - Step 3510, Loss 0.10249116271734238\n",
            "Train epoch - Accuracy: 0.5942279942279942 Loss: 0.09959775923091439 Corrects: 4118\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.0989222526550293\n",
            "Train step - Step 3530, Loss 0.09810816496610641\n",
            "Train step - Step 3540, Loss 0.09908459335565567\n",
            "Train step - Step 3550, Loss 0.10148487240076065\n",
            "Train step - Step 3560, Loss 0.10002800077199936\n",
            "Train step - Step 3570, Loss 0.09856607019901276\n",
            "Train epoch - Accuracy: 0.6001443001443001 Loss: 0.09956722517980297 Corrects: 4159\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.10009252279996872\n",
            "Train step - Step 3590, Loss 0.1013968214392662\n",
            "Train step - Step 3600, Loss 0.09949924796819687\n",
            "Train step - Step 3610, Loss 0.100712850689888\n",
            "Train step - Step 3620, Loss 0.10790999978780746\n",
            "Train epoch - Accuracy: 0.5930735930735931 Loss: 0.09957065888469525 Corrects: 4110\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.09774717688560486\n",
            "Train step - Step 3640, Loss 0.10557468980550766\n",
            "Train step - Step 3650, Loss 0.09591393917798996\n",
            "Train step - Step 3660, Loss 0.09590127319097519\n",
            "Train step - Step 3670, Loss 0.10360796749591827\n",
            "Train step - Step 3680, Loss 0.09975671768188477\n",
            "Train epoch - Accuracy: 0.5998556998556999 Loss: 0.09982974854382602 Corrects: 4157\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.10051371157169342\n",
            "Train step - Step 3700, Loss 0.09853747487068176\n",
            "Train step - Step 3710, Loss 0.09948767721652985\n",
            "Train step - Step 3720, Loss 0.09927644580602646\n",
            "Train step - Step 3730, Loss 0.09697089344263077\n",
            "Train epoch - Accuracy: 0.604040404040404 Loss: 0.09969205978241834 Corrects: 4186\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.09695447981357574\n",
            "Train step - Step 3750, Loss 0.10074106603860855\n",
            "Train step - Step 3760, Loss 0.10756879299879074\n",
            "Train step - Step 3770, Loss 0.09885658323764801\n",
            "Train step - Step 3780, Loss 0.10032568126916885\n",
            "Train step - Step 3790, Loss 0.09551038593053818\n",
            "Train epoch - Accuracy: 0.5982683982683983 Loss: 0.09939077862499424 Corrects: 4146\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.10016553848981857\n",
            "Train step - Step 3810, Loss 0.09982430189847946\n",
            "Train step - Step 3820, Loss 0.1013665422797203\n",
            "Train step - Step 3830, Loss 0.09540192037820816\n",
            "Train step - Step 3840, Loss 0.09726407378911972\n",
            "Train epoch - Accuracy: 0.6051948051948052 Loss: 0.09918831422129407 Corrects: 4194\n",
            "Training finished in 438.95626044273376 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36]\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  50\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b68f50>\n",
            "Constructing exemplars of class 95\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [1714, 36509, 29776, 30877, 42567, 46247, 32689, 18053, 29929, 32805, 8970, 18230, 11673, 1391, 32678, 24974, 2028, 22152, 48708, 5054, 6860, 6236, 18410, 18405, 13798, 49037, 30413, 46284, 41953, 34804, 27500, 42997, 801, 25680, 27842, 19756, 9403, 27009, 24608, 38297, 43375, 6250, 6860, 22789, 6880, 42741, 17792, 34988, 36621, 15787]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234c1dd0>\n",
            "Constructing exemplars of class 83\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [20945, 6712, 48299, 45100, 28252, 44535, 20751, 44151, 30230, 12854, 18173, 15516, 12590, 23627, 27927, 35374, 26199, 19142, 30476, 20942, 20858, 3884, 30835, 19310, 8952, 37150, 2346, 6204, 28744, 39898, 15639, 12162, 22554, 6067, 27531, 26721, 17227, 47209, 20858, 39631, 29306, 21500, 11495, 14458, 35450, 14953, 48299, 32334, 19715, 47910]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234c1110>\n",
            "Constructing exemplars of class 63\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [40687, 15796, 6009, 30844, 21446, 15178, 46842, 5503, 35288, 49121, 47599, 12934, 9819, 9276, 49389, 46023, 12717, 20973, 28707, 30385, 39207, 36633, 22224, 33468, 3091, 8330, 40190, 15796, 8582, 31174, 29157, 45935, 20135, 43779, 47976, 2462, 25755, 2089, 39180, 20760, 16862, 890, 34632, 41920, 28129, 9953, 41334, 24543, 20435, 45586]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237dbed0>\n",
            "Constructing exemplars of class 42\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [12121, 38744, 28053, 47361, 18934, 12681, 4182, 14051, 9361, 7162, 21374, 12681, 35973, 13438, 36432, 40394, 28464, 10308, 37986, 33114, 20460, 36214, 46380, 42472, 44038, 13681, 21430, 26098, 931, 9292, 29066, 1745, 30879, 30922, 20282, 5526, 37854, 1856, 18523, 48383, 8064, 18792, 26292, 48741, 17755, 16667, 32313, 13155, 45878, 34838]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723517550>\n",
            "Constructing exemplars of class 30\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [29722, 9799, 9928, 41275, 33295, 40217, 40166, 15711, 16223, 48439, 20071, 12281, 24811, 35489, 28897, 1012, 19962, 37692, 5737, 36642, 3864, 41012, 9300, 18486, 8726, 44574, 44328, 35855, 37151, 20885, 30650, 9193, 17504, 3409, 3794, 34286, 4589, 22139, 37151, 13670, 505, 32574, 36642, 35863, 46979, 15610, 15018, 7413, 6576, 34222]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67104f2fd0>\n",
            "Constructing exemplars of class 6\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [17809, 23612, 26180, 12234, 14104, 30419, 12330, 28255, 37581, 763, 31978, 47426, 46016, 28578, 23480, 46135, 13994, 29444, 46636, 22246, 8221, 21946, 2121, 29444, 42055, 30252, 40809, 38409, 22539, 9929, 39685, 14926, 33259, 2121, 44421, 31356, 763, 1762, 27311, 38845, 43666, 37670, 28578, 31584, 32148, 9079, 30811, 29127, 24106, 21716]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67103c5510>\n",
            "Constructing exemplars of class 2\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [19819, 38345, 5180, 41119, 16339, 49976, 6878, 37758, 18277, 5164, 32596, 33889, 38155, 29239, 22121, 28642, 45445, 48670, 20458, 5335, 6923, 35048, 18974, 23209, 28097, 37788, 46971, 12037, 12363, 5180, 37015, 24918, 795, 4861, 12114, 26051, 13261, 36874, 6901, 10367, 8681, 41391, 2051, 20415, 11139, 16332, 6975, 42302, 30742, 38155]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67107d5310>\n",
            "Constructing exemplars of class 97\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [46311, 24866, 24834, 37541, 43596, 45326, 40556, 42282, 15414, 43854, 9099, 33836, 18898, 10823, 43193, 36866, 8551, 31682, 22743, 40829, 3614, 39087, 3532, 47988, 18406, 13649, 26771, 39561, 18412, 36284, 44541, 16713, 30380, 46225, 12941, 18406, 14861, 10485, 21266, 19113, 46539, 41773, 35067, 26637, 10935, 43341, 7174, 48617, 5300, 37167]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b6dbd0>\n",
            "Constructing exemplars of class 72\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [45617, 45018, 25029, 32274, 43501, 10288, 26525, 16079, 1709, 9465, 30720, 39047, 44042, 25359, 28376, 1588, 7462, 32560, 42700, 15163, 34178, 22880, 26513, 17513, 23550, 17987, 17434, 37279, 10379, 19614, 12060, 9873, 4926, 6532, 7200, 43771, 4328, 42759, 37519, 4582, 31944, 20130, 26038, 18289, 5232, 49399, 27946, 48969, 35718, 17805]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b79e10>\n",
            "Constructing exemplars of class 36\n",
            "lunghezza exemplar set:  50\n",
            "exemplar set:  [19019, 17494, 41845, 6275, 18767, 32854, 11568, 33871, 22306, 34722, 49714, 13153, 12207, 48846, 28566, 48121, 35484, 16245, 29379, 24960, 34600, 13153, 47418, 46609, 36848, 6246, 42505, 38329, 43998, 20838, 4102, 14638, 4758, 24421, 3806, 35913, 40437, 39190, 37767, 36033, 9643, 20961, 17194, 37555, 9678, 40564, 32854, 43983, 31120, 31117]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.38 0.11830411106348038\n",
            "TEST GROUP:  0.448\n",
            "TEST ALL:  0.57675\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  5000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 80, 97, 93, 85, 81, 65, 61, 49, 21, 9, 96, 76, 83, 72, 68, 64, 56, 36, 32, 24, 20, 16, 4, 2, 6, 10, 18, 79, 75, 67, 63, 59, 55, 47, 39, 31, 23, 19, 7, 98, 94, 90, 82, 54, 42, 34, 30, 22, 0]\n",
            "TRAIN_SET CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "VALIDATION CLASSES:  [55, 54, 98, 96, 31, 94, 93, 85, 19, 9]\n",
            "GROUP:  5\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  50\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.2401297390460968\n",
            "Train step - Step 10, Loss 0.1374843418598175\n",
            "Train step - Step 20, Loss 0.13900445401668549\n",
            "Train step - Step 30, Loss 0.1338469237089157\n",
            "Train step - Step 40, Loss 0.12515728175640106\n",
            "Train step - Step 50, Loss 0.11650682240724564\n",
            "Train epoch - Accuracy: 0.20633093525179855 Loss: 0.14063185968201794 Corrects: 1434\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.1200551986694336\n",
            "Train step - Step 70, Loss 0.12120986729860306\n",
            "Train step - Step 80, Loss 0.11483851820230484\n",
            "Train step - Step 90, Loss 0.11509191244840622\n",
            "Train step - Step 100, Loss 0.11256244778633118\n",
            "Train epoch - Accuracy: 0.2585611510791367 Loss: 0.11752688943053322 Corrects: 1797\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.11905830353498459\n",
            "Train step - Step 120, Loss 0.11517882347106934\n",
            "Train step - Step 130, Loss 0.11379452794790268\n",
            "Train step - Step 140, Loss 0.1110161691904068\n",
            "Train step - Step 150, Loss 0.11679499596357346\n",
            "Train step - Step 160, Loss 0.12054570019245148\n",
            "Train epoch - Accuracy: 0.2824460431654676 Loss: 0.1146090709605663 Corrects: 1963\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11687961220741272\n",
            "Train step - Step 180, Loss 0.11428339034318924\n",
            "Train step - Step 190, Loss 0.11105800420045853\n",
            "Train step - Step 200, Loss 0.11262845993041992\n",
            "Train step - Step 210, Loss 0.11079683899879456\n",
            "Train epoch - Accuracy: 0.3083453237410072 Loss: 0.11367140741013794 Corrects: 2143\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.11239407956600189\n",
            "Train step - Step 230, Loss 0.11191773414611816\n",
            "Train step - Step 240, Loss 0.11485197395086288\n",
            "Train step - Step 250, Loss 0.10812146961688995\n",
            "Train step - Step 260, Loss 0.11355771124362946\n",
            "Train step - Step 270, Loss 0.11225660890340805\n",
            "Train epoch - Accuracy: 0.33266187050359713 Loss: 0.112518080342159 Corrects: 2312\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.11389680951833725\n",
            "Train step - Step 290, Loss 0.11902015656232834\n",
            "Train step - Step 300, Loss 0.11115964502096176\n",
            "Train step - Step 310, Loss 0.10184727609157562\n",
            "Train step - Step 320, Loss 0.10725919157266617\n",
            "Train epoch - Accuracy: 0.3480575539568345 Loss: 0.1118127033886292 Corrects: 2419\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.1120045855641365\n",
            "Train step - Step 340, Loss 0.10732470452785492\n",
            "Train step - Step 350, Loss 0.10990733653306961\n",
            "Train step - Step 360, Loss 0.1123872697353363\n",
            "Train step - Step 370, Loss 0.11197186261415482\n",
            "Train step - Step 380, Loss 0.11708101630210876\n",
            "Train epoch - Accuracy: 0.3651798561151079 Loss: 0.11132570362562756 Corrects: 2538\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11470835655927658\n",
            "Train step - Step 400, Loss 0.11455752700567245\n",
            "Train step - Step 410, Loss 0.11299736052751541\n",
            "Train step - Step 420, Loss 0.11541156470775604\n",
            "Train step - Step 430, Loss 0.1120849996805191\n",
            "Train epoch - Accuracy: 0.3753956834532374 Loss: 0.11012286927202623 Corrects: 2609\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.10539029538631439\n",
            "Train step - Step 450, Loss 0.1066155806183815\n",
            "Train step - Step 460, Loss 0.10739674419164658\n",
            "Train step - Step 470, Loss 0.11407855898141861\n",
            "Train step - Step 480, Loss 0.10718520730733871\n",
            "Train step - Step 490, Loss 0.11981397122144699\n",
            "Train epoch - Accuracy: 0.39136690647482014 Loss: 0.1105687997259682 Corrects: 2720\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.10742538422346115\n",
            "Train step - Step 510, Loss 0.10920115560293198\n",
            "Train step - Step 520, Loss 0.10804133862257004\n",
            "Train step - Step 530, Loss 0.11250722408294678\n",
            "Train step - Step 540, Loss 0.10452982038259506\n",
            "Train epoch - Accuracy: 0.3994244604316547 Loss: 0.10990556405817005 Corrects: 2776\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.10418392717838287\n",
            "Train step - Step 560, Loss 0.10360398888587952\n",
            "Train step - Step 570, Loss 0.11992177367210388\n",
            "Train step - Step 580, Loss 0.11139582097530365\n",
            "Train step - Step 590, Loss 0.10894381999969482\n",
            "Train step - Step 600, Loss 0.10709173232316971\n",
            "Train epoch - Accuracy: 0.4071942446043165 Loss: 0.1095473128878813 Corrects: 2830\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.10714582353830338\n",
            "Train step - Step 620, Loss 0.10963109135627747\n",
            "Train step - Step 630, Loss 0.10278791934251785\n",
            "Train step - Step 640, Loss 0.10941774398088455\n",
            "Train step - Step 650, Loss 0.11006703972816467\n",
            "Train epoch - Accuracy: 0.4084892086330935 Loss: 0.10919350179408094 Corrects: 2839\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.10628670454025269\n",
            "Train step - Step 670, Loss 0.10738618671894073\n",
            "Train step - Step 680, Loss 0.1136660948395729\n",
            "Train step - Step 690, Loss 0.11406031250953674\n",
            "Train step - Step 700, Loss 0.10200686007738113\n",
            "Train step - Step 710, Loss 0.10920791327953339\n",
            "Train epoch - Accuracy: 0.4279136690647482 Loss: 0.10880669271774429 Corrects: 2974\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.1103982925415039\n",
            "Train step - Step 730, Loss 0.10248788446187973\n",
            "Train step - Step 740, Loss 0.11053996533155441\n",
            "Train step - Step 750, Loss 0.10510218143463135\n",
            "Train step - Step 760, Loss 0.11115377396345139\n",
            "Train epoch - Accuracy: 0.4329496402877698 Loss: 0.10834551920779317 Corrects: 3009\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.10460572689771652\n",
            "Train step - Step 780, Loss 0.10313796997070312\n",
            "Train step - Step 790, Loss 0.10908746719360352\n",
            "Train step - Step 800, Loss 0.10486671328544617\n",
            "Train step - Step 810, Loss 0.11005048453807831\n",
            "Train step - Step 820, Loss 0.10616876184940338\n",
            "Train epoch - Accuracy: 0.4352517985611511 Loss: 0.10816405873075663 Corrects: 3025\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.10712732374668121\n",
            "Train step - Step 840, Loss 0.10252605378627777\n",
            "Train step - Step 850, Loss 0.10445970296859741\n",
            "Train step - Step 860, Loss 0.10747931897640228\n",
            "Train step - Step 870, Loss 0.09736328572034836\n",
            "Train epoch - Accuracy: 0.44244604316546765 Loss: 0.10798677547586907 Corrects: 3075\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.10829821974039078\n",
            "Train step - Step 890, Loss 0.10747373104095459\n",
            "Train step - Step 900, Loss 0.11151191592216492\n",
            "Train step - Step 910, Loss 0.10549253225326538\n",
            "Train step - Step 920, Loss 0.10766097903251648\n",
            "Train step - Step 930, Loss 0.11166103184223175\n",
            "Train epoch - Accuracy: 0.4474820143884892 Loss: 0.10811275503618253 Corrects: 3110\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.10650945454835892\n",
            "Train step - Step 950, Loss 0.10398051887750626\n",
            "Train step - Step 960, Loss 0.10390162467956543\n",
            "Train step - Step 970, Loss 0.10239668935537338\n",
            "Train step - Step 980, Loss 0.11029967665672302\n",
            "Train epoch - Accuracy: 0.45798561151079137 Loss: 0.10787402464331483 Corrects: 3183\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10499995946884155\n",
            "Train step - Step 1000, Loss 0.10400239378213882\n",
            "Train step - Step 1010, Loss 0.10033219307661057\n",
            "Train step - Step 1020, Loss 0.11165527999401093\n",
            "Train step - Step 1030, Loss 0.10589735954999924\n",
            "Train step - Step 1040, Loss 0.11022882163524628\n",
            "Train epoch - Accuracy: 0.46863309352517984 Loss: 0.10736986479527659 Corrects: 3257\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10808175057172775\n",
            "Train step - Step 1060, Loss 0.11174335330724716\n",
            "Train step - Step 1070, Loss 0.10439649224281311\n",
            "Train step - Step 1080, Loss 0.1041305735707283\n",
            "Train step - Step 1090, Loss 0.10987982153892517\n",
            "Train epoch - Accuracy: 0.47035971223021583 Loss: 0.1072120681019138 Corrects: 3269\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.11438877135515213\n",
            "Train step - Step 1110, Loss 0.10824903100728989\n",
            "Train step - Step 1120, Loss 0.10344596952199936\n",
            "Train step - Step 1130, Loss 0.10722379386425018\n",
            "Train step - Step 1140, Loss 0.10283754020929337\n",
            "Train step - Step 1150, Loss 0.10587921738624573\n",
            "Train epoch - Accuracy: 0.47741007194244606 Loss: 0.1070693280864105 Corrects: 3318\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.10391233116388321\n",
            "Train step - Step 1170, Loss 0.09836195409297943\n",
            "Train step - Step 1180, Loss 0.10768270492553711\n",
            "Train step - Step 1190, Loss 0.1075260117650032\n",
            "Train step - Step 1200, Loss 0.10813996195793152\n",
            "Train epoch - Accuracy: 0.47741007194244606 Loss: 0.1066899754546529 Corrects: 3318\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.10475020855665207\n",
            "Train step - Step 1220, Loss 0.10975810885429382\n",
            "Train step - Step 1230, Loss 0.11007459461688995\n",
            "Train step - Step 1240, Loss 0.10811322182416916\n",
            "Train step - Step 1250, Loss 0.11049461364746094\n",
            "Train step - Step 1260, Loss 0.10557645559310913\n",
            "Train epoch - Accuracy: 0.48863309352517986 Loss: 0.10662967285878366 Corrects: 3396\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10573988407850266\n",
            "Train step - Step 1280, Loss 0.10167800635099411\n",
            "Train step - Step 1290, Loss 0.10100024193525314\n",
            "Train step - Step 1300, Loss 0.10677836090326309\n",
            "Train step - Step 1310, Loss 0.11151617020368576\n",
            "Train epoch - Accuracy: 0.4870503597122302 Loss: 0.10692943289554377 Corrects: 3385\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.09932739287614822\n",
            "Train step - Step 1330, Loss 0.11303789168596268\n",
            "Train step - Step 1340, Loss 0.10530679672956467\n",
            "Train step - Step 1350, Loss 0.10550473630428314\n",
            "Train step - Step 1360, Loss 0.10033951699733734\n",
            "Train step - Step 1370, Loss 0.10443960130214691\n",
            "Train epoch - Accuracy: 0.48906474820143886 Loss: 0.10644107011582354 Corrects: 3399\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10722945630550385\n",
            "Train step - Step 1390, Loss 0.1058310866355896\n",
            "Train step - Step 1400, Loss 0.10636585205793381\n",
            "Train step - Step 1410, Loss 0.1070999950170517\n",
            "Train step - Step 1420, Loss 0.10444774478673935\n",
            "Train epoch - Accuracy: 0.4976978417266187 Loss: 0.10631940241340253 Corrects: 3459\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10148134082555771\n",
            "Train step - Step 1440, Loss 0.10464508086442947\n",
            "Train step - Step 1450, Loss 0.10611579567193985\n",
            "Train step - Step 1460, Loss 0.1043439581990242\n",
            "Train step - Step 1470, Loss 0.10649034380912781\n",
            "Train step - Step 1480, Loss 0.11494799703359604\n",
            "Train epoch - Accuracy: 0.498273381294964 Loss: 0.10600995369094739 Corrects: 3463\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10678955167531967\n",
            "Train step - Step 1500, Loss 0.10375462472438812\n",
            "Train step - Step 1510, Loss 0.10696753859519958\n",
            "Train step - Step 1520, Loss 0.1108599454164505\n",
            "Train step - Step 1530, Loss 0.10455993562936783\n",
            "Train epoch - Accuracy: 0.5103597122302158 Loss: 0.1053280342632918 Corrects: 3547\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.1048063412308693\n",
            "Train step - Step 1550, Loss 0.10924646258354187\n",
            "Train step - Step 1560, Loss 0.10867763310670853\n",
            "Train step - Step 1570, Loss 0.11158820986747742\n",
            "Train step - Step 1580, Loss 0.1035294234752655\n",
            "Train step - Step 1590, Loss 0.10209735482931137\n",
            "Train epoch - Accuracy: 0.5148201438848921 Loss: 0.10601054710235527 Corrects: 3578\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10739106684923172\n",
            "Train step - Step 1610, Loss 0.10489514470100403\n",
            "Train step - Step 1620, Loss 0.10426675528287888\n",
            "Train step - Step 1630, Loss 0.10427150130271912\n",
            "Train step - Step 1640, Loss 0.10075635462999344\n",
            "Train epoch - Accuracy: 0.5097841726618705 Loss: 0.1056918876248298 Corrects: 3543\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.11106830090284348\n",
            "Train step - Step 1660, Loss 0.10962482541799545\n",
            "Train step - Step 1670, Loss 0.0989442840218544\n",
            "Train step - Step 1680, Loss 0.10939639806747437\n",
            "Train step - Step 1690, Loss 0.1119777113199234\n",
            "Train step - Step 1700, Loss 0.10971513390541077\n",
            "Train epoch - Accuracy: 0.5139568345323741 Loss: 0.10584436316284344 Corrects: 3572\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.11377782374620438\n",
            "Train step - Step 1720, Loss 0.10399609059095383\n",
            "Train step - Step 1730, Loss 0.10270792990922928\n",
            "Train step - Step 1740, Loss 0.10725828260183334\n",
            "Train step - Step 1750, Loss 0.10554756969213486\n",
            "Train epoch - Accuracy: 0.5198561151079136 Loss: 0.1054068162372644 Corrects: 3613\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.1015549749135971\n",
            "Train step - Step 1770, Loss 0.10344516485929489\n",
            "Train step - Step 1780, Loss 0.1082683801651001\n",
            "Train step - Step 1790, Loss 0.10676390677690506\n",
            "Train step - Step 1800, Loss 0.10235905647277832\n",
            "Train step - Step 1810, Loss 0.10599477589130402\n",
            "Train epoch - Accuracy: 0.5228776978417267 Loss: 0.10544335678970214 Corrects: 3634\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.10017875581979752\n",
            "Train step - Step 1830, Loss 0.10390615463256836\n",
            "Train step - Step 1840, Loss 0.10962457209825516\n",
            "Train step - Step 1850, Loss 0.10393186658620834\n",
            "Train step - Step 1860, Loss 0.10048162192106247\n",
            "Train epoch - Accuracy: 0.5261870503597122 Loss: 0.10547152185182777 Corrects: 3657\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10247310250997543\n",
            "Train step - Step 1880, Loss 0.10517951101064682\n",
            "Train step - Step 1890, Loss 0.10733073949813843\n",
            "Train step - Step 1900, Loss 0.10758445411920547\n",
            "Train step - Step 1910, Loss 0.10665031522512436\n",
            "Train step - Step 1920, Loss 0.10927975177764893\n",
            "Train epoch - Accuracy: 0.5300719424460432 Loss: 0.10515331495794461 Corrects: 3684\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10515796393156052\n",
            "Train step - Step 1940, Loss 0.10533077269792557\n",
            "Train step - Step 1950, Loss 0.10765787214040756\n",
            "Train step - Step 1960, Loss 0.10683806985616684\n",
            "Train step - Step 1970, Loss 0.10492505878210068\n",
            "Train epoch - Accuracy: 0.5424460431654676 Loss: 0.10479780542121517 Corrects: 3770\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.10505445301532745\n",
            "Train step - Step 1990, Loss 0.10007709264755249\n",
            "Train step - Step 2000, Loss 0.11125388741493225\n",
            "Train step - Step 2010, Loss 0.1069943979382515\n",
            "Train step - Step 2020, Loss 0.10857423394918442\n",
            "Train step - Step 2030, Loss 0.1078653410077095\n",
            "Train epoch - Accuracy: 0.5384172661870503 Loss: 0.10500120746360408 Corrects: 3742\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10805152356624603\n",
            "Train step - Step 2050, Loss 0.10860833525657654\n",
            "Train step - Step 2060, Loss 0.09918109327554703\n",
            "Train step - Step 2070, Loss 0.10379484295845032\n",
            "Train step - Step 2080, Loss 0.10082387924194336\n",
            "Train epoch - Accuracy: 0.5423021582733812 Loss: 0.10486091094480145 Corrects: 3769\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10628696531057358\n",
            "Train step - Step 2100, Loss 0.10189180821180344\n",
            "Train step - Step 2110, Loss 0.10260140895843506\n",
            "Train step - Step 2120, Loss 0.10230337083339691\n",
            "Train step - Step 2130, Loss 0.107392318546772\n",
            "Train step - Step 2140, Loss 0.10077987611293793\n",
            "Train epoch - Accuracy: 0.5539568345323741 Loss: 0.1044695445852314 Corrects: 3850\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.10556585341691971\n",
            "Train step - Step 2160, Loss 0.10020696371793747\n",
            "Train step - Step 2170, Loss 0.10315045714378357\n",
            "Train step - Step 2180, Loss 0.10720863193273544\n",
            "Train step - Step 2190, Loss 0.1072443276643753\n",
            "Train epoch - Accuracy: 0.5487769784172661 Loss: 0.10433585144847417 Corrects: 3814\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.10311859101057053\n",
            "Train step - Step 2210, Loss 0.10714423656463623\n",
            "Train step - Step 2220, Loss 0.10262898355722427\n",
            "Train step - Step 2230, Loss 0.10567941516637802\n",
            "Train step - Step 2240, Loss 0.10170291364192963\n",
            "Train step - Step 2250, Loss 0.10318414121866226\n",
            "Train epoch - Accuracy: 0.5493525179856115 Loss: 0.10455709800016966 Corrects: 3818\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10757798701524734\n",
            "Train step - Step 2270, Loss 0.10059656202793121\n",
            "Train step - Step 2280, Loss 0.10256969928741455\n",
            "Train step - Step 2290, Loss 0.09932783991098404\n",
            "Train step - Step 2300, Loss 0.11159812659025192\n",
            "Train epoch - Accuracy: 0.5541007194244605 Loss: 0.10405428988684853 Corrects: 3851\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10006019473075867\n",
            "Train step - Step 2320, Loss 0.10557834059000015\n",
            "Train step - Step 2330, Loss 0.11377101391553879\n",
            "Train step - Step 2340, Loss 0.10209914296865463\n",
            "Train step - Step 2350, Loss 0.10755819082260132\n",
            "Train step - Step 2360, Loss 0.11245008558034897\n",
            "Train epoch - Accuracy: 0.560431654676259 Loss: 0.10412144287241448 Corrects: 3895\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.10209237039089203\n",
            "Train step - Step 2380, Loss 0.09469474852085114\n",
            "Train step - Step 2390, Loss 0.09832460433244705\n",
            "Train step - Step 2400, Loss 0.10655527561903\n",
            "Train step - Step 2410, Loss 0.10433845221996307\n",
            "Train epoch - Accuracy: 0.557841726618705 Loss: 0.10417904604681962 Corrects: 3877\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.10307589918375015\n",
            "Train step - Step 2430, Loss 0.09504281729459763\n",
            "Train step - Step 2440, Loss 0.10537251085042953\n",
            "Train step - Step 2450, Loss 0.10078813135623932\n",
            "Train step - Step 2460, Loss 0.10773451626300812\n",
            "Train step - Step 2470, Loss 0.10394151508808136\n",
            "Train epoch - Accuracy: 0.5686330935251799 Loss: 0.10368596680730367 Corrects: 3952\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10202585160732269\n",
            "Train step - Step 2490, Loss 0.1008119285106659\n",
            "Train step - Step 2500, Loss 0.10809246450662613\n",
            "Train step - Step 2510, Loss 0.09467858821153641\n",
            "Train step - Step 2520, Loss 0.10671456903219223\n",
            "Train epoch - Accuracy: 0.563884892086331 Loss: 0.10379012962897047 Corrects: 3919\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10666216909885406\n",
            "Train step - Step 2540, Loss 0.10211251676082611\n",
            "Train step - Step 2550, Loss 0.10069150477647781\n",
            "Train step - Step 2560, Loss 0.09694652259349823\n",
            "Train step - Step 2570, Loss 0.1028040274977684\n",
            "Train step - Step 2580, Loss 0.10794345289468765\n",
            "Train epoch - Accuracy: 0.5644604316546763 Loss: 0.10318435567531654 Corrects: 3923\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.09927831590175629\n",
            "Train step - Step 2600, Loss 0.09867344051599503\n",
            "Train step - Step 2610, Loss 0.10635512322187424\n",
            "Train step - Step 2620, Loss 0.1050441563129425\n",
            "Train step - Step 2630, Loss 0.10061142593622208\n",
            "Train epoch - Accuracy: 0.5741007194244604 Loss: 0.1033149590638044 Corrects: 3990\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.09848775714635849\n",
            "Train step - Step 2650, Loss 0.0963212177157402\n",
            "Train step - Step 2660, Loss 0.1021532490849495\n",
            "Train step - Step 2670, Loss 0.10666080564260483\n",
            "Train step - Step 2680, Loss 0.11079864203929901\n",
            "Train step - Step 2690, Loss 0.10701249539852142\n",
            "Train epoch - Accuracy: 0.5735251798561151 Loss: 0.10363533938102584 Corrects: 3986\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10679323226213455\n",
            "Train step - Step 2710, Loss 0.10382918268442154\n",
            "Train step - Step 2720, Loss 0.10659340769052505\n",
            "Train step - Step 2730, Loss 0.11061055213212967\n",
            "Train step - Step 2740, Loss 0.10794167965650558\n",
            "Train epoch - Accuracy: 0.5774100719424461 Loss: 0.10228808034667008 Corrects: 4013\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10046781599521637\n",
            "Train step - Step 2760, Loss 0.10090665519237518\n",
            "Train step - Step 2770, Loss 0.10341070592403412\n",
            "Train step - Step 2780, Loss 0.09642192721366882\n",
            "Train step - Step 2790, Loss 0.10864816606044769\n",
            "Train step - Step 2800, Loss 0.09806790947914124\n",
            "Train epoch - Accuracy: 0.579136690647482 Loss: 0.10208983531101144 Corrects: 4025\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.09842648357152939\n",
            "Train step - Step 2820, Loss 0.09773983806371689\n",
            "Train step - Step 2830, Loss 0.09876569360494614\n",
            "Train step - Step 2840, Loss 0.10514747351408005\n",
            "Train step - Step 2850, Loss 0.10221574455499649\n",
            "Train epoch - Accuracy: 0.5843165467625899 Loss: 0.10197232821862474 Corrects: 4061\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.1029958501458168\n",
            "Train step - Step 2870, Loss 0.09641633182764053\n",
            "Train step - Step 2880, Loss 0.10625907778739929\n",
            "Train step - Step 2890, Loss 0.10246291756629944\n",
            "Train step - Step 2900, Loss 0.10213138163089752\n",
            "Train step - Step 2910, Loss 0.09779368340969086\n",
            "Train epoch - Accuracy: 0.5788489208633093 Loss: 0.1016851394832563 Corrects: 4023\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10240825265645981\n",
            "Train step - Step 2930, Loss 0.09893874078989029\n",
            "Train step - Step 2940, Loss 0.103189617395401\n",
            "Train step - Step 2950, Loss 0.10649415105581284\n",
            "Train step - Step 2960, Loss 0.10527782142162323\n",
            "Train epoch - Accuracy: 0.5883453237410072 Loss: 0.1020199024527193 Corrects: 4089\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.10369113832712173\n",
            "Train step - Step 2980, Loss 0.09809041768312454\n",
            "Train step - Step 2990, Loss 0.10513865947723389\n",
            "Train step - Step 3000, Loss 0.10193170607089996\n",
            "Train step - Step 3010, Loss 0.10644567012786865\n",
            "Train step - Step 3020, Loss 0.10444705933332443\n",
            "Train epoch - Accuracy: 0.5890647482014388 Loss: 0.10195053120740026 Corrects: 4094\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.10267848521471024\n",
            "Train step - Step 3040, Loss 0.09900781512260437\n",
            "Train step - Step 3050, Loss 0.10365758836269379\n",
            "Train step - Step 3060, Loss 0.10000726580619812\n",
            "Train step - Step 3070, Loss 0.10211993008852005\n",
            "Train epoch - Accuracy: 0.5848920863309353 Loss: 0.10206571616714807 Corrects: 4065\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.10198109596967697\n",
            "Train step - Step 3090, Loss 0.10688558965921402\n",
            "Train step - Step 3100, Loss 0.09634215384721756\n",
            "Train step - Step 3110, Loss 0.10112470388412476\n",
            "Train step - Step 3120, Loss 0.10608766973018646\n",
            "Train step - Step 3130, Loss 0.10638727247714996\n",
            "Train epoch - Accuracy: 0.5850359712230215 Loss: 0.10164989188635092 Corrects: 4066\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10438022017478943\n",
            "Train step - Step 3150, Loss 0.10202813893556595\n",
            "Train step - Step 3160, Loss 0.10003667324781418\n",
            "Train step - Step 3170, Loss 0.09809713065624237\n",
            "Train step - Step 3180, Loss 0.09630763530731201\n",
            "Train epoch - Accuracy: 0.5890647482014388 Loss: 0.10202216787518358 Corrects: 4094\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10239043086767197\n",
            "Train step - Step 3200, Loss 0.10401572287082672\n",
            "Train step - Step 3210, Loss 0.10235249251127243\n",
            "Train step - Step 3220, Loss 0.10879578441381454\n",
            "Train step - Step 3230, Loss 0.09444568306207657\n",
            "Train step - Step 3240, Loss 0.10448721051216125\n",
            "Train epoch - Accuracy: 0.5876258992805755 Loss: 0.10204260570968655 Corrects: 4084\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.09965548664331436\n",
            "Train step - Step 3260, Loss 0.10085777193307877\n",
            "Train step - Step 3270, Loss 0.09916020184755325\n",
            "Train step - Step 3280, Loss 0.10152202099561691\n",
            "Train step - Step 3290, Loss 0.1014854684472084\n",
            "Train epoch - Accuracy: 0.5856115107913669 Loss: 0.10212233379161616 Corrects: 4070\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.11354389041662216\n",
            "Train step - Step 3310, Loss 0.09676572680473328\n",
            "Train step - Step 3320, Loss 0.09715720266103745\n",
            "Train step - Step 3330, Loss 0.10279145836830139\n",
            "Train step - Step 3340, Loss 0.1005653440952301\n",
            "Train step - Step 3350, Loss 0.10482732206583023\n",
            "Train epoch - Accuracy: 0.5870503597122302 Loss: 0.10131285520337469 Corrects: 4080\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.09963628649711609\n",
            "Train step - Step 3370, Loss 0.09671865403652191\n",
            "Train step - Step 3380, Loss 0.09853820502758026\n",
            "Train step - Step 3390, Loss 0.09534119069576263\n",
            "Train step - Step 3400, Loss 0.10081817209720612\n",
            "Train epoch - Accuracy: 0.5870503597122302 Loss: 0.10139839376048218 Corrects: 4080\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.10700801759958267\n",
            "Train step - Step 3420, Loss 0.10569580644369125\n",
            "Train step - Step 3430, Loss 0.10283345729112625\n",
            "Train step - Step 3440, Loss 0.10024964809417725\n",
            "Train step - Step 3450, Loss 0.10074624419212341\n",
            "Train step - Step 3460, Loss 0.09802886843681335\n",
            "Train epoch - Accuracy: 0.5854676258992806 Loss: 0.1018600034542221 Corrects: 4069\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.10718793421983719\n",
            "Train step - Step 3480, Loss 0.10233794897794724\n",
            "Train step - Step 3490, Loss 0.09859495609998703\n",
            "Train step - Step 3500, Loss 0.10040700435638428\n",
            "Train step - Step 3510, Loss 0.09928697347640991\n",
            "Train epoch - Accuracy: 0.5962589928057555 Loss: 0.10151335040656782 Corrects: 4144\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.10142233967781067\n",
            "Train step - Step 3530, Loss 0.09334696829319\n",
            "Train step - Step 3540, Loss 0.10986267030239105\n",
            "Train step - Step 3550, Loss 0.10697471350431442\n",
            "Train step - Step 3560, Loss 0.10241597890853882\n",
            "Train step - Step 3570, Loss 0.09687982499599457\n",
            "Train epoch - Accuracy: 0.5879136690647482 Loss: 0.10155858535346367 Corrects: 4086\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.09425298124551773\n",
            "Train step - Step 3590, Loss 0.10336637496948242\n",
            "Train step - Step 3600, Loss 0.10119979828596115\n",
            "Train step - Step 3610, Loss 0.09910091012716293\n",
            "Train step - Step 3620, Loss 0.1004842072725296\n",
            "Train epoch - Accuracy: 0.5920863309352518 Loss: 0.10151128698381588 Corrects: 4115\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.10681694000959396\n",
            "Train step - Step 3640, Loss 0.09701670706272125\n",
            "Train step - Step 3650, Loss 0.09879113733768463\n",
            "Train step - Step 3660, Loss 0.09584496170282364\n",
            "Train step - Step 3670, Loss 0.10287003964185715\n",
            "Train step - Step 3680, Loss 0.09510640799999237\n",
            "Train epoch - Accuracy: 0.5887769784172662 Loss: 0.10152216556904127 Corrects: 4092\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.0971750020980835\n",
            "Train step - Step 3700, Loss 0.09953559935092926\n",
            "Train step - Step 3710, Loss 0.09867126494646072\n",
            "Train step - Step 3720, Loss 0.10362931340932846\n",
            "Train step - Step 3730, Loss 0.10279463231563568\n",
            "Train epoch - Accuracy: 0.598273381294964 Loss: 0.1011570111646069 Corrects: 4158\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.10020843148231506\n",
            "Train step - Step 3750, Loss 0.10191211104393005\n",
            "Train step - Step 3760, Loss 0.09952440857887268\n",
            "Train step - Step 3770, Loss 0.10238223522901535\n",
            "Train step - Step 3780, Loss 0.09898891299962997\n",
            "Train step - Step 3790, Loss 0.1021418422460556\n",
            "Train epoch - Accuracy: 0.5916546762589928 Loss: 0.10122844387730248 Corrects: 4112\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.10053863376379013\n",
            "Train step - Step 3810, Loss 0.10407558083534241\n",
            "Train step - Step 3820, Loss 0.10527225583791733\n",
            "Train step - Step 3830, Loss 0.0998845249414444\n",
            "Train step - Step 3840, Loss 0.09877750277519226\n",
            "Train epoch - Accuracy: 0.5922302158273381 Loss: 0.10136116558913705 Corrects: 4116\n",
            "Training finished in 439.3895015716553 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96]\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  40\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237091d0>\n",
            "Constructing exemplars of class 55\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [8285, 40351, 1874, 26609, 23638, 44330, 31734, 15451, 25045, 13225, 24741, 11539, 28326, 41874, 21390, 2457, 36319, 14118, 24780, 12947, 38505, 1544, 15739, 7394, 47700, 13225, 7569, 47239, 13636, 27793, 41998, 9318, 33155, 31554, 23248, 15792, 37251, 9693, 5861, 380]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710340150>\n",
            "Constructing exemplars of class 31\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [10629, 10264, 12201, 29841, 20730, 2266, 7567, 36597, 24690, 11801, 23234, 8943, 2014, 28462, 14450, 7267, 39980, 9751, 36831, 29081, 29212, 20757, 13006, 8913, 6327, 9528, 41495, 23412, 24828, 44232, 4506, 7770, 43629, 23628, 41291, 33133, 33584, 9768, 24157, 45735]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b20f90>\n",
            "Constructing exemplars of class 19\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [32912, 32415, 37308, 44006, 38116, 30909, 3255, 15279, 17371, 351, 49758, 36011, 33818, 16642, 17773, 26339, 8360, 24477, 25925, 4993, 20607, 9423, 38332, 2208, 23946, 16908, 3416, 17972, 44231, 24181, 5946, 28663, 39074, 4919, 14911, 16186, 31712, 38897, 45771, 15855]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723584290>\n",
            "Constructing exemplars of class 98\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [637, 45343, 48433, 19023, 11806, 5039, 45936, 12513, 29073, 7108, 19014, 1267, 33110, 18208, 44398, 7050, 10259, 27881, 17733, 6097, 49763, 29909, 15835, 11547, 12194, 31524, 490, 29008, 34740, 12194, 25961, 14930, 18990, 31438, 21469, 45343, 38659, 36191, 27498, 29088]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671036a610>\n",
            "Constructing exemplars of class 94\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [33445, 45652, 18234, 35487, 47770, 17888, 41133, 12531, 32537, 22009, 11436, 10808, 44101, 9714, 5888, 21742, 43117, 626, 48149, 42471, 13826, 18675, 40908, 3363, 29501, 31910, 27975, 37068, 39985, 25935, 45593, 21048, 29603, 11066, 48746, 48158, 49023, 30594, 39005, 48006]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723484450>\n",
            "Constructing exemplars of class 54\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [10668, 32787, 7725, 4378, 33406, 36783, 37811, 36123, 33810, 27944, 30007, 8202, 45975, 33997, 12200, 40617, 1197, 24603, 6525, 29793, 45923, 40617, 21344, 40111, 12507, 1888, 2642, 12983, 27988, 7259, 36252, 498, 9082, 28273, 3926, 17111, 15935, 46727, 6794, 11851]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b20750>\n",
            "Constructing exemplars of class 93\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [7589, 37430, 37119, 28782, 33550, 32642, 19285, 35110, 35989, 34121, 44420, 38310, 27641, 35143, 23497, 35126, 38430, 35559, 16669, 12310, 11146, 38430, 47323, 27564, 27722, 16851, 47543, 14651, 41834, 6963, 36572, 43507, 11146, 9717, 1488, 7309, 5045, 22730, 730, 11099]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237ddfd0>\n",
            "Constructing exemplars of class 85\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [14097, 28405, 31125, 23413, 4941, 5548, 37650, 2461, 39634, 47723, 14641, 18907, 1604, 16648, 21602, 40961, 37190, 16247, 34615, 3481, 13613, 21638, 31125, 42142, 28144, 33784, 12601, 35358, 18175, 16549, 1326, 19780, 3071, 5288, 18743, 2195, 35998, 17758, 43631, 48928]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723063bd0>\n",
            "Constructing exemplars of class 9\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [46763, 35043, 45128, 44039, 17218, 49925, 46945, 8540, 4404, 45150, 9933, 31188, 41724, 1165, 28458, 13736, 20680, 32310, 13668, 37666, 433, 5671, 14003, 45087, 36678, 9178, 39887, 13866, 14188, 30367, 39336, 40703, 30001, 12993, 32659, 14188, 23279, 36120, 25471, 27333]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6786099810>\n",
            "Constructing exemplars of class 96\n",
            "lunghezza exemplar set:  40\n",
            "exemplar set:  [349, 18099, 31871, 47211, 10056, 41191, 27370, 48344, 31615, 29327, 10348, 16530, 48655, 14915, 10861, 704, 8274, 47254, 28535, 38158, 17552, 2552, 2960, 31046, 16530, 23671, 40701, 2145, 11674, 10613, 15172, 34709, 39017, 17725, 43123, 44895, 42917, 6421, 2545, 33085]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.5 0.09587802737951279\n",
            "TEST GROUP:  0.487\n",
            "TEST ALL:  0.5342\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  6000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 95, 85, 81, 65, 61, 57, 49, 45, 21, 13, 9, 96, 88, 80, 76, 72, 68, 64, 60, 56, 40, 36, 32, 24, 20, 16, 8, 4, 93, 97, 2, 15, 83, 79, 75, 67, 63, 59, 55, 47, 39, 31, 23, 19, 7, 6, 98, 94, 90, 82, 54, 42, 34, 30, 22, 18, 14, 10, 0]\n",
            "TRAIN_SET CLASSES:  [99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "VALIDATION CLASSES:  [60, 57, 45, 40, 99, 88, 15, 14, 13, 8]\n",
            "GROUP:  6\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  60\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.2581162452697754\n",
            "Train step - Step 10, Loss 0.13761138916015625\n",
            "Train step - Step 20, Loss 0.1396266669034958\n",
            "Train step - Step 30, Loss 0.12900273501873016\n",
            "Train step - Step 40, Loss 0.12832438945770264\n",
            "Train step - Step 50, Loss 0.1293415129184723\n",
            "Train epoch - Accuracy: 0.18402877697841727 Loss: 0.14341389579738645 Corrects: 1279\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.1238412857055664\n",
            "Train step - Step 70, Loss 0.11931054294109344\n",
            "Train step - Step 80, Loss 0.11457224190235138\n",
            "Train step - Step 90, Loss 0.12169662117958069\n",
            "Train step - Step 100, Loss 0.12420988827943802\n",
            "Train epoch - Accuracy: 0.21179856115107915 Loss: 0.12066250219405127 Corrects: 1472\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.12129595875740051\n",
            "Train step - Step 120, Loss 0.12334241718053818\n",
            "Train step - Step 130, Loss 0.11264220625162125\n",
            "Train step - Step 140, Loss 0.11972592025995255\n",
            "Train step - Step 150, Loss 0.11517290771007538\n",
            "Train step - Step 160, Loss 0.11801870912313461\n",
            "Train epoch - Accuracy: 0.2428776978417266 Loss: 0.11818093205956247 Corrects: 1688\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11374663561582565\n",
            "Train step - Step 180, Loss 0.11698907613754272\n",
            "Train step - Step 190, Loss 0.11393740028142929\n",
            "Train step - Step 200, Loss 0.120743028819561\n",
            "Train step - Step 210, Loss 0.11960768699645996\n",
            "Train epoch - Accuracy: 0.2693525179856115 Loss: 0.11692473070226984 Corrects: 1872\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.12042507529258728\n",
            "Train step - Step 230, Loss 0.12472689151763916\n",
            "Train step - Step 240, Loss 0.11343985795974731\n",
            "Train step - Step 250, Loss 0.12058250606060028\n",
            "Train step - Step 260, Loss 0.11924199014902115\n",
            "Train step - Step 270, Loss 0.11506547033786774\n",
            "Train epoch - Accuracy: 0.29165467625899283 Loss: 0.11596262793317973 Corrects: 2027\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.11897166818380356\n",
            "Train step - Step 290, Loss 0.11380088329315186\n",
            "Train step - Step 300, Loss 0.11727141588926315\n",
            "Train step - Step 310, Loss 0.11904598027467728\n",
            "Train step - Step 320, Loss 0.11669204384088516\n",
            "Train epoch - Accuracy: 0.31553956834532376 Loss: 0.11515629877932637 Corrects: 2193\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.11831852048635483\n",
            "Train step - Step 340, Loss 0.12037820369005203\n",
            "Train step - Step 350, Loss 0.11265809834003448\n",
            "Train step - Step 360, Loss 0.1153489500284195\n",
            "Train step - Step 370, Loss 0.11689251661300659\n",
            "Train step - Step 380, Loss 0.10752636939287186\n",
            "Train epoch - Accuracy: 0.33050359712230215 Loss: 0.11508882005223267 Corrects: 2297\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11246539652347565\n",
            "Train step - Step 400, Loss 0.11830034852027893\n",
            "Train step - Step 410, Loss 0.11695889383554459\n",
            "Train step - Step 420, Loss 0.1155414879322052\n",
            "Train step - Step 430, Loss 0.11057128012180328\n",
            "Train epoch - Accuracy: 0.34733812949640286 Loss: 0.1142755348498015 Corrects: 2414\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.11922325193881989\n",
            "Train step - Step 450, Loss 0.11368726193904877\n",
            "Train step - Step 460, Loss 0.11653255671262741\n",
            "Train step - Step 470, Loss 0.11031594127416611\n",
            "Train step - Step 480, Loss 0.10795696079730988\n",
            "Train step - Step 490, Loss 0.11372501403093338\n",
            "Train epoch - Accuracy: 0.36503597122302156 Loss: 0.11353822999720951 Corrects: 2537\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.11619891226291656\n",
            "Train step - Step 510, Loss 0.11034266650676727\n",
            "Train step - Step 520, Loss 0.11623083800077438\n",
            "Train step - Step 530, Loss 0.10749796032905579\n",
            "Train step - Step 540, Loss 0.107472725212574\n",
            "Train epoch - Accuracy: 0.3702158273381295 Loss: 0.11358423717587972 Corrects: 2573\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.11510854959487915\n",
            "Train step - Step 560, Loss 0.11148907244205475\n",
            "Train step - Step 570, Loss 0.11494459211826324\n",
            "Train step - Step 580, Loss 0.11031622439622879\n",
            "Train step - Step 590, Loss 0.11676908284425735\n",
            "Train step - Step 600, Loss 0.11885780096054077\n",
            "Train epoch - Accuracy: 0.38719424460431656 Loss: 0.11330045768897311 Corrects: 2691\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.11634662002325058\n",
            "Train step - Step 620, Loss 0.11619787663221359\n",
            "Train step - Step 630, Loss 0.11338358372449875\n",
            "Train step - Step 640, Loss 0.11197686940431595\n",
            "Train step - Step 650, Loss 0.11282601952552795\n",
            "Train epoch - Accuracy: 0.3906474820143885 Loss: 0.11281229135158251 Corrects: 2715\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.11002720892429352\n",
            "Train step - Step 670, Loss 0.11497881263494492\n",
            "Train step - Step 680, Loss 0.11369574069976807\n",
            "Train step - Step 690, Loss 0.11135827004909515\n",
            "Train step - Step 700, Loss 0.11546461284160614\n",
            "Train step - Step 710, Loss 0.11974126100540161\n",
            "Train epoch - Accuracy: 0.400431654676259 Loss: 0.11274896670588487 Corrects: 2783\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.11740072071552277\n",
            "Train step - Step 730, Loss 0.11137905716896057\n",
            "Train step - Step 740, Loss 0.11327429860830307\n",
            "Train step - Step 750, Loss 0.10893476009368896\n",
            "Train step - Step 760, Loss 0.11914607882499695\n",
            "Train epoch - Accuracy: 0.4060431654676259 Loss: 0.11243125109363802 Corrects: 2822\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.11180900037288666\n",
            "Train step - Step 780, Loss 0.11666058003902435\n",
            "Train step - Step 790, Loss 0.1118726059794426\n",
            "Train step - Step 800, Loss 0.11286288499832153\n",
            "Train step - Step 810, Loss 0.11312265694141388\n",
            "Train step - Step 820, Loss 0.11296820640563965\n",
            "Train epoch - Accuracy: 0.4223021582733813 Loss: 0.11228106757505335 Corrects: 2935\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.1055988147854805\n",
            "Train step - Step 840, Loss 0.11364047974348068\n",
            "Train step - Step 850, Loss 0.10757055878639221\n",
            "Train step - Step 860, Loss 0.11182229220867157\n",
            "Train step - Step 870, Loss 0.11658366769552231\n",
            "Train epoch - Accuracy: 0.4179856115107914 Loss: 0.11211070391771605 Corrects: 2905\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.1114320158958435\n",
            "Train step - Step 890, Loss 0.11144407093524933\n",
            "Train step - Step 900, Loss 0.10891734063625336\n",
            "Train step - Step 910, Loss 0.10928278416395187\n",
            "Train step - Step 920, Loss 0.11987404525279999\n",
            "Train step - Step 930, Loss 0.11430742591619492\n",
            "Train epoch - Accuracy: 0.4322302158273381 Loss: 0.1117070732271071 Corrects: 3004\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.10964304208755493\n",
            "Train step - Step 950, Loss 0.11281763762235641\n",
            "Train step - Step 960, Loss 0.11148416996002197\n",
            "Train step - Step 970, Loss 0.11093473434448242\n",
            "Train step - Step 980, Loss 0.10602183640003204\n",
            "Train epoch - Accuracy: 0.439136690647482 Loss: 0.11187929706178981 Corrects: 3052\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10619877278804779\n",
            "Train step - Step 1000, Loss 0.11669664829969406\n",
            "Train step - Step 1010, Loss 0.1119813472032547\n",
            "Train step - Step 1020, Loss 0.1216697096824646\n",
            "Train step - Step 1030, Loss 0.11040396243333817\n",
            "Train step - Step 1040, Loss 0.12076179683208466\n",
            "Train epoch - Accuracy: 0.44316546762589926 Loss: 0.11114640812436453 Corrects: 3080\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.11609693616628647\n",
            "Train step - Step 1060, Loss 0.11283757537603378\n",
            "Train step - Step 1070, Loss 0.11176060885190964\n",
            "Train step - Step 1080, Loss 0.1111292615532875\n",
            "Train step - Step 1090, Loss 0.11165514588356018\n",
            "Train epoch - Accuracy: 0.4486330935251799 Loss: 0.1113444488897598 Corrects: 3118\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.11275544762611389\n",
            "Train step - Step 1110, Loss 0.11683919280767441\n",
            "Train step - Step 1120, Loss 0.11582623422145844\n",
            "Train step - Step 1130, Loss 0.11168376356363297\n",
            "Train step - Step 1140, Loss 0.1108260527253151\n",
            "Train step - Step 1150, Loss 0.11645341664552689\n",
            "Train epoch - Accuracy: 0.4589928057553957 Loss: 0.11124429822396889 Corrects: 3190\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.11241362243890762\n",
            "Train step - Step 1170, Loss 0.10983593016862869\n",
            "Train step - Step 1180, Loss 0.10889679938554764\n",
            "Train step - Step 1190, Loss 0.10741976648569107\n",
            "Train step - Step 1200, Loss 0.10937134176492691\n",
            "Train epoch - Accuracy: 0.4687769784172662 Loss: 0.11090518279255723 Corrects: 3258\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.11279621720314026\n",
            "Train step - Step 1220, Loss 0.11139960587024689\n",
            "Train step - Step 1230, Loss 0.10774142295122147\n",
            "Train step - Step 1240, Loss 0.11230111867189407\n",
            "Train step - Step 1250, Loss 0.10724770277738571\n",
            "Train step - Step 1260, Loss 0.11104457825422287\n",
            "Train epoch - Accuracy: 0.4716546762589928 Loss: 0.11076420424867876 Corrects: 3278\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.11017189919948578\n",
            "Train step - Step 1280, Loss 0.10459825396537781\n",
            "Train step - Step 1290, Loss 0.11471790820360184\n",
            "Train step - Step 1300, Loss 0.113836370408535\n",
            "Train step - Step 1310, Loss 0.10819438844919205\n",
            "Train epoch - Accuracy: 0.4656115107913669 Loss: 0.11061704329020686 Corrects: 3236\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.11108794063329697\n",
            "Train step - Step 1330, Loss 0.10440327972173691\n",
            "Train step - Step 1340, Loss 0.10567203164100647\n",
            "Train step - Step 1350, Loss 0.11398380249738693\n",
            "Train step - Step 1360, Loss 0.10753154009580612\n",
            "Train step - Step 1370, Loss 0.11080790311098099\n",
            "Train epoch - Accuracy: 0.48215827338129497 Loss: 0.11041327150176755 Corrects: 3351\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10807539522647858\n",
            "Train step - Step 1390, Loss 0.1049450933933258\n",
            "Train step - Step 1400, Loss 0.10868969559669495\n",
            "Train step - Step 1410, Loss 0.10940518975257874\n",
            "Train step - Step 1420, Loss 0.1055397093296051\n",
            "Train epoch - Accuracy: 0.4856115107913669 Loss: 0.11021057014842685 Corrects: 3375\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10731077939271927\n",
            "Train step - Step 1440, Loss 0.10837835818529129\n",
            "Train step - Step 1450, Loss 0.11574745923280716\n",
            "Train step - Step 1460, Loss 0.11247094720602036\n",
            "Train step - Step 1470, Loss 0.1087767630815506\n",
            "Train step - Step 1480, Loss 0.11084498465061188\n",
            "Train epoch - Accuracy: 0.47942446043165465 Loss: 0.11009088909668888 Corrects: 3332\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.11076908558607101\n",
            "Train step - Step 1500, Loss 0.1143593043088913\n",
            "Train step - Step 1510, Loss 0.11388768255710602\n",
            "Train step - Step 1520, Loss 0.11107657849788666\n",
            "Train step - Step 1530, Loss 0.11178269982337952\n",
            "Train epoch - Accuracy: 0.49366906474820144 Loss: 0.11017378983523349 Corrects: 3431\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.10781334340572357\n",
            "Train step - Step 1550, Loss 0.10591861605644226\n",
            "Train step - Step 1560, Loss 0.10175041109323502\n",
            "Train step - Step 1570, Loss 0.10423630475997925\n",
            "Train step - Step 1580, Loss 0.10308385640382767\n",
            "Train step - Step 1590, Loss 0.11387293040752411\n",
            "Train epoch - Accuracy: 0.49424460431654677 Loss: 0.10991777272747574 Corrects: 3435\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10753180086612701\n",
            "Train step - Step 1610, Loss 0.11132263392210007\n",
            "Train step - Step 1620, Loss 0.10992235690355301\n",
            "Train step - Step 1630, Loss 0.1113245040178299\n",
            "Train step - Step 1640, Loss 0.11195018887519836\n",
            "Train epoch - Accuracy: 0.4962589928057554 Loss: 0.11001112912198623 Corrects: 3449\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.10771133750677109\n",
            "Train step - Step 1660, Loss 0.1106928214430809\n",
            "Train step - Step 1670, Loss 0.10900644212961197\n",
            "Train step - Step 1680, Loss 0.11196154356002808\n",
            "Train step - Step 1690, Loss 0.10989416390657425\n",
            "Train step - Step 1700, Loss 0.1074259951710701\n",
            "Train epoch - Accuracy: 0.505179856115108 Loss: 0.1097544642403829 Corrects: 3511\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.10763797163963318\n",
            "Train step - Step 1720, Loss 0.10529592633247375\n",
            "Train step - Step 1730, Loss 0.10914395749568939\n",
            "Train step - Step 1740, Loss 0.11845328658819199\n",
            "Train step - Step 1750, Loss 0.11183823645114899\n",
            "Train epoch - Accuracy: 0.5130935251798561 Loss: 0.10961912860115655 Corrects: 3566\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.1071605235338211\n",
            "Train step - Step 1770, Loss 0.11039543896913528\n",
            "Train step - Step 1780, Loss 0.1156000867486\n",
            "Train step - Step 1790, Loss 0.1080486848950386\n",
            "Train step - Step 1800, Loss 0.10493582487106323\n",
            "Train step - Step 1810, Loss 0.11139976978302002\n",
            "Train epoch - Accuracy: 0.5119424460431655 Loss: 0.1095697424051573 Corrects: 3558\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.10964058339595795\n",
            "Train step - Step 1830, Loss 0.10936934500932693\n",
            "Train step - Step 1840, Loss 0.10612437129020691\n",
            "Train step - Step 1850, Loss 0.11009609699249268\n",
            "Train step - Step 1860, Loss 0.10910908877849579\n",
            "Train epoch - Accuracy: 0.5123741007194245 Loss: 0.10959464043164424 Corrects: 3561\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10359741002321243\n",
            "Train step - Step 1880, Loss 0.10937478393316269\n",
            "Train step - Step 1890, Loss 0.10318771004676819\n",
            "Train step - Step 1900, Loss 0.10704576224088669\n",
            "Train step - Step 1910, Loss 0.113003671169281\n",
            "Train step - Step 1920, Loss 0.11319727450609207\n",
            "Train epoch - Accuracy: 0.522158273381295 Loss: 0.10891757463165325 Corrects: 3629\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.12001149356365204\n",
            "Train step - Step 1940, Loss 0.11063531786203384\n",
            "Train step - Step 1950, Loss 0.10812057554721832\n",
            "Train step - Step 1960, Loss 0.10591144859790802\n",
            "Train step - Step 1970, Loss 0.11231452226638794\n",
            "Train epoch - Accuracy: 0.5166906474820144 Loss: 0.10931402396169498 Corrects: 3591\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.10634211450815201\n",
            "Train step - Step 1990, Loss 0.11387041956186295\n",
            "Train step - Step 2000, Loss 0.1106315478682518\n",
            "Train step - Step 2010, Loss 0.10351687669754028\n",
            "Train step - Step 2020, Loss 0.10970611125230789\n",
            "Train step - Step 2030, Loss 0.11120744794607162\n",
            "Train epoch - Accuracy: 0.5273381294964029 Loss: 0.10866241714294009 Corrects: 3665\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.1037677749991417\n",
            "Train step - Step 2050, Loss 0.10670337080955505\n",
            "Train step - Step 2060, Loss 0.10691112279891968\n",
            "Train step - Step 2070, Loss 0.10647791624069214\n",
            "Train step - Step 2080, Loss 0.10277542471885681\n",
            "Train epoch - Accuracy: 0.5353956834532374 Loss: 0.10866360339758208 Corrects: 3721\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.11222034692764282\n",
            "Train step - Step 2100, Loss 0.11480475217103958\n",
            "Train step - Step 2110, Loss 0.10823675245046616\n",
            "Train step - Step 2120, Loss 0.10758635401725769\n",
            "Train step - Step 2130, Loss 0.10363341867923737\n",
            "Train step - Step 2140, Loss 0.1144760325551033\n",
            "Train epoch - Accuracy: 0.5353956834532374 Loss: 0.10893554002904206 Corrects: 3721\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.11203684657812119\n",
            "Train step - Step 2160, Loss 0.10607348382472992\n",
            "Train step - Step 2170, Loss 0.11088867485523224\n",
            "Train step - Step 2180, Loss 0.10589217394590378\n",
            "Train step - Step 2190, Loss 0.10417552292346954\n",
            "Train epoch - Accuracy: 0.5310791366906474 Loss: 0.10860055414678381 Corrects: 3691\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.109883613884449\n",
            "Train step - Step 2210, Loss 0.10834582149982452\n",
            "Train step - Step 2220, Loss 0.10903039574623108\n",
            "Train step - Step 2230, Loss 0.1033472940325737\n",
            "Train step - Step 2240, Loss 0.11306742578744888\n",
            "Train step - Step 2250, Loss 0.10939132422208786\n",
            "Train epoch - Accuracy: 0.5361151079136691 Loss: 0.10891899405409106 Corrects: 3726\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10626896470785141\n",
            "Train step - Step 2270, Loss 0.10839556902647018\n",
            "Train step - Step 2280, Loss 0.1132328063249588\n",
            "Train step - Step 2290, Loss 0.1057899221777916\n",
            "Train step - Step 2300, Loss 0.11690154671669006\n",
            "Train epoch - Accuracy: 0.544748201438849 Loss: 0.10888087475256954 Corrects: 3786\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10462918877601624\n",
            "Train step - Step 2320, Loss 0.11032168567180634\n",
            "Train step - Step 2330, Loss 0.09965582191944122\n",
            "Train step - Step 2340, Loss 0.1127111166715622\n",
            "Train step - Step 2350, Loss 0.10892678052186966\n",
            "Train step - Step 2360, Loss 0.11010490357875824\n",
            "Train epoch - Accuracy: 0.5471942446043165 Loss: 0.10882988400167698 Corrects: 3803\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.1091216653585434\n",
            "Train step - Step 2380, Loss 0.1072297915816307\n",
            "Train step - Step 2390, Loss 0.10491656512022018\n",
            "Train step - Step 2400, Loss 0.10776761174201965\n",
            "Train step - Step 2410, Loss 0.10648278892040253\n",
            "Train epoch - Accuracy: 0.5415827338129496 Loss: 0.10826300280557262 Corrects: 3764\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.10726131498813629\n",
            "Train step - Step 2430, Loss 0.10837897658348083\n",
            "Train step - Step 2440, Loss 0.10993802547454834\n",
            "Train step - Step 2450, Loss 0.11006549000740051\n",
            "Train step - Step 2460, Loss 0.11245168745517731\n",
            "Train step - Step 2470, Loss 0.10772982984781265\n",
            "Train epoch - Accuracy: 0.5581294964028777 Loss: 0.10818321354312005 Corrects: 3879\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.11018848419189453\n",
            "Train step - Step 2490, Loss 0.10056041926145554\n",
            "Train step - Step 2500, Loss 0.10624726861715317\n",
            "Train step - Step 2510, Loss 0.10692911595106125\n",
            "Train step - Step 2520, Loss 0.11083535850048065\n",
            "Train epoch - Accuracy: 0.5598561151079137 Loss: 0.1078178646581636 Corrects: 3891\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.10624759644269943\n",
            "Train step - Step 2540, Loss 0.1091860681772232\n",
            "Train step - Step 2550, Loss 0.10873105376958847\n",
            "Train step - Step 2560, Loss 0.10688959062099457\n",
            "Train step - Step 2570, Loss 0.10524780303239822\n",
            "Train step - Step 2580, Loss 0.11182071268558502\n",
            "Train epoch - Accuracy: 0.5575539568345323 Loss: 0.10794682116174012 Corrects: 3875\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.10713168978691101\n",
            "Train step - Step 2600, Loss 0.11434449255466461\n",
            "Train step - Step 2610, Loss 0.11361940205097198\n",
            "Train step - Step 2620, Loss 0.10402023792266846\n",
            "Train step - Step 2630, Loss 0.1093176007270813\n",
            "Train epoch - Accuracy: 0.5644604316546763 Loss: 0.1078433972425598 Corrects: 3923\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.10740958154201508\n",
            "Train step - Step 2650, Loss 0.11126924306154251\n",
            "Train step - Step 2660, Loss 0.10970217734575272\n",
            "Train step - Step 2670, Loss 0.11016730219125748\n",
            "Train step - Step 2680, Loss 0.11557967960834503\n",
            "Train step - Step 2690, Loss 0.10711081326007843\n",
            "Train epoch - Accuracy: 0.5623021582733813 Loss: 0.10771312182541373 Corrects: 3908\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10139849781990051\n",
            "Train step - Step 2710, Loss 0.10502795875072479\n",
            "Train step - Step 2720, Loss 0.10901454091072083\n",
            "Train step - Step 2730, Loss 0.10819932818412781\n",
            "Train step - Step 2740, Loss 0.10726416110992432\n",
            "Train epoch - Accuracy: 0.5713669064748201 Loss: 0.10727381893627935 Corrects: 3971\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.10164731740951538\n",
            "Train step - Step 2760, Loss 0.10925069451332092\n",
            "Train step - Step 2770, Loss 0.10684370249509811\n",
            "Train step - Step 2780, Loss 0.10229739546775818\n",
            "Train step - Step 2790, Loss 0.10487835109233856\n",
            "Train step - Step 2800, Loss 0.10598412156105042\n",
            "Train epoch - Accuracy: 0.5728057553956835 Loss: 0.1068039956731762 Corrects: 3981\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10308349132537842\n",
            "Train step - Step 2820, Loss 0.10128766298294067\n",
            "Train step - Step 2830, Loss 0.10268158465623856\n",
            "Train step - Step 2840, Loss 0.10705991834402084\n",
            "Train step - Step 2850, Loss 0.11060699075460434\n",
            "Train epoch - Accuracy: 0.5689208633093525 Loss: 0.10678267237308214 Corrects: 3954\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.10718438029289246\n",
            "Train step - Step 2870, Loss 0.10121414065361023\n",
            "Train step - Step 2880, Loss 0.1059269905090332\n",
            "Train step - Step 2890, Loss 0.09798502922058105\n",
            "Train step - Step 2900, Loss 0.10825664550065994\n",
            "Train step - Step 2910, Loss 0.10323290526866913\n",
            "Train epoch - Accuracy: 0.5805755395683453 Loss: 0.10660769355811661 Corrects: 4035\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10670235008001328\n",
            "Train step - Step 2930, Loss 0.11284276098012924\n",
            "Train step - Step 2940, Loss 0.10606522113084793\n",
            "Train step - Step 2950, Loss 0.10826753824949265\n",
            "Train step - Step 2960, Loss 0.10077906399965286\n",
            "Train epoch - Accuracy: 0.5707913669064748 Loss: 0.10641612453640793 Corrects: 3967\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.10165024548768997\n",
            "Train step - Step 2980, Loss 0.10408211499452591\n",
            "Train step - Step 2990, Loss 0.10930266976356506\n",
            "Train step - Step 3000, Loss 0.10364323854446411\n",
            "Train step - Step 3010, Loss 0.10717128217220306\n",
            "Train step - Step 3020, Loss 0.10422942042350769\n",
            "Train epoch - Accuracy: 0.5706474820143885 Loss: 0.10662417486846018 Corrects: 3966\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.113578662276268\n",
            "Train step - Step 3040, Loss 0.10702688992023468\n",
            "Train step - Step 3050, Loss 0.10360583662986755\n",
            "Train step - Step 3060, Loss 0.1066293865442276\n",
            "Train step - Step 3070, Loss 0.10788579285144806\n",
            "Train epoch - Accuracy: 0.5764028776978417 Loss: 0.10681192526500002 Corrects: 4006\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.11046472936868668\n",
            "Train step - Step 3090, Loss 0.11236601322889328\n",
            "Train step - Step 3100, Loss 0.10950970649719238\n",
            "Train step - Step 3110, Loss 0.10977113991975784\n",
            "Train step - Step 3120, Loss 0.10367489606142044\n",
            "Train step - Step 3130, Loss 0.11001718044281006\n",
            "Train epoch - Accuracy: 0.5792805755395684 Loss: 0.106282663555454 Corrects: 4026\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10729574412107468\n",
            "Train step - Step 3150, Loss 0.10629023611545563\n",
            "Train step - Step 3160, Loss 0.10829183459281921\n",
            "Train step - Step 3170, Loss 0.10580805689096451\n",
            "Train step - Step 3180, Loss 0.11011160910129547\n",
            "Train epoch - Accuracy: 0.5766906474820144 Loss: 0.10666820903690599 Corrects: 4008\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10664094239473343\n",
            "Train step - Step 3200, Loss 0.11096317321062088\n",
            "Train step - Step 3210, Loss 0.10570016503334045\n",
            "Train step - Step 3220, Loss 0.10825253278017044\n",
            "Train step - Step 3230, Loss 0.10683214664459229\n",
            "Train step - Step 3240, Loss 0.11049968749284744\n",
            "Train epoch - Accuracy: 0.5784172661870504 Loss: 0.10667069461705873 Corrects: 4020\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.10407662391662598\n",
            "Train step - Step 3260, Loss 0.10315617173910141\n",
            "Train step - Step 3270, Loss 0.10796964168548584\n",
            "Train step - Step 3280, Loss 0.10002370923757553\n",
            "Train step - Step 3290, Loss 0.10690445452928543\n",
            "Train epoch - Accuracy: 0.581294964028777 Loss: 0.10631389367709057 Corrects: 4040\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.11217213422060013\n",
            "Train step - Step 3310, Loss 0.09665629267692566\n",
            "Train step - Step 3320, Loss 0.11204330623149872\n",
            "Train step - Step 3330, Loss 0.10748304426670074\n",
            "Train step - Step 3340, Loss 0.10756397992372513\n",
            "Train step - Step 3350, Loss 0.11124339699745178\n",
            "Train epoch - Accuracy: 0.5781294964028777 Loss: 0.10643501962903593 Corrects: 4018\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.10353461652994156\n",
            "Train step - Step 3370, Loss 0.10529270768165588\n",
            "Train step - Step 3380, Loss 0.10618676245212555\n",
            "Train step - Step 3390, Loss 0.10076097398996353\n",
            "Train step - Step 3400, Loss 0.09820663183927536\n",
            "Train epoch - Accuracy: 0.5824460431654677 Loss: 0.1064169011163197 Corrects: 4048\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.11487891525030136\n",
            "Train step - Step 3420, Loss 0.10939426720142365\n",
            "Train step - Step 3430, Loss 0.11138490587472916\n",
            "Train step - Step 3440, Loss 0.10941577702760696\n",
            "Train step - Step 3450, Loss 0.10702308267354965\n",
            "Train step - Step 3460, Loss 0.10558855533599854\n",
            "Train epoch - Accuracy: 0.5779856115107914 Loss: 0.10649247469661904 Corrects: 4017\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.1007041484117508\n",
            "Train step - Step 3480, Loss 0.10237227380275726\n",
            "Train step - Step 3490, Loss 0.1060694083571434\n",
            "Train step - Step 3500, Loss 0.10609985142946243\n",
            "Train step - Step 3510, Loss 0.10765978693962097\n",
            "Train epoch - Accuracy: 0.5810071942446043 Loss: 0.10620507389092616 Corrects: 4038\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.11005537211894989\n",
            "Train step - Step 3530, Loss 0.10722685605287552\n",
            "Train step - Step 3540, Loss 0.10720746964216232\n",
            "Train step - Step 3550, Loss 0.10502539575099945\n",
            "Train step - Step 3560, Loss 0.10379602760076523\n",
            "Train step - Step 3570, Loss 0.09752707928419113\n",
            "Train epoch - Accuracy: 0.576978417266187 Loss: 0.10606612875307207 Corrects: 4010\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.11193301528692245\n",
            "Train step - Step 3590, Loss 0.10721780359745026\n",
            "Train step - Step 3600, Loss 0.10495670884847641\n",
            "Train step - Step 3610, Loss 0.10095252841711044\n",
            "Train step - Step 3620, Loss 0.10661473870277405\n",
            "Train epoch - Accuracy: 0.5889208633093526 Loss: 0.10614195612265909 Corrects: 4093\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.10800988227128983\n",
            "Train step - Step 3640, Loss 0.10581903904676437\n",
            "Train step - Step 3650, Loss 0.10124936699867249\n",
            "Train step - Step 3660, Loss 0.10221614688634872\n",
            "Train step - Step 3670, Loss 0.1029585674405098\n",
            "Train step - Step 3680, Loss 0.10177747905254364\n",
            "Train epoch - Accuracy: 0.5801438848920863 Loss: 0.10627867832243872 Corrects: 4032\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.10215438902378082\n",
            "Train step - Step 3700, Loss 0.1046941801905632\n",
            "Train step - Step 3710, Loss 0.10517548769712448\n",
            "Train step - Step 3720, Loss 0.11063544452190399\n",
            "Train step - Step 3730, Loss 0.1034659892320633\n",
            "Train epoch - Accuracy: 0.5823021582733813 Loss: 0.10624408648811656 Corrects: 4047\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.1032218188047409\n",
            "Train step - Step 3750, Loss 0.1004425436258316\n",
            "Train step - Step 3760, Loss 0.1100405752658844\n",
            "Train step - Step 3770, Loss 0.10544875264167786\n",
            "Train step - Step 3780, Loss 0.10183047503232956\n",
            "Train step - Step 3790, Loss 0.10800421237945557\n",
            "Train epoch - Accuracy: 0.5768345323741008 Loss: 0.10615305885994177 Corrects: 4009\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.11465344578027725\n",
            "Train step - Step 3810, Loss 0.10417577624320984\n",
            "Train step - Step 3820, Loss 0.10267079621553421\n",
            "Train step - Step 3830, Loss 0.11421826481819153\n",
            "Train step - Step 3840, Loss 0.1014619991183281\n",
            "Train epoch - Accuracy: 0.5861870503597122 Loss: 0.10604530650077107 Corrects: 4074\n",
            "Training finished in 440.0236828327179 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8]\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  33\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67235778d0>\n",
            "Constructing exemplars of class 99\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [32723, 37099, 16239, 27288, 24561, 11626, 33087, 9129, 25635, 30583, 36899, 1640, 22698, 41278, 5903, 28110, 10718, 4427, 33326, 40593, 39640, 14381, 16719, 30627, 44540, 3121, 47507, 40720, 32302, 25410, 32284, 41888, 47362]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723484590>\n",
            "Constructing exemplars of class 15\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [23590, 17904, 37351, 23790, 20988, 37806, 23092, 36867, 376, 44628, 21203, 35927, 40863, 47242, 26245, 49784, 12704, 33400, 40183, 36811, 5681, 38652, 3374, 14190, 48110, 11997, 22550, 46564, 34376, 42487, 36331, 32785, 16817]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67235bed50>\n",
            "Constructing exemplars of class 14\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [16853, 27439, 1900, 11754, 31904, 8670, 8798, 34820, 8105, 22868, 2749, 950, 7947, 40702, 32161, 38357, 1077, 3364, 27878, 13483, 49786, 29764, 48611, 7787, 15045, 40424, 43142, 13340, 7674, 4196, 40980, 34931, 16675]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710393e50>\n",
            "Constructing exemplars of class 57\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [24125, 1618, 23739, 25893, 19134, 30242, 36415, 20026, 43877, 1495, 9545, 671, 12021, 24125, 40142, 38648, 45428, 27433, 22770, 31414, 40061, 13139, 37512, 43288, 34659, 558, 21487, 45413, 36234, 20748, 9915, 9596, 30600]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723594350>\n",
            "Constructing exemplars of class 45\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [1381, 23201, 40709, 23244, 31102, 13896, 15433, 41411, 48892, 11346, 34202, 29459, 18395, 3242, 18596, 31279, 39163, 4933, 43766, 28415, 21414, 39648, 33006, 18057, 2291, 34570, 19831, 34834, 25316, 11370, 22422, 20172, 30348]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f672306a3d0>\n",
            "Constructing exemplars of class 13\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [20252, 25063, 11592, 25181, 28777, 20010, 24585, 7977, 39012, 15928, 15779, 24907, 11815, 15015, 37026, 46081, 7422, 29766, 48124, 49173, 29416, 40139, 31874, 49822, 36884, 10362, 3798, 44713, 18290, 49052, 23227, 43536, 15895]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710340710>\n",
            "Constructing exemplars of class 88\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [34980, 49844, 37737, 29062, 18469, 5686, 33576, 4694, 3372, 2774, 5155, 39639, 16583, 28329, 46863, 6323, 24034, 25796, 26433, 27087, 27361, 39639, 19773, 15656, 39745, 5092, 48766, 14483, 3161, 26496, 9786, 31666, 39306]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67235bed50>\n",
            "Constructing exemplars of class 60\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [15319, 15999, 32450, 11399, 36552, 7035, 16305, 11691, 29273, 4259, 5062, 47225, 39293, 48071, 35593, 34830, 26999, 34687, 49402, 10766, 24109, 49583, 44990, 19494, 34891, 32347, 26799, 29146, 4268, 5667, 25950, 24169, 10943]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67107c7d10>\n",
            "Constructing exemplars of class 40\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [11533, 30033, 6843, 2224, 21459, 10305, 11515, 40215, 6495, 41074, 20591, 5172, 13838, 2129, 5050, 16630, 11742, 8254, 44947, 14916, 20821, 14609, 5125, 237, 35496, 24708, 22497, 933, 26817, 29677, 23926, 13056, 17166]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234c1350>\n",
            "Constructing exemplars of class 8\n",
            "lunghezza exemplar set:  33\n",
            "exemplar set:  [34391, 29550, 22967, 34354, 25640, 9094, 42499, 18831, 27306, 42539, 46186, 24723, 9230, 5588, 39754, 921, 18327, 37439, 40156, 8674, 32842, 14786, 4690, 18164, 25035, 42107, 22862, 39157, 39754, 3597, 27134, 6540, 47519]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.54 0.09515775740146637\n",
            "TEST GROUP:  0.529\n",
            "TEST ALL:  0.505\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  7000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 49, 96, 9, 13, 17, 21, 45, 53, 84, 57, 61, 65, 69, 81, 85, 88, 80, 95, 36, 4, 8, 16, 20, 24, 32, 40, 76, 52, 56, 60, 64, 68, 72, 93, 97, 2, 47, 19, 23, 27, 31, 35, 39, 55, 6, 59, 63, 67, 75, 79, 83, 15, 7, 98, 94, 90, 86, 82, 70, 54, 50, 42, 34, 30, 22, 18, 14, 10, 0]\n",
            "TRAIN_SET CLASSES:  [35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "VALIDATION CLASSES:  [53, 52, 50, 35, 27, 86, 84, 17, 70, 69]\n",
            "GROUP:  7\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "Len TOTAL train susbset:  6930\n",
            "training\n",
            "num classes till now:  70\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.21743938326835632\n",
            "Train step - Step 10, Loss 0.13682545721530914\n",
            "Train step - Step 20, Loss 0.12454388290643692\n",
            "Train step - Step 30, Loss 0.12725523114204407\n",
            "Train step - Step 40, Loss 0.12353307008743286\n",
            "Train step - Step 50, Loss 0.1135208010673523\n",
            "Train epoch - Accuracy: 0.1738816738816739 Loss: 0.13291637033955186 Corrects: 1205\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.10940840095281601\n",
            "Train step - Step 70, Loss 0.11092469096183777\n",
            "Train step - Step 80, Loss 0.10569246858358383\n",
            "Train step - Step 90, Loss 0.11174558103084564\n",
            "Train step - Step 100, Loss 0.11895501613616943\n",
            "Train epoch - Accuracy: 0.2152958152958153 Loss: 0.11372265943029054 Corrects: 1492\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.11023924499750137\n",
            "Train step - Step 120, Loss 0.10828979313373566\n",
            "Train step - Step 130, Loss 0.11228924244642258\n",
            "Train step - Step 140, Loss 0.11506103724241257\n",
            "Train step - Step 150, Loss 0.11692989617586136\n",
            "Train step - Step 160, Loss 0.11680417507886887\n",
            "Train epoch - Accuracy: 0.2523809523809524 Loss: 0.111118374717614 Corrects: 1749\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.1147061362862587\n",
            "Train step - Step 180, Loss 0.10789922624826431\n",
            "Train step - Step 190, Loss 0.11077307164669037\n",
            "Train step - Step 200, Loss 0.10792036354541779\n",
            "Train step - Step 210, Loss 0.11014694720506668\n",
            "Train epoch - Accuracy: 0.27705627705627706 Loss: 0.11006861773318198 Corrects: 1920\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.10546792298555374\n",
            "Train step - Step 230, Loss 0.10926923900842667\n",
            "Train step - Step 240, Loss 0.11256005614995956\n",
            "Train step - Step 250, Loss 0.10757562518119812\n",
            "Train step - Step 260, Loss 0.10858485102653503\n",
            "Train step - Step 270, Loss 0.11332370340824127\n",
            "Train epoch - Accuracy: 0.3007215007215007 Loss: 0.10919078562467817 Corrects: 2084\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.10992152243852615\n",
            "Train step - Step 290, Loss 0.11036258190870285\n",
            "Train step - Step 300, Loss 0.10847041010856628\n",
            "Train step - Step 310, Loss 0.10806877166032791\n",
            "Train step - Step 320, Loss 0.10693435370922089\n",
            "Train epoch - Accuracy: 0.32135642135642134 Loss: 0.10876360765912316 Corrects: 2227\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.10528579354286194\n",
            "Train step - Step 340, Loss 0.10427871346473694\n",
            "Train step - Step 350, Loss 0.10553035885095596\n",
            "Train step - Step 360, Loss 0.10812323540449142\n",
            "Train step - Step 370, Loss 0.10520375519990921\n",
            "Train step - Step 380, Loss 0.10692229866981506\n",
            "Train epoch - Accuracy: 0.33650793650793653 Loss: 0.10789919711466647 Corrects: 2332\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.11182286590337753\n",
            "Train step - Step 400, Loss 0.10912828147411346\n",
            "Train step - Step 410, Loss 0.10604270547628403\n",
            "Train step - Step 420, Loss 0.10476246476173401\n",
            "Train step - Step 430, Loss 0.11001697182655334\n",
            "Train epoch - Accuracy: 0.3503607503607504 Loss: 0.10766771606251618 Corrects: 2428\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.11128601431846619\n",
            "Train step - Step 450, Loss 0.10650145262479782\n",
            "Train step - Step 460, Loss 0.11125423014163971\n",
            "Train step - Step 470, Loss 0.10592512786388397\n",
            "Train step - Step 480, Loss 0.10297238826751709\n",
            "Train step - Step 490, Loss 0.10580950975418091\n",
            "Train epoch - Accuracy: 0.3601731601731602 Loss: 0.1073827091126043 Corrects: 2496\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 500, Loss 0.10750088095664978\n",
            "Train step - Step 510, Loss 0.10370466113090515\n",
            "Train step - Step 520, Loss 0.10968829691410065\n",
            "Train step - Step 530, Loss 0.10607090592384338\n",
            "Train step - Step 540, Loss 0.1017896831035614\n",
            "Train epoch - Accuracy: 0.36753246753246754 Loss: 0.1073948767901671 Corrects: 2547\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.10644416511058807\n",
            "Train step - Step 560, Loss 0.11340980231761932\n",
            "Train step - Step 570, Loss 0.10994312167167664\n",
            "Train step - Step 580, Loss 0.10765541344881058\n",
            "Train step - Step 590, Loss 0.1012691780924797\n",
            "Train step - Step 600, Loss 0.10048425942659378\n",
            "Train epoch - Accuracy: 0.3759018759018759 Loss: 0.10695876080279398 Corrects: 2605\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 610, Loss 0.11271485686302185\n",
            "Train step - Step 620, Loss 0.11629010736942291\n",
            "Train step - Step 630, Loss 0.10253670811653137\n",
            "Train step - Step 640, Loss 0.1056472510099411\n",
            "Train step - Step 650, Loss 0.10582203418016434\n",
            "Train epoch - Accuracy: 0.39235209235209234 Loss: 0.10700159356707618 Corrects: 2719\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 660, Loss 0.10996249318122864\n",
            "Train step - Step 670, Loss 0.09956404566764832\n",
            "Train step - Step 680, Loss 0.10815822333097458\n",
            "Train step - Step 690, Loss 0.10750533640384674\n",
            "Train step - Step 700, Loss 0.10141556710004807\n",
            "Train step - Step 710, Loss 0.10832835733890533\n",
            "Train epoch - Accuracy: 0.398989898989899 Loss: 0.10680068690453429 Corrects: 2765\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 720, Loss 0.11054067313671112\n",
            "Train step - Step 730, Loss 0.10597193986177444\n",
            "Train step - Step 740, Loss 0.10617002844810486\n",
            "Train step - Step 750, Loss 0.10868824273347855\n",
            "Train step - Step 760, Loss 0.10441474616527557\n",
            "Train epoch - Accuracy: 0.4093795093795094 Loss: 0.10621601239083306 Corrects: 2837\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 770, Loss 0.1060926541686058\n",
            "Train step - Step 780, Loss 0.11232367902994156\n",
            "Train step - Step 790, Loss 0.10597753524780273\n",
            "Train step - Step 800, Loss 0.10290315002202988\n",
            "Train step - Step 810, Loss 0.10697659105062485\n",
            "Train step - Step 820, Loss 0.1097416877746582\n",
            "Train epoch - Accuracy: 0.41774891774891776 Loss: 0.10619745080992257 Corrects: 2895\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 830, Loss 0.1071779802441597\n",
            "Train step - Step 840, Loss 0.10923763364553452\n",
            "Train step - Step 850, Loss 0.10752306133508682\n",
            "Train step - Step 860, Loss 0.1062287911772728\n",
            "Train step - Step 870, Loss 0.10492408275604248\n",
            "Train epoch - Accuracy: 0.42308802308802307 Loss: 0.10632685222494997 Corrects: 2932\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 880, Loss 0.10635185986757278\n",
            "Train step - Step 890, Loss 0.107950359582901\n",
            "Train step - Step 900, Loss 0.10470376908779144\n",
            "Train step - Step 910, Loss 0.10578035563230515\n",
            "Train step - Step 920, Loss 0.10638558864593506\n",
            "Train step - Step 930, Loss 0.10043833404779434\n",
            "Train epoch - Accuracy: 0.42712842712842713 Loss: 0.10625929632056155 Corrects: 2960\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.10403987020254135\n",
            "Train step - Step 950, Loss 0.10936100780963898\n",
            "Train step - Step 960, Loss 0.10470474511384964\n",
            "Train step - Step 970, Loss 0.10518345236778259\n",
            "Train step - Step 980, Loss 0.11086396127939224\n",
            "Train epoch - Accuracy: 0.4316017316017316 Loss: 0.10599395472120929 Corrects: 2991\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 990, Loss 0.10366775095462799\n",
            "Train step - Step 1000, Loss 0.10755825787782669\n",
            "Train step - Step 1010, Loss 0.10981914401054382\n",
            "Train step - Step 1020, Loss 0.10941291600465775\n",
            "Train step - Step 1030, Loss 0.11023328453302383\n",
            "Train step - Step 1040, Loss 0.1050640195608139\n",
            "Train epoch - Accuracy: 0.4388167388167388 Loss: 0.10575019810751919 Corrects: 3041\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1050, Loss 0.10529936105012894\n",
            "Train step - Step 1060, Loss 0.10372141748666763\n",
            "Train step - Step 1070, Loss 0.11097479611635208\n",
            "Train step - Step 1080, Loss 0.1058429554104805\n",
            "Train step - Step 1090, Loss 0.10670126229524612\n",
            "Train epoch - Accuracy: 0.43593073593073595 Loss: 0.105918128311118 Corrects: 3021\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.09910649061203003\n",
            "Train step - Step 1110, Loss 0.10702677816152573\n",
            "Train step - Step 1120, Loss 0.1097906231880188\n",
            "Train step - Step 1130, Loss 0.10887166857719421\n",
            "Train step - Step 1140, Loss 0.11159495264291763\n",
            "Train step - Step 1150, Loss 0.11153433471918106\n",
            "Train epoch - Accuracy: 0.44617604617604617 Loss: 0.10595446153722628 Corrects: 3092\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1160, Loss 0.10223884880542755\n",
            "Train step - Step 1170, Loss 0.10332665592432022\n",
            "Train step - Step 1180, Loss 0.11285765469074249\n",
            "Train step - Step 1190, Loss 0.1078774482011795\n",
            "Train step - Step 1200, Loss 0.11029566079378128\n",
            "Train epoch - Accuracy: 0.4536796536796537 Loss: 0.10564278486745182 Corrects: 3144\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1210, Loss 0.10897251963615417\n",
            "Train step - Step 1220, Loss 0.10340549051761627\n",
            "Train step - Step 1230, Loss 0.10988787561655045\n",
            "Train step - Step 1240, Loss 0.10276547074317932\n",
            "Train step - Step 1250, Loss 0.10935474187135696\n",
            "Train step - Step 1260, Loss 0.1090582013130188\n",
            "Train epoch - Accuracy: 0.45670995670995673 Loss: 0.1052393804273392 Corrects: 3165\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1270, Loss 0.10421834141016006\n",
            "Train step - Step 1280, Loss 0.10510043054819107\n",
            "Train step - Step 1290, Loss 0.10652197152376175\n",
            "Train step - Step 1300, Loss 0.10271956771612167\n",
            "Train step - Step 1310, Loss 0.10326109081506729\n",
            "Train epoch - Accuracy: 0.4673881673881674 Loss: 0.10548407638399804 Corrects: 3239\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1320, Loss 0.10893993079662323\n",
            "Train step - Step 1330, Loss 0.10026482492685318\n",
            "Train step - Step 1340, Loss 0.10503184050321579\n",
            "Train step - Step 1350, Loss 0.10587720572948456\n",
            "Train step - Step 1360, Loss 0.10860460251569748\n",
            "Train step - Step 1370, Loss 0.10512515157461166\n",
            "Train epoch - Accuracy: 0.46955266955266955 Loss: 0.10569940525904019 Corrects: 3254\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1380, Loss 0.10873974859714508\n",
            "Train step - Step 1390, Loss 0.10551386326551437\n",
            "Train step - Step 1400, Loss 0.10470069944858551\n",
            "Train step - Step 1410, Loss 0.10393960773944855\n",
            "Train step - Step 1420, Loss 0.10357236117124557\n",
            "Train epoch - Accuracy: 0.47344877344877345 Loss: 0.10521237840943178 Corrects: 3281\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1430, Loss 0.10620959848165512\n",
            "Train step - Step 1440, Loss 0.10191121697425842\n",
            "Train step - Step 1450, Loss 0.10239232331514359\n",
            "Train step - Step 1460, Loss 0.10174199938774109\n",
            "Train step - Step 1470, Loss 0.10646325349807739\n",
            "Train step - Step 1480, Loss 0.10005520284175873\n",
            "Train epoch - Accuracy: 0.4666666666666667 Loss: 0.10508071389506217 Corrects: 3234\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1490, Loss 0.10924378782510757\n",
            "Train step - Step 1500, Loss 0.10640959441661835\n",
            "Train step - Step 1510, Loss 0.10428271442651749\n",
            "Train step - Step 1520, Loss 0.10796477645635605\n",
            "Train step - Step 1530, Loss 0.10430117696523666\n",
            "Train epoch - Accuracy: 0.4769119769119769 Loss: 0.10520717747412718 Corrects: 3305\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1540, Loss 0.10683257132768631\n",
            "Train step - Step 1550, Loss 0.10387073457241058\n",
            "Train step - Step 1560, Loss 0.10953521728515625\n",
            "Train step - Step 1570, Loss 0.10707807540893555\n",
            "Train step - Step 1580, Loss 0.0996704250574112\n",
            "Train step - Step 1590, Loss 0.1094944179058075\n",
            "Train epoch - Accuracy: 0.48354978354978356 Loss: 0.10524603919506417 Corrects: 3351\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1600, Loss 0.10388617217540741\n",
            "Train step - Step 1610, Loss 0.10930444300174713\n",
            "Train step - Step 1620, Loss 0.10842403769493103\n",
            "Train step - Step 1630, Loss 0.10251271724700928\n",
            "Train step - Step 1640, Loss 0.10554734617471695\n",
            "Train epoch - Accuracy: 0.4777777777777778 Loss: 0.10478936644085558 Corrects: 3311\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1650, Loss 0.10652275383472443\n",
            "Train step - Step 1660, Loss 0.10971534997224808\n",
            "Train step - Step 1670, Loss 0.10254305601119995\n",
            "Train step - Step 1680, Loss 0.10153758525848389\n",
            "Train step - Step 1690, Loss 0.10596141964197159\n",
            "Train step - Step 1700, Loss 0.10669848322868347\n",
            "Train epoch - Accuracy: 0.49076479076479074 Loss: 0.10499097175068325 Corrects: 3401\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1710, Loss 0.10361859202384949\n",
            "Train step - Step 1720, Loss 0.10397696495056152\n",
            "Train step - Step 1730, Loss 0.10346656292676926\n",
            "Train step - Step 1740, Loss 0.1019376814365387\n",
            "Train step - Step 1750, Loss 0.10726028680801392\n",
            "Train epoch - Accuracy: 0.4945165945165945 Loss: 0.10485733357643841 Corrects: 3427\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1760, Loss 0.1087818369269371\n",
            "Train step - Step 1770, Loss 0.11192259192466736\n",
            "Train step - Step 1780, Loss 0.1017703041434288\n",
            "Train step - Step 1790, Loss 0.10680986940860748\n",
            "Train step - Step 1800, Loss 0.10591290891170502\n",
            "Train step - Step 1810, Loss 0.10999120026826859\n",
            "Train epoch - Accuracy: 0.5017316017316017 Loss: 0.10457771693774288 Corrects: 3477\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1820, Loss 0.10253623127937317\n",
            "Train step - Step 1830, Loss 0.10253623127937317\n",
            "Train step - Step 1840, Loss 0.09894531220197678\n",
            "Train step - Step 1850, Loss 0.10583707690238953\n",
            "Train step - Step 1860, Loss 0.10460890084505081\n",
            "Train epoch - Accuracy: 0.5043290043290043 Loss: 0.10479772216485864 Corrects: 3495\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1870, Loss 0.10676749795675278\n",
            "Train step - Step 1880, Loss 0.10173478722572327\n",
            "Train step - Step 1890, Loss 0.10574783384799957\n",
            "Train step - Step 1900, Loss 0.1040777713060379\n",
            "Train step - Step 1910, Loss 0.1067998856306076\n",
            "Train step - Step 1920, Loss 0.10544995963573456\n",
            "Train epoch - Accuracy: 0.5106782106782107 Loss: 0.10413847230213545 Corrects: 3539\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1930, Loss 0.10682840645313263\n",
            "Train step - Step 1940, Loss 0.10727107524871826\n",
            "Train step - Step 1950, Loss 0.10631295293569565\n",
            "Train step - Step 1960, Loss 0.10142700374126434\n",
            "Train step - Step 1970, Loss 0.10331746935844421\n",
            "Train epoch - Accuracy: 0.5051948051948052 Loss: 0.10459059298382521 Corrects: 3501\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1980, Loss 0.10475842654705048\n",
            "Train step - Step 1990, Loss 0.10700429230928421\n",
            "Train step - Step 2000, Loss 0.10549566149711609\n",
            "Train step - Step 2010, Loss 0.102813720703125\n",
            "Train step - Step 2020, Loss 0.10012470185756683\n",
            "Train step - Step 2030, Loss 0.1009695753455162\n",
            "Train epoch - Accuracy: 0.5171717171717172 Loss: 0.10442037473595332 Corrects: 3584\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2040, Loss 0.10570698976516724\n",
            "Train step - Step 2050, Loss 0.10322019457817078\n",
            "Train step - Step 2060, Loss 0.09922955185174942\n",
            "Train step - Step 2070, Loss 0.0990677997469902\n",
            "Train step - Step 2080, Loss 0.10835152864456177\n",
            "Train epoch - Accuracy: 0.5069264069264069 Loss: 0.10400178689848293 Corrects: 3513\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2090, Loss 0.10791373997926712\n",
            "Train step - Step 2100, Loss 0.10448998212814331\n",
            "Train step - Step 2110, Loss 0.1004796177148819\n",
            "Train step - Step 2120, Loss 0.10455804318189621\n",
            "Train step - Step 2130, Loss 0.10240744054317474\n",
            "Train step - Step 2140, Loss 0.10346908867359161\n",
            "Train epoch - Accuracy: 0.5155844155844156 Loss: 0.10413237560707081 Corrects: 3573\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2150, Loss 0.10487096011638641\n",
            "Train step - Step 2160, Loss 0.10251004248857498\n",
            "Train step - Step 2170, Loss 0.10417595505714417\n",
            "Train step - Step 2180, Loss 0.10168473422527313\n",
            "Train step - Step 2190, Loss 0.10130569338798523\n",
            "Train epoch - Accuracy: 0.5204906204906204 Loss: 0.1042923098088687 Corrects: 3607\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2200, Loss 0.1008220687508583\n",
            "Train step - Step 2210, Loss 0.10446435958147049\n",
            "Train step - Step 2220, Loss 0.10013711452484131\n",
            "Train step - Step 2230, Loss 0.1085599735379219\n",
            "Train step - Step 2240, Loss 0.10136209428310394\n",
            "Train step - Step 2250, Loss 0.10908639430999756\n",
            "Train epoch - Accuracy: 0.524963924963925 Loss: 0.1039012439753242 Corrects: 3638\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2260, Loss 0.10597697645425797\n",
            "Train step - Step 2270, Loss 0.10621856153011322\n",
            "Train step - Step 2280, Loss 0.10555423051118851\n",
            "Train step - Step 2290, Loss 0.10238375514745712\n",
            "Train step - Step 2300, Loss 0.10346195101737976\n",
            "Train epoch - Accuracy: 0.521067821067821 Loss: 0.10432538172985396 Corrects: 3611\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2310, Loss 0.10926501452922821\n",
            "Train step - Step 2320, Loss 0.10956409573554993\n",
            "Train step - Step 2330, Loss 0.0980592891573906\n",
            "Train step - Step 2340, Loss 0.10627472400665283\n",
            "Train step - Step 2350, Loss 0.1024034321308136\n",
            "Train step - Step 2360, Loss 0.10029769688844681\n",
            "Train epoch - Accuracy: 0.5258297258297259 Loss: 0.10408319350745943 Corrects: 3644\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2370, Loss 0.10863463580608368\n",
            "Train step - Step 2380, Loss 0.09514912217855453\n",
            "Train step - Step 2390, Loss 0.09256713092327118\n",
            "Train step - Step 2400, Loss 0.10243933647871017\n",
            "Train step - Step 2410, Loss 0.10730013251304626\n",
            "Train epoch - Accuracy: 0.5372294372294373 Loss: 0.10409455300237537 Corrects: 3723\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2420, Loss 0.09798335283994675\n",
            "Train step - Step 2430, Loss 0.10394509136676788\n",
            "Train step - Step 2440, Loss 0.09757240861654282\n",
            "Train step - Step 2450, Loss 0.10688117891550064\n",
            "Train step - Step 2460, Loss 0.10351216048002243\n",
            "Train step - Step 2470, Loss 0.10050111263990402\n",
            "Train epoch - Accuracy: 0.5282828282828282 Loss: 0.10367711966730987 Corrects: 3661\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2480, Loss 0.10031283646821976\n",
            "Train step - Step 2490, Loss 0.09947821497917175\n",
            "Train step - Step 2500, Loss 0.1053730845451355\n",
            "Train step - Step 2510, Loss 0.10975280404090881\n",
            "Train step - Step 2520, Loss 0.10455192625522614\n",
            "Train epoch - Accuracy: 0.5327561327561328 Loss: 0.10364802424912845 Corrects: 3692\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2530, Loss 0.0970812663435936\n",
            "Train step - Step 2540, Loss 0.10409721732139587\n",
            "Train step - Step 2550, Loss 0.10625290870666504\n",
            "Train step - Step 2560, Loss 0.10702315717935562\n",
            "Train step - Step 2570, Loss 0.10284925252199173\n",
            "Train step - Step 2580, Loss 0.10138446092605591\n",
            "Train epoch - Accuracy: 0.541991341991342 Loss: 0.10383931721787776 Corrects: 3756\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2590, Loss 0.10727732628583908\n",
            "Train step - Step 2600, Loss 0.10785355418920517\n",
            "Train step - Step 2610, Loss 0.1019466370344162\n",
            "Train step - Step 2620, Loss 0.10545727610588074\n",
            "Train step - Step 2630, Loss 0.09746789187192917\n",
            "Train epoch - Accuracy: 0.5447330447330447 Loss: 0.10386755096619951 Corrects: 3775\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2640, Loss 0.09796100854873657\n",
            "Train step - Step 2650, Loss 0.09755201637744904\n",
            "Train step - Step 2660, Loss 0.09821679443120956\n",
            "Train step - Step 2670, Loss 0.1100553497672081\n",
            "Train step - Step 2680, Loss 0.1064487174153328\n",
            "Train step - Step 2690, Loss 0.09928537160158157\n",
            "Train epoch - Accuracy: 0.55007215007215 Loss: 0.10352242237432695 Corrects: 3812\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2700, Loss 0.10058187693357468\n",
            "Train step - Step 2710, Loss 0.10473371297121048\n",
            "Train step - Step 2720, Loss 0.10486365109682083\n",
            "Train step - Step 2730, Loss 0.10672871768474579\n",
            "Train step - Step 2740, Loss 0.09630052000284195\n",
            "Train epoch - Accuracy: 0.5437229437229437 Loss: 0.1032445808316206 Corrects: 3768\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2750, Loss 0.1025882363319397\n",
            "Train step - Step 2760, Loss 0.10270290076732635\n",
            "Train step - Step 2770, Loss 0.10247918218374252\n",
            "Train step - Step 2780, Loss 0.09742243587970734\n",
            "Train step - Step 2790, Loss 0.10372099280357361\n",
            "Train step - Step 2800, Loss 0.10491756349802017\n",
            "Train epoch - Accuracy: 0.5493506493506494 Loss: 0.10287231810681231 Corrects: 3807\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10476551204919815\n",
            "Train step - Step 2820, Loss 0.10572686791419983\n",
            "Train step - Step 2830, Loss 0.09762994199991226\n",
            "Train step - Step 2840, Loss 0.10365653783082962\n",
            "Train step - Step 2850, Loss 0.10646791756153107\n",
            "Train epoch - Accuracy: 0.5545454545454546 Loss: 0.10251019164855346 Corrects: 3843\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2860, Loss 0.10286463052034378\n",
            "Train step - Step 2870, Loss 0.1018415093421936\n",
            "Train step - Step 2880, Loss 0.10217403620481491\n",
            "Train step - Step 2890, Loss 0.09623735398054123\n",
            "Train step - Step 2900, Loss 0.09939408302307129\n",
            "Train step - Step 2910, Loss 0.10277926921844482\n",
            "Train epoch - Accuracy: 0.5522366522366522 Loss: 0.10276883526625916 Corrects: 3827\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.10108274966478348\n",
            "Train step - Step 2930, Loss 0.09925390034914017\n",
            "Train step - Step 2940, Loss 0.09964893758296967\n",
            "Train step - Step 2950, Loss 0.10706833004951477\n",
            "Train step - Step 2960, Loss 0.10469561815261841\n",
            "Train epoch - Accuracy: 0.553968253968254 Loss: 0.1029448074050796 Corrects: 3839\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.10217191278934479\n",
            "Train step - Step 2980, Loss 0.1015005111694336\n",
            "Train step - Step 2990, Loss 0.10653059929609299\n",
            "Train step - Step 3000, Loss 0.10814544558525085\n",
            "Train step - Step 3010, Loss 0.1054033562541008\n",
            "Train step - Step 3020, Loss 0.0958327129483223\n",
            "Train epoch - Accuracy: 0.5548340548340548 Loss: 0.10245624507144416 Corrects: 3845\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.10431914031505585\n",
            "Train step - Step 3040, Loss 0.10328162461519241\n",
            "Train step - Step 3050, Loss 0.10021648555994034\n",
            "Train step - Step 3060, Loss 0.09701979905366898\n",
            "Train step - Step 3070, Loss 0.10102363675832748\n",
            "Train epoch - Accuracy: 0.5440115440115441 Loss: 0.10246312394415662 Corrects: 3770\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.10297328233718872\n",
            "Train step - Step 3090, Loss 0.10287956893444061\n",
            "Train step - Step 3100, Loss 0.10852696746587753\n",
            "Train step - Step 3110, Loss 0.10095998644828796\n",
            "Train step - Step 3120, Loss 0.10494647920131683\n",
            "Train step - Step 3130, Loss 0.10141877084970474\n",
            "Train epoch - Accuracy: 0.5506493506493506 Loss: 0.10276586406502716 Corrects: 3816\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10266294330358505\n",
            "Train step - Step 3150, Loss 0.10221640020608902\n",
            "Train step - Step 3160, Loss 0.10703568905591965\n",
            "Train step - Step 3170, Loss 0.102031409740448\n",
            "Train step - Step 3180, Loss 0.10517298430204391\n",
            "Train epoch - Accuracy: 0.555988455988456 Loss: 0.10265874476057799 Corrects: 3853\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.10311369597911835\n",
            "Train step - Step 3200, Loss 0.10853665322065353\n",
            "Train step - Step 3210, Loss 0.10610129684209824\n",
            "Train step - Step 3220, Loss 0.10076916217803955\n",
            "Train step - Step 3230, Loss 0.10262162238359451\n",
            "Train step - Step 3240, Loss 0.10410906374454498\n",
            "Train epoch - Accuracy: 0.5564213564213564 Loss: 0.10261597127195389 Corrects: 3856\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3250, Loss 0.1007789820432663\n",
            "Train step - Step 3260, Loss 0.10475267469882965\n",
            "Train step - Step 3270, Loss 0.10198471695184708\n",
            "Train step - Step 3280, Loss 0.10340654104948044\n",
            "Train step - Step 3290, Loss 0.09848576784133911\n",
            "Train epoch - Accuracy: 0.5546897546897547 Loss: 0.10266407615952677 Corrects: 3844\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.1027161180973053\n",
            "Train step - Step 3310, Loss 0.10689960420131683\n",
            "Train step - Step 3320, Loss 0.09992405027151108\n",
            "Train step - Step 3330, Loss 0.09926743805408478\n",
            "Train step - Step 3340, Loss 0.10070904344320297\n",
            "Train step - Step 3350, Loss 0.10638371109962463\n",
            "Train epoch - Accuracy: 0.554978354978355 Loss: 0.10233876901916611 Corrects: 3846\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3360, Loss 0.10128957778215408\n",
            "Train step - Step 3370, Loss 0.10132362693548203\n",
            "Train step - Step 3380, Loss 0.10016244649887085\n",
            "Train step - Step 3390, Loss 0.10627139359712601\n",
            "Train step - Step 3400, Loss 0.10137639939785004\n",
            "Train epoch - Accuracy: 0.5556998556998557 Loss: 0.10245540083357782 Corrects: 3851\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3410, Loss 0.09890574216842651\n",
            "Train step - Step 3420, Loss 0.09792663902044296\n",
            "Train step - Step 3430, Loss 0.10439544171094894\n",
            "Train step - Step 3440, Loss 0.10199659317731857\n",
            "Train step - Step 3450, Loss 0.10520752519369125\n",
            "Train step - Step 3460, Loss 0.10894892364740372\n",
            "Train epoch - Accuracy: 0.5561327561327561 Loss: 0.10271702951726115 Corrects: 3854\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3470, Loss 0.10232330113649368\n",
            "Train step - Step 3480, Loss 0.09762994199991226\n",
            "Train step - Step 3490, Loss 0.10029182583093643\n",
            "Train step - Step 3500, Loss 0.11147496104240417\n",
            "Train step - Step 3510, Loss 0.10470448434352875\n",
            "Train epoch - Accuracy: 0.5555555555555556 Loss: 0.10257763640060054 Corrects: 3850\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3520, Loss 0.10221093147993088\n",
            "Train step - Step 3530, Loss 0.1044965460896492\n",
            "Train step - Step 3540, Loss 0.10182194411754608\n",
            "Train step - Step 3550, Loss 0.10254904627799988\n",
            "Train step - Step 3560, Loss 0.10479491204023361\n",
            "Train step - Step 3570, Loss 0.10350047796964645\n",
            "Train epoch - Accuracy: 0.554978354978355 Loss: 0.10255558218532826 Corrects: 3846\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3580, Loss 0.10943565517663956\n",
            "Train step - Step 3590, Loss 0.10190263390541077\n",
            "Train step - Step 3600, Loss 0.09713539481163025\n",
            "Train step - Step 3610, Loss 0.10248780250549316\n",
            "Train step - Step 3620, Loss 0.09948194026947021\n",
            "Train epoch - Accuracy: 0.5528138528138529 Loss: 0.10236936813653118 Corrects: 3831\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3630, Loss 0.10226843506097794\n",
            "Train step - Step 3640, Loss 0.10469279438257217\n",
            "Train step - Step 3650, Loss 0.10509917140007019\n",
            "Train step - Step 3660, Loss 0.10024068504571915\n",
            "Train step - Step 3670, Loss 0.0981915220618248\n",
            "Train step - Step 3680, Loss 0.10163266211748123\n",
            "Train epoch - Accuracy: 0.5591630591630592 Loss: 0.1025905107157399 Corrects: 3875\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3690, Loss 0.10653235763311386\n",
            "Train step - Step 3700, Loss 0.09976837784051895\n",
            "Train step - Step 3710, Loss 0.10162569582462311\n",
            "Train step - Step 3720, Loss 0.10238225013017654\n",
            "Train step - Step 3730, Loss 0.10345129668712616\n",
            "Train epoch - Accuracy: 0.564069264069264 Loss: 0.1024505335122648 Corrects: 3909\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3740, Loss 0.11060236394405365\n",
            "Train step - Step 3750, Loss 0.10763029754161835\n",
            "Train step - Step 3760, Loss 0.10282394289970398\n",
            "Train step - Step 3770, Loss 0.10352422297000885\n",
            "Train step - Step 3780, Loss 0.10367435216903687\n",
            "Train step - Step 3790, Loss 0.10228941589593887\n",
            "Train epoch - Accuracy: 0.5541125541125541 Loss: 0.10230411765035269 Corrects: 3840\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3800, Loss 0.10187307000160217\n",
            "Train step - Step 3810, Loss 0.10000859946012497\n",
            "Train step - Step 3820, Loss 0.09848599135875702\n",
            "Train step - Step 3830, Loss 0.09946916252374649\n",
            "Train step - Step 3840, Loss 0.10219822078943253\n",
            "Train epoch - Accuracy: 0.5643578643578644 Loss: 0.10249522781432277 Corrects: 3911\n",
            "Training finished in 441.2144808769226 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52]\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  28\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f671039c610>\n",
            "Constructing exemplars of class 35\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [43451, 597, 28503, 40210, 27438, 13407, 11018, 40345, 49625, 29563, 40910, 10356, 5584, 39716, 24700, 1648, 41536, 24557, 9473, 47889, 21765, 35852, 36050, 6825, 16595, 49527, 25565, 35124]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f672345f250>\n",
            "Constructing exemplars of class 27\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [45312, 17963, 44683, 41788, 36457, 37470, 13061, 25834, 42787, 28815, 7215, 43579, 37513, 11025, 22940, 19771, 35362, 26442, 39268, 5599, 5194, 44127, 21252, 39146, 20987, 42141, 16259, 4296]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723577390>\n",
            "Constructing exemplars of class 86\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [47890, 43084, 14994, 37044, 37774, 47984, 23108, 32129, 16656, 49171, 45306, 4150, 26907, 12066, 29633, 30757, 34052, 45137, 24367, 46659, 35599, 38753, 15077, 43938, 40963, 1485, 5645, 49734]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b68d50>\n",
            "Constructing exemplars of class 70\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [27054, 16392, 25868, 14126, 1896, 34885, 15422, 48935, 39649, 10989, 2990, 15421, 27175, 49066, 18737, 34511, 5041, 21455, 16725, 38517, 31339, 44544, 12105, 40940, 9754, 7086, 44115, 20944]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710338650>\n",
            "Constructing exemplars of class 50\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [29494, 41997, 27929, 38226, 5927, 43122, 43094, 18153, 565, 2490, 30354, 32273, 38516, 28739, 21573, 35017, 6855, 22046, 38927, 19719, 17335, 39364, 22159, 17729, 36110, 32586, 41149, 12607]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723054c90>\n",
            "Constructing exemplars of class 69\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [31481, 6693, 47800, 16892, 35735, 14892, 33664, 38407, 29665, 5048, 36067, 13875, 37267, 43890, 639, 36129, 3014, 42127, 15424, 35869, 19162, 1881, 18904, 32108, 29664, 10607, 37313, 19510]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710338b10>\n",
            "Constructing exemplars of class 53\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [11201, 20224, 37223, 44656, 2143, 19484, 5765, 10566, 47685, 13410, 25985, 7879, 49618, 47472, 37417, 1057, 45599, 22432, 29010, 42751, 6662, 12519, 45584, 46606, 27692, 2708, 23348, 27441]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237ba1d0>\n",
            "Constructing exemplars of class 17\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [7030, 28741, 25335, 49351, 42596, 39909, 18127, 41761, 18959, 18455, 8388, 28021, 34087, 30085, 18697, 28643, 26425, 23145, 28044, 2310, 3414, 13, 22577, 7052, 47289, 29300, 25010, 34868]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234c3f90>\n",
            "Constructing exemplars of class 84\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [31432, 23054, 30550, 28513, 44791, 22544, 20439, 31823, 45743, 48427, 36942, 48127, 48646, 15738, 2376, 10939, 25895, 3218, 22245, 45679, 24100, 26951, 43425, 29669, 22791, 49384, 40335, 47557]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6722b2a350>\n",
            "Constructing exemplars of class 52\n",
            "lunghezza exemplar set:  28\n",
            "exemplar set:  [34941, 44732, 27974, 39235, 48936, 2978, 40941, 17012, 17290, 34461, 36292, 8102, 20869, 11503, 33200, 13699, 5639, 44173, 36526, 31796, 9971, 37091, 1567, 17976, 45386, 47457, 47642, 44228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.48 0.09025534987449646\n",
            "TEST GROUP:  0.521\n",
            "TEST ALL:  0.479\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  8000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [99, 95, 96, 9, 13, 17, 21, 29, 37, 45, 49, 53, 57, 61, 65, 69, 81, 85, 93, 88, 84, 80, 40, 4, 8, 16, 20, 24, 32, 36, 44, 76, 48, 52, 56, 60, 64, 68, 72, 97, 2, 6, 51, 23, 27, 31, 35, 39, 43, 47, 55, 15, 59, 63, 67, 71, 75, 79, 83, 19, 7, 10, 50, 14, 18, 22, 30, 34, 38, 42, 54, 98, 70, 74, 78, 82, 86, 90, 94, 0]\n",
            "TRAIN_SET CLASSES:  [71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "VALIDATION CLASSES:  [51, 48, 44, 43, 38, 37, 29, 78, 74, 71]\n",
            "GROUP:  8\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "Len TOTAL train susbset:  6910\n",
            "training\n",
            "num classes till now:  80\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.21874120831489563\n",
            "Train step - Step 10, Loss 0.1411202847957611\n",
            "Train step - Step 20, Loss 0.128341943025589\n",
            "Train step - Step 30, Loss 0.1338077038526535\n",
            "Train step - Step 40, Loss 0.13048997521400452\n",
            "Train step - Step 50, Loss 0.11996491253376007\n",
            "Train epoch - Accuracy: 0.15918958031837915 Loss: 0.13761497163867467 Corrects: 1100\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.11747204512357712\n",
            "Train step - Step 70, Loss 0.1226222887635231\n",
            "Train step - Step 80, Loss 0.12130890041589737\n",
            "Train step - Step 90, Loss 0.12086760997772217\n",
            "Train step - Step 100, Loss 0.11668085306882858\n",
            "Train epoch - Accuracy: 0.17756874095513747 Loss: 0.12109049464402082 Corrects: 1227\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.12049847841262817\n",
            "Train step - Step 120, Loss 0.11342406272888184\n",
            "Train step - Step 130, Loss 0.12242420762777328\n",
            "Train step - Step 140, Loss 0.11682136356830597\n",
            "Train step - Step 150, Loss 0.11917225271463394\n",
            "Train step - Step 160, Loss 0.11865568161010742\n",
            "Train epoch - Accuracy: 0.1975397973950796 Loss: 0.11919658229768534 Corrects: 1365\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11508476734161377\n",
            "Train step - Step 180, Loss 0.12191057205200195\n",
            "Train step - Step 190, Loss 0.11874276399612427\n",
            "Train step - Step 200, Loss 0.1162482276558876\n",
            "Train step - Step 210, Loss 0.12014458328485489\n",
            "Train epoch - Accuracy: 0.21244573082489146 Loss: 0.11806555879875133 Corrects: 1468\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.11543269455432892\n",
            "Train step - Step 230, Loss 0.1175149455666542\n",
            "Train step - Step 240, Loss 0.11280880123376846\n",
            "Train step - Step 250, Loss 0.11936912685632706\n",
            "Train step - Step 260, Loss 0.1146838441491127\n",
            "Train epoch - Accuracy: 0.2272069464544139 Loss: 0.11763525235583917 Corrects: 1570\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 270, Loss 0.11968207359313965\n",
            "Train step - Step 280, Loss 0.12221864610910416\n",
            "Train step - Step 290, Loss 0.12204264849424362\n",
            "Train step - Step 300, Loss 0.11141312122344971\n",
            "Train step - Step 310, Loss 0.1170068010687828\n",
            "Train step - Step 320, Loss 0.1112942323088646\n",
            "Train epoch - Accuracy: 0.24052098408104197 Loss: 0.11708513898545857 Corrects: 1662\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.1182112917304039\n",
            "Train step - Step 340, Loss 0.11785236746072769\n",
            "Train step - Step 350, Loss 0.11278410255908966\n",
            "Train step - Step 360, Loss 0.11664136499166489\n",
            "Train step - Step 370, Loss 0.12048698961734772\n",
            "Train epoch - Accuracy: 0.2646888567293777 Loss: 0.11647199955802578 Corrects: 1829\n",
            "Starting epoch 8/70, LR = [0.1]\n",
            "Train step - Step 380, Loss 0.1217404380440712\n",
            "Train step - Step 390, Loss 0.1164126917719841\n",
            "Train step - Step 400, Loss 0.12323488295078278\n",
            "Train step - Step 410, Loss 0.11654853820800781\n",
            "Train step - Step 420, Loss 0.1110539361834526\n",
            "Train step - Step 430, Loss 0.11505331844091415\n",
            "Train epoch - Accuracy: 0.2703328509406657 Loss: 0.11672607368739744 Corrects: 1868\n",
            "Starting epoch 9/70, LR = [0.1]\n",
            "Train step - Step 440, Loss 0.11675997823476791\n",
            "Train step - Step 450, Loss 0.11709165573120117\n",
            "Train step - Step 460, Loss 0.12049391120672226\n",
            "Train step - Step 470, Loss 0.11639025062322617\n",
            "Train step - Step 480, Loss 0.1141098141670227\n",
            "Train epoch - Accuracy: 0.2761215629522431 Loss: 0.1156719166251754 Corrects: 1908\n",
            "Starting epoch 10/70, LR = [0.1]\n",
            "Train step - Step 490, Loss 0.11577272415161133\n",
            "Train step - Step 500, Loss 0.11137705296278\n",
            "Train step - Step 510, Loss 0.11356627941131592\n",
            "Train step - Step 520, Loss 0.11989684402942657\n",
            "Train step - Step 530, Loss 0.11911924183368683\n",
            "Train epoch - Accuracy: 0.2832127351664255 Loss: 0.11566935300654509 Corrects: 1957\n",
            "Starting epoch 11/70, LR = [0.1]\n",
            "Train step - Step 540, Loss 0.11337997764348984\n",
            "Train step - Step 550, Loss 0.11575370281934738\n",
            "Train step - Step 560, Loss 0.11127123981714249\n",
            "Train step - Step 570, Loss 0.11610493808984756\n",
            "Train step - Step 580, Loss 0.11458165943622589\n",
            "Train step - Step 590, Loss 0.1192079558968544\n",
            "Train epoch - Accuracy: 0.2926193921852388 Loss: 0.11516925515081361 Corrects: 2022\n",
            "Starting epoch 12/70, LR = [0.1]\n",
            "Train step - Step 600, Loss 0.11728224903345108\n",
            "Train step - Step 610, Loss 0.11505117267370224\n",
            "Train step - Step 620, Loss 0.11599967628717422\n",
            "Train step - Step 630, Loss 0.11692982167005539\n",
            "Train step - Step 640, Loss 0.11890049278736115\n",
            "Train epoch - Accuracy: 0.30709117221418236 Loss: 0.11529093736461896 Corrects: 2122\n",
            "Starting epoch 13/70, LR = [0.1]\n",
            "Train step - Step 650, Loss 0.1209392324090004\n",
            "Train step - Step 660, Loss 0.1163322702050209\n",
            "Train step - Step 670, Loss 0.11267074197530746\n",
            "Train step - Step 680, Loss 0.11395370960235596\n",
            "Train step - Step 690, Loss 0.11574921756982803\n",
            "Train step - Step 700, Loss 0.12348338216543198\n",
            "Train epoch - Accuracy: 0.3060781476121563 Loss: 0.11506833558317203 Corrects: 2115\n",
            "Starting epoch 14/70, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.11306443065404892\n",
            "Train step - Step 720, Loss 0.11409981548786163\n",
            "Train step - Step 730, Loss 0.1170239970088005\n",
            "Train step - Step 740, Loss 0.11655651777982712\n",
            "Train step - Step 750, Loss 0.11179312318563461\n",
            "Train epoch - Accuracy: 0.31968162083936325 Loss: 0.11480574770015159 Corrects: 2209\n",
            "Starting epoch 15/70, LR = [0.1]\n",
            "Train step - Step 760, Loss 0.11509270966053009\n",
            "Train step - Step 770, Loss 0.11239991337060928\n",
            "Train step - Step 780, Loss 0.11198943108320236\n",
            "Train step - Step 790, Loss 0.1215144544839859\n",
            "Train step - Step 800, Loss 0.11659619957208633\n",
            "Train epoch - Accuracy: 0.32214182344428366 Loss: 0.11472685394859866 Corrects: 2226\n",
            "Starting epoch 16/70, LR = [0.1]\n",
            "Train step - Step 810, Loss 0.10826347023248672\n",
            "Train step - Step 820, Loss 0.11630497127771378\n",
            "Train step - Step 830, Loss 0.11202992498874664\n",
            "Train step - Step 840, Loss 0.11313658207654953\n",
            "Train step - Step 850, Loss 0.10850628465414047\n",
            "Train step - Step 860, Loss 0.11220257729291916\n",
            "Train epoch - Accuracy: 0.3384949348769899 Loss: 0.11450951743746977 Corrects: 2339\n",
            "Starting epoch 17/70, LR = [0.1]\n",
            "Train step - Step 870, Loss 0.11474552005529404\n",
            "Train step - Step 880, Loss 0.11722209304571152\n",
            "Train step - Step 890, Loss 0.11217232048511505\n",
            "Train step - Step 900, Loss 0.10720200836658478\n",
            "Train step - Step 910, Loss 0.11437243223190308\n",
            "Train epoch - Accuracy: 0.33835021707670043 Loss: 0.11481028093097868 Corrects: 2338\n",
            "Starting epoch 18/70, LR = [0.1]\n",
            "Train step - Step 920, Loss 0.1140911728143692\n",
            "Train step - Step 930, Loss 0.1040823683142662\n",
            "Train step - Step 940, Loss 0.11587812751531601\n",
            "Train step - Step 950, Loss 0.11495714634656906\n",
            "Train step - Step 960, Loss 0.11581700295209885\n",
            "Train step - Step 970, Loss 0.11346825212240219\n",
            "Train epoch - Accuracy: 0.3395079594790159 Loss: 0.1145609694930648 Corrects: 2346\n",
            "Starting epoch 19/70, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.12052800506353378\n",
            "Train step - Step 990, Loss 0.11966216564178467\n",
            "Train step - Step 1000, Loss 0.11379070580005646\n",
            "Train step - Step 1010, Loss 0.11466062068939209\n",
            "Train step - Step 1020, Loss 0.11626198142766953\n",
            "Train epoch - Accuracy: 0.352821997105644 Loss: 0.11434916869215614 Corrects: 2438\n",
            "Starting epoch 20/70, LR = [0.1]\n",
            "Train step - Step 1030, Loss 0.11443139612674713\n",
            "Train step - Step 1040, Loss 0.11347901821136475\n",
            "Train step - Step 1050, Loss 0.11565013229846954\n",
            "Train step - Step 1060, Loss 0.1153925210237503\n",
            "Train step - Step 1070, Loss 0.10873106867074966\n",
            "Train epoch - Accuracy: 0.3557163531114327 Loss: 0.11403967768773329 Corrects: 2458\n",
            "Starting epoch 21/70, LR = [0.1]\n",
            "Train step - Step 1080, Loss 0.11405523866415024\n",
            "Train step - Step 1090, Loss 0.11532652378082275\n",
            "Train step - Step 1100, Loss 0.11540304869413376\n",
            "Train step - Step 1110, Loss 0.11762851476669312\n",
            "Train step - Step 1120, Loss 0.11505603790283203\n",
            "Train step - Step 1130, Loss 0.11494717746973038\n",
            "Train epoch - Accuracy: 0.36078147612156297 Loss: 0.11440864043194375 Corrects: 2493\n",
            "Starting epoch 22/70, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.11612608283758163\n",
            "Train step - Step 1150, Loss 0.1107286587357521\n",
            "Train step - Step 1160, Loss 0.11652979999780655\n",
            "Train step - Step 1170, Loss 0.11402838677167892\n",
            "Train step - Step 1180, Loss 0.11423426121473312\n",
            "Train epoch - Accuracy: 0.35933429811866857 Loss: 0.11386504258243461 Corrects: 2483\n",
            "Starting epoch 23/70, LR = [0.1]\n",
            "Train step - Step 1190, Loss 0.1146538257598877\n",
            "Train step - Step 1200, Loss 0.11437203735113144\n",
            "Train step - Step 1210, Loss 0.10920238494873047\n",
            "Train step - Step 1220, Loss 0.11246013641357422\n",
            "Train step - Step 1230, Loss 0.11604616791009903\n",
            "Train step - Step 1240, Loss 0.11734461039304733\n",
            "Train epoch - Accuracy: 0.3597684515195369 Loss: 0.1136300427825682 Corrects: 2486\n",
            "Starting epoch 24/70, LR = [0.1]\n",
            "Train step - Step 1250, Loss 0.1151624470949173\n",
            "Train step - Step 1260, Loss 0.11093687266111374\n",
            "Train step - Step 1270, Loss 0.11496943235397339\n",
            "Train step - Step 1280, Loss 0.11000700294971466\n",
            "Train step - Step 1290, Loss 0.11840653419494629\n",
            "Train epoch - Accuracy: 0.37424023154848046 Loss: 0.1138946505255361 Corrects: 2586\n",
            "Starting epoch 25/70, LR = [0.1]\n",
            "Train step - Step 1300, Loss 0.11405179649591446\n",
            "Train step - Step 1310, Loss 0.12018264830112457\n",
            "Train step - Step 1320, Loss 0.12132586538791656\n",
            "Train step - Step 1330, Loss 0.1118507906794548\n",
            "Train step - Step 1340, Loss 0.11085405200719833\n",
            "Train epoch - Accuracy: 0.367438494934877 Loss: 0.11376552540598661 Corrects: 2539\n",
            "Starting epoch 26/70, LR = [0.1]\n",
            "Train step - Step 1350, Loss 0.11287365108728409\n",
            "Train step - Step 1360, Loss 0.11528189480304718\n",
            "Train step - Step 1370, Loss 0.11545506864786148\n",
            "Train step - Step 1380, Loss 0.10951299965381622\n",
            "Train step - Step 1390, Loss 0.11085882037878036\n",
            "Train step - Step 1400, Loss 0.10759138315916061\n",
            "Train epoch - Accuracy: 0.3824891461649783 Loss: 0.11357421892467352 Corrects: 2643\n",
            "Starting epoch 27/70, LR = [0.1]\n",
            "Train step - Step 1410, Loss 0.1096920520067215\n",
            "Train step - Step 1420, Loss 0.10965041071176529\n",
            "Train step - Step 1430, Loss 0.11326759308576584\n",
            "Train step - Step 1440, Loss 0.10834461450576782\n",
            "Train step - Step 1450, Loss 0.1114933043718338\n",
            "Train epoch - Accuracy: 0.38393632416787266 Loss: 0.11355617530482205 Corrects: 2653\n",
            "Starting epoch 28/70, LR = [0.1]\n",
            "Train step - Step 1460, Loss 0.11296217888593674\n",
            "Train step - Step 1470, Loss 0.11220993846654892\n",
            "Train step - Step 1480, Loss 0.10969480127096176\n",
            "Train step - Step 1490, Loss 0.11026616394519806\n",
            "Train step - Step 1500, Loss 0.12024535983800888\n",
            "Train step - Step 1510, Loss 0.1145811602473259\n",
            "Train epoch - Accuracy: 0.388712011577424 Loss: 0.11361318198066372 Corrects: 2686\n",
            "Starting epoch 29/70, LR = [0.1]\n",
            "Train step - Step 1520, Loss 0.11018689721822739\n",
            "Train step - Step 1530, Loss 0.11607346683740616\n",
            "Train step - Step 1540, Loss 0.11934357136487961\n",
            "Train step - Step 1550, Loss 0.1173555999994278\n",
            "Train step - Step 1560, Loss 0.1159750372171402\n",
            "Train epoch - Accuracy: 0.3939218523878437 Loss: 0.11339249892750629 Corrects: 2722\n",
            "Starting epoch 30/70, LR = [0.1]\n",
            "Train step - Step 1570, Loss 0.11201601475477219\n",
            "Train step - Step 1580, Loss 0.11053897440433502\n",
            "Train step - Step 1590, Loss 0.11749958992004395\n",
            "Train step - Step 1600, Loss 0.10877015441656113\n",
            "Train step - Step 1610, Loss 0.10792839527130127\n",
            "Train epoch - Accuracy: 0.3862518089725036 Loss: 0.11322583470994933 Corrects: 2669\n",
            "Starting epoch 31/70, LR = [0.1]\n",
            "Train step - Step 1620, Loss 0.12063782662153244\n",
            "Train step - Step 1630, Loss 0.11170534044504166\n",
            "Train step - Step 1640, Loss 0.11804931610822678\n",
            "Train step - Step 1650, Loss 0.11609122902154922\n",
            "Train step - Step 1660, Loss 0.11396098136901855\n",
            "Train step - Step 1670, Loss 0.1131119504570961\n",
            "Train epoch - Accuracy: 0.39536903039073806 Loss: 0.11307250300338748 Corrects: 2732\n",
            "Starting epoch 32/70, LR = [0.1]\n",
            "Train step - Step 1680, Loss 0.11524713039398193\n",
            "Train step - Step 1690, Loss 0.11649224907159805\n",
            "Train step - Step 1700, Loss 0.10974698513746262\n",
            "Train step - Step 1710, Loss 0.1096549779176712\n",
            "Train step - Step 1720, Loss 0.12105569988489151\n",
            "Train epoch - Accuracy: 0.396671490593343 Loss: 0.11342347507754559 Corrects: 2741\n",
            "Starting epoch 33/70, LR = [0.1]\n",
            "Train step - Step 1730, Loss 0.11631739139556885\n",
            "Train step - Step 1740, Loss 0.11173518002033234\n",
            "Train step - Step 1750, Loss 0.11632820218801498\n",
            "Train step - Step 1760, Loss 0.10721323639154434\n",
            "Train step - Step 1770, Loss 0.11305078119039536\n",
            "Train step - Step 1780, Loss 0.1130489632487297\n",
            "Train epoch - Accuracy: 0.4125904486251809 Loss: 0.11334631354824334 Corrects: 2851\n",
            "Starting epoch 34/70, LR = [0.1]\n",
            "Train step - Step 1790, Loss 0.11774992942810059\n",
            "Train step - Step 1800, Loss 0.11412656307220459\n",
            "Train step - Step 1810, Loss 0.11342692375183105\n",
            "Train step - Step 1820, Loss 0.11501870304346085\n",
            "Train step - Step 1830, Loss 0.11130199581384659\n",
            "Train epoch - Accuracy: 0.408972503617945 Loss: 0.11315017806853986 Corrects: 2826\n",
            "Starting epoch 35/70, LR = [0.1]\n",
            "Train step - Step 1840, Loss 0.1234867125749588\n",
            "Train step - Step 1850, Loss 0.11303656548261642\n",
            "Train step - Step 1860, Loss 0.11397557705640793\n",
            "Train step - Step 1870, Loss 0.11533645540475845\n",
            "Train step - Step 1880, Loss 0.10669323056936264\n",
            "Train epoch - Accuracy: 0.4151953690303907 Loss: 0.11325640288948495 Corrects: 2869\n",
            "Starting epoch 36/70, LR = [0.1]\n",
            "Train step - Step 1890, Loss 0.10800667107105255\n",
            "Train step - Step 1900, Loss 0.11391545832157135\n",
            "Train step - Step 1910, Loss 0.11310499161481857\n",
            "Train step - Step 1920, Loss 0.11474180221557617\n",
            "Train step - Step 1930, Loss 0.10854067653417587\n",
            "Train step - Step 1940, Loss 0.11596725136041641\n",
            "Train epoch - Accuracy: 0.40347322720694645 Loss: 0.11289614328168408 Corrects: 2788\n",
            "Starting epoch 37/70, LR = [0.1]\n",
            "Train step - Step 1950, Loss 0.11360490322113037\n",
            "Train step - Step 1960, Loss 0.1116095557808876\n",
            "Train step - Step 1970, Loss 0.11192309111356735\n",
            "Train step - Step 1980, Loss 0.1157291904091835\n",
            "Train step - Step 1990, Loss 0.10952271521091461\n",
            "Train epoch - Accuracy: 0.4085383502170767 Loss: 0.11289184997464745 Corrects: 2823\n",
            "Starting epoch 38/70, LR = [0.1]\n",
            "Train step - Step 2000, Loss 0.11170535534620285\n",
            "Train step - Step 2010, Loss 0.10867687314748764\n",
            "Train step - Step 2020, Loss 0.11286840587854385\n",
            "Train step - Step 2030, Loss 0.11976490169763565\n",
            "Train step - Step 2040, Loss 0.10830710083246231\n",
            "Train step - Step 2050, Loss 0.11482851952314377\n",
            "Train epoch - Accuracy: 0.4204052098408104 Loss: 0.11285485886414731 Corrects: 2905\n",
            "Starting epoch 39/70, LR = [0.1]\n",
            "Train step - Step 2060, Loss 0.11497791111469269\n",
            "Train step - Step 2070, Loss 0.11407992988824844\n",
            "Train step - Step 2080, Loss 0.10482802242040634\n",
            "Train step - Step 2090, Loss 0.10831385105848312\n",
            "Train step - Step 2100, Loss 0.10941141098737717\n",
            "Train epoch - Accuracy: 0.41736613603473227 Loss: 0.11283488278149179 Corrects: 2884\n",
            "Starting epoch 40/70, LR = [0.1]\n",
            "Train step - Step 2110, Loss 0.11362264305353165\n",
            "Train step - Step 2120, Loss 0.10865341871976852\n",
            "Train step - Step 2130, Loss 0.11449354887008667\n",
            "Train step - Step 2140, Loss 0.11539154499769211\n",
            "Train step - Step 2150, Loss 0.107645682990551\n",
            "Train epoch - Accuracy: 0.4321273516642547 Loss: 0.11257266707815414 Corrects: 2986\n",
            "Starting epoch 41/70, LR = [0.1]\n",
            "Train step - Step 2160, Loss 0.11256052553653717\n",
            "Train step - Step 2170, Loss 0.11868058890104294\n",
            "Train step - Step 2180, Loss 0.11103806644678116\n",
            "Train step - Step 2190, Loss 0.11356434971094131\n",
            "Train step - Step 2200, Loss 0.11557042598724365\n",
            "Train step - Step 2210, Loss 0.1098172590136528\n",
            "Train epoch - Accuracy: 0.42199710564399423 Loss: 0.11277401418830828 Corrects: 2916\n",
            "Starting epoch 42/70, LR = [0.1]\n",
            "Train step - Step 2220, Loss 0.10982868820428848\n",
            "Train step - Step 2230, Loss 0.1113969013094902\n",
            "Train step - Step 2240, Loss 0.11340152472257614\n",
            "Train step - Step 2250, Loss 0.106999471783638\n",
            "Train step - Step 2260, Loss 0.11812470108270645\n",
            "Train epoch - Accuracy: 0.42981186685962375 Loss: 0.11263443692418842 Corrects: 2970\n",
            "Starting epoch 43/70, LR = [0.1]\n",
            "Train step - Step 2270, Loss 0.11343403160572052\n",
            "Train step - Step 2280, Loss 0.11222603172063828\n",
            "Train step - Step 2290, Loss 0.11085164546966553\n",
            "Train step - Step 2300, Loss 0.11694154888391495\n",
            "Train step - Step 2310, Loss 0.10875570774078369\n",
            "Train step - Step 2320, Loss 0.11481630802154541\n",
            "Train epoch - Accuracy: 0.4312590448625181 Loss: 0.1126479673985117 Corrects: 2980\n",
            "Starting epoch 44/70, LR = [0.1]\n",
            "Train step - Step 2330, Loss 0.11344283074140549\n",
            "Train step - Step 2340, Loss 0.11395394802093506\n",
            "Train step - Step 2350, Loss 0.11220846325159073\n",
            "Train step - Step 2360, Loss 0.1171548143029213\n",
            "Train step - Step 2370, Loss 0.11697188764810562\n",
            "Train epoch - Accuracy: 0.4314037626628075 Loss: 0.11238994701036324 Corrects: 2981\n",
            "Starting epoch 45/70, LR = [0.1]\n",
            "Train step - Step 2380, Loss 0.1138017401099205\n",
            "Train step - Step 2390, Loss 0.11266632378101349\n",
            "Train step - Step 2400, Loss 0.1099725291132927\n",
            "Train step - Step 2410, Loss 0.11350896209478378\n",
            "Train step - Step 2420, Loss 0.11348950862884521\n",
            "Train epoch - Accuracy: 0.4392185238784371 Loss: 0.11229091301754483 Corrects: 3035\n",
            "Starting epoch 46/70, LR = [0.1]\n",
            "Train step - Step 2430, Loss 0.11397483199834824\n",
            "Train step - Step 2440, Loss 0.11127876490354538\n",
            "Train step - Step 2450, Loss 0.11411923170089722\n",
            "Train step - Step 2460, Loss 0.11917483806610107\n",
            "Train step - Step 2470, Loss 0.1114787608385086\n",
            "Train step - Step 2480, Loss 0.11471213400363922\n",
            "Train epoch - Accuracy: 0.43690303907380607 Loss: 0.1123191835178135 Corrects: 3019\n",
            "Starting epoch 47/70, LR = [0.1]\n",
            "Train step - Step 2490, Loss 0.1126890704035759\n",
            "Train step - Step 2500, Loss 0.11983443796634674\n",
            "Train step - Step 2510, Loss 0.1134178414940834\n",
            "Train step - Step 2520, Loss 0.1115446463227272\n",
            "Train step - Step 2530, Loss 0.10801907628774643\n",
            "Train epoch - Accuracy: 0.44037626628075255 Loss: 0.1125918784789342 Corrects: 3043\n",
            "Starting epoch 48/70, LR = [0.1]\n",
            "Train step - Step 2540, Loss 0.11317956447601318\n",
            "Train step - Step 2550, Loss 0.11296796798706055\n",
            "Train step - Step 2560, Loss 0.11443966627120972\n",
            "Train step - Step 2570, Loss 0.11188645660877228\n",
            "Train step - Step 2580, Loss 0.11442422866821289\n",
            "Train step - Step 2590, Loss 0.11413156986236572\n",
            "Train epoch - Accuracy: 0.4455861070911722 Loss: 0.11238403949784129 Corrects: 3079\n",
            "Starting epoch 49/70, LR = [0.1]\n",
            "Train step - Step 2600, Loss 0.1104024201631546\n",
            "Train step - Step 2610, Loss 0.10642702877521515\n",
            "Train step - Step 2620, Loss 0.11051340401172638\n",
            "Train step - Step 2630, Loss 0.11471479386091232\n",
            "Train step - Step 2640, Loss 0.11507993936538696\n",
            "Train epoch - Accuracy: 0.44746743849493487 Loss: 0.11192618492672654 Corrects: 3092\n",
            "Starting epoch 50/70, LR = [0.004000000000000001]\n",
            "Train step - Step 2650, Loss 0.10960429161787033\n",
            "Train step - Step 2660, Loss 0.11901091784238815\n",
            "Train step - Step 2670, Loss 0.11607728153467178\n",
            "Train step - Step 2680, Loss 0.11150746792554855\n",
            "Train step - Step 2690, Loss 0.11231639236211777\n",
            "Train epoch - Accuracy: 0.4506512301013025 Loss: 0.11185023669913605 Corrects: 3114\n",
            "Starting epoch 51/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2700, Loss 0.10865819454193115\n",
            "Train step - Step 2710, Loss 0.11340846866369247\n",
            "Train step - Step 2720, Loss 0.1115812286734581\n",
            "Train step - Step 2730, Loss 0.11335543543100357\n",
            "Train step - Step 2740, Loss 0.10939998924732208\n",
            "Train step - Step 2750, Loss 0.10858716070652008\n",
            "Train epoch - Accuracy: 0.4513748191027496 Loss: 0.11201295023501005 Corrects: 3119\n",
            "Starting epoch 52/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2760, Loss 0.10979598760604858\n",
            "Train step - Step 2770, Loss 0.10987510532140732\n",
            "Train step - Step 2780, Loss 0.10948232561349869\n",
            "Train step - Step 2790, Loss 0.11749515682458878\n",
            "Train step - Step 2800, Loss 0.11436494439840317\n",
            "Train epoch - Accuracy: 0.45557163531114325 Loss: 0.11169915577954735 Corrects: 3148\n",
            "Starting epoch 53/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2810, Loss 0.10573738813400269\n",
            "Train step - Step 2820, Loss 0.11171412467956543\n",
            "Train step - Step 2830, Loss 0.11373353004455566\n",
            "Train step - Step 2840, Loss 0.1115230843424797\n",
            "Train step - Step 2850, Loss 0.10966046154499054\n",
            "Train step - Step 2860, Loss 0.1157517209649086\n",
            "Train epoch - Accuracy: 0.4549927641099855 Loss: 0.11163558873918053 Corrects: 3144\n",
            "Starting epoch 54/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2870, Loss 0.1164579913020134\n",
            "Train step - Step 2880, Loss 0.11575867980718613\n",
            "Train step - Step 2890, Loss 0.11433928459882736\n",
            "Train step - Step 2900, Loss 0.11286746710538864\n",
            "Train step - Step 2910, Loss 0.11323279142379761\n",
            "Train epoch - Accuracy: 0.45195369030390736 Loss: 0.11157545692970715 Corrects: 3123\n",
            "Starting epoch 55/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2920, Loss 0.11362927407026291\n",
            "Train step - Step 2930, Loss 0.1123051568865776\n",
            "Train step - Step 2940, Loss 0.11381494998931885\n",
            "Train step - Step 2950, Loss 0.10851406306028366\n",
            "Train step - Step 2960, Loss 0.10816432535648346\n",
            "Train epoch - Accuracy: 0.45832127351664254 Loss: 0.11149662407020756 Corrects: 3167\n",
            "Starting epoch 56/70, LR = [0.020000000000000004]\n",
            "Train step - Step 2970, Loss 0.11103957146406174\n",
            "Train step - Step 2980, Loss 0.1089378148317337\n",
            "Train step - Step 2990, Loss 0.10996305197477341\n",
            "Train step - Step 3000, Loss 0.1105443462729454\n",
            "Train step - Step 3010, Loss 0.11150572448968887\n",
            "Train step - Step 3020, Loss 0.11225073784589767\n",
            "Train epoch - Accuracy: 0.4539797395079595 Loss: 0.11105445032742538 Corrects: 3137\n",
            "Starting epoch 57/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3030, Loss 0.10978160053491592\n",
            "Train step - Step 3040, Loss 0.10783445090055466\n",
            "Train step - Step 3050, Loss 0.11009427160024643\n",
            "Train step - Step 3060, Loss 0.10970337688922882\n",
            "Train step - Step 3070, Loss 0.11080863326787949\n",
            "Train epoch - Accuracy: 0.458465991316932 Loss: 0.1116595180222681 Corrects: 3168\n",
            "Starting epoch 58/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3080, Loss 0.10910864919424057\n",
            "Train step - Step 3090, Loss 0.11489661037921906\n",
            "Train step - Step 3100, Loss 0.11480813473463058\n",
            "Train step - Step 3110, Loss 0.11101019382476807\n",
            "Train step - Step 3120, Loss 0.11235909909009933\n",
            "Train step - Step 3130, Loss 0.10886090993881226\n",
            "Train epoch - Accuracy: 0.459479015918958 Loss: 0.11187717348725337 Corrects: 3175\n",
            "Starting epoch 59/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3140, Loss 0.10862951725721359\n",
            "Train step - Step 3150, Loss 0.10913854837417603\n",
            "Train step - Step 3160, Loss 0.11398527771234512\n",
            "Train step - Step 3170, Loss 0.11165213584899902\n",
            "Train step - Step 3180, Loss 0.11528625339269638\n",
            "Train epoch - Accuracy: 0.45311143270622284 Loss: 0.11142141818353306 Corrects: 3131\n",
            "Starting epoch 60/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3190, Loss 0.11342394351959229\n",
            "Train step - Step 3200, Loss 0.10685016959905624\n",
            "Train step - Step 3210, Loss 0.10801815986633301\n",
            "Train step - Step 3220, Loss 0.11245787143707275\n",
            "Train step - Step 3230, Loss 0.11034226417541504\n",
            "Train epoch - Accuracy: 0.4609261939218524 Loss: 0.11141054676643501 Corrects: 3185\n",
            "Starting epoch 61/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3240, Loss 0.10889394581317902\n",
            "Train step - Step 3250, Loss 0.1083330512046814\n",
            "Train step - Step 3260, Loss 0.1119697093963623\n",
            "Train step - Step 3270, Loss 0.11178932338953018\n",
            "Train step - Step 3280, Loss 0.11518261581659317\n",
            "Train step - Step 3290, Loss 0.1096794381737709\n",
            "Train epoch - Accuracy: 0.45455861070911724 Loss: 0.11159037616421966 Corrects: 3141\n",
            "Starting epoch 62/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3300, Loss 0.11477488279342651\n",
            "Train step - Step 3310, Loss 0.11198022216558456\n",
            "Train step - Step 3320, Loss 0.1097174882888794\n",
            "Train step - Step 3330, Loss 0.11481904983520508\n",
            "Train step - Step 3340, Loss 0.11395056545734406\n",
            "Train epoch - Accuracy: 0.46251808972503616 Loss: 0.11158975653900251 Corrects: 3196\n",
            "Starting epoch 63/70, LR = [0.020000000000000004]\n",
            "Train step - Step 3350, Loss 0.11447087675333023\n",
            "Train step - Step 3360, Loss 0.11625876277685165\n",
            "Train step - Step 3370, Loss 0.11265522241592407\n",
            "Train step - Step 3380, Loss 0.10933186858892441\n",
            "Train step - Step 3390, Loss 0.1094948798418045\n",
            "Train step - Step 3400, Loss 0.11027612537145615\n",
            "Train epoch - Accuracy: 0.46367583212735164 Loss: 0.11136096734904001 Corrects: 3204\n",
            "Starting epoch 64/70, LR = [0.0008000000000000003]\n",
            "Train step - Step 3410, Loss 0.10785830020904541\n",
            "Train step - Step 3420, Loss 0.11778467148542404\n",
            "Train step - Step 3430, Loss 0.10972116142511368\n",
            "Train step - Step 3440, Loss 0.11061346530914307\n",
            "Train step - Step 3450, Loss 0.11285848915576935\n",
            "Train epoch - Accuracy: 0.4657018813314038 Loss: 0.11126942586709035 Corrects: 3218\n",
            "Starting epoch 65/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3460, Loss 0.11052652448415756\n",
            "Train step - Step 3470, Loss 0.11102898418903351\n",
            "Train step - Step 3480, Loss 0.11686702817678452\n",
            "Train step - Step 3490, Loss 0.11425016075372696\n",
            "Train step - Step 3500, Loss 0.1116742417216301\n",
            "Train epoch - Accuracy: 0.4560057887120116 Loss: 0.1115022247783872 Corrects: 3151\n",
            "Starting epoch 66/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3510, Loss 0.11631938070058823\n",
            "Train step - Step 3520, Loss 0.11059039831161499\n",
            "Train step - Step 3530, Loss 0.11446113884449005\n",
            "Train step - Step 3540, Loss 0.10660872608423233\n",
            "Train step - Step 3550, Loss 0.10894908756017685\n",
            "Train step - Step 3560, Loss 0.11057517677545547\n",
            "Train epoch - Accuracy: 0.4558610709117221 Loss: 0.11161728676209057 Corrects: 3150\n",
            "Starting epoch 67/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3570, Loss 0.1181972399353981\n",
            "Train step - Step 3580, Loss 0.10680844634771347\n",
            "Train step - Step 3590, Loss 0.11213929951190948\n",
            "Train step - Step 3600, Loss 0.10729485005140305\n",
            "Train step - Step 3610, Loss 0.1139548048377037\n",
            "Train epoch - Accuracy: 0.46063675832127354 Loss: 0.11099915975211498 Corrects: 3183\n",
            "Starting epoch 68/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3620, Loss 0.10922199487686157\n",
            "Train step - Step 3630, Loss 0.11331858485937119\n",
            "Train step - Step 3640, Loss 0.11413548141717911\n",
            "Train step - Step 3650, Loss 0.1095309630036354\n",
            "Train step - Step 3660, Loss 0.11271822452545166\n",
            "Train step - Step 3670, Loss 0.11301296204328537\n",
            "Train epoch - Accuracy: 0.46251808972503616 Loss: 0.11183207758989416 Corrects: 3196\n",
            "Starting epoch 69/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3680, Loss 0.11663918942213058\n",
            "Train step - Step 3690, Loss 0.1056310161948204\n",
            "Train step - Step 3700, Loss 0.11289580166339874\n",
            "Train step - Step 3710, Loss 0.11646425724029541\n",
            "Train step - Step 3720, Loss 0.10817314684391022\n",
            "Train epoch - Accuracy: 0.45904486251808974 Loss: 0.11119411461562048 Corrects: 3172\n",
            "Starting epoch 70/70, LR = [0.004000000000000001]\n",
            "Train step - Step 3730, Loss 0.10576202720403671\n",
            "Train step - Step 3740, Loss 0.11346014589071274\n",
            "Train step - Step 3750, Loss 0.11787033081054688\n",
            "Train step - Step 3760, Loss 0.11077596992254257\n",
            "Train step - Step 3770, Loss 0.11600182205438614\n",
            "Train epoch - Accuracy: 0.4603473227206946 Loss: 0.11147287817922584 Corrects: 3181\n",
            "Training finished in 439.889436006546 seconds\n",
            "reducing exemplars for each class\n",
            "[67, 59, 39, 22, 18, 65, 49, 56, 20, 4, 79, 47, 7, 82, 34, 81, 21, 80, 68, 16, 75, 23, 90, 10, 61, 76, 64, 32, 24, 0, 95, 83, 63, 42, 30, 6, 2, 97, 72, 36, 55, 31, 19, 98, 94, 54, 93, 85, 9, 96, 99, 15, 14, 57, 45, 13, 88, 60, 40, 8, 35, 27, 86, 70, 50, 69, 53, 17, 84, 52, 71, 51, 43, 78, 74, 38, 37, 29, 48, 44]\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  25\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "REDUCED EXEMPLAR:  0\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723674fd0>\n",
            "Constructing exemplars of class 71\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [1793, 568, 36878, 48873, 37844, 923, 7068, 12409, 23060, 9672, 37224, 25007, 30598, 31778, 18802, 33475, 4274, 48496, 38727, 19, 23768, 434, 1111, 4274, 23060]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f672345ff10>\n",
            "Constructing exemplars of class 51\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [17400, 11938, 31820, 4778, 3781, 34857, 35833, 48525, 32970, 27356, 43278, 33943, 20794, 41544, 35304, 46371, 39553, 12132, 33959, 27843, 7393, 22008, 33911, 27690, 253]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234f9f50>\n",
            "Constructing exemplars of class 43\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [14537, 12297, 12525, 26077, 30984, 4847, 37748, 24515, 26909, 36909, 2332, 30314, 43899, 4737, 21741, 14912, 18853, 44649, 23643, 11457, 37087, 17127, 45098, 16161, 44510]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f672306ac10>\n",
            "Constructing exemplars of class 78\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [27253, 7374, 47905, 5328, 9387, 41190, 1811, 5912, 37553, 40087, 42037, 3764, 37998, 13832, 25864, 15718, 47918, 16414, 35605, 19034, 37001, 9951, 41491, 287, 23509]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6710397350>\n",
            "Constructing exemplars of class 74\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [36630, 25988, 45969, 774, 28817, 37845, 13511, 2914, 36749, 37488, 3419, 28143, 38112, 25433, 10553, 13184, 16306, 45252, 45040, 665, 15871, 25880, 23736, 13734, 38354]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234e8310>\n",
            "Constructing exemplars of class 38\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [42384, 45202, 40732, 23951, 14940, 10185, 39108, 48610, 9326, 24417, 36445, 2414, 35956, 43523, 29090, 25945, 601, 2567, 9400, 9021, 16932, 24357, 35406, 39371, 24770]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67234fb1d0>\n",
            "Constructing exemplars of class 37\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [23685, 7014, 30466, 810, 10586, 22625, 19894, 45280, 32315, 49042, 40399, 23103, 25351, 33039, 9345, 19293, 2982, 48397, 14781, 20110, 1463, 13672, 40865, 18972, 6396]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67237091d0>\n",
            "Constructing exemplars of class 29\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [7724, 39294, 31420, 7704, 27321, 27094, 18870, 35894, 24168, 13568, 6328, 10840, 13308, 49528, 37413, 8244, 1323, 11422, 39177, 46156, 11664, 238, 27887, 48458, 48438]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f67107e8bd0>\n",
            "Constructing exemplars of class 48\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [47888, 22564, 29825, 15888, 28259, 47180, 24813, 41180, 7070, 9137, 49176, 42732, 31900, 13642, 21584, 10741, 682, 13322, 32674, 33569, 2790, 48837, 16701, 21730, 26026]\n",
            "class train:  <torch.utils.data.dataset.Subset object at 0x7f6723456bd0>\n",
            "Constructing exemplars of class 44\n",
            "lunghezza exemplar set:  25\n",
            "exemplar set:  [980, 38190, 2288, 48691, 47016, 39175, 49472, 17115, 30063, 26561, 25759, 45891, 5558, 6468, 1118, 15575, 39668, 25917, 13665, 33415, 38012, 20540, 48215, 34190, 36211]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EVALUATION:  0.36 0.08485576510429382\n",
            "TEST GROUP:  0.395\n",
            "TEST ALL:  0.456625\n",
            "TRAIN:  4950\n",
            "TEST SET LENGHT:  9000\n",
            "TEST CURRENT GROUP SET LENGHT:  1000\n",
            "TEST_SET CLASSES:  [95, 10, 26, 34, 42, 50, 58, 74, 82, 90, 98, 19, 27, 35, 43, 51, 59, 67, 75, 83, 99, 18, 2, 87, 97, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 9, 17, 41, 49, 57, 65, 81, 4, 12, 20, 28, 22, 30, 38, 46, 54, 70, 78, 86, 94, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 14, 6, 93, 5, 36, 44, 52, 60, 68, 76, 84, 92, 13, 85, 21, 29, 37, 45, 53, 61, 69, 77, 0]\n",
            "TRAIN_SET CLASSES:  [87, 58, 46, 26, 77, 41, 5, 92, 28, 12]\n",
            "VALIDATION CLASSES:  [28, 58, 46, 41, 92, 26, 87, 77, 12, 5]\n",
            "GROUP:  9\n",
            "Starting the update representation\n",
            "NEW CLASSES:  [87, 58, 46, 26, 77, 41, 5, 92, 28, 12]\n",
            "Len TOTAL train susbset:  6950\n",
            "training\n",
            "num classes till now:  90\n",
            "Starting epoch 1/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.21645911037921906\n",
            "Train step - Step 10, Loss 0.14282315969467163\n",
            "Train step - Step 20, Loss 0.13609002530574799\n",
            "Train step - Step 30, Loss 0.1341378390789032\n",
            "Train step - Step 40, Loss 0.12924978137016296\n",
            "Train step - Step 50, Loss 0.1214863732457161\n",
            "Train epoch - Accuracy: 0.14345323741007193 Loss: 0.1389816409735371 Corrects: 997\n",
            "Starting epoch 2/70, LR = [0.1]\n",
            "Train step - Step 60, Loss 0.11980964243412018\n",
            "Train step - Step 70, Loss 0.12245038896799088\n",
            "Train step - Step 80, Loss 0.128311887383461\n",
            "Train step - Step 90, Loss 0.1270342469215393\n",
            "Train step - Step 100, Loss 0.11902938783168793\n",
            "Train epoch - Accuracy: 0.15769784172661871 Loss: 0.1217344370848841 Corrects: 1096\n",
            "Starting epoch 3/70, LR = [0.1]\n",
            "Train step - Step 110, Loss 0.12181170284748077\n",
            "Train step - Step 120, Loss 0.11761373281478882\n",
            "Train step - Step 130, Loss 0.12155438959598541\n",
            "Train step - Step 140, Loss 0.12003295123577118\n",
            "Train step - Step 150, Loss 0.11672062426805496\n",
            "Train step - Step 160, Loss 0.12125933915376663\n",
            "Train epoch - Accuracy: 0.16762589928057553 Loss: 0.11957013167280088 Corrects: 1165\n",
            "Starting epoch 4/70, LR = [0.1]\n",
            "Train step - Step 170, Loss 0.11805621534585953\n",
            "Train step - Step 180, Loss 0.12075956165790558\n",
            "Train step - Step 190, Loss 0.1253500133752823\n",
            "Train step - Step 200, Loss 0.12081659585237503\n",
            "Train step - Step 210, Loss 0.11723000556230545\n",
            "Train epoch - Accuracy: 0.18258992805755395 Loss: 0.1187160517629102 Corrects: 1269\n",
            "Starting epoch 5/70, LR = [0.1]\n",
            "Train step - Step 220, Loss 0.12143637984991074\n",
            "Train step - Step 230, Loss 0.11765030771493912\n",
            "Train step - Step 240, Loss 0.12027028948068619\n",
            "Train step - Step 250, Loss 0.11818286031484604\n",
            "Train step - Step 260, Loss 0.11405420303344727\n",
            "Train step - Step 270, Loss 0.11589120328426361\n",
            "Train epoch - Accuracy: 0.19798561151079136 Loss: 0.11762007790503742 Corrects: 1376\n",
            "Starting epoch 6/70, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.1164015457034111\n",
            "Train step - Step 290, Loss 0.12622052431106567\n",
            "Train step - Step 300, Loss 0.11598023772239685\n",
            "Train step - Step 310, Loss 0.11850327998399734\n",
            "Train step - Step 320, Loss 0.12192977219820023\n",
            "Train epoch - Accuracy: 0.21136690647482015 Loss: 0.11735943168830529 Corrects: 1469\n",
            "Starting epoch 7/70, LR = [0.1]\n",
            "Train step - Step 330, Loss 0.11474016308784485\n",
            "Train step - Step 340, Loss 0.10829473286867142\n",
            "Train step - Step 350, Loss 0.1185423955321312\n",
            "Train step - Step 360, Loss 0.11917130649089813\n",
            "Train step - Step 370, Loss 0.11619015038013458\n",
            "Train step - Step 380, Loss 0.11479140818119049\n",
            "Train epoch - Accuracy: 0.22935251798561151 Loss: 0.11701467300061699 Corrects: 1594\n",
            "Starting epoch 8/70, LR = [0.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU1ONpIVBqKM"
      },
      "source": [
        "### plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6fD5peKBpWb"
      },
      "source": [
        "method = \"Learning Without Forgetting\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}