{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "c9XO0l5B9WDO",
        "uhi2ESn89cml",
        "LCnzW3XCF0JW",
        "ClFYYN4dYzKf",
        "C9vHvoVoY4XR",
        "8BBkS-svY697"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb361197e16e459a906e45b7544b9cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a8a7b3b01b1431dbec076e7fee5a63b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af3851793d2a4484aeeaa9b9f3befbd5",
              "IPY_MODEL_ac614629b97347da8cf62ec50910c402"
            ]
          }
        },
        "2a8a7b3b01b1431dbec076e7fee5a63b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af3851793d2a4484aeeaa9b9f3befbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2cc58963d424bbe9fb710af09104fcc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65fb1ac94df84bbe8a2c43a21cef60eb"
          }
        },
        "ac614629b97347da8cf62ec50910c402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e00722f340f840bdadb1d11897e049f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:07&lt;00:00, 21893844.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb21b582793f427b87d8f5dda8b38325"
          }
        },
        "e2cc58963d424bbe9fb710af09104fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65fb1ac94df84bbe8a2c43a21cef60eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e00722f340f840bdadb1d11897e049f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb21b582793f427b87d8f5dda8b38325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXuDQrvO35Pb"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg0q7WTHJxB8",
        "outputId": "34e785d4-5541-4f5e-e172-a2dc197b0830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 24 16:15:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj4HVjkW2RBe"
      },
      "source": [
        "#import sys\n",
        "#sys.path.insert(0,\"/content/drive/MyDrive/OWR-project/Project_MLDL\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXZiclrtCLr7"
      },
      "source": [
        "Classification Network (using Resnet32) on CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlNz0nWYCR0L"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9XO0l5B9WDO"
      },
      "source": [
        "### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "eb361197e16e459a906e45b7544b9cbb",
            "2a8a7b3b01b1431dbec076e7fee5a63b",
            "af3851793d2a4484aeeaa9b9f3befbd5",
            "ac614629b97347da8cf62ec50910c402",
            "e2cc58963d424bbe9fb710af09104fcc",
            "65fb1ac94df84bbe8a2c43a21cef60eb",
            "e00722f340f840bdadb1d11897e049f8",
            "eb21b582793f427b87d8f5dda8b38325"
          ]
        },
        "id": "CMcd8DV4C1nw",
        "outputId": "4ed5a868-8309-457a-929c-3d0f84ccc638"
      },
      "source": [
        "# we build a transform to normalize images: Data normalization is an important step which ensures \n",
        "# each input parameter (pixel, in this case) has a similar data distribution. This makes convergence \n",
        "# faster while training the network.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 128\n",
        "\n",
        "trainset_raw = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "for i in range(len(trainset_raw)):\n",
        "  if(i==0):\n",
        "    trainset = [[trainset_raw[i][0], trainset_raw[i][1]]]\n",
        "  else:\n",
        "    trainset.append([trainset_raw[i][0], trainset_raw[i][1]])\n",
        "\n",
        "\n",
        "# DataLoader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "# batch_size = how many samples per batch to load\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb361197e16e459a906e45b7544b9cbb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzgEQ4uchaBn",
        "outputId": "6f1e85ae-aed7-437e-f45b-228a2fb18e0c"
      },
      "source": [
        "for i in range(500):\n",
        "  print(trainset[i][1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "29\n",
            "0\n",
            "11\n",
            "1\n",
            "86\n",
            "90\n",
            "28\n",
            "23\n",
            "31\n",
            "39\n",
            "96\n",
            "82\n",
            "17\n",
            "71\n",
            "39\n",
            "8\n",
            "97\n",
            "80\n",
            "71\n",
            "74\n",
            "59\n",
            "70\n",
            "87\n",
            "59\n",
            "84\n",
            "64\n",
            "52\n",
            "42\n",
            "64\n",
            "8\n",
            "17\n",
            "47\n",
            "65\n",
            "21\n",
            "22\n",
            "81\n",
            "11\n",
            "24\n",
            "84\n",
            "78\n",
            "45\n",
            "49\n",
            "97\n",
            "56\n",
            "76\n",
            "11\n",
            "90\n",
            "89\n",
            "78\n",
            "73\n",
            "14\n",
            "87\n",
            "9\n",
            "71\n",
            "6\n",
            "47\n",
            "20\n",
            "98\n",
            "47\n",
            "36\n",
            "55\n",
            "72\n",
            "43\n",
            "51\n",
            "35\n",
            "83\n",
            "33\n",
            "27\n",
            "53\n",
            "92\n",
            "50\n",
            "15\n",
            "89\n",
            "36\n",
            "18\n",
            "89\n",
            "46\n",
            "33\n",
            "42\n",
            "39\n",
            "64\n",
            "75\n",
            "38\n",
            "23\n",
            "42\n",
            "66\n",
            "77\n",
            "49\n",
            "18\n",
            "46\n",
            "15\n",
            "35\n",
            "69\n",
            "95\n",
            "83\n",
            "75\n",
            "99\n",
            "73\n",
            "93\n",
            "55\n",
            "39\n",
            "4\n",
            "97\n",
            "61\n",
            "93\n",
            "51\n",
            "69\n",
            "56\n",
            "84\n",
            "59\n",
            "64\n",
            "94\n",
            "4\n",
            "11\n",
            "33\n",
            "68\n",
            "38\n",
            "20\n",
            "33\n",
            "34\n",
            "32\n",
            "46\n",
            "53\n",
            "88\n",
            "67\n",
            "70\n",
            "64\n",
            "53\n",
            "64\n",
            "8\n",
            "96\n",
            "87\n",
            "30\n",
            "20\n",
            "30\n",
            "66\n",
            "19\n",
            "76\n",
            "87\n",
            "52\n",
            "62\n",
            "35\n",
            "63\n",
            "40\n",
            "4\n",
            "99\n",
            "63\n",
            "74\n",
            "53\n",
            "26\n",
            "95\n",
            "48\n",
            "27\n",
            "33\n",
            "29\n",
            "39\n",
            "79\n",
            "32\n",
            "46\n",
            "64\n",
            "28\n",
            "85\n",
            "32\n",
            "82\n",
            "78\n",
            "39\n",
            "54\n",
            "28\n",
            "66\n",
            "65\n",
            "72\n",
            "21\n",
            "64\n",
            "62\n",
            "72\n",
            "0\n",
            "44\n",
            "7\n",
            "12\n",
            "19\n",
            "11\n",
            "31\n",
            "61\n",
            "79\n",
            "45\n",
            "81\n",
            "79\n",
            "98\n",
            "43\n",
            "46\n",
            "67\n",
            "80\n",
            "68\n",
            "74\n",
            "48\n",
            "81\n",
            "94\n",
            "86\n",
            "69\n",
            "39\n",
            "73\n",
            "2\n",
            "46\n",
            "49\n",
            "63\n",
            "43\n",
            "14\n",
            "49\n",
            "68\n",
            "65\n",
            "41\n",
            "37\n",
            "45\n",
            "36\n",
            "21\n",
            "77\n",
            "37\n",
            "39\n",
            "8\n",
            "9\n",
            "62\n",
            "86\n",
            "39\n",
            "19\n",
            "54\n",
            "39\n",
            "28\n",
            "11\n",
            "89\n",
            "90\n",
            "90\n",
            "79\n",
            "66\n",
            "81\n",
            "21\n",
            "79\n",
            "40\n",
            "29\n",
            "22\n",
            "13\n",
            "25\n",
            "11\n",
            "38\n",
            "10\n",
            "96\n",
            "54\n",
            "65\n",
            "39\n",
            "40\n",
            "42\n",
            "48\n",
            "48\n",
            "51\n",
            "11\n",
            "23\n",
            "23\n",
            "89\n",
            "52\n",
            "46\n",
            "2\n",
            "95\n",
            "43\n",
            "86\n",
            "34\n",
            "66\n",
            "18\n",
            "46\n",
            "66\n",
            "56\n",
            "57\n",
            "1\n",
            "44\n",
            "11\n",
            "82\n",
            "23\n",
            "90\n",
            "56\n",
            "19\n",
            "68\n",
            "66\n",
            "28\n",
            "1\n",
            "57\n",
            "67\n",
            "5\n",
            "13\n",
            "78\n",
            "6\n",
            "84\n",
            "7\n",
            "41\n",
            "65\n",
            "80\n",
            "12\n",
            "50\n",
            "63\n",
            "26\n",
            "8\n",
            "53\n",
            "60\n",
            "99\n",
            "97\n",
            "85\n",
            "0\n",
            "78\n",
            "31\n",
            "10\n",
            "2\n",
            "7\n",
            "43\n",
            "83\n",
            "97\n",
            "91\n",
            "82\n",
            "28\n",
            "42\n",
            "0\n",
            "82\n",
            "5\n",
            "68\n",
            "60\n",
            "30\n",
            "98\n",
            "82\n",
            "20\n",
            "64\n",
            "66\n",
            "10\n",
            "75\n",
            "54\n",
            "57\n",
            "87\n",
            "66\n",
            "66\n",
            "73\n",
            "54\n",
            "88\n",
            "42\n",
            "37\n",
            "80\n",
            "87\n",
            "3\n",
            "29\n",
            "43\n",
            "12\n",
            "73\n",
            "96\n",
            "23\n",
            "96\n",
            "84\n",
            "19\n",
            "62\n",
            "0\n",
            "21\n",
            "11\n",
            "36\n",
            "64\n",
            "76\n",
            "60\n",
            "3\n",
            "80\n",
            "82\n",
            "79\n",
            "26\n",
            "65\n",
            "72\n",
            "11\n",
            "15\n",
            "31\n",
            "48\n",
            "12\n",
            "91\n",
            "71\n",
            "87\n",
            "77\n",
            "15\n",
            "7\n",
            "58\n",
            "51\n",
            "55\n",
            "85\n",
            "2\n",
            "3\n",
            "89\n",
            "10\n",
            "3\n",
            "11\n",
            "20\n",
            "4\n",
            "48\n",
            "27\n",
            "48\n",
            "7\n",
            "67\n",
            "3\n",
            "65\n",
            "56\n",
            "9\n",
            "44\n",
            "95\n",
            "46\n",
            "83\n",
            "40\n",
            "58\n",
            "87\n",
            "59\n",
            "18\n",
            "48\n",
            "5\n",
            "88\n",
            "26\n",
            "21\n",
            "24\n",
            "53\n",
            "68\n",
            "49\n",
            "89\n",
            "96\n",
            "92\n",
            "7\n",
            "13\n",
            "99\n",
            "49\n",
            "22\n",
            "56\n",
            "67\n",
            "13\n",
            "97\n",
            "6\n",
            "19\n",
            "76\n",
            "65\n",
            "9\n",
            "71\n",
            "63\n",
            "71\n",
            "18\n",
            "55\n",
            "34\n",
            "18\n",
            "0\n",
            "56\n",
            "23\n",
            "75\n",
            "70\n",
            "78\n",
            "45\n",
            "66\n",
            "91\n",
            "25\n",
            "58\n",
            "90\n",
            "29\n",
            "68\n",
            "35\n",
            "54\n",
            "77\n",
            "97\n",
            "0\n",
            "70\n",
            "75\n",
            "60\n",
            "65\n",
            "5\n",
            "58\n",
            "82\n",
            "49\n",
            "61\n",
            "28\n",
            "44\n",
            "56\n",
            "82\n",
            "61\n",
            "43\n",
            "20\n",
            "38\n",
            "85\n",
            "87\n",
            "49\n",
            "85\n",
            "24\n",
            "7\n",
            "88\n",
            "40\n",
            "38\n",
            "72\n",
            "56\n",
            "4\n",
            "81\n",
            "98\n",
            "97\n",
            "14\n",
            "46\n",
            "23\n",
            "89\n",
            "86\n",
            "83\n",
            "54\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhi2ESn89cml"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyFOrsg4-L7"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def addOutputNodes(self, num_new_outputs):\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "        self.fc = nn.Linear(in_features, out_features + num_new_outputs)\n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        # print(self.fc.out_features)\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzrCPkfN5txO",
        "outputId": "ff5b2e8c-131a-410a-fd8c-f8d672fb86f4"
      },
      "source": [
        "net = resnet32()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSAhwwBr9iZ9"
      },
      "source": [
        "### Define the loss and the optimization technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI6grd9hI2as"
      },
      "source": [
        "lr = 0.01\n",
        "decay = 0.0001\n",
        "epochs = 40\n",
        "momentum = 0.9\n",
        "factor = 5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJqiRlCoI-b0"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCnzW3XCF0JW"
      },
      "source": [
        "### NON INCREMENTAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9zwIkLXJPx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4106fa-6801-4b87-d2d9-6313d20853f1"
      },
      "source": [
        "#train the network\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "    # get the inputs; data is a list of  [input,labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "\n",
        "    outputs = net.forward(inputs) # forward: assign weights to each edge in each layer\n",
        "    loss = criterion(outputs,labels) # calculate the loss \n",
        "    loss.backward() # redesign the weights evaluating the performance of the network\n",
        "    optimizer.step() # update parameters \n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 20 == 19:    # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "      running_loss = 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 4.508\n",
            "[1,   200] loss: 4.198\n",
            "[1,   300] loss: 4.023\n",
            "[2,   100] loss: 3.724\n",
            "[2,   200] loss: 3.646\n",
            "[2,   300] loss: 3.560\n",
            "[3,   100] loss: 3.371\n",
            "[3,   200] loss: 3.293\n",
            "[3,   300] loss: 3.219\n",
            "[4,   100] loss: 3.065\n",
            "[4,   200] loss: 3.013\n",
            "[4,   300] loss: 2.946\n",
            "[5,   100] loss: 2.766\n",
            "[5,   200] loss: 2.744\n",
            "[5,   300] loss: 2.704\n",
            "[6,   100] loss: 2.542\n",
            "[6,   200] loss: 2.505\n",
            "[6,   300] loss: 2.554\n",
            "[7,   100] loss: 2.366\n",
            "[7,   200] loss: 2.357\n",
            "[7,   300] loss: 2.327\n",
            "[8,   100] loss: 2.215\n",
            "[8,   200] loss: 2.174\n",
            "[8,   300] loss: 2.220\n",
            "[9,   100] loss: 2.039\n",
            "[9,   200] loss: 2.106\n",
            "[9,   300] loss: 2.093\n",
            "[10,   100] loss: 1.927\n",
            "[10,   200] loss: 1.958\n",
            "[10,   300] loss: 1.953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "g6YoczYtQu90",
        "outputId": "76c7d37a-6b3c-4512-fe27-4b23f2e3dafa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 40 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdXyhojz73ba"
      },
      "source": [
        "###INCREMENTAL with catastrophic forgetting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFYYN4dYzKf"
      },
      "source": [
        "#### training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8z0BUyK9tt"
      },
      "source": [
        "# Each time we call training function we must pass a different trainloader, updated with the following 10 classes\n",
        "def training(trainloader, iteration, network, device, epochs):\n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(10)\n",
        "    network.to(device)\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of  [input,labels]\n",
        "      #print(i, data[0])\n",
        "      #inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      #print(type(data[0][0]), data[0][0])\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "\n",
        "      outputs = network.forward(inputs) # forward: assign weights to each edge in each layer\n",
        "      loss = criterion(outputs,labels) # calculate the loss \n",
        "      loss.backward() # redesign the weights evaluating the performance of the network\n",
        "      optimizer.step() # update parameters \n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if i % 20 == 19:    # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vHvoVoY4XR"
      },
      "source": [
        "####test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmbA81iYSSSc"
      },
      "source": [
        "def test(testloader, iteration, network, acc):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  # if(iteration == 9):\n",
        "  #   confusion_matrix = torch.zeros(100,100)\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          # if(iteration == 9):\n",
        "          #   for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          #     confusion_matrix[t.long(),p.long()] += 1\n",
        "         \n",
        "  # if(iteration == 9):          \n",
        "  #   plt.figure()\n",
        "  #   plt.imshow(confusion_matrix,interpolation=\"nearest\",cmap=plt.cm.Blues)\n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BBkS-svY697"
      },
      "source": [
        "#### train execution NOT RANDOMIZED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDn00aWqQ2FM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f759c48-f196-4d71-a152-1dc10469e28f"
      },
      "source": [
        "#NOT RANDOMIZED\n",
        "\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "for i in range(iterations):\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  training(train_loader, i, net, device, epochs) # Train the network with 10 classes at a time\n",
        "  print(\"Length train_loader: \", len(train_loader))\n",
        "  print(\"Length valid_loader: \", len(valid_loader))\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\n",
        "\n",
        "  # train loader contains at each iteration the new 10 classes used to evaluate the network, while valid loader contains all classes seen so far"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "[1,    20] loss: 2.228\n",
            "[1,    40] loss: 2.101\n",
            "[2,    20] loss: 1.942\n",
            "[2,    40] loss: 1.846\n",
            "Length train_loader:  40\n",
            "Length valid_loader:  40\n",
            "ITERATION:  0\n",
            "Accuracy of the network on the 0 iteration: 29 %\n",
            "Train the network, iteration:  1  on classes:  range(10, 20)\n",
            "[1,    20] loss: 3.246\n",
            "[1,    40] loss: 2.779\n",
            "[2,    20] loss: 2.602\n",
            "[2,    40] loss: 2.436\n",
            "Length train_loader:  40\n",
            "Length valid_loader:  79\n",
            "ITERATION:  1\n",
            "Accuracy of the network on the 1 iteration: 14 %\n",
            "Train the network, iteration:  2  on classes:  range(20, 30)\n",
            "[1,    20] loss: 3.506\n",
            "[1,    40] loss: 2.951\n",
            "[2,    20] loss: 2.703\n",
            "[2,    40] loss: 2.555\n",
            "Length train_loader:  40\n",
            "Length valid_loader:  118\n",
            "ITERATION:  2\n",
            "Accuracy of the network on the 2 iteration: 11 %\n",
            "Train the network, iteration:  3  on classes:  range(30, 40)\n",
            "[1,    20] loss: 3.881\n",
            "[1,    40] loss: 3.284\n",
            "[2,    20] loss: 2.855\n",
            "[2,    40] loss: 2.701\n",
            "Length train_loader:  40\n",
            "Length valid_loader:  157\n",
            "ITERATION:  3\n",
            "Accuracy of the network on the 3 iteration: 7 %\n",
            "Train the network, iteration:  4  on classes:  range(40, 50)\n",
            "[1,    20] loss: 4.082\n",
            "[1,    40] loss: 3.420\n",
            "[2,    20] loss: 2.971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndz6rDT6Ts4Z"
      },
      "source": [
        "#### train execution RANDOMIZED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZZY4nY4GD3"
      },
      "source": [
        "import random\n",
        "indices = list(range(0,100))\n",
        "random.shuffle(indices)\n",
        "dict_classes = dict(zip(indices,range(100)))\n",
        "for i in range(len(trainset)):\n",
        "  trainset[i][1] = dict_classes[trainset[i][1]]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9c_Sfsop3wQ",
        "outputId": "f441b47d-19e2-480f-d01e-88bc6b7045eb"
      },
      "source": [
        "#TRYING TO RANDOMIZE CLASSES\n",
        "\n",
        "\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "#import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  #classes_current_iter = dict(zip(indices[i*num_classes : i*num_classes+num_classes],range(i*num_classes,i*num_classes+num_classes)))\n",
        "  # print(classes_current_iter)\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    #if(trainset[j][-1] in classes_current_iter.keys()):\n",
        "      #trainset[j][-1] = classes_current_iter[trainset[j][-1]]\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  training(train_loader, i, net, device, epochs) # Train the network with 10 classes at a time\n",
        "  #print(\"Train_loader length: \",len(train_loader))\n",
        "  #print(\"valid_loader length: \",len(valid_loader))\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\n",
        "\n",
        "  # train loader contains at each iteration the new 10 classes used to evaluate the network, while valid loader contains all classes seen so far\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "[1,    20] loss: 2.130\n",
            "[1,    40] loss: 1.843\n",
            "[2,    20] loss: 1.673\n",
            "[2,    40] loss: 1.478\n",
            "[3,    20] loss: 1.450\n",
            "[3,    40] loss: 1.244\n",
            "[4,    20] loss: 1.193\n",
            "[4,    40] loss: 1.125\n",
            "[5,    20] loss: 1.062\n",
            "[5,    40] loss: 1.065\n",
            "[6,    20] loss: 1.055\n",
            "[6,    40] loss: 1.013\n",
            "[7,    20] loss: 0.970\n",
            "[7,    40] loss: 0.934\n",
            "[8,    20] loss: 0.996\n",
            "[8,    40] loss: 0.867\n",
            "[9,    20] loss: 0.846\n",
            "[9,    40] loss: 0.772\n",
            "[10,    20] loss: 0.738\n",
            "[10,    40] loss: 0.701\n",
            "[11,    20] loss: 0.624\n",
            "[11,    40] loss: 0.618\n",
            "[12,    20] loss: 0.689\n",
            "[12,    40] loss: 0.615\n",
            "[13,    20] loss: 0.564\n",
            "[13,    40] loss: 0.485\n",
            "[14,    20] loss: 0.624\n",
            "[14,    40] loss: 0.514\n",
            "[15,    20] loss: 0.407\n",
            "[15,    40] loss: 0.429\n",
            "[16,    20] loss: 0.673\n",
            "[16,    40] loss: 0.625\n",
            "[17,    20] loss: 0.549\n",
            "[17,    40] loss: 0.443\n",
            "[18,    20] loss: 0.367\n",
            "[18,    40] loss: 0.341\n",
            "[19,    20] loss: 0.459\n",
            "[19,    40] loss: 0.382\n",
            "[20,    20] loss: 0.272\n",
            "[20,    40] loss: 0.212\n",
            "[21,    20] loss: 0.228\n",
            "[21,    40] loss: 0.200\n",
            "[22,    20] loss: 0.245\n",
            "[22,    40] loss: 0.268\n",
            "[23,    20] loss: 0.619\n",
            "[23,    40] loss: 0.467\n",
            "[24,    20] loss: 0.472\n",
            "[24,    40] loss: 0.351\n",
            "[25,    20] loss: 0.229\n",
            "[25,    40] loss: 0.162\n",
            "[26,    20] loss: 0.094\n",
            "[26,    40] loss: 0.096\n",
            "[27,    20] loss: 0.069\n",
            "[27,    40] loss: 0.148\n",
            "[28,    20] loss: 0.400\n",
            "[28,    40] loss: 0.298\n",
            "[29,    20] loss: 0.367\n",
            "[29,    40] loss: 0.259\n",
            "[30,    20] loss: 0.494\n",
            "[30,    40] loss: 0.306\n",
            "[31,    20] loss: 0.243\n",
            "[31,    40] loss: 0.160\n",
            "[32,    20] loss: 0.203\n",
            "[32,    40] loss: 0.161\n",
            "[33,    20] loss: 0.234\n",
            "[33,    40] loss: 0.183\n",
            "[34,    20] loss: 0.194\n",
            "[34,    40] loss: 0.137\n",
            "[35,    20] loss: 0.106\n",
            "[35,    40] loss: 0.063\n",
            "[36,    20] loss: 0.049\n",
            "[36,    40] loss: 0.033\n",
            "[37,    20] loss: 0.021\n",
            "[37,    40] loss: 0.014\n",
            "[38,    20] loss: 0.009\n",
            "[38,    40] loss: 0.012\n",
            "[39,    20] loss: 0.010\n",
            "[39,    40] loss: 0.026\n",
            "[40,    20] loss: 0.134\n",
            "[40,    40] loss: 0.068\n",
            "ITERATION:  0\n",
            "Accuracy of the network on the 0 iteration: 89 %\n",
            "Train the network, iteration:  1  on classes:  range(10, 20)\n",
            "[1,    20] loss: 5.278\n",
            "[1,    40] loss: 3.368\n",
            "[2,    20] loss: 2.957\n",
            "[2,    40] loss: 2.654\n",
            "[3,    20] loss: 2.405\n",
            "[3,    40] loss: 2.299\n",
            "[4,    20] loss: 2.156\n",
            "[4,    40] loss: 1.998\n",
            "[5,    20] loss: 1.928\n",
            "[5,    40] loss: 1.925\n",
            "[6,    20] loss: 1.818\n",
            "[6,    40] loss: 1.772\n",
            "[7,    20] loss: 1.691\n",
            "[7,    40] loss: 1.732\n",
            "[8,    20] loss: 1.656\n",
            "[8,    40] loss: 1.603\n",
            "[9,    20] loss: 1.540\n",
            "[9,    40] loss: 1.540\n",
            "[10,    20] loss: 1.518\n",
            "[10,    40] loss: 1.437\n",
            "[11,    20] loss: 1.398\n",
            "[11,    40] loss: 1.384\n",
            "[12,    20] loss: 1.321\n",
            "[12,    40] loss: 1.356\n",
            "[13,    20] loss: 1.289\n",
            "[13,    40] loss: 1.196\n",
            "[14,    20] loss: 1.185\n",
            "[14,    40] loss: 1.128\n",
            "[15,    20] loss: 1.039\n",
            "[15,    40] loss: 1.087\n",
            "[16,    20] loss: 0.995\n",
            "[16,    40] loss: 1.009\n",
            "[17,    20] loss: 1.018\n",
            "[17,    40] loss: 0.950\n",
            "[18,    20] loss: 0.887\n",
            "[18,    40] loss: 0.884\n",
            "[19,    20] loss: 0.830\n",
            "[19,    40] loss: 0.803\n",
            "[20,    20] loss: 0.690\n",
            "[20,    40] loss: 0.676\n",
            "[21,    20] loss: 0.591\n",
            "[21,    40] loss: 0.650\n",
            "[22,    20] loss: 0.587\n",
            "[22,    40] loss: 0.547\n",
            "[23,    20] loss: 0.517\n",
            "[23,    40] loss: 0.497\n",
            "[24,    20] loss: 0.539\n",
            "[24,    40] loss: 0.478\n",
            "[25,    20] loss: 0.442\n",
            "[25,    40] loss: 0.374\n",
            "[26,    20] loss: 0.360\n",
            "[26,    40] loss: 0.313\n",
            "[27,    20] loss: 0.279\n",
            "[27,    40] loss: 0.268\n",
            "[28,    20] loss: 0.462\n",
            "[28,    40] loss: 0.390\n",
            "[29,    20] loss: 0.329\n",
            "[29,    40] loss: 0.326\n",
            "[30,    20] loss: 0.461\n",
            "[30,    40] loss: 0.388\n",
            "[31,    20] loss: 0.414\n",
            "[31,    40] loss: 0.301\n",
            "[32,    20] loss: 0.211\n",
            "[32,    40] loss: 0.176\n",
            "[33,    20] loss: 0.143\n",
            "[33,    40] loss: 0.134\n",
            "[34,    20] loss: 0.397\n",
            "[34,    40] loss: 0.322\n",
            "[35,    20] loss: 0.243\n",
            "[35,    40] loss: 0.205\n",
            "[36,    20] loss: 0.278\n",
            "[36,    40] loss: 0.212\n",
            "[37,    20] loss: 0.159\n",
            "[37,    40] loss: 0.172\n",
            "[38,    20] loss: 0.240\n",
            "[38,    40] loss: 0.221\n",
            "[39,    20] loss: 0.380\n",
            "[39,    40] loss: 0.289\n",
            "[40,    20] loss: 0.202\n",
            "[40,    40] loss: 0.168\n",
            "ITERATION:  1\n",
            "Accuracy of the network on the 1 iteration: 49 %\n",
            "Train the network, iteration:  2  on classes:  range(20, 30)\n",
            "[1,    20] loss: 4.653\n",
            "[1,    40] loss: 3.409\n",
            "[2,    20] loss: 2.885\n",
            "[2,    40] loss: 2.533\n",
            "[3,    20] loss: 2.218\n",
            "[3,    40] loss: 2.073\n",
            "[4,    20] loss: 1.828\n",
            "[4,    40] loss: 1.694\n",
            "[5,    20] loss: 1.662\n",
            "[5,    40] loss: 1.512\n",
            "[6,    20] loss: 1.348\n",
            "[6,    40] loss: 1.292\n",
            "[7,    20] loss: 1.092\n",
            "[7,    40] loss: 1.136\n",
            "[8,    20] loss: 0.902\n",
            "[8,    40] loss: 0.980\n",
            "[9,    20] loss: 0.851\n",
            "[9,    40] loss: 0.837\n",
            "[10,    20] loss: 0.804\n",
            "[10,    40] loss: 0.717\n",
            "[11,    20] loss: 0.568\n",
            "[11,    40] loss: 0.577\n",
            "[12,    20] loss: 0.505\n",
            "[12,    40] loss: 0.460\n",
            "[13,    20] loss: 0.350\n",
            "[13,    40] loss: 0.373\n",
            "[14,    20] loss: 0.396\n",
            "[14,    40] loss: 0.403\n",
            "[15,    20] loss: 0.621\n",
            "[15,    40] loss: 0.536\n",
            "[16,    20] loss: 0.394\n",
            "[16,    40] loss: 0.354\n",
            "[17,    20] loss: 0.307\n",
            "[17,    40] loss: 0.264\n",
            "[18,    20] loss: 0.238\n",
            "[18,    40] loss: 0.244\n",
            "[19,    20] loss: 0.482\n",
            "[19,    40] loss: 0.388\n",
            "[20,    20] loss: 0.287\n",
            "[20,    40] loss: 0.304\n",
            "[21,    20] loss: 0.495\n",
            "[21,    40] loss: 0.366\n",
            "[22,    20] loss: 0.332\n",
            "[22,    40] loss: 0.247\n",
            "[23,    20] loss: 0.207\n",
            "[23,    40] loss: 0.162\n",
            "[24,    20] loss: 0.128\n",
            "[24,    40] loss: 0.137\n",
            "[25,    20] loss: 0.245\n",
            "[25,    40] loss: 0.195\n",
            "[26,    20] loss: 0.174\n",
            "[26,    40] loss: 0.135\n",
            "[27,    20] loss: 0.145\n",
            "[27,    40] loss: 0.102\n",
            "[28,    20] loss: 0.063\n",
            "[28,    40] loss: 0.077\n",
            "[29,    20] loss: 0.115\n",
            "[29,    40] loss: 0.142\n",
            "[30,    20] loss: 0.381\n",
            "[30,    40] loss: 0.363\n",
            "[31,    20] loss: 0.513\n",
            "[31,    40] loss: 0.335\n",
            "[32,    20] loss: 0.252\n",
            "[32,    40] loss: 0.195\n",
            "[33,    20] loss: 0.087\n",
            "[33,    40] loss: 0.114\n",
            "[34,    20] loss: 0.149\n",
            "[34,    40] loss: 0.177\n",
            "[35,    20] loss: 0.152\n",
            "[35,    40] loss: 0.160\n",
            "[36,    20] loss: 0.127\n",
            "[36,    40] loss: 0.113\n",
            "[37,    20] loss: 0.140\n",
            "[37,    40] loss: 0.211\n",
            "[38,    20] loss: 0.310\n",
            "[38,    40] loss: 0.221\n",
            "[39,    20] loss: 0.194\n",
            "[39,    40] loss: 0.133\n",
            "[40,    20] loss: 0.069\n",
            "[40,    40] loss: 0.052\n",
            "ITERATION:  2\n",
            "Accuracy of the network on the 2 iteration: 33 %\n",
            "Train the network, iteration:  3  on classes:  range(30, 40)\n",
            "[1,    20] loss: 6.039\n",
            "[1,    40] loss: 4.200\n",
            "[2,    20] loss: 3.586\n",
            "[2,    40] loss: 3.100\n",
            "[3,    20] loss: 2.768\n",
            "[3,    40] loss: 2.521\n",
            "[4,    20] loss: 2.238\n",
            "[4,    40] loss: 2.103\n",
            "[5,    20] loss: 1.867\n",
            "[5,    40] loss: 1.798\n",
            "[6,    20] loss: 1.565\n",
            "[6,    40] loss: 1.505\n",
            "[7,    20] loss: 1.299\n",
            "[7,    40] loss: 1.319\n",
            "[8,    20] loss: 1.058\n",
            "[8,    40] loss: 1.111\n",
            "[9,    20] loss: 1.018\n",
            "[9,    40] loss: 0.943\n",
            "[10,    20] loss: 0.776\n",
            "[10,    40] loss: 0.751\n",
            "[11,    20] loss: 0.742\n",
            "[11,    40] loss: 0.717\n",
            "[12,    20] loss: 0.672\n",
            "[12,    40] loss: 0.633\n",
            "[13,    20] loss: 0.643\n",
            "[13,    40] loss: 0.696\n",
            "[14,    20] loss: 0.736\n",
            "[14,    40] loss: 0.676\n",
            "[15,    20] loss: 0.505\n",
            "[15,    40] loss: 0.505\n",
            "[16,    20] loss: 0.714\n",
            "[16,    40] loss: 0.696\n",
            "[17,    20] loss: 0.656\n",
            "[17,    40] loss: 0.507\n",
            "[18,    20] loss: 0.441\n",
            "[18,    40] loss: 0.423\n",
            "[19,    20] loss: 0.412\n",
            "[19,    40] loss: 0.290\n",
            "[20,    20] loss: 0.196\n",
            "[20,    40] loss: 0.192\n",
            "[21,    20] loss: 0.212\n",
            "[21,    40] loss: 0.196\n",
            "[22,    20] loss: 0.195\n",
            "[22,    40] loss: 0.188\n",
            "[23,    20] loss: 0.249\n",
            "[23,    40] loss: 0.212\n",
            "[24,    20] loss: 0.423\n",
            "[24,    40] loss: 0.351\n",
            "[25,    20] loss: 0.408\n",
            "[25,    40] loss: 0.412\n",
            "[26,    20] loss: 0.259\n",
            "[26,    40] loss: 0.249\n",
            "[27,    20] loss: 0.224\n",
            "[27,    40] loss: 0.201\n",
            "[28,    20] loss: 0.188\n",
            "[28,    40] loss: 0.166\n",
            "[29,    20] loss: 0.299\n",
            "[29,    40] loss: 0.269\n",
            "[30,    20] loss: 0.313\n",
            "[30,    40] loss: 0.236\n",
            "[31,    20] loss: 0.202\n",
            "[31,    40] loss: 0.157\n",
            "[32,    20] loss: 0.142\n",
            "[32,    40] loss: 0.168\n",
            "[33,    20] loss: 0.164\n",
            "[33,    40] loss: 0.231\n",
            "[34,    20] loss: 0.260\n",
            "[34,    40] loss: 0.221\n",
            "[35,    20] loss: 0.192\n",
            "[35,    40] loss: 0.179\n",
            "[36,    20] loss: 0.410\n",
            "[36,    40] loss: 0.405\n",
            "[37,    20] loss: 0.258\n",
            "[37,    40] loss: 0.205\n",
            "[38,    20] loss: 0.273\n",
            "[38,    40] loss: 0.286\n",
            "[39,    20] loss: 0.678\n",
            "[39,    40] loss: 0.489\n",
            "[40,    20] loss: 0.348\n",
            "[40,    40] loss: 0.228\n",
            "ITERATION:  3\n",
            "Accuracy of the network on the 3 iteration: 24 %\n",
            "Train the network, iteration:  4  on classes:  range(40, 50)\n",
            "[1,    20] loss: 5.133\n",
            "[1,    40] loss: 3.573\n",
            "[2,    20] loss: 2.768\n",
            "[2,    40] loss: 2.273\n",
            "[3,    20] loss: 1.834\n",
            "[3,    40] loss: 1.632\n",
            "[4,    20] loss: 1.332\n",
            "[4,    40] loss: 1.258\n",
            "[5,    20] loss: 1.052\n",
            "[5,    40] loss: 0.990\n",
            "[6,    20] loss: 0.867\n",
            "[6,    40] loss: 0.870\n",
            "[7,    20] loss: 0.708\n",
            "[7,    40] loss: 0.659\n",
            "[8,    20] loss: 0.555\n",
            "[8,    40] loss: 0.589\n",
            "[9,    20] loss: 0.599\n",
            "[9,    40] loss: 0.566\n",
            "[10,    20] loss: 0.436\n",
            "[10,    40] loss: 0.411\n",
            "[11,    20] loss: 0.303\n",
            "[11,    40] loss: 0.277\n",
            "[12,    20] loss: 0.225\n",
            "[12,    40] loss: 0.237\n",
            "[13,    20] loss: 0.267\n",
            "[13,    40] loss: 0.301\n",
            "[14,    20] loss: 0.273\n",
            "[14,    40] loss: 0.221\n",
            "[15,    20] loss: 0.123\n",
            "[15,    40] loss: 0.173\n",
            "[16,    20] loss: 0.218\n",
            "[16,    40] loss: 0.211\n",
            "[17,    20] loss: 0.213\n",
            "[17,    40] loss: 0.255\n",
            "[18,    20] loss: 0.450\n",
            "[18,    40] loss: 0.344\n",
            "[19,    20] loss: 0.232\n",
            "[19,    40] loss: 0.163\n",
            "[20,    20] loss: 0.096\n",
            "[20,    40] loss: 0.149\n",
            "[21,    20] loss: 0.119\n",
            "[21,    40] loss: 0.099\n",
            "[22,    20] loss: 0.072\n",
            "[22,    40] loss: 0.092\n",
            "[23,    20] loss: 0.149\n",
            "[23,    40] loss: 0.117\n",
            "[24,    20] loss: 0.064\n",
            "[24,    40] loss: 0.093\n",
            "[25,    20] loss: 0.240\n",
            "[25,    40] loss: 0.290\n",
            "[26,    20] loss: 0.324\n",
            "[26,    40] loss: 0.233\n",
            "[27,    20] loss: 0.139\n",
            "[27,    40] loss: 0.137\n",
            "[28,    20] loss: 0.209\n",
            "[28,    40] loss: 0.133\n",
            "[29,    20] loss: 0.086\n",
            "[29,    40] loss: 0.084\n",
            "[30,    20] loss: 0.059\n",
            "[30,    40] loss: 0.067\n",
            "[31,    20] loss: 0.106\n",
            "[31,    40] loss: 0.116\n",
            "[32,    20] loss: 0.130\n",
            "[32,    40] loss: 0.119\n",
            "[33,    20] loss: 0.108\n",
            "[33,    40] loss: 0.116\n",
            "[34,    20] loss: 0.251\n",
            "[34,    40] loss: 0.167\n",
            "[35,    20] loss: 0.110\n",
            "[35,    40] loss: 0.089\n",
            "[36,    20] loss: 0.096\n",
            "[36,    40] loss: 0.155\n",
            "[37,    20] loss: 0.237\n",
            "[37,    40] loss: 0.137\n",
            "[38,    20] loss: 0.175\n",
            "[38,    40] loss: 0.132\n",
            "[39,    20] loss: 0.091\n",
            "[39,    40] loss: 0.076\n",
            "[40,    20] loss: 0.225\n",
            "[40,    40] loss: 0.129\n",
            "ITERATION:  4\n",
            "Accuracy of the network on the 4 iteration: 19 %\n",
            "Train the network, iteration:  5  on classes:  range(50, 60)\n",
            "[1,    20] loss: 5.514\n",
            "[1,    40] loss: 3.726\n",
            "[2,    20] loss: 3.070\n",
            "[2,    40] loss: 2.623\n",
            "[3,    20] loss: 2.168\n",
            "[3,    40] loss: 1.953\n",
            "[4,    20] loss: 1.605\n",
            "[4,    40] loss: 1.561\n",
            "[5,    20] loss: 1.205\n",
            "[5,    40] loss: 1.182\n",
            "[6,    20] loss: 0.950\n",
            "[6,    40] loss: 0.863\n",
            "[7,    20] loss: 0.648\n",
            "[7,    40] loss: 0.683\n",
            "[8,    20] loss: 0.468\n",
            "[8,    40] loss: 0.468\n",
            "[9,    20] loss: 0.365\n",
            "[9,    40] loss: 0.377\n",
            "[10,    20] loss: 0.356\n",
            "[10,    40] loss: 0.365\n",
            "[11,    20] loss: 0.464\n",
            "[11,    40] loss: 0.405\n",
            "[12,    20] loss: 0.545\n",
            "[12,    40] loss: 0.448\n",
            "[13,    20] loss: 0.469\n",
            "[13,    40] loss: 0.421\n",
            "[14,    20] loss: 0.245\n",
            "[14,    40] loss: 0.222\n",
            "[15,    20] loss: 0.119\n",
            "[15,    40] loss: 0.139\n",
            "[16,    20] loss: 0.166\n",
            "[16,    40] loss: 0.139\n",
            "[17,    20] loss: 0.123\n",
            "[17,    40] loss: 0.121\n",
            "[18,    20] loss: 0.144\n",
            "[18,    40] loss: 0.128\n",
            "[19,    20] loss: 0.122\n",
            "[19,    40] loss: 0.154\n",
            "[20,    20] loss: 0.296\n",
            "[20,    40] loss: 0.264\n",
            "[21,    20] loss: 0.273\n",
            "[21,    40] loss: 0.183\n",
            "[22,    20] loss: 0.092\n",
            "[22,    40] loss: 0.088\n",
            "[23,    20] loss: 0.159\n",
            "[23,    40] loss: 0.166\n",
            "[24,    20] loss: 0.169\n",
            "[24,    40] loss: 0.135\n",
            "[25,    20] loss: 0.097\n",
            "[25,    40] loss: 0.079\n",
            "[26,    20] loss: 0.073\n",
            "[26,    40] loss: 0.083\n",
            "[27,    20] loss: 0.141\n",
            "[27,    40] loss: 0.166\n",
            "[28,    20] loss: 0.211\n",
            "[28,    40] loss: 0.163\n",
            "[29,    20] loss: 0.207\n",
            "[29,    40] loss: 0.185\n",
            "[30,    20] loss: 0.378\n",
            "[30,    40] loss: 0.308\n",
            "[31,    20] loss: 0.225\n",
            "[31,    40] loss: 0.216\n",
            "[32,    20] loss: 0.106\n",
            "[32,    40] loss: 0.121\n",
            "[33,    20] loss: 0.190\n",
            "[33,    40] loss: 0.144\n",
            "[34,    20] loss: 0.199\n",
            "[34,    40] loss: 0.248\n",
            "[35,    20] loss: 0.240\n",
            "[35,    40] loss: 0.172\n",
            "[36,    20] loss: 0.079\n",
            "[36,    40] loss: 0.066\n",
            "[37,    20] loss: 0.043\n",
            "[37,    40] loss: 0.037\n",
            "[38,    20] loss: 0.025\n",
            "[38,    40] loss: 0.068\n",
            "[39,    20] loss: 0.163\n",
            "[39,    40] loss: 0.145\n",
            "[40,    20] loss: 0.114\n",
            "[40,    40] loss: 0.084\n",
            "ITERATION:  5\n",
            "Accuracy of the network on the 5 iteration: 16 %\n",
            "Train the network, iteration:  6  on classes:  range(60, 70)\n",
            "[1,    20] loss: 5.924\n",
            "[1,    40] loss: 3.876\n",
            "[2,    20] loss: 2.840\n",
            "[2,    40] loss: 2.289\n",
            "[3,    20] loss: 1.773\n",
            "[3,    40] loss: 1.666\n",
            "[4,    20] loss: 1.333\n",
            "[4,    40] loss: 1.296\n",
            "[5,    20] loss: 0.979\n",
            "[5,    40] loss: 1.031\n",
            "[6,    20] loss: 0.785\n",
            "[6,    40] loss: 0.774\n",
            "[7,    20] loss: 0.610\n",
            "[7,    40] loss: 0.591\n",
            "[8,    20] loss: 0.446\n",
            "[8,    40] loss: 0.449\n",
            "[9,    20] loss: 0.401\n",
            "[9,    40] loss: 0.378\n",
            "[10,    20] loss: 0.317\n",
            "[10,    40] loss: 0.272\n",
            "[11,    20] loss: 0.179\n",
            "[11,    40] loss: 0.278\n",
            "[12,    20] loss: 0.320\n",
            "[12,    40] loss: 0.373\n",
            "[13,    20] loss: 0.271\n",
            "[13,    40] loss: 0.224\n",
            "[14,    20] loss: 0.161\n",
            "[14,    40] loss: 0.149\n",
            "[15,    20] loss: 0.130\n",
            "[15,    40] loss: 0.122\n",
            "[16,    20] loss: 0.089\n",
            "[16,    40] loss: 0.098\n",
            "[17,    20] loss: 0.167\n",
            "[17,    40] loss: 0.202\n",
            "[18,    20] loss: 0.393\n",
            "[18,    40] loss: 0.302\n",
            "[19,    20] loss: 0.156\n",
            "[19,    40] loss: 0.154\n",
            "[20,    20] loss: 0.212\n",
            "[20,    40] loss: 0.209\n",
            "[21,    20] loss: 0.205\n",
            "[21,    40] loss: 0.190\n",
            "[22,    20] loss: 0.289\n",
            "[22,    40] loss: 0.292\n",
            "[23,    20] loss: 0.197\n",
            "[23,    40] loss: 0.174\n",
            "[24,    20] loss: 0.127\n",
            "[24,    40] loss: 0.141\n",
            "[25,    20] loss: 0.111\n",
            "[25,    40] loss: 0.122\n",
            "[26,    20] loss: 0.111\n",
            "[26,    40] loss: 0.102\n",
            "[27,    20] loss: 0.209\n",
            "[27,    40] loss: 0.165\n",
            "[28,    20] loss: 0.139\n",
            "[28,    40] loss: 0.110\n",
            "[29,    20] loss: 0.089\n",
            "[29,    40] loss: 0.088\n",
            "[30,    20] loss: 0.103\n",
            "[30,    40] loss: 0.094\n",
            "[31,    20] loss: 0.070\n",
            "[31,    40] loss: 0.123\n",
            "[32,    20] loss: 0.350\n",
            "[32,    40] loss: 0.243\n",
            "[33,    20] loss: 0.185\n",
            "[33,    40] loss: 0.100\n",
            "[34,    20] loss: 0.069\n",
            "[34,    40] loss: 0.067\n",
            "[35,    20] loss: 0.065\n",
            "[35,    40] loss: 0.078\n",
            "[36,    20] loss: 0.093\n",
            "[36,    40] loss: 0.150\n",
            "[37,    20] loss: 0.275\n",
            "[37,    40] loss: 0.192\n",
            "[38,    20] loss: 0.076\n",
            "[38,    40] loss: 0.059\n",
            "[39,    20] loss: 0.044\n",
            "[39,    40] loss: 0.092\n",
            "[40,    20] loss: 0.428\n",
            "[40,    40] loss: 0.306\n",
            "ITERATION:  6\n",
            "Accuracy of the network on the 6 iteration: 13 %\n",
            "Train the network, iteration:  7  on classes:  range(70, 80)\n",
            "[1,    20] loss: 6.109\n",
            "[1,    40] loss: 4.007\n",
            "[2,    20] loss: 3.293\n",
            "[2,    40] loss: 2.976\n",
            "[3,    20] loss: 2.617\n",
            "[3,    40] loss: 2.364\n",
            "[4,    20] loss: 2.210\n",
            "[4,    40] loss: 2.030\n",
            "[5,    20] loss: 1.840\n",
            "[5,    40] loss: 1.672\n",
            "[6,    20] loss: 1.497\n",
            "[6,    40] loss: 1.391\n",
            "[7,    20] loss: 1.113\n",
            "[7,    40] loss: 1.117\n",
            "[8,    20] loss: 0.872\n",
            "[8,    40] loss: 0.918\n",
            "[9,    20] loss: 0.661\n",
            "[9,    40] loss: 0.778\n",
            "[10,    20] loss: 0.572\n",
            "[10,    40] loss: 0.568\n",
            "[11,    20] loss: 0.426\n",
            "[11,    40] loss: 0.420\n",
            "[12,    20] loss: 0.362\n",
            "[12,    40] loss: 0.373\n",
            "[13,    20] loss: 0.529\n",
            "[13,    40] loss: 0.640\n",
            "[14,    20] loss: 0.621\n",
            "[14,    40] loss: 0.549\n",
            "[15,    20] loss: 0.412\n",
            "[15,    40] loss: 0.393\n",
            "[16,    20] loss: 0.392\n",
            "[16,    40] loss: 0.488\n",
            "[17,    20] loss: 0.361\n",
            "[17,    40] loss: 0.341\n",
            "[18,    20] loss: 0.336\n",
            "[18,    40] loss: 0.314\n",
            "[19,    20] loss: 0.358\n",
            "[19,    40] loss: 0.313\n",
            "[20,    20] loss: 0.223\n",
            "[20,    40] loss: 0.213\n",
            "[21,    20] loss: 0.172\n",
            "[21,    40] loss: 0.132\n",
            "[22,    20] loss: 0.112\n",
            "[22,    40] loss: 0.128\n",
            "[23,    20] loss: 0.176\n",
            "[23,    40] loss: 0.201\n",
            "[24,    20] loss: 0.218\n",
            "[24,    40] loss: 0.242\n",
            "[25,    20] loss: 0.226\n",
            "[25,    40] loss: 0.314\n",
            "[26,    20] loss: 0.310\n",
            "[26,    40] loss: 0.251\n",
            "[27,    20] loss: 0.173\n",
            "[27,    40] loss: 0.154\n",
            "[28,    20] loss: 0.108\n",
            "[28,    40] loss: 0.116\n",
            "[29,    20] loss: 0.114\n",
            "[29,    40] loss: 0.141\n",
            "[30,    20] loss: 0.186\n",
            "[30,    40] loss: 0.209\n",
            "[31,    20] loss: 0.499\n",
            "[31,    40] loss: 0.357\n",
            "[32,    20] loss: 0.220\n",
            "[32,    40] loss: 0.166\n",
            "[33,    20] loss: 0.064\n",
            "[33,    40] loss: 0.127\n",
            "[34,    20] loss: 0.106\n",
            "[34,    40] loss: 0.110\n",
            "[35,    20] loss: 0.183\n",
            "[35,    40] loss: 0.159\n",
            "[36,    20] loss: 0.159\n",
            "[36,    40] loss: 0.112\n",
            "[37,    20] loss: 0.060\n",
            "[37,    40] loss: 0.107\n",
            "[38,    20] loss: 0.132\n",
            "[38,    40] loss: 0.091\n",
            "[39,    20] loss: 0.050\n",
            "[39,    40] loss: 0.040\n",
            "[40,    20] loss: 0.027\n",
            "[40,    40] loss: 0.031\n",
            "ITERATION:  7\n",
            "Accuracy of the network on the 7 iteration: 12 %\n",
            "Train the network, iteration:  8  on classes:  range(80, 90)\n",
            "[1,    20] loss: 6.004\n",
            "[1,    40] loss: 3.924\n",
            "[2,    20] loss: 3.080\n",
            "[2,    40] loss: 2.644\n",
            "[3,    20] loss: 2.239\n",
            "[3,    40] loss: 2.054\n",
            "[4,    20] loss: 1.694\n",
            "[4,    40] loss: 1.545\n",
            "[5,    20] loss: 1.289\n",
            "[5,    40] loss: 1.207\n",
            "[6,    20] loss: 1.086\n",
            "[6,    40] loss: 0.977\n",
            "[7,    20] loss: 0.702\n",
            "[7,    40] loss: 0.682\n",
            "[8,    20] loss: 0.457\n",
            "[8,    40] loss: 0.566\n",
            "[9,    20] loss: 0.420\n",
            "[9,    40] loss: 0.575\n",
            "[10,    20] loss: 0.564\n",
            "[10,    40] loss: 0.473\n",
            "[11,    20] loss: 0.310\n",
            "[11,    40] loss: 0.264\n",
            "[12,    20] loss: 0.163\n",
            "[12,    40] loss: 0.190\n",
            "[13,    20] loss: 0.155\n",
            "[13,    40] loss: 0.151\n",
            "[14,    20] loss: 0.153\n",
            "[14,    40] loss: 0.156\n",
            "[15,    20] loss: 0.365\n",
            "[15,    40] loss: 0.338\n",
            "[16,    20] loss: 0.269\n",
            "[16,    40] loss: 0.214\n",
            "[17,    20] loss: 0.183\n",
            "[17,    40] loss: 0.177\n",
            "[18,    20] loss: 0.126\n",
            "[18,    40] loss: 0.161\n",
            "[19,    20] loss: 0.172\n",
            "[19,    40] loss: 0.261\n",
            "[20,    20] loss: 0.311\n",
            "[20,    40] loss: 0.407\n",
            "[21,    20] loss: 0.333\n",
            "[21,    40] loss: 0.261\n",
            "[22,    20] loss: 0.134\n",
            "[22,    40] loss: 0.104\n",
            "[23,    20] loss: 0.053\n",
            "[23,    40] loss: 0.107\n",
            "[24,    20] loss: 0.072\n",
            "[24,    40] loss: 0.061\n",
            "[25,    20] loss: 0.099\n",
            "[25,    40] loss: 0.067\n",
            "[26,    20] loss: 0.078\n",
            "[26,    40] loss: 0.069\n",
            "[27,    20] loss: 0.045\n",
            "[27,    40] loss: 0.129\n",
            "[28,    20] loss: 0.223\n",
            "[28,    40] loss: 0.161\n",
            "[29,    20] loss: 0.117\n",
            "[29,    40] loss: 0.110\n",
            "[30,    20] loss: 0.065\n",
            "[30,    40] loss: 0.094\n",
            "[31,    20] loss: 0.109\n",
            "[31,    40] loss: 0.114\n",
            "[32,    20] loss: 0.075\n",
            "[32,    40] loss: 0.060\n",
            "[33,    20] loss: 0.028\n",
            "[33,    40] loss: 0.070\n",
            "[34,    20] loss: 0.178\n",
            "[34,    40] loss: 0.173\n",
            "[35,    20] loss: 0.204\n",
            "[35,    40] loss: 0.142\n",
            "[36,    20] loss: 0.047\n",
            "[36,    40] loss: 0.069\n",
            "[37,    20] loss: 0.101\n",
            "[37,    40] loss: 0.069\n",
            "[38,    20] loss: 0.049\n",
            "[38,    40] loss: 0.072\n",
            "[39,    20] loss: 0.054\n",
            "[39,    40] loss: 0.046\n",
            "[40,    20] loss: 0.028\n",
            "[40,    40] loss: 0.061\n",
            "ITERATION:  8\n",
            "Accuracy of the network on the 8 iteration: 10 %\n",
            "Train the network, iteration:  9  on classes:  range(90, 100)\n",
            "[1,    20] loss: 6.100\n",
            "[1,    40] loss: 3.906\n",
            "[2,    20] loss: 2.962\n",
            "[2,    40] loss: 2.478\n",
            "[3,    20] loss: 2.023\n",
            "[3,    40] loss: 1.849\n",
            "[4,    20] loss: 1.528\n",
            "[4,    40] loss: 1.386\n",
            "[5,    20] loss: 1.167\n",
            "[5,    40] loss: 1.218\n",
            "[6,    20] loss: 0.951\n",
            "[6,    40] loss: 0.928\n",
            "[7,    20] loss: 0.786\n",
            "[7,    40] loss: 0.734\n",
            "[8,    20] loss: 0.545\n",
            "[8,    40] loss: 0.537\n",
            "[9,    20] loss: 0.390\n",
            "[9,    40] loss: 0.391\n",
            "[10,    20] loss: 0.317\n",
            "[10,    40] loss: 0.284\n",
            "[11,    20] loss: 0.213\n",
            "[11,    40] loss: 0.311\n",
            "[12,    20] loss: 0.457\n",
            "[12,    40] loss: 0.327\n",
            "[13,    20] loss: 0.234\n",
            "[13,    40] loss: 0.195\n",
            "[14,    20] loss: 0.134\n",
            "[14,    40] loss: 0.128\n",
            "[15,    20] loss: 0.125\n",
            "[15,    40] loss: 0.167\n",
            "[16,    20] loss: 0.259\n",
            "[16,    40] loss: 0.191\n",
            "[17,    20] loss: 0.151\n",
            "[17,    40] loss: 0.137\n",
            "[18,    20] loss: 0.095\n",
            "[18,    40] loss: 0.105\n",
            "[19,    20] loss: 0.182\n",
            "[19,    40] loss: 0.186\n",
            "[20,    20] loss: 0.317\n",
            "[20,    40] loss: 0.244\n",
            "[21,    20] loss: 0.208\n",
            "[21,    40] loss: 0.181\n",
            "[22,    20] loss: 0.077\n",
            "[22,    40] loss: 0.224\n",
            "[23,    20] loss: 0.337\n",
            "[23,    40] loss: 0.203\n",
            "[24,    20] loss: 0.238\n",
            "[24,    40] loss: 0.217\n",
            "[25,    20] loss: 0.153\n",
            "[25,    40] loss: 0.116\n",
            "[26,    20] loss: 0.059\n",
            "[26,    40] loss: 0.072\n",
            "[27,    20] loss: 0.196\n",
            "[27,    40] loss: 0.205\n",
            "[28,    20] loss: 0.342\n",
            "[28,    40] loss: 0.367\n",
            "[29,    20] loss: 0.349\n",
            "[29,    40] loss: 0.291\n",
            "[30,    20] loss: 0.139\n",
            "[30,    40] loss: 0.143\n",
            "[31,    20] loss: 0.149\n",
            "[31,    40] loss: 0.154\n",
            "[32,    20] loss: 0.165\n",
            "[32,    40] loss: 0.204\n",
            "[33,    20] loss: 0.131\n",
            "[33,    40] loss: 0.154\n",
            "[34,    20] loss: 0.116\n",
            "[34,    40] loss: 0.091\n",
            "[35,    20] loss: 0.050\n",
            "[35,    40] loss: 0.173\n",
            "[36,    20] loss: 0.107\n",
            "[36,    40] loss: 0.165\n",
            "[37,    20] loss: 0.215\n",
            "[37,    40] loss: 0.180\n",
            "[38,    20] loss: 0.119\n",
            "[38,    40] loss: 0.167\n",
            "[39,    20] loss: 0.305\n",
            "[39,    40] loss: 0.238\n",
            "[40,    20] loss: 0.087\n",
            "[40,    40] loss: 0.071\n",
            "ITERATION:  9\n",
            "Accuracy of the network on the 9 iteration: 9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLE5LnQkZXSI"
      },
      "source": [
        "#### confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "yw2RugH6WcEv",
        "outputId": "feb9800a-5f0a-4fb0-a911-87609999fb3f"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in valid_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net.forward(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 9 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "he3I4t3Yc1_o",
        "outputId": "3c6d9216-61bc-4d13-ce50-1c2fdf182884"
      },
      "source": [
        "x = [10,20,30,40,50,60,70,80,90,100]\n",
        "plt.plot(x,acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1740bdf310>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU933v8fd3tIE2tCIkNoEx2IAlbGTXvk6IY2PHiwi0TdykTsLN44R7b1I3id3Gbtp70/Vepzex6zRNUmI3JWniOnVsMDh2jPGapcTC7Pu+CCQkJIEW0PrtHzPIggg0CI1mRvN5PY+emXPmjM6XeQ4fned7fr855u6IiEj8CUS7ABERGRwFuIhInFKAi4jEKQW4iEicUoCLiMSp5OHcWUFBgZeWlg7nLkVE4t66devq3b3w/PXDGuClpaVUVVUN5y5FROKemR3sb71aKCIicUoBLiISpxTgIiJxKqwAN7MvmNkWM9tqZl8Mrcszs9Vmtjv0mBvZUkVEpK8BA9zMZgOfBW4AyoFKM5sGPAKscfcrgTWhZRERGSbhnIFfDax19zZ37wLeBH4PWAgsC22zDFgUmRJFRKQ/4QT4FuD9ZpZvZunA3cBEoMjdj4W2qQGK+nuzmS0xsyozq6qrqxuSokVEJIwAd/ftwNeAV4CXgQ1A93nbONDv99K6+1J3r3D3isLC3xqHHpaVG4/yo7X9DoMUEUlYYV3EdPen3H2uu88DGoFdQK2ZFQOEHo9HqsiXthzj8dW76OruidQuRETiTrijUMaGHicR7H//GHgBWBzaZDGwIhIFAlSWlVDf0sHa/Q2R2oWISNwJdxz4T81sG7AS+Ly7NwGPAreb2W5gfmg5Ij44YywZqUms3Hg0UrsQEYk7YX0Xiru/v591J4DbhryifoxOTWL+zCJe3lrD3yyaTUqS5h+JiMRNElaWldDU1skv9tRHuxQRkZgQNwE+b3oBWaOSWbXx2MAbi4gkgLgJ8LTkJD40axyvbK3hTGf3wG8QERnh4ibAASrLimlu7+KtXZoQJCISVwF+87QCctNTWLVJbRQRkbgK8JSkAHfOLubV7bWc7lAbRUQSW1wFOMCCsmLaOrp5bUfEJn6KiMSFuAvw35maT0FmGqs2aVKPiCS2uAvwpIBx9zXjeG3HcVrau6JdjohI1MRdgAMsKC+hvauHV7fVRrsUEZGoicsAnzspl3HZo9RGEZGEFpcBHggY95QV8+auOk6e7ox2OSIiURGXAQ7BST2d3c4rW2uiXYqISFTEbYDPmZjDhNzRrNSkHhFJUHEb4GZGZVkJv9xTT0NrR7TLEREZdnEb4BBso3T3OC9vURtFRBJPuLdU+5KZbTWzLWb2tJmNMrMpZrbWzPaY2TNmlhrpYs83qySbKQUZGo0iIglpwAA3s/HAHwMV7j4bSAI+RvBO9Y+7+zSCNzq+P5KFXqA2FpQV85/7TnC8+cxw715EJKrCbaEkA6PNLBlIB44BtwLPhl5fBiwa+vIGVlleQo/DS5vVRhGRxDJggLt7NfB14BDB4D4JrAOa3P3sXPYjwPj+3m9mS8ysysyq6uqG/nu8pxdlMb0oU20UEUk44bRQcoGFwBSgBMgA7gx3B+6+1N0r3L2isLBw0IVezIKyEt450Mixk6cj8vtFRGJROC2U+cB+d69z907gOeBmICfUUgGYAFRHqMYBVZaXAPCixoSLSAIJJ8APATeaWbqZGXAbsA14HfhIaJvFwIrIlDiwKQUZzCrJ1qQeEUko4fTA1xK8WPkusDn0nqXAw8CDZrYHyAeeimCdA6osK2Hj4SYON7RFswwRkWET1igUd/+qu1/l7rPd/ZPu3u7u+9z9Bnef5u4fdff2SBd7MZVlxQC6X6aIJIy4nonZ18S8dOZMzGHlRo1GEZHEMGICHIJn4duOnWJfXUu0SxERibgRFeD3qI0iIglkRAV48ZjR3FCap0k9IpIQRlSAA1SWF7OrtoWdNc3RLkVEJKJGXIDfNbuYgKGzcBEZ8UZcgBdmpXHj1HxWbTqGu0e7HBGRiBlxAQ6woLyE/fWtbD16KtqliIhEzIgM8DtnjSM5YKxUG0VERrARGeC5GancPK2AF9VGEZERbEQGOATbKEcaT7PhcFO0SxERiYgRG+B3zCoiNSmgST0iMmKN2ADPHpXCvOmFvLjpGD09aqOIyMgzYgMcYEF5MTWnzlB1sDHapYiIDLkRHeDzry5iVEpAk3pEZEQa0QGekZbMrVeN5Webj9HV3RPtckREhlQ4NzWeYWYb+vycMrMvmlmema02s92hx9zhKPhSVZaVUN/Swdr9DdEuRURkSIVzS7Wd7j7H3ecAc4E24HngEWCNu18JrAktx5wPzhhLemqS2igiMuJcagvlNmCvux8EFgLLQuuXAYuGsrChMjo1idtnFvHSlho61UYRkRHkUgP8Y8DToedF7n52kHUNUNTfG8xsiZlVmVlVXV3dIMu8PJVlJTS1dfKLPfVR2b+ISCSEHeBmlgp8GPiP81/z4Hz1fgdbu/tSd69w94rCwsJBF3o55k0vIGtUMqs2alKPiIwcl3IGfhfwrrvXhpZrzawYIPR4fKiLGyppyUncMXMcr2yrob2rO9rliIgMiUsJ8I/zXvsE4AVgcej5YmDFUBUVCQvKi2k+08Vbu9RGEZGRIawAN7MM4HbguT6rHwVuN7PdwPzQcsy6eVoBuekprNyo0SgiMjIkh7ORu7cC+eetO0FwVEpcSEkKcOfscazYcJTTHd2MTk2KdkkiIpdlRM/EPF9lWQltHd28vjNm2/UiImFLqAC/cWo+BZlpmtQjIiNCQgV4UsC4+5pxrNl+nJb2rmiXIyJyWRIqwCHYRmnv6mHN9tqBNxYRiWEJF+AVk3MZlz2KlZrUIyJxLuECPBAw7ikr5q1ddZw83RntckREBi3hAhygsqyYju4eXtlaE+1SREQGLSEDfM7EHCbkjtYNj0UkriVkgJsZlWUl/HJPPY2tHdEuR0RkUBIywCHYRunqcV5WG0VE4lTCBviskmymFGTou1FEJG4lbIAH2yjF/Oe+E9Q1t0e7HBGRS5awAQ6woLyEHoeXtuhipojEn4QO8OlFWUwvytSdekQkLiV0gENwav1vDjRw7OTpaJciInJJFOBlxQC8qDHhIhJnwr0jT46ZPWtmO8xsu5ndZGZ5ZrbazHaHHnMjXWwkTC3MZFZJtib1iEjcCfcM/AngZXe/CigHtgOPAGvc/UpgTWg5LlWWlbDhcBOHG9qiXYqISNgGDHAzGwPMA54CcPcOd28CFgLLQpstAxZFqshIO9tG0Vm4iMSTcM7ApwB1wPfNbL2ZPRm6yXGRu59NvBqgqL83m9kSM6sys6q6urqhqXqITcxLZ87EHN2pR0TiSjgBngxcB3zH3a8FWjmvXeLuDnh/b3b3pe5e4e4VhYWFl1tvxFSWFbP16Cn217dGuxQRkbCEE+BHgCPuvja0/CzBQK81s2KA0GNc3yn4nrNtFE2tF5E4MWCAu3sNcNjMZoRW3QZsA14AFofWLQZWRKTCYVI8ZjTXl+ayUm0UEYkT4Y5CeQD4kZltAuYA/xd4FLjdzHYD80PLcW1BeQm7alvYVdsc7VJERAYUVoC7+4ZQH7vM3Re5e6O7n3D329z9Snef7+4NkS420u6aXUzA1EYRkfiQ8DMx+yrMSuPGqfms3HSM4HVZEZHYpQA/T2VZCfvrW9l69FS0SxERuSgF+HnunD2O5IBpUo+IxDwF+HnyMlK5eVoBqzYdVRtFRGKaArwflWXFHGk8zYbDTdEuRUTkghTg/bhj1jhSkwJqo4hITFOA92PM6BTmTS/kxU3H6OlRG0VEYpMC/AIWlBdTc+oM6w41RrsUEZF+KcAv4Lari0hLDrBSk3pEJEYpwC8gMy2ZW68ay88219CtNoqIxCAF+EUsKC+hvqWdtftORLsUEZHfogC/iA/OGEt6ahIrNRpFRGKQAvwiRqcmMf/qIl7acozO7p5olyMicg4F+AAWlJfQ1NbJL/fUR7sUEZFzKMAHMG96AVmjkjWpR0RijgJ8AGnJSdwxcxw/31pDe1d3tMsREekVVoCb2QEz22xmG8ysKrQuz8xWm9nu0GNuZEuNnsryYprPdPHWLrVRRCR2XMoZ+AfdfY67V4SWHwHWuPuVwBrOu1P9SPK+aQXkpKewSvfLFJEYcjktlIXAstDzZcCiyy8nNqUkBbhr9jhe3VbLmU61UUQkNoQb4A68YmbrzGxJaF2Ru5+9slcDFPX3RjNbYmZVZlZVV1d3meVGT2VZCa0d3by+43i0SxERAcIP8Pe5+3XAXcDnzWxe3xc9eOeDfuebu/vS0A2RKwoLCy+v2ii6cWo+Y7PSeGLNblrbu6JdjohI2Helrw49HgeeB24Aas2sGCD0OKJPTZMCxtc/Ws6u2mYe/MkGfc2siETdgAFuZhlmlnX2OXAHsAV4AVgc2mwxsCJSRcaKedML+crdV/PzrbU8sWZ3tMsRkQSXHMY2RcDzZnZ2+x+7+8tm9g7wEzO7HzgI3Bu5MmPH/e+bwo6aZp5Ys5sZ47K4+5riaJckIglqwAB3931AeT/rTwC3RaKoWGZm/N3vzmZfXQsP/WQjk/PTmVUyJtpliUgC0kzMQUhLTuK7n5xLTnoKS36wjvqW9miXJCIJSAE+SGOzRrH0kxXUt7TzuX97l44ufVuhiAwvBfhluGbCGP7+I2X85kADX31hC8HRlCIiwyOci5hyEQvnjGdnTTPffmMvVxdn86mbSqNdkogkCJ2BD4E/uWMG868ey1+t3Mav9L3hIjJMFOBDIBAwHv+DOUwtyOBzP36XQyfaol2SiCQABfgQyRqVwpOLK3CHz/zgHVo03V5EIkwBPoQm52fw7fuuY29dK1/8d023F5HIUoAPsZunFfC/77maV7fX8tjqXdEuR0RGMI1CiYDF/62UHTXNfOv1PcwYl8WC8pJolyQiI5DOwCPAzPjrhbO5vjSXP312I1uqT0a7JBEZgRTgEZKaHOA7n5hLXnoqn/1BFXXNmm4vIkNLAR5BBZlpfG9xBY1tHfzPf1unu9qLyJBSgEfYrJIxfOOjc1h3sJG/eF7T7UVk6CjAh8E9ZcX88a3T+I91R/j+Lw9EuxwRGSEU4MPki/Onc8fMIv72xW28vTt+b+4sIrEj7AA3syQzW29mq0LLU8xsrZntMbNnzCw1cmXGv7PT7acXZfFHP17P/vrWaJckInHuUs7AvwBs77P8NeBxd58GNAL3D2VhI1FGWjLf+1QFAYPP/qCKU2c6o12SiMSxsALczCYA9wBPhpYNuBV4NrTJMmBRJAocaSbmpfPt++ZyoD443b5b0+1FZJDCPQP/B+DLwNnbzuQDTe5+9hubjgDj+3ujmS0xsyozq6qrU+8X4KYr8vnqh2fx2o7j/P+f74x2OSISpwYMcDOrBI67+7rB7MDdl7p7hbtXFBYWDuZXjEifvHEy9/3OJL775l6Wr6+OdjkiEofC+S6Um4EPm9ndwCggG3gCyDGz5NBZ+ARAKXSJvrpgFnuOt/Dln25iSkEG5RNzol2SiMSRAc/A3f3P3H2Cu5cCHwNec/f7gNeBj4Q2WwysiFiVI1RqcoBv33cdhZlpLPlhFcdPnYl2SSISRy5nHPjDwINmtodgT/ypoSkpseRnpvHk4gqaz3Sx5IfrONOp6fYiEp5LCnB3f8PdK0PP97n7De4+zd0/6u76tqZBuro4m8fuLWfD4Sa+8txmTbcXkbBoJmaMuHN2MV+aP53n1lfz5Nv7o12OiMQBBXgMeeDWadx9zTj+30vbeWPn8WiXIyIxTgEeQwIB4+sfLWfGuGweeHo9e+taol2SiMQwBXiMSU9N5nufmktqUoDPLqvi5GlNtxeR/inAY9CE3HS+84m5HGpo44Gn12u6vYj0SwEeo26YksffLJrNW7vqePSl7QO/QUQSju5KH8M+fsMkdhw7xffe3s9V47L5/bkTol2SiMQQnYHHuL+onMlNU/P5s+c28+6hxmiXIyIxRAEe41KSgtPti8ak8T9+uI6ak5puLyJBCvA4kJuRypOfup629i6W/LBK0+1FBFCAx40Z47L4h49dy+bqkzz8002abi8iCvB4cvvMIv7kjhms2HCUP3p6vb69UCTBaRRKnPncLVfQ0+P84+t7eGtnHX965wzu+53JJAUs2qWJyDDTGXicMTMeuO1Kfv7FeZRPzOH/rNjK7377l2w+cjLapYnIMFOAx6kpBRn88P4b+ObHr+Vo0xkW/tMv+MsXtupO9yIJRAEex8yMD5eXsOahD/CJGyez7NcHmP+NN1m16agucookgHBuajzKzH5jZhvNbKuZ/VVo/RQzW2tme8zsGTNLjXy50p8xo1P464WzWf65mynMSuOPfryexd9/h4MnWqNdmohEUDhn4O3Are5eDswB7jSzG4GvAY+7+zSgEbg/cmVKOMon5rDi8zfz1QUzefdgI3c8/hb/uGY37V0aNy4yEoVzU2N397NfTJ0S+nHgVuDZ0PplwKKIVCiXJDkpwKdvnsKahz7A/JlFfGP1Lu564m1+tbc+2qWJyBALqwduZklmtgE4DqwG9gJN7t4V2uQIMP4C711iZlVmVlVXVzcUNUsYirJH8U9/eB3/+unr6ep2/vB7a3nwmQ3Ut+jWpSIjRVgB7u7d7j4HmADcAFwV7g7cfam7V7h7RWFh4SDLlMG6ZcZYXvnSPB64dRorNx3l1q+/wY/XHqJH3zEuEvcu9a70TcDrwE1AjpmdnQg0Aage4tpkiIxKSeKhO2bw0hfmMbMkm688v5nf/+6v2Hb0VLRLE5HLEM4olEIzywk9Hw3cDmwnGOQfCW22GFgRqSJlaEwbm8nTn72Rx+4t59CJNhZ86xf87apttLZ3DfxmEYk54ZyBFwOvm9km4B1gtbuvAh4GHjSzPUA+8FTkypShYmb83nUTWPPQB7i3YiJP/mI/8x97k5e31GjsuEicseH8T1tRUeFVVVXDtj8Z2LqDjfz585vZUdPMbVeN5S8/PIuJeenRLktE+jCzde5ecf56zcRMcHMn57LqgffxF/dcza/3neD2x9/kO2/spaOrJ9qlicgAFOBCclKAz7x/Kq8++AFumT6Wr728g3u++Ta/2d8Q7dJE5CIU4NKrJGc03/3kXJ5aXEFbRzf3/vOv+dP/2EhDa0e0SxORfijA5bfcdnURqx+cx/+65QqeX1/Nrd94g5+8c1hjx0VijAJc+pWemszDd17Fz77wfq4cm8mXf7qJP1j6a3bWNEe7NBEJUYDLRU0vyuKZJTfx9x8pY8/xFu755ts8+tIO2jo0dlwk2hTgMqBAwLi3YiJrHrqF37tuPN99cy+3P/YWq7fVauy4SBRpHLhcsncONPDnz29mV20Lk/PTWThnPIvmlDC1MDPapYmMSBcaB64Al0Hp7O5h+fpqlm+o5ld7T+AO5RPGsHDOeBaUl1CYlRbtEkVGDAW4REzNyTOs3HiU59dXs+3YKZICxs3TClg0p4QPzRpHRlrywL9ERC5IAS7DYndtM8s3VLN8/VGqm04zOiWJ22cWsejaEt5/ZSEpSbrsInKpFOAyrHp6nHWHGlm+vpoXNx+jqa2TvIxUKsuKWThnPNdNysHMol2mSFxQgEvUdHT18OauOpZvqObVbbW0d/UwKS+dRXNKWHjteK7QxU+Ri1KAS0xoPtPJy1tqWLHhKL/aW0+PQ1nvxc9ixmaNinaJIjFHAS4xp/ZU8OLn8g3VbKk+RcAIXfwcz4dmjyNTFz9FAAW4xLg9x5tZvj4Y5kcaTzMqJcDtM8exaE4J86br4qcktkEHuJlNBH4AFAEOLHX3J8wsD3gGKAUOAPe6e+PFfpcCXAbi7rx7qJHn11fz4qZjNLZ1kpuewj1lxfzuteO5blKuLn5KwrmcAC8Git39XTPLAtYBi4D/DjS4+6Nm9giQ6+4PX+x3KcDlUnR09fD27jqWbzjK6m01nOnsYWLeaBbNGc/COeOZNlYXPyUxDFkLxcxWAN8K/dzi7sdCIf+Gu8+42HsV4DJYLe1d/HxLDcs3VPPLPcGLn7PHZ7MoNPOzKFsXP2XkGpIAN7NS4C1gNnDI3c/erd6AxrPL571nCbAEYNKkSXMPHjw4mPpFeh1vPsPKjcdYsaGaTUdOAjC1IIOK0lwqSvO4vjSP0vx0tVpkxLjsADezTOBN4O/c/Tkza+ob2GbW6O65F/sdOgOXoba3roXV22qpOtBI1cEGmto6ASjITKVich4VpblcX5rHzJJsXQiVuHWhAA9rnJaZpQA/BX7k7s+FVteaWXGfFsrxoStXJDxXFGZyxQcy4QPB2Z/76lt450Aj7xxooOpAIy9vrQFgdEoS107KCZ2h53LtpFwNU5S4N+ARHGqPPAVsd/fH+rz0ArAYeDT0uCIiFYqEKRAwpo3NYtrYLD5+wyQgONa86mygH2zgW6/tpschYDCzJJuKycGWy/WluYxVH13iTDijUN4HvA1sBnpCq78CrAV+AkwCDhIcRnjR25irhSLR1tLexfpDjbxzoJGqAw2sP9TE6c5uACblpfe2XK4vzeWKwkz10SUmaCKPSD86u3vYdvRUb8ul6mAD9S0dAOSmpzB3cjDMK0rzuGb8GFKT1UeX4XdZPXCRkSolKUD5xBzKJ+bwmfcHJxIdONEWCvRgqL+6vRaAtOTgtjeUBi+OXjc5l+xRKVH+F0gi0xm4yADqmttZdzDYcnnnYCNbq0/S1eOYwVXjsnvP0K+dmMP4nNEEAmq7yNBSC0VkiLR1dLHhcFPvxdF3DzbS2hHso2ekJjGtKIsZRZlML8pixrgsphdlMTYrTf10GTQFuEiEdHX3sKOmmc3VJ9lZ08yu2mZ21bZQ39Leu82Y0SnMKMriyqLM3lCfXpRFXkZqFCuXeKEeuEiEJCcFmD1+DLPHjzln/YmWdnbVtoQCPfizcuNRfrS2q3ebgsw0ZozL7A304E8mWeqtSxgU4CIRkp+Zxk2Zadx0RX7vOnfneHN775n6zppmdh1v4Zl3DtMWasMAjM8ZHTxb7xPs08ZmMjo1KRr/FIlRCnCRYWRmFGWPoih7FPOmF/au7+lxqptOhwK9mV01zeysbeFXe07Q0d0Tei9MzkvnyqKsYLCPCz5OKcjQ8MYEpQAXiQGBgDExL52JeenMn1nUu76ru4eDDW2hQG9md20LO2ubeW3Hcbp7gtevkgPGlIIMpo/LYvrYYJ99SkEGUwoyGJWiM/aRTAEuEsOSkwLB73spzOSua4p717d3dbOvrrW3t76zpoUt1Sf52eZj9B2XMD5nNFMKMphamNEb6lcUZlKSM5okDXeMewpwkTiUlpzE1cXZXF2cfc76to4u9te3sq+ulf31raHnLTz/bjXN7e9dPE1NDlCanx4K9UymFmYwNRTweRmpGvIYJxTgIiNIemoys0rGMKvk3BEx7k59S0co1FvYV9fKvvpW9ta18tqO43R2v3faPmZ0SvCsvffM/b2WjC6ixhYFuEgCMDMKs9IozErjhil557zW1d1DddPp3lA/G/C/3neC59ZXn7NtyZhRTC18L9CDZ+6ZjM9VSyYaFOAiCS45KcDk/Awm52fwwfNeO9uS6duW2VffyvIN1TSf6dOSSQow+WxLpjCDKwoyGZudRl5GKrnpqeRnpjI6JUmtmSGmABeRC7pYS+ZEa0co1FvYFwr4ffWtvL7z3JbMWWnJgd5Az8tIJTcjlbz0lOBj3/Whx5z0FI2iGYACXEQumZlRkJlGQWb/LZmjTWeoazlDQ2snja0dNLR1BB9bO2hsCz5WN52mobWDk6c7L7ifjNSkCwR8KPjTU895PTc9heQEunWeAlxEhlRyUoBJ+elMyk8Pa/uu7h6aTneeF/CdvUHf9w/AvvoWGls7aekzouZ82aOSyQuF+ns/aRRkBp/nZ6aRnxFs6+RlpJKWHL9n+eHcUu1fgErguLvPDq3LA54BSoEDBO/G0xi5MkVkpEpOCvSezYervaubprbO3wr4c4K/rYOjTWfYUn2KhtaO3hmt58tKS+4N8/zMPkGfkUZ+Zt/H4Nl+LN0cO5wz8H8FvgX8oM+6R4A17v6omT0SWn546MsTEfltaclJFGUnURTmfUzdneb2Lk60dNDQ2k59SzDkT7T0ed7azuGGNjYcbqKhtaN3puv5xoxO6Q30vuGen5kW+iPw3vrc9NSIjs4ZMMDd/S0zKz1v9ULgltDzZcAbKMBFJEaZGdmjUsgeFRzjPpCeHufUmU7qW4Ih39DaQX1rBw0twaA/EXrcW9fCbw4Ez/b7+2ZuM4KjcDJS+edPzmVqYeaQ/rsG2wMvcvdjoec1QNGFNjSzJcASgEmTJg1ydyIiwycQMHLSU8lJT2Xa2IFDt7vHe1s39S3toTP9YPifaO3gREtHRL4i+LIvYrq7m9kF7wrh7kuBpRC8ocPl7k9EJNYkBd4blTO9KGvY9jvYbnytmRUDhB6PD11JIiISjsEG+AvA4tDzxcCKoSlHRETCNWCAm9nTwK+BGWZ2xMzuBx4Fbjez3cD80LKIiAyjcEahfPwCL902xLWIiMgliJ0R6SIickkU4CIicUoBLiISpxTgIiJxyry/+Z+R2plZHXBw2HYYGQVAfbSLiBH6LM6lz+Nc+jzec7mfxWR3Lzx/5bAG+EhgZlXuXhHtOmKBPotz6fM4lz6P90Tqs1ALRUQkTinARUTilAL80i2NdgExRJ/FufR5nEufx3si8lmoBy4iEqd0Bi4iEqcU4CIicUoBfgFmNtHMXjezbWa21cy+EFqfZ2arzWx36DE32rUOJzNLMrP1ZrYqtDzFzNaa2R4ze8bMUqNd43Axsxwze9bMdpjZdjO7KVGPDzP7Uuj/yRYze9rMRiXSsWFm/2Jmx81sS591/R4LFvTN0OeyycyuG+x+FeAX1gU85O4zgRuBz5vZTN67ofOVwJrQciL5ArC9z/LXgMfdfRrQCNwflaqi4wngZXe/Cign+Lkk3PFhZuOBPwYq3H02kAR8jMQ6Nv4VuPO8dRc6Fu4Crgz9LAG+M+i9urt+wvgheNOK24GdQHFoXTGwM9q1DeNnMCF0IN4KrAKM4Oyy5NDrNwE/j3adw+/Wj3kAAAIjSURBVPRZjAH2ExoI0Gd9wh0fwHjgMJBH8CuqVwEfSrRjAygFtgx0LAD/DHy8v+0u9Udn4GEws1LgWmAtl3BD5xHoH4AvAz2h5Xygyd27QstHCP5nTgRTgDrg+6GW0pNmlkECHh/uXg18HTgEHANOAutI3GPjrAsdC2f/4J016M9GAT4AM8sEfgp80d1P9X3Ng38+E2IcpplVAsfdfV20a4kRycB1wHfc/VqglfPaJYlyfIR6uwsJ/lErATL47XZCQovUsaAAvwgzSyEY3j9y9+dCqxP1hs43Ax82swPAvxNsozwB5JjZ2Ts7TQCqo1PesDsCHHH3taHlZwkGeiIeH/OB/e5e5+6dwHMEj5dEPTbOutCxUA1M7LPdoD8bBfgFmJkBTwHb3f2xPi8l5A2d3f3P3H2Cu5cSvED1mrvfB7wOfCS0WSJ9HjXAYTObEVp1G7CNxDw+DgE3mll66P/N2c8iIY+NPi50LLwAfCo0GuVG4GSfVssl0UzMCzCz9wFvA5t5r+f7FYJ98J8Akwh+Ne697t4QlSKjxMxuAf7E3SvNbCrBM/I8YD3wCXdvj2Z9w8XM5gBPAqnAPuDTBE+KEu74MLO/Av6A4Oit9cBnCPZ1E+LYCN38/RaCXxtbC3wVWE4/x0Loj9y3CLaZ2oBPu3vVoParABcRiU9qoYiIxCkFuIhInFKAi4jEKQW4iEicUoCLiMQpBbiISJxSgIuIxKn/ApSsOKL4b882AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxW7gWn7FaVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}