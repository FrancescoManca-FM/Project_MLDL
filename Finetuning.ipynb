{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "c9XO0l5B9WDO",
        "uhi2ESn89cml",
        "LCnzW3XCF0JW",
        "ClFYYN4dYzKf",
        "C9vHvoVoY4XR",
        "8BBkS-svY697"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXuDQrvO35Pb"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg0q7WTHJxB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e284d14-43db-4b4c-ee76-2bfcf28f8d92"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 31 13:38:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj4HVjkW2RBe"
      },
      "source": [
        "#import sys\n",
        "#sys.path.insert(0,\"/content/drive/MyDrive/OWR-project/Project_MLDL\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXZiclrtCLr7"
      },
      "source": [
        "Classification Network (using Resnet32) on CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlNz0nWYCR0L"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9XO0l5B9WDO"
      },
      "source": [
        "### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMcd8DV4C1nw",
        "outputId": "5f2235cf-7cd0-4892-ba7a-aa0d562cc93d"
      },
      "source": [
        "# we build a transform to normalize images: Data normalization is an important step which ensures \n",
        "# each input parameter (pixel, in this case) has a similar data distribution. This makes convergence \n",
        "# faster while training the network.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 128\n",
        "\n",
        "trainset_raw = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "for i in range(len(trainset_raw)):\n",
        "  if(i==0):\n",
        "    trainset = [[trainset_raw[i][0], trainset_raw[i][1]]]\n",
        "  else:\n",
        "    trainset.append([trainset_raw[i][0], trainset_raw[i][1]])\n",
        "\n",
        "\n",
        "# DataLoader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "# batch_size = how many samples per batch to load\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzgEQ4uchaBn",
        "outputId": "3b18dee0-7313-4303-8b41-0c95be0d3ba9"
      },
      "source": [
        "for i in range(500):\n",
        "  print(trainset[i][1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "29\n",
            "0\n",
            "11\n",
            "1\n",
            "86\n",
            "90\n",
            "28\n",
            "23\n",
            "31\n",
            "39\n",
            "96\n",
            "82\n",
            "17\n",
            "71\n",
            "39\n",
            "8\n",
            "97\n",
            "80\n",
            "71\n",
            "74\n",
            "59\n",
            "70\n",
            "87\n",
            "59\n",
            "84\n",
            "64\n",
            "52\n",
            "42\n",
            "64\n",
            "8\n",
            "17\n",
            "47\n",
            "65\n",
            "21\n",
            "22\n",
            "81\n",
            "11\n",
            "24\n",
            "84\n",
            "78\n",
            "45\n",
            "49\n",
            "97\n",
            "56\n",
            "76\n",
            "11\n",
            "90\n",
            "89\n",
            "78\n",
            "73\n",
            "14\n",
            "87\n",
            "9\n",
            "71\n",
            "6\n",
            "47\n",
            "20\n",
            "98\n",
            "47\n",
            "36\n",
            "55\n",
            "72\n",
            "43\n",
            "51\n",
            "35\n",
            "83\n",
            "33\n",
            "27\n",
            "53\n",
            "92\n",
            "50\n",
            "15\n",
            "89\n",
            "36\n",
            "18\n",
            "89\n",
            "46\n",
            "33\n",
            "42\n",
            "39\n",
            "64\n",
            "75\n",
            "38\n",
            "23\n",
            "42\n",
            "66\n",
            "77\n",
            "49\n",
            "18\n",
            "46\n",
            "15\n",
            "35\n",
            "69\n",
            "95\n",
            "83\n",
            "75\n",
            "99\n",
            "73\n",
            "93\n",
            "55\n",
            "39\n",
            "4\n",
            "97\n",
            "61\n",
            "93\n",
            "51\n",
            "69\n",
            "56\n",
            "84\n",
            "59\n",
            "64\n",
            "94\n",
            "4\n",
            "11\n",
            "33\n",
            "68\n",
            "38\n",
            "20\n",
            "33\n",
            "34\n",
            "32\n",
            "46\n",
            "53\n",
            "88\n",
            "67\n",
            "70\n",
            "64\n",
            "53\n",
            "64\n",
            "8\n",
            "96\n",
            "87\n",
            "30\n",
            "20\n",
            "30\n",
            "66\n",
            "19\n",
            "76\n",
            "87\n",
            "52\n",
            "62\n",
            "35\n",
            "63\n",
            "40\n",
            "4\n",
            "99\n",
            "63\n",
            "74\n",
            "53\n",
            "26\n",
            "95\n",
            "48\n",
            "27\n",
            "33\n",
            "29\n",
            "39\n",
            "79\n",
            "32\n",
            "46\n",
            "64\n",
            "28\n",
            "85\n",
            "32\n",
            "82\n",
            "78\n",
            "39\n",
            "54\n",
            "28\n",
            "66\n",
            "65\n",
            "72\n",
            "21\n",
            "64\n",
            "62\n",
            "72\n",
            "0\n",
            "44\n",
            "7\n",
            "12\n",
            "19\n",
            "11\n",
            "31\n",
            "61\n",
            "79\n",
            "45\n",
            "81\n",
            "79\n",
            "98\n",
            "43\n",
            "46\n",
            "67\n",
            "80\n",
            "68\n",
            "74\n",
            "48\n",
            "81\n",
            "94\n",
            "86\n",
            "69\n",
            "39\n",
            "73\n",
            "2\n",
            "46\n",
            "49\n",
            "63\n",
            "43\n",
            "14\n",
            "49\n",
            "68\n",
            "65\n",
            "41\n",
            "37\n",
            "45\n",
            "36\n",
            "21\n",
            "77\n",
            "37\n",
            "39\n",
            "8\n",
            "9\n",
            "62\n",
            "86\n",
            "39\n",
            "19\n",
            "54\n",
            "39\n",
            "28\n",
            "11\n",
            "89\n",
            "90\n",
            "90\n",
            "79\n",
            "66\n",
            "81\n",
            "21\n",
            "79\n",
            "40\n",
            "29\n",
            "22\n",
            "13\n",
            "25\n",
            "11\n",
            "38\n",
            "10\n",
            "96\n",
            "54\n",
            "65\n",
            "39\n",
            "40\n",
            "42\n",
            "48\n",
            "48\n",
            "51\n",
            "11\n",
            "23\n",
            "23\n",
            "89\n",
            "52\n",
            "46\n",
            "2\n",
            "95\n",
            "43\n",
            "86\n",
            "34\n",
            "66\n",
            "18\n",
            "46\n",
            "66\n",
            "56\n",
            "57\n",
            "1\n",
            "44\n",
            "11\n",
            "82\n",
            "23\n",
            "90\n",
            "56\n",
            "19\n",
            "68\n",
            "66\n",
            "28\n",
            "1\n",
            "57\n",
            "67\n",
            "5\n",
            "13\n",
            "78\n",
            "6\n",
            "84\n",
            "7\n",
            "41\n",
            "65\n",
            "80\n",
            "12\n",
            "50\n",
            "63\n",
            "26\n",
            "8\n",
            "53\n",
            "60\n",
            "99\n",
            "97\n",
            "85\n",
            "0\n",
            "78\n",
            "31\n",
            "10\n",
            "2\n",
            "7\n",
            "43\n",
            "83\n",
            "97\n",
            "91\n",
            "82\n",
            "28\n",
            "42\n",
            "0\n",
            "82\n",
            "5\n",
            "68\n",
            "60\n",
            "30\n",
            "98\n",
            "82\n",
            "20\n",
            "64\n",
            "66\n",
            "10\n",
            "75\n",
            "54\n",
            "57\n",
            "87\n",
            "66\n",
            "66\n",
            "73\n",
            "54\n",
            "88\n",
            "42\n",
            "37\n",
            "80\n",
            "87\n",
            "3\n",
            "29\n",
            "43\n",
            "12\n",
            "73\n",
            "96\n",
            "23\n",
            "96\n",
            "84\n",
            "19\n",
            "62\n",
            "0\n",
            "21\n",
            "11\n",
            "36\n",
            "64\n",
            "76\n",
            "60\n",
            "3\n",
            "80\n",
            "82\n",
            "79\n",
            "26\n",
            "65\n",
            "72\n",
            "11\n",
            "15\n",
            "31\n",
            "48\n",
            "12\n",
            "91\n",
            "71\n",
            "87\n",
            "77\n",
            "15\n",
            "7\n",
            "58\n",
            "51\n",
            "55\n",
            "85\n",
            "2\n",
            "3\n",
            "89\n",
            "10\n",
            "3\n",
            "11\n",
            "20\n",
            "4\n",
            "48\n",
            "27\n",
            "48\n",
            "7\n",
            "67\n",
            "3\n",
            "65\n",
            "56\n",
            "9\n",
            "44\n",
            "95\n",
            "46\n",
            "83\n",
            "40\n",
            "58\n",
            "87\n",
            "59\n",
            "18\n",
            "48\n",
            "5\n",
            "88\n",
            "26\n",
            "21\n",
            "24\n",
            "53\n",
            "68\n",
            "49\n",
            "89\n",
            "96\n",
            "92\n",
            "7\n",
            "13\n",
            "99\n",
            "49\n",
            "22\n",
            "56\n",
            "67\n",
            "13\n",
            "97\n",
            "6\n",
            "19\n",
            "76\n",
            "65\n",
            "9\n",
            "71\n",
            "63\n",
            "71\n",
            "18\n",
            "55\n",
            "34\n",
            "18\n",
            "0\n",
            "56\n",
            "23\n",
            "75\n",
            "70\n",
            "78\n",
            "45\n",
            "66\n",
            "91\n",
            "25\n",
            "58\n",
            "90\n",
            "29\n",
            "68\n",
            "35\n",
            "54\n",
            "77\n",
            "97\n",
            "0\n",
            "70\n",
            "75\n",
            "60\n",
            "65\n",
            "5\n",
            "58\n",
            "82\n",
            "49\n",
            "61\n",
            "28\n",
            "44\n",
            "56\n",
            "82\n",
            "61\n",
            "43\n",
            "20\n",
            "38\n",
            "85\n",
            "87\n",
            "49\n",
            "85\n",
            "24\n",
            "7\n",
            "88\n",
            "40\n",
            "38\n",
            "72\n",
            "56\n",
            "4\n",
            "81\n",
            "98\n",
            "97\n",
            "14\n",
            "46\n",
            "23\n",
            "89\n",
            "86\n",
            "83\n",
            "54\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhi2ESn89cml"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyFOrsg4-L7"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=100):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def addOutputNodes(self, num_new_outputs):\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "        self.fc = nn.Linear(in_features, out_features + num_new_outputs)\n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        # print(self.fc.out_features)\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzrCPkfN5txO",
        "outputId": "4b347a9f-d1da-41a9-bab9-868ada05dc28"
      },
      "source": [
        "net = resnet32()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSAhwwBr9iZ9"
      },
      "source": [
        "### Define the loss and the optimization technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI6grd9hI2as"
      },
      "source": [
        "lr = 0.01\n",
        "decay = 0.00001\n",
        "epochs = 70\n",
        "momentum = 0.9\n",
        "factor = 5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJqiRlCoI-b0"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCnzW3XCF0JW"
      },
      "source": [
        "### NON INCREMENTAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9zwIkLXJPx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b7e81c-7b2c-4c97-e9ac-f6fe211e583a"
      },
      "source": [
        "#train the network\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "    # get the inputs; data is a list of  [input,labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "\n",
        "    outputs = net.forward(inputs) # forward: assign weights to each edge in each layer\n",
        "    loss = nn.CrossEntropyLoss(ignore_index=0)(outputs,labels) # calculate the loss\n",
        "\n",
        "    loss.backward() # redesign the weights evaluating the performance of the network\n",
        "    \n",
        "    optimizer.step() # update parameters \n",
        "\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 100 == 99:    # print every 100 mini-batches the average value of the loss accumulated in each batch\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "      running_loss = 0.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 4.545\n",
            "[1,   200] loss: 4.220\n",
            "[1,   300] loss: 3.997\n",
            "[2,   100] loss: 3.742\n",
            "[2,   200] loss: 3.641\n",
            "[2,   300] loss: 3.578\n",
            "[3,   100] loss: 3.389\n",
            "[3,   200] loss: 3.317\n",
            "[3,   300] loss: 3.238\n",
            "[4,   100] loss: 3.055\n",
            "[4,   200] loss: 3.012\n",
            "[4,   300] loss: 2.987\n",
            "[5,   100] loss: 2.788\n",
            "[5,   200] loss: 2.767\n",
            "[5,   300] loss: 2.730\n",
            "[6,   100] loss: 2.573\n",
            "[6,   200] loss: 2.540\n",
            "[6,   300] loss: 2.528\n",
            "[7,   100] loss: 2.380\n",
            "[7,   200] loss: 2.370\n",
            "[7,   300] loss: 2.343\n",
            "[8,   100] loss: 2.210\n",
            "[8,   200] loss: 2.230\n",
            "[8,   300] loss: 2.216\n",
            "[9,   100] loss: 2.068\n",
            "[9,   200] loss: 2.097\n",
            "[9,   300] loss: 2.088\n",
            "[10,   100] loss: 1.918\n",
            "[10,   200] loss: 1.972\n",
            "[10,   300] loss: 1.984\n",
            "[11,   100] loss: 1.811\n",
            "[11,   200] loss: 1.862\n",
            "[11,   300] loss: 1.877\n",
            "[12,   100] loss: 1.731\n",
            "[12,   200] loss: 1.747\n",
            "[12,   300] loss: 1.772\n",
            "[13,   100] loss: 1.642\n",
            "[13,   200] loss: 1.648\n",
            "[13,   300] loss: 1.703\n",
            "[14,   100] loss: 1.514\n",
            "[14,   200] loss: 1.555\n",
            "[14,   300] loss: 1.595\n",
            "[15,   100] loss: 1.433\n",
            "[15,   200] loss: 1.502\n",
            "[15,   300] loss: 1.532\n",
            "[16,   100] loss: 1.373\n",
            "[16,   200] loss: 1.405\n",
            "[16,   300] loss: 1.465\n",
            "[17,   100] loss: 1.291\n",
            "[17,   200] loss: 1.333\n",
            "[17,   300] loss: 1.386\n",
            "[18,   100] loss: 1.194\n",
            "[18,   200] loss: 1.268\n",
            "[18,   300] loss: 1.292\n",
            "[19,   100] loss: 1.109\n",
            "[19,   200] loss: 1.201\n",
            "[19,   300] loss: 1.272\n",
            "[20,   100] loss: 1.044\n",
            "[20,   200] loss: 1.118\n",
            "[20,   300] loss: 1.184\n",
            "[21,   100] loss: 0.995\n",
            "[21,   200] loss: 1.066\n",
            "[21,   300] loss: 1.115\n",
            "[22,   100] loss: 0.919\n",
            "[22,   200] loss: 1.005\n",
            "[22,   300] loss: 1.058\n",
            "[23,   100] loss: 0.858\n",
            "[23,   200] loss: 0.932\n",
            "[23,   300] loss: 1.006\n",
            "[24,   100] loss: 0.818\n",
            "[24,   200] loss: 0.883\n",
            "[24,   300] loss: 0.941\n",
            "[25,   100] loss: 0.765\n",
            "[25,   200] loss: 0.822\n",
            "[25,   300] loss: 0.886\n",
            "[26,   100] loss: 0.704\n",
            "[26,   200] loss: 0.776\n",
            "[26,   300] loss: 0.879\n",
            "[27,   100] loss: 0.681\n",
            "[27,   200] loss: 0.717\n",
            "[27,   300] loss: 0.802\n",
            "[28,   100] loss: 0.632\n",
            "[28,   200] loss: 0.705\n",
            "[28,   300] loss: 0.767\n",
            "[29,   100] loss: 0.583\n",
            "[29,   200] loss: 0.635\n",
            "[29,   300] loss: 0.719\n",
            "[30,   100] loss: 0.562\n",
            "[30,   200] loss: 0.598\n",
            "[30,   300] loss: 0.690\n",
            "[31,   100] loss: 0.532\n",
            "[31,   200] loss: 0.597\n",
            "[31,   300] loss: 0.658\n",
            "[32,   100] loss: 0.482\n",
            "[32,   200] loss: 0.524\n",
            "[32,   300] loss: 0.589\n",
            "[33,   100] loss: 0.484\n",
            "[33,   200] loss: 0.486\n",
            "[33,   300] loss: 0.535\n",
            "[34,   100] loss: 0.430\n",
            "[34,   200] loss: 0.478\n",
            "[34,   300] loss: 0.514\n",
            "[35,   100] loss: 0.413\n",
            "[35,   200] loss: 0.451\n",
            "[35,   300] loss: 0.506\n",
            "[36,   100] loss: 0.415\n",
            "[36,   200] loss: 0.411\n",
            "[36,   300] loss: 0.454\n",
            "[37,   100] loss: 0.332\n",
            "[37,   200] loss: 0.352\n",
            "[37,   300] loss: 0.419\n",
            "[38,   100] loss: 0.375\n",
            "[38,   200] loss: 0.356\n",
            "[38,   300] loss: 0.409\n",
            "[39,   100] loss: 0.335\n",
            "[39,   200] loss: 0.333\n",
            "[39,   300] loss: 0.388\n",
            "[40,   100] loss: 0.295\n",
            "[40,   200] loss: 0.320\n",
            "[40,   300] loss: 0.353\n",
            "[41,   100] loss: 0.264\n",
            "[41,   200] loss: 0.272\n",
            "[41,   300] loss: 0.330\n",
            "[42,   100] loss: 0.282\n",
            "[42,   200] loss: 0.296\n",
            "[42,   300] loss: 0.327\n",
            "[43,   100] loss: 0.297\n",
            "[43,   200] loss: 0.285\n",
            "[43,   300] loss: 0.298\n",
            "[44,   100] loss: 0.249\n",
            "[44,   200] loss: 0.258\n",
            "[44,   300] loss: 0.276\n",
            "[45,   100] loss: 0.242\n",
            "[45,   200] loss: 0.228\n",
            "[45,   300] loss: 0.244\n",
            "[46,   100] loss: 0.224\n",
            "[46,   200] loss: 0.190\n",
            "[46,   300] loss: 0.246\n",
            "[47,   100] loss: 0.203\n",
            "[47,   200] loss: 0.208\n",
            "[47,   300] loss: 0.229\n",
            "[48,   100] loss: 0.197\n",
            "[48,   200] loss: 0.205\n",
            "[48,   300] loss: 0.206\n",
            "[49,   100] loss: 0.161\n",
            "[49,   200] loss: 0.153\n",
            "[49,   300] loss: 0.193\n",
            "[50,   100] loss: 0.164\n",
            "[50,   200] loss: 0.164\n",
            "[50,   300] loss: 0.167\n",
            "[51,   100] loss: 0.164\n",
            "[51,   200] loss: 0.163\n",
            "[51,   300] loss: 0.202\n",
            "[52,   100] loss: 0.178\n",
            "[52,   200] loss: 0.178\n",
            "[52,   300] loss: 0.213\n",
            "[53,   100] loss: 0.183\n",
            "[53,   200] loss: 0.178\n",
            "[53,   300] loss: 0.216\n",
            "[54,   100] loss: 0.153\n",
            "[54,   200] loss: 0.157\n",
            "[54,   300] loss: 0.193\n",
            "[55,   100] loss: 0.145\n",
            "[55,   200] loss: 0.135\n",
            "[55,   300] loss: 0.151\n",
            "[56,   100] loss: 0.113\n",
            "[56,   200] loss: 0.121\n",
            "[56,   300] loss: 0.131\n",
            "[57,   100] loss: 0.107\n",
            "[57,   200] loss: 0.093\n",
            "[57,   300] loss: 0.104\n",
            "[58,   100] loss: 0.074\n",
            "[58,   200] loss: 0.070\n",
            "[58,   300] loss: 0.088\n",
            "[59,   100] loss: 0.059\n",
            "[59,   200] loss: 0.054\n",
            "[59,   300] loss: 0.058\n",
            "[60,   100] loss: 0.047\n",
            "[60,   200] loss: 0.046\n",
            "[60,   300] loss: 0.043\n",
            "[61,   100] loss: 0.036\n",
            "[61,   200] loss: 0.036\n",
            "[61,   300] loss: 0.037\n",
            "[62,   100] loss: 0.030\n",
            "[62,   200] loss: 0.023\n",
            "[62,   300] loss: 0.026\n",
            "[63,   100] loss: 0.020\n",
            "[63,   200] loss: 0.020\n",
            "[63,   300] loss: 0.020\n",
            "[64,   100] loss: 0.012\n",
            "[64,   200] loss: 0.012\n",
            "[64,   300] loss: 0.012\n",
            "[65,   100] loss: 0.009\n",
            "[65,   200] loss: 0.008\n",
            "[65,   300] loss: 0.009\n",
            "[66,   100] loss: 0.008\n",
            "[66,   200] loss: 0.008\n",
            "[66,   300] loss: 0.009\n",
            "[67,   100] loss: 0.006\n",
            "[67,   200] loss: 0.007\n",
            "[67,   300] loss: 0.007\n",
            "[68,   100] loss: 0.005\n",
            "[68,   200] loss: 0.006\n",
            "[68,   300] loss: 0.005\n",
            "[69,   100] loss: 0.005\n",
            "[69,   200] loss: 0.004\n",
            "[69,   300] loss: 0.005\n",
            "[70,   100] loss: 0.004\n",
            "[70,   200] loss: 0.004\n",
            "[70,   300] loss: 0.006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "g6YoczYtQu90",
        "outputId": "5a19e030-c1fb-442a-8f3b-9a4718ae2af5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de9BdVZXgfzsPYgBJwjsCAvLQxrdkFIuWQdExo46MpWWjtq023To+0fYF9Ng6reOjx1bp0bZkpB172hnaQW0otWLRCGUP1aJBLVEQBAQBiUk0gMgrybfnj3vX/fZddz/Pvcm98a5fVSrfvefsxzn3nL3WXnuttZ33HsMwfvdZMu0OGIaxe7CX3TDmBHvZDWNOsJfdMOYEe9kNY06wl90w5oSxXnbn3Hrn3PXOuRudc2dPqlOGYUwe13Wd3Tm3FLgBeA5wO/Bd4GXe+2sn1z3DMCbFsjHKPhW40Xt/M4Bz7kLgdCD5sh944IH+yCOPIja8OPXZq+/155D7t+8E4GHLlybPmQSpPuwMBswlzg2dk+v37macvsg1LnWLpR/asQDAXsviCuJDO3tl9lqablH6tBCpX59Tc09j/ayly/35zYM7AHj4inFepUUW+p1Y0tCJsN+33noLW7dujZYep4eHAbcFn28HnqZPcs69FngtwBGPfCRXXrWRnf0rWlhYfEmWqwdGzlnav2r9OeS6O+4B4Pi1D0+eMwlSfbj3gR2Dv1futXTonO39F0Jf3zTI3cMS9/Uf6r2Dh/q2X90HwBEH7B0tc+ddDwCwdvXDin26/6HegL3vw0YfyZZnIdbPWrrcn2/dsAWAU44/qLm9GA8owVVD2O+Tn7Yued5khqMM3vvzgfMBTjxxnQd4y1d+BMCnXvz4ZDl9w3M/wLGH7Fs8J4XcqO07ey9l7ian6pcXHIYHMIAlqszO4Hjq4c0NEKkHUl8HjF5Lqkz4fap+fR0Aj1izMttfeclj16w/L8tI/5ZnYfnS+KAqA3JuMNGfY+3ItQrjvOQxoSfolz414KX6GWMccXMHcETw+fD+d4ZhzCDjSPbvAsc5546m95KfAby8pqBI9K/9+M7Bd89/7Nqhc2QEFYmSG73knDt+fT8Ah+3fkzh6xI6xWG/3ca9mOjLa3iIP9kdxUT3lekQNXrVy8WfS6qke8ZcuKat/WjqFfUrd55zGsyShobSopLlzJjEVikl0odTfnZHfV/+uKUkca0d/Dr9fktAqcp9zWktI55fde7/DOfcm4BvAUuDvvPc/7lqfYRi7lrHm7N77rwNfn1BfDMPYhexyA12OUHUXq+YTD18NwKq9lwOL6lDOaCLfifoeQ1Tt1LQgZ/jQVmXdl5whLUfJciztabW7tn45R08TUqporg4hpvKnLOotFmUhXNlY0e9napoQQ/8Wm+/u/XYHrxpeEQjvqZRJGcMWKoxhOWNoiwGw1tgW1llS34XprwcZhrFbmKpkDxGJvuWeB4FFyR6TuCXGWU+OERrISvVqKZwz2K1Q0kCMPIvt9I7Hlr1qrk0kkixHdbkvufVv3RfRVLSvQQvh0uEKde+6+C7s13+OBvVnysr9F4ecwXU9tPi7rOqXS11b7B6X+h3TJkvGzZrlUo1JdsOYE6Yi2WMjkUhy+f+NX7oGWFymi41aqflkzEmhi4aQWtLQy4K/2Hb/4Jg4mqRG2dx1dBnFc3PqkuSrkbyhw1CJAx6+IlpvjSORfF6zz14j9cr9ztlIUuh7miubuv+rAu0gJUXvvm87sPishNdc0o5iv6/0pUaL2R1ONYZh7EFMRbLXSGmR6C+54DsA/P0fPgUYtlynRrTYKFgaIWPHUyOxnCNlUr7hte13mf+VyoZtLlEaj8yLa/zH5dyFhfLKQ2puWmN1brGw7yr0MxjTEKUvovWJXWGVsg2EyHPUIqVL8/vUO5TTW02yG8acMDPW+IHlWI1k//BHJwLw5WtuB+APnvTIwbEWa69IKL3GnKujFG11z/29eZrMVWHRiioW8C7zTKHm+lJSNdamzB110EnOtVNfR66fUk9s9aDUf11XeKwmgKe1vZiLs3wnYbLyOaYBaWldQ80zIBqDtpWUJLocy90Rk+yGMSdMVbLHAgw0YpV8+VOOBODkD10+OHblOc8s1ivI6Jyyxse8ykrzylCi6/52oTagIden8D5qaSDSQrScmLTQ3oIt0rNke4idW6MxTJIq24BY/zNht7qM1hhC7SaV/yD2O9dY7FuOhZhkN4w5wV52w5gTpqrG59SPlLtgqLqLSq/V+RqVR1w7tctqjC7LIC3nCC1GGY12tYV0cIa44WpnFcinkNKU+tclxVIXclOvVF6EnCEwZ0grOTXFpoOp6VQM/ay1PAO29GYYBjAlyS6j11DQw/Lh4AmdSyw2wolEP+frPwHgQ897THUfdHs5N1rtSJFyn42VkeW5mBuoMInAndwyUYpxnVUWElIu9RvG+NVveoFPYuysca3NGU5TUjr3++p2UsvAMXT4cKxPqfZi6DYnaaQ0yW4Yc8JUJLuMXlvvfWjw3cGJxAFCbIQTiSoS/W+vvBmA1z396JEyLdIhhZ5r1Swf7bdyOAlHS5uxVM2pMi0SXfqyqb/Mlkv6kaM0r6y5p3r5cpyEDrFzW7QmHUhVEzSlbT4tGXtrqCm77be990ietRQm2Q1jTpiqNT5m+R3kP68IGtDH3nDyowB49Re+D8DfvmQxL31K8tVkf02V0Zb9WDstlnptvT7qoH1Gymi7QZfMq9LeoRWbN0xqpWGcMqmyOdfXlnZ0erBcHYMEF0viCTq0HSPX/5hrbBftSOxBJU3EJLthzAkzk7xCqJkHl+q74GVPAuAPPvfdwTkXnfnUqj7kAkmSIbUVVucYur6a9WgdxNJFkqXab62nti3J5w/pnP5dJH3uWWmpr5SLP2Tbb3urKwfvNxwgNEiM2g+iCWfP2rov2oH8lpOyuFsgjGEYgL3shjE3TEWNjxkxUsaFGqcUjdQbqu6yLCdGvFQkUkvOtZ1KPYNuBrMW1bkmT52Q2pJIq5XhvU85ieQYGFXV5pjyfWxpr+TWGvZTVONUXveWPtYYHHN90nsHaOOeGO5iEZ1SX266No4B84HtO8nZ6EyyG8acMFWnmpybqdAi0XOjojjanHnhDwC44IwnDZWJZR4pja6x46ktmmNxzoPsOcrAl8odF343sgQX2XJa/tYSPuWGCqNx/7lzhUVnlPK5KbIbeKrHZFct9aWWvXIOUS3GPf3cTyq3XpiRNneZJtkNY06YqlNNbmSrCfUTiTW6j9twCGd4TCT6sz72LQC++WenJPtUypqq+5q7pnhW2fj2vjUjvs5mKlI1Rss8P3Ust0wnpO5LLmtLLgy2yzJsqo4cJekfe+ZS2zprBylgsMOM3J+WHPA1mollqjEMY4iZyS6rSTm0DFk5JfPp8rJlV0tnkehPOHcDAD/84PqRPugRs0Vqp+rInZPSHMI6btx0LwDHHrpvsQ/jWnYhbzku1VvTpxpHopI0belTjJyLqyblQNXFQarLbi/j/KYm2Q1jTpiKZM9JDT3ayTrmkogkKGWKzdUriEQ/719uAuCsZxwzUraUv3zcQIyWfOtaoqfqCvslfZD9yPbu+xLU7HuWSuuUaztnwU+Vz1r7XVxzG2ef+ZBUPWFyFUE/s+OkkdLus2H9NVqeZvuOBUtLZRjGtNbZI/MevQumkEoOAN3WcTff3UvYcPCqYU8okejvv/SGQZlzTzuuqp1QIqckSGyk1rvHpL7PJe7Ijfx6rzJtwa/ZZURLH1lBiKE1iUkF5aT6lCtbqj/mTzG6AhFfLQnpssOQ9lKMabhd1uCXL1syXiCMc+4I59zlzrlrnXM/ds6d1f9+f+fcpc65n/b/X9PcO8Mwdhs1w8cO4O3e+xOAk4A3OudOAM4GLvPeHwdc1v9sGMaMUlTjvfd3Anf2//6Nc+464DDgdODU/mmfB64A3l3TaEzV0SqmDjAQcvm4a7ZFFvU91Zf3POf4wd+H/8mFANz+2TOy1yE5wGAxD5iuN2Z8Szu7lJdtSltPx9pM5eGrWcKqCd6o6VPqnJwxbxynmpR63SWzT66+muW7lIttrr+TyDwsNE0MnHNHAU8GrgIO6Q8EAJuAQxJlXuuc2+ic27hl65YxumoYxjhUG+icc/sCXwLe6r2/xwXLId5775yLWjG89+cD5wOceOK6pKVDb26fGv1yI1zNaF3KkBIeF4l+zFu+AsBNf/OioXOkbBisM8hYUmGsKo3aOU2li8RqcVVtQepNaWM1v0uNgS53bi1dHHFqjMK5ZcAuhsrSs9GlnSrJ7pxbTu9F/4L3/sv9r3/pnFvbP74W2FxTl2EY06Eo2V1PhF8AXOe9/1hw6BLgVcCH+/9fXNtozJ1VltxSklGIjbIyZ24Jh63ZyUPaEon+4ct+CsDZ/SW5GCM5ySpCQ1PknGy0nUIneAiJ3e/UuS1ozSO1b15ul5fc7itdJPg4+wPoJByxJeKUZpgLhJE/dUBMjtK162VV6XfOv6hGjT8ZeCVwjXPuB/3vzqX3kn/ROXcmcCvw0oq6DMOYEjXW+P8HybX607o0Ok7gSOx4aSeMWPmatEu6LZHoJSt9ro4cWlJq6R0eE0RaL19Sn1+/RutIzb9z9daEiAot+6lpalZdZA+5wY48Gc1Hl61ZDUmVFXbVzrXZlY8dC7jM42busoYxJ0w1xLXGyikSRk7V7rS5sl36UlOXSPSj3/glAH72qRdX15O75l0VQiu0BLXo9FS59koJJ2Plu+x1L6TKhuX1HnLL1bmx4CVNLlR6nN+5CzX3Z2x3WcMwfjeYuR1hhBoLu1g8d+yMJ42sCRkVaoJN9GeR6GKlh1FLfct6+2h6rVEPt3GkRI1E17Scq+ep0RRNiflwS+hsTdmSRlJjK4itnae8NkWrEY0o1BxS6dBr3oNJ+UKASXbDmBvsZTeMOWFmctBp1VuWTHJZSQZZPdxwRpFJ5WPT04CUYShU3T96xY0AvO2UY4bay7VfWobq4moLo3n5RdUU12RRK3Mq7SQCMWLZhWqCl4SWPGyp+vU0KracqadTg00aA+ea0nQglnUoNRXNTR1jmZli7ZTqCzHJbhhzwlQke2wEShnBatwda4wt2r0wlbkkl+NcSIUhArzj1GMB+NqPewGBz3/s2uS58t0SdazG4USkdEs2FTF66jDfcZHr0Pvl5bSY0hJciHZfFVfnFctH20mFFuvfLGe81Q44NQZGqS+2M0+yncwyoNZIcr9vrdZlkt0w5oSZmbMLLTm99LJHbKTX9Qp6SaNlWapG2xCJrneeqQmIqemDlhy3br0PgEcdvE+yHi3Ru8yXc8QcnjQlZ5p4e8NaXssOs0JLfjx9b1uWvUT7yCURqVkG1BI+93yGUt+yyxqGMbtONTVuiDL6ldIvhaScFHQCBliUICUJGPZJzy9FosfCY1PZZWvmfbpPoUTX/ZL6xPlIEoTEVjhKtowa5xddVyyXfcomU9OXLimlatpJhd+GtKyY1BxLkQp4KeXiN3dZwzBmxxo/TtncqK0prVvG5oOplEMxqaF3kJVjItHf+KVrBud+6sWPH6q3JcSyJQHCoE8u7kZc4ypcg94zPlZ/lxBmIbVik1szF61myz29kNcjDth7pJ2U3WDSz2nqnJiWoW0Mt2z5LQBHHTSqwdVikt0w5gR72Q1jTpiZpbeWTQeFLq6cqW2mpA45Dou57FuMVILuv9QrqjssGu3e+cyeI07NBoWamqXJQTabBpW8xtlFty2/3ThoF18YdYzRfctlrJEpjKjvLds0dXVTLlGz3KinWjX937ngbenNMIwZWnpLOWTUZGeVc+5/aGeyLjlnxfL8+KZ3poHFUbbkchuic7jF+iQS/YN9CS+70XSRHrEyJUkeM6jlXIF1/frcLtlndP0xd2VtkEstWcbaanEcSi3L1uxoo8ktIeaW+Er1l5b4bOnNMIzZmbOXQhKF3Nwx565ZWtbKjbIpp4scqRzqsT6JRD/zwl6m7vNf+sRi2VSGlBZy+fy0ZtISUpmTpoOtnxM51GNbKT+YCPusyUjUsr1zTFPQ1OTkK7VTM2dPaQOSNVfn2KvBJLthzAlTkew6PBPiQf/h9y3ONLlRVc/LJrlLZlif/hzb5VOfe8EZTwLgLzZcD8Bfrn80EJ8zirSrCT6RlQCxV9RcexdNQfcxRimoJPz99f5/WrOqSVLSsrNQCgl5hXx+/hI5W4PuV6pPItG75CU0yW4Yc8JUJLuM7pvvfmDwnYRflubDOWvwprt69R22/8pi27H6Yp+hvM5eM8rm5vu6jEj0b1y7CYBnHX/wSFul1YuwXr3CIOds7ruQrl09XjKLlJtsF8J7oQN2Yufkyte2Uyqb2/MtZcmP/Q5Sz6SDZmpdaU2yG8acMFVrfGxe2DKyaWl5aIWE6jJH1+u7Otglmz6qkGYrhrQjEv0/XfTDwTGZ16faLiU3CM+pkegpj8MQSUNVO1/OEfZV8q1L8tFJeFV2CX9eiEhpXb6kMeb61IWwLvGuK2GS3TDmBHvZDWNOmKoan3PTFLoELOglG0i7cuqsMGEm0VIusppMLy052UU11+2I6g7w/E//KwBfe/3TR9qOtR/7rkW9jrkPj1N/qb/h55LjSClrS83nsJ7UkmT4G6ZUfSkjmW/DKWrK6Jxz7xZS0zVbejMMI8nMuctOwsiTC4QZzYGmRvPcbvaFvofoHOo6Nx2MSgHpky4bIhL9yhu3AnDysQcm+xVqKWHbNfcytTtKzCkmJ9U0pbaHcrT3fwu9M8skMsnEJGNK03owcGpKSWEpU2N01sunuUCblGZ4V38PAKh3nTXJbhhzQrVkd84tBTYCd3jvX+CcOxq4EDgAuBp4pff+oVwdQo0LrA6YyOXrqqm/FFgT24VFH0vlbgulkUgfGbUHrp0RqaqDZaSeGucUkejHv+0SAK776/8wUv842/zq+5WbueekWiuxPpetBmVagk/0vDz2TIzjjltj1ym1E0rzWu23RbKfBVwXfP4I8HHv/bHANuDMhroMw9jNVA3FzrnDgecD/xX4M+ecA54FvLx/yueB9wGfrqkvZxGVYympFJaVMEyRmjW7ZqRGymzoYyFffG6Xz5zFteSYkXOtlWM3fPyFwGjwTK6/OamUkhI65BVGU0ildjEJKe1jl5OIqb7Fdl/p4sijn70uiS9iobtd0pppu0EujDe8jkmkpfoE8C5A7uoBwF3ee9lR4XbgsFhB59xrnXMbnXMbt2zdUtmcYRiTpijZnXMvADZ77692zp3a2oD3/nzgfIATT1znIT5iFsMMI6N6ao4Yk4jaUlya79f0KTaX1yNxbv5dmmu1SCeR6I95x1cH3/3koy/o1G6Mlnz6uYQUJYleE4iU6keOluCTnETXElfOiQXApPqnQ13H0Sp1+dwvWqPGnwy80Dn3POBhwH7AecBq59yyvnQ/HLijoi7DMKZEcUj03p/jvT/ce38UcAbwTe/9K4DLgZf0T3sVcPEu66VhGGMzzlrJu4ELnXMfAL4PXFBbsCVKTGhZemvJvKKXWVocTmrUvJwxTB8TY14qjjsklek2VN0lL/1bfv/oXn1Ly/XmjF+psqV7Flu60mVz8f5CLNtPCX3fY4bGVN+E2GafLTn4df01S6K1brkwvISbM9A1veze+yuAK/p/3ww8taW8YRjTY2bcZVNGmC7x4Dl0VpUujic1fajZPFEf0+6TsVFcS6RcvW//t8cA8LLPbwTgojPjY3NOW0rlzA/LpYxWNYEqmtjSak2m3pr6oM7xR/92McNgl8Ctmn0HYsu5sTI1mXA15i5rGHPCzOwIk1rGGWT2rHAuyM37ZFRNLYXFMrJ0WQ5scYJI1aPvRUyylbaRhsV7JxL9hjt/A8Axh+ybLJMidj01y5ealPSP1SlSOHVPa0Jp9TMRC0gaaCY7h+0TD25PS9kWp5dBHySgZ0l5abKUizG2c869D+xgwafLmWQ3jDlhqnP22FxxxHrddz/MuRrq3HCxc2JzzhCR6F3CP4cku+zQsmz41tY4auSCclK09Peg/XrBExuu62WtXf97hw4dz7Wdy3uvpaWuI6y/ixU75aTTpa6cjUaO5fLulebqOW0jNc/OBdrUtC/frdxrKUsyIdom2Q1jTpiKZJdRaVsQgL9mn72i59ak45ER+c5+3viD+xIsZhPQ1LiOptbia9bzc2vyqT6IZKyxI6TmpmF/BbnHz3/sWgA+esWNALzj1GOLfYqxeB/ymVVjWlVNAJLWdIRx/DRqSOXZj5FbedDlU9K/ZZfYWP21eftNshvGnDDVOXtMmo8THJLLg95lXVRoWYtPhc7WJOzQWsCqDnPSmnBV+V4k+vpPXjk4tuFNJ2frv3HTvYO/jz103+g5ut3QclyTZFGokf6aLvP4FLn5saYl0EZTk7xCiO3+EmoiuZZMshvGnGAvu2HMCTO39FY6Vzajh8XNIFPkcsDvbmoMN11cgVMqeq4+vYwWqu77n/F3APz6wj+OtpNS3XN9CpnE5o85usTqp8hNuWr7EWOcLLylzRtzmGQ3jDlhqpK9ZeSU70vSHNpCCbtIglyYZKoeWV4JXTJXJLKb1CxHpc6tuY6cEUsk+pPf8w0AvvPe5wyVaVkmikm3QZBPJg99KzFtRmeD0cdDUuGk45D7Hbpk4a3ZErqESXbDmBNmbs6upWYXyTvOuTUjpg7QiGUSlV1E9K4usaAWvd9cKuFC2PZIHZG+jLMjzPff/1wArrrp1wA85cjVI/VrUhIybG+hQesSJ6kD9x1eoq1xmEndy9jzlMof13L/a6jJMa/RjmOCLGHC8B4Fk8guaxjGHs5UJHsuLDCVqGBSVtZSXvTh0MF4SiAdihqSyiqbs8brPOW6TG5H0JjjimZgfV8eDwHO3dN1R68B4JNX3gzAWc84Jnluqo8hJbfl0DVW3J5r+qnrqV3dCc8VK7l+BqPaWEMwTup+1GRBThHbB3DpEmdONYZhTEmyt7g0TmK9tKa+mrlYTV9aQhP1uZMKaRVqdtUB+Ma1mwZ/P/eEQ6PnikRf975LB8c2vu850fZy0lWCn7Sr9Di+BrF6aj+HpJ6BaLhqQ2BVi+t36TnMrQSVMMluGHOCveyGMSfMTHZZoRSv3ZUWo9SuYJLGpa71p9Cqe45QdV9z8jsB2HblfwPqcrRr9b1Ldp4ck3SXraHLvgMt9Wly6rstvRmGAUx56W2Sscelemu3Ct5VErgmk8k41PRJ359xfweR6Cd94DIAvv2fTxs6ntt1peU+a6ej1HnhuaVl01w9OoNMLJNri0t2Sx/EWabrfga29GYYxnQke8wBRPKtLV866khSSy4fWE2usPB4eE7LrjR6FxdxyBDN4p77tw/O3W/l8mh9tTnFQmr2QdMSvEai1wSuiET/wS13AfCko1Yn60sthcXysclzktrvTOfsi50rIdGrEzkOw/q0Q4u0H3NN7TI3T/1G4TWncjHmtLDwmbU5u2EY080uG6IzegqlfO+p+mqpmbd2cQJKaSbhyJ3a6bVGoo9jddY2gvAeaw1IPi+PlNVti0R/zDu+CgzvKCuknGp0+zl0uzlXYZHoNTni9G9W2kUI6gJthJR2WXPNOTtL2JbN2Q3DmL11dk1NvnW922cuQYGEedbkc9ft1IQmtrhG1toRauob7COWKdOSYbfmOlKumyLRn3DuBgB++MH1g2OpdfZSu610WeHQa9zy+8TSm6Xm+eO4VIf1ps4ZZwXLJLthzAkzL9lzpOZaMq/ZfM9icsrD9l85dE7LyF8arRcy89iW+mukXGrkF4kjlnxIh9lOysustGIiEv2Uv7pi8N233nVqtE85UvelJhd/C6m17fB7WTUSG5O+BzUrKYO9Cd3onH1Xev6ZZDeMOcFedsOYE6rUeOfcauCzwOPordv/MXA98I/AUcAtwEu999vG7dAkVExRi7TqHjIJlTYXg93FFbXkFgpl55mWbZWEO359/+BvuWep/t/2q/sGfx9xwN5Dx+Re6i2eQtX9dV/8IQCfeekTon1ryZo6jqGrhthUL7VELNTc/9TWzTWIk9ABD19ROHOU2lbPAzZ47x8DPBG4DjgbuMx7fxxwWf+zYRgzSnEYcs6tAk4BXg3gvX8IeMg5dzpwav+0zwNXAO8et0OTMFDs6jDHmjzjOUePcZh08BDkNSCNluYhcr9z0k0k+poXfRqAbV95fbSO0newaAwL87HJuXKsJIlzTEpzaHG3LpFz+y1R8+QcDWwBPuec+75z7rPOuX2AQ7z3d/bP2QQcEivsnHutc26jc27jlq1bOnfUMIzxqJmzLwOeArzZe3+Vc+48lMruvffOuehalvf+fOB8gBNPXDd0TpddLWJIfnHZsrmmri67gNQEerS4T2pqQjhbctyN06dxHH5yfZLvRKKf8T83AnDhq9cNHa9pM6dBdJHoLQ4+pb7FAnomQWqZVhg3EOZ24Hbv/VX9zxfRe/l/6ZxbC9D/f3Nlfw3DmAJFye693+Scu80592jv/fXAacC1/X+vAj7c///i2kZbLNU6l3qsjM4vXtNml+QAKYmek0aTsBuM64JZ6lNN/3M7zsScQ1J90t+JRD/9M98G4OLXnZS8jho2393T8mr2BCz1LUdq55+W4JYYN266Fyjvlpvqa+4Kaj3o3gx8wTm3F3Az8Bp6WsEXnXNnArcCL62syzCMKVD1snvvfwCsixw6LfJdkdioJ9bTFRJS2f9f5js1oa45Jjlvys3tWua44nq5917DgRea2M6pNdqRtla3BOkIOmAovPZUUomW+gWR6O+/9IbBd+eedtxQ+ZrklHr9Wbuv6qCpWP36+1ggzHL1nGq62qNEoqd+33FsKOZBZxhzgr3shjEnzEzU2wqltmtajHk1MfBdMsMKubILCVUz1rda9V3caMNzdfx67Lr00pTuQ829kJx5azIZX1Kx3V14+ymPGvx9zc/vBuDxj1wF1DnKjGSxUd3N5TxIkZtCTnppUpDfPGX0lCkg1OfFM8luGHPCVCR7zJAzkFRLRg1B4efcck6XJaoao4824KQkZOw7+V80lpyxbXAPlg5rOcsjY/KOnf36l5alTooaw5wY96occZaWjUklB5/QcHb82p6x6nGDhgwAABKxSURBVNs3/wqApx61f/Z6YoiWkXqewrZ1AE+O0v2oMdrGDIOx+xCjJfOwYJLdMOaEqUj2uBSNzyNTn2vOCUfS1LEuWsE4jjMxm8RAgi+J34OYlBAbR67twbyvIaRy9N6V25Fjem7bJYNMWMf2vvYiEv2tF/8YgE+9+PHZOnJ9HNQdaFg6gEdrAaGU3RVz9Jb7JHXc1c/SC/XBMSbZDWNOmOqOMDnHg5ZRUNOSu60FvfdYyk00PEdL1ViOOJ2QosadteY6pO0u2ove56zm/tU4LrWEe+p5qUj0//29WwF4+VOOHOpbWJ+2xdyxrZegQ0J0c33NaQFdnFxK9z3Wf525V3/elckrDMPYw5mZHWG6nJM6N+cSqWmR+IsSshxEkwq0ia0Rl0JPw88tQUTjaDFd3ECrtI3CGn+Nj4RI9DX/5k0AbPvuJ0fO1drMUQftk2x3nFztNWHDpX0HYmW0r0LJOl+DSXbDmBNmxoOuC3oe02V3kZaEDpqWMjW7x3SRjMIkvNfCersEzbTQpR5dRiT68W+7ZPDdDR9/4dA5uZUNQZI4psJia4JacqHApTI19dfs0rtzwdsuroZh2MtuGHPDVNT4mKrTRY1OGS1iqmzJsNVluW4cI2JXUn2K3YvUuTr/XtfYa7mnW+/tOXhIDkDdfkiqfp1HsIVQdf/Dv78agH/4oxOz7YWUstrUuBXLOV0y1IT1S15+ncV3ElmFTbIbxpwwFck+qdznKQNXLHNsbZs1Uq4mM+2u2oq4RctInav7HTtPb2AYQ+5pShrnrvmWLb8FFpfEukj0mOYiEv2Yt3wFgJv+5kXJc3P1lMoILcbZmvpTeflr+5LrjUl2w5gTprr0Fko/cS+VdF9dsr8KubItub10UgaZF8fmusJgCUbt26ZdbcNjXZJK1KBdRoWadkSitzjxaGmt+xG2pc8RYvnWUy6wuT7d8In/CMDVP+ttP/iEI1YNHY8FSeml3Fz/Nbm+dVl609rjwEV7SfrZg/HzxhuG8TvAVJNXDI+u+RGrpb6cxEpJg5jTgvytR/pc8gohNS/+xbYHB9/J/Kwkabtay7UjySBJRsU97rILbWpX13FDgHU9t27tWawfdXBcOwjPFYn+P666BYA/fdpRyT7p37nFCt9yrv4+1PZSrtg14cOQzxtvkt0w5oSZmbPrua4e4XIW8HFcXoWcBNNSrmbnk5Q1O7cLao1LpFCjzeh7pufAOeQaZR4u/c6V1S67XSzfkhoKFpNFrlC2jUNX1Yd3yjW/4eReIkvZr++xh+83OEdrVtreEssb32VVJK0NRFKhueEyWuuI9amESXbDmBNmJsRVRu3UKCUJFslszqklY5e5bmzETCU6yGkSXRICtnj36WuNpTvW97JFcxBymshInyrMLSWJGLtv2sbQJdhH6pD9+p5w7obBsR9+cL3q2/DvUCM5u6zJ6wQhISVbSZfVKpPshjEn2MtuGHPCzMSzl9SWnHqngxBa3Fl1rricATDVboyWMl0Mi/p+RfPgFQyLOfSGiDXocyflHKQNWrrecHcUMYiWHHBEdQdY+5ovAHDn516RbWfSTMptvBaT7IYxJ8zMjjALStKKEUYbMWJOL3oEjklnLe0XpcXwsk5o6Cq51MYMLHrZRvc1RhfDmSbWF50ZVrv95vomUlruWy6TrqDdTVPLqGGfapxRcv2EfF6/mnsqEv0b124C4FnHHzx0PFwOTGk6Ne2kNM7c+9CSzXb7jgVzlzUMY8pz9piUjuWUh9HdUaFtzpPbiRMY7LMW0wpaMqE+uL13bs0oXpIGLbvS5pB2HtwxbJ+I1TuiAbnh3yWH1hhyNpOaeXFqqSol7WrK5IKXnnHMgQB879ae4826o9cAi7vv5KjZuSgV+BTrS4pc/Q/uWGDBp58Hk+yGMSdUSXbn3NuAP6EXQXcN8BpgLXAhcABwNfBK7/1DyUoCWqzYIpFFKoWjbEuwRmmH0ZzTTksSi8G+bRU7mg76lpA6XXLD56z9uk+x+6elcc7FVl9TbbBG7Tm1Ia25OvROubl7Ktf6tGN6e8u9/9IbADj7mccm+9biNitltJbUknhEiAXP7PuwZQNNLEbxaXLOHQa8BVjnvX8csBQ4A/gI8HHv/bHANuDMUl2GYUyP2jn7MmClc247sDdwJ/As4OX9458H3gd8umtHtMVYLLoyEsfmjKVEAi1r2isi0rU0usbmpKnEFi2WaV025sIruc5lz69YX/XOOLLXekugTa7fup771P7mNf4OOeRZEGu4XGvL+rfuQ8x/YFCfCj55z3OOBxaDgSAdENQl9DhH6pmQ36Nkg4pRlOze+zuAjwI/p/eS301Pbb/Ley+7FN4OHBYr75x7rXNuo3Nu45atW5o7aBjGZKhR49cApwNHA48A9gHWZwsFeO/P996v896vO+jAgzp31DCM8ahR458N/Mx7vwXAOfdl4GRgtXNuWV+6Hw7cMU5HdFaYlkwgKW7evKh+HXngsPrVxRjWgu5vzZJeSj0Ny4pqnlJpw+saZyso7XRUg3ZuaSkbQ/qvHaxq3KLlPuhjMaeY0jMW5stb/8krAdjwppOHzsk5f+l2ZCohKvmaffZKnjvax+73tOYJ/zlwknNub+ecA04DrgUuB17SP+dVwMWde2EYxi6nOPR7769yzl0EfA/YAXwfOB/4GnChc+4D/e8umGTHtEtqi+SVsiLNIe2SOumgh5Z6uvSllCdtUoE2NZTcWVsMpTW/sz5W47QzDrH+i0Rf8+z3A7B5w59H+5arLxdcVPu8d8nVUKXnee/fC7xXfX0z8NSqVgzDmDozE+KaoibHeepY+FkvVWhJn1timgQtgR+TlsC6Pr381DV77ab+/myH7b8yejy3FfKIW+vOdg0uRpfQ3BS5e7Htn98DwF9suB6A9/6744tlau5tat+8XF2hvcACYQzDmF3JrrOz1uSVq7GIChL4IvbjmrDYFOEuJilNpEWi5yzsKdfRXD4zPS/WEj3sW8u+ZCmJLufupxJJxPqUyp5aQ6xPuWtrqSf1vf7uL9c/GoC3X3ItAH/1gt8bqX+gNVaECWuJntqlJiSsL3e1JtkNY06YWcme2j00t36ZkvRQtuTGJKN2fU1J3iWRkV/bAGL1l4IoYpbZwdxWlakKBkrku49pDl3sBjpwJZZ3XaRbF41HUzM/7pJCrKZ+jUj09f+9tw5/6Vm/H9QT3wMhhn4uU34nXTDJbhhzwsxK9i6JCkplQ7TVtkYypubwsYQaeu+6XP2p64iV0W3LdSxb2peUQYhjyn7QxTux5RzdTk3iz5zGlkrQMalVi3F8I/T3G97cW4d//qf/dXDsktedNHROS2CQDniKEd4fs8YbhmEvu2HMCzOjxo+ommpprKWOQVx1xhimtbGaDJ8LC/GlmZ1B3q+W/paomY7o2PGavGY5A+CkHXqgu9OOLtPFSLUrrieGnuL9058+bXDshZ/5NgBfe/3TgfoMPACrI0EymvAabenNMIzZkewavWyj86eF6BE/tWwXksqdHi7XaQeV1NJVLvtMC1Lmnvt7DkUS+phbQtRGsLDdzff0jDurVvZ+5sHWx4nc9rk+CZOWqi31dVkWrOl/yZkmd/8FfS/D80SiS067d556TLRM2HZJ6ouzDdQ7JJlkN4w5Yao7wizNzKm3qxznescYWBzRSktwUL8M1SUQI+cOWlNOj+I6mUHYJ63ppAJKYNH1cjQLbCbA47cPDfVhnDmvdjCC7vnooPwbht+lPo/Trm4rVn/MvVXKnHvacQC84aJrAPj46SeMnFu7HBqT5jsXvC29GYYxJcleMyLrYJYWySujazjnllm8brsmtLVkBe66S42+tprAG+1uqvtYswttLpf6fiuXV/dFo+uTdu99INCwEhpJC1I2FyQyjntprkwprLemPpHoH778JmAxmGZcli5xZo03DGNKkr0mbG8cciO9oC3pOUmWmt/n1sHFjVVytcfQ9eZWHITUnmtdJFhuTb5LEo9U38JEEl0s6SktJvf81MylU+hnIXx2SmG9epUnhvRBEl484dwNg2Oyb/yuSGRikt0w5gR72Q1jTpiKGr8ioh7VLpnEykwiaqnLklBMDdYZRCfRt5pzJpGZpbWMTGNkuS6Wa662HdliKczRnmo7V98dv74fGFW3a9T3lINSLFONINO1GkcujdQrqjssZrz56xee0FxfCZPshjEnTEWyx1wBUwa0mlG9JnfYOGjnl5xGsaDO1buXxOLNx8ls23Kt2qBYk7E351or9YhErzGCpdoUiS6SEtIZYnV+whAt0eWaJWvrwfulN8KUa31w+7CxLecuuyqTZ09o0UBFol9106+Bxe2jJ2HUNsluGHPCVCR7TRhmzSjYsluMrqclv3hKq9DOMJCe++dsAl3sBTX7xI3jCtxlCa5G6pQ0kJrfo2V+LNdcysMO6d+hiy0l1AZaAo8EkehrTjkHgG3f+lB12RQm2Q1jTpiZENcuedFSkqrGHVdLkJYdZ/T8rCVU9LZf3Tf4LmZ5rqVm9WISlvsWuuzLV0PJmSmmWelsvr/Y1rPSP2LNyqG6YvVPgiFX7SXd74dI9NP7CTAu7uezS9kILBDGMIzZkexdRtVx8oqnzo1ZXruETaY0lVCa69FZpM8RB+xNihYplHIB1mXDfewfdfA+0XbkswSCwKjlOxdgI0i21NWJENqYNpYKkhLC65PyOpBK7mnXcORWJl2nSPTz/qUXPHPWM46JnmeBMIZhTFeyj+sNl6ovN2cv1Z/zitM7webmpvdL0ssGTzqRPqn18LC8TjIRQwJrSnNpkeYhKW0mF9pZM2fP5T/X7WotQN/TUvlYn7p4DdaEMIcaYeq8SXg5ikQXTzuo97YzyW4Yc4K97IYxJ0xVjX8wWDLR+eRatl8W7uqrtjlVsSVDaY3LaKqMVjVzS2Nyrdr55cZN9wJw+AErgzK9Pmj1vWXjSEGWAXMGwZrfQZ/Tkhc9h/4dc7kBUtS4BqeIGQhTU8Waa2x59krnhKr7ZT/5JQCnPeaQbBmT7IYxJ0w1u2ztBvMp9OiqJUFsRK5ZHtKkJHpMmur2Un0OSWV4OfbQfYt9E2quQwJIVizvnSsOJjlqNKuSc1MOHeCRWxpbzGk3nAWoxhEqdTx2zp395cWYi23KcJkzqgqpnP9d+h8iEv2NX7qGW++6P3meSXbDmBOc93EJtEsac24L8Ftg625rdDwOZM/pK+xZ/d2T+gp7Tn+P9N4fFDuwW192AOfcRu/9ut3aaEf2pL7CntXfPamvsOf1N4ap8YYxJ9jLbhhzwjRe9vOn0GZX9qS+wp7V3z2pr7Dn9XeE3T5nNwxjOpgabxhzgr3shjEn7LaX3Tm33jl3vXPuRufc2bur3Vqcc0c45y53zl3rnPuxc+6s/vf7O+cudc79tP//mmn3VXDOLXXOfd8599X+56Odc1f17/E/OufS8a+7GefcaufcRc65nzjnrnPOPX1W761z7m39Z+BHzrn/45x72Czf21p2y8vunFsKfAr498AJwMucc5Pf8mI8dgBv996fAJwEvLHfx7OBy7z3xwGX9T/PCmcB1wWfPwJ83Ht/LLANOHMqvYpzHrDBe/8Y4In0+j1z99Y5dxjwFmCd9/5xwFLgDGb73tbhvd/l/4CnA98IPp8DnLM72h6jzxcDzwGuB9b2v1sLXD/tvvX7cji9F+RZwFfpZSTaCiyL3fMp93UV8DP6BuHg+5m7t8BhwG3A/vRiR74KPHdW723Lv92lxssNFG7vfzeTOOeOAp4MXAUc4r2/s39oE5CPI9x9fAJ4FyApUg4A7vLey5Yqs3SPjwa2AJ/rTzs+65zbhxm8t977O4CPAj8H7gTuBq5mdu9tNWagUzjn9gW+BLzVe39PeMz3hvWpr1U6514AbPbeXz3tvlSyDHgK8Gnv/ZPpxUcMqewzdG/XAKfTG6AeAewDrM8W2kPYXS/7HcARwefD+9/NFM655fRe9C9477/c//qXzrm1/eNrgc3T6l/AycALnXO3ABfSU+XPA1Y75yRueJbu8e3A7d77q/qfL6L38s/ivX028DPv/Rbv/Xbgy/Tu96ze22p218v+XeC4vkVzL3oGj0t2U9tVOOcccAFwnff+Y8GhS4BX9f9+Fb25/FTx3p/jvT/ce38UvXv5Te/9K4DLgZf0T5uJvgJ47zcBtznnHt3/6jTgWmbw3tJT309yzu3dfyakrzN5b5vYjYaP5wE3ADcBfz5tY0Wkf79PT438IfCD/r/n0ZsLXwb8FPhnYP9p91X1+1Tgq/2/HwV8B7gR+L/Aimn3L+jnk4CN/fv7T8CaWb23wH8BfgL8CPhfwIpZvre1/8xd1jDmBDPQGcacYC+7YcwJ9rIbxpxgL7thzAn2shvGnGAvu2HMCfayG8ac8P8Byz2vs2HtjKMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdXyhojz73ba"
      },
      "source": [
        "###INCREMENTAL with catastrophic forgetting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFYYN4dYzKf"
      },
      "source": [
        "#### training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8z0BUyK9tt"
      },
      "source": [
        "# Each time we call training function we must pass a different trainloader, updated with the following 10 classes\n",
        "def training(trainloader, iteration, network, device, epochs):\n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(10)\n",
        "    network.to(device)\n",
        "\n",
        "  # add the output neurons to the optimizer\n",
        "  optimizer = optim.SGD(network.parameters(), lr = lr, weight_decay=decay,momentum= momentum)\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # divide by 5 learning rate after 49 and 63 epoch\n",
        "    #if(epoch == 49 or epoch == 63):\n",
        "    #  optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / factor\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of  [input,labels]\n",
        "    \n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "\n",
        "      # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      # forward: assign weights to each edge in each layer\n",
        "      outputs = network.forward(inputs) \n",
        "\n",
        "      # calculate the loss \n",
        "      loss = nn.CrossEntropyLoss(ignore_index=0)(outputs,labels) \n",
        "\n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward() \n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()  \n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if i % 20 == 19:    # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9vHvoVoY4XR"
      },
      "source": [
        "####test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmbA81iYSSSc"
      },
      "source": [
        "def test(testloader, iteration, network, acc):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          # if(iteration == 9):\n",
        "          #   for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          #     confusion_matrix[t.long(),p.long()] += 1\n",
        "         \n",
        "  # if(iteration == 9):          \n",
        "  #   plt.figure()\n",
        "  #   plt.imshow(confusion_matrix,interpolation=\"nearest\",cmap=plt.cm.Blues)\n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BBkS-svY697"
      },
      "source": [
        "#### train execution NOT RANDOMIZED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDn00aWqQ2FM"
      },
      "source": [
        "# #NOT RANDOMIZED\n",
        "\n",
        "# # divided our dataset into sample of 10 classes each\n",
        "# # train the network on the first 10 classes\n",
        "# # evaluate the network on the first 10 classes\n",
        "# # train the network on the second 10 classes (adding 10 output layers)\n",
        "# # evaluate the network on the first 20 classes\n",
        "# iterations = 10\n",
        "# num_classes = 10\n",
        "# test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "# acc = []\n",
        "# for i in range(iterations):\n",
        "#   classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "#   train_iter = []\n",
        "#   for j in range(len(trainset)):\n",
        "#     if(trainset[j][-1] in classes_current_iter):\n",
        "#       test_set.append(trainset[j]) \n",
        "#       train_iter.append(trainset[j])\n",
        "\n",
        "\n",
        "#   train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "#   valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "#   print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "#   training(train_loader, i, net, device, epochs) # Train the network with 10 classes at a time\n",
        "#   print(\"Length train_loader: \", len(train_loader))\n",
        "#   print(\"Length valid_loader: \", len(valid_loader))\n",
        "#   test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\n",
        "\n",
        "#   # train loader contains at each iteration the new 10 classes used to evaluate the network, while valid loader contains all classes seen so far"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndz6rDT6Ts4Z"
      },
      "source": [
        "#### train execution RANDOMIZED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZZY4nY4GD3"
      },
      "source": [
        "import random\n",
        "indices = list(range(0,100))\n",
        "random.shuffle(indices)\n",
        "dict_classes = dict(zip(indices,range(100)))\n",
        "for i in range(len(trainset)):\n",
        "  trainset[i][1] = dict_classes[trainset[i][1]]\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9c_Sfsop3wQ",
        "outputId": "7691446a-a3c6-4079-a7a7-f3f3e5c10c2f"
      },
      "source": [
        "#TRYING TO RANDOMIZE CLASSES\n",
        "\n",
        "\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "#import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  #classes_current_iter = dict(zip(indices[i*num_classes : i*num_classes+num_classes],range(i*num_classes,i*num_classes+num_classes)))\n",
        "  # print(classes_current_iter)\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    #if(trainset[j][-1] in classes_current_iter.keys()):\n",
        "      #trainset[j][-1] = classes_current_iter[trainset[j][-1]]\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  \n",
        "  # Train the network with 10 classes at a time\n",
        "  net = training(train_loader, i, net, device, epochs) \n",
        "\n",
        "   # Test the network with all classes seen until this iteration\n",
        "  test(valid_loader, i, net, acc)\n",
        "\n",
        "  # train loader contains at each iteration the new 10 classes used to evaluate the network, while valid loader contains all classes seen so far\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "[1,    20] loss: 2.112\n",
            "[1,    40] loss: 1.768\n",
            "[2,    20] loss: 1.602\n",
            "[2,    40] loss: 1.460\n",
            "[3,    20] loss: 1.420\n",
            "[3,    40] loss: 1.388\n",
            "[4,    20] loss: 1.297\n",
            "[4,    40] loss: 1.245\n",
            "[5,    20] loss: 1.208\n",
            "[5,    40] loss: 1.199\n",
            "[6,    20] loss: 1.181\n",
            "[6,    40] loss: 1.087\n",
            "[7,    20] loss: 1.057\n",
            "[7,    40] loss: 0.988\n",
            "[8,    20] loss: 0.965\n",
            "[8,    40] loss: 0.917\n",
            "[9,    20] loss: 0.919\n",
            "[9,    40] loss: 0.877\n",
            "[10,    20] loss: 0.852\n",
            "[10,    40] loss: 0.904\n",
            "[11,    20] loss: 0.938\n",
            "[11,    40] loss: 0.875\n",
            "[12,    20] loss: 0.759\n",
            "[12,    40] loss: 0.765\n",
            "[13,    20] loss: 0.736\n",
            "[13,    40] loss: 0.693\n",
            "[14,    20] loss: 0.605\n",
            "[14,    40] loss: 0.615\n",
            "[15,    20] loss: 0.551\n",
            "[15,    40] loss: 0.576\n",
            "[16,    20] loss: 0.635\n",
            "[16,    40] loss: 0.630\n",
            "[17,    20] loss: 0.643\n",
            "[17,    40] loss: 0.585\n",
            "[18,    20] loss: 0.653\n",
            "[18,    40] loss: 0.585\n",
            "[19,    20] loss: 0.553\n",
            "[19,    40] loss: 0.440\n",
            "[20,    20] loss: 0.338\n",
            "[20,    40] loss: 0.331\n",
            "[21,    20] loss: 0.268\n",
            "[21,    40] loss: 0.231\n",
            "[22,    20] loss: 0.221\n",
            "[22,    40] loss: 0.237\n",
            "[23,    20] loss: 0.345\n",
            "[23,    40] loss: 0.394\n",
            "[24,    20] loss: 0.536\n",
            "[24,    40] loss: 0.429\n",
            "[25,    20] loss: 0.382\n",
            "[25,    40] loss: 0.340\n",
            "[26,    20] loss: 0.676\n",
            "[26,    40] loss: 0.549\n",
            "[27,    20] loss: 0.435\n",
            "[27,    40] loss: 0.357\n",
            "[28,    20] loss: 0.473\n",
            "[28,    40] loss: 0.386\n",
            "[29,    20] loss: 0.260\n",
            "[29,    40] loss: 0.192\n",
            "[30,    20] loss: 0.187\n",
            "[30,    40] loss: 0.134\n",
            "[31,    20] loss: 0.088\n",
            "[31,    40] loss: 0.086\n",
            "[32,    20] loss: 0.179\n",
            "[32,    40] loss: 0.128\n",
            "[33,    20] loss: 0.160\n",
            "[33,    40] loss: 0.114\n",
            "[34,    20] loss: 0.047\n",
            "[34,    40] loss: 0.050\n",
            "[35,    20] loss: 0.077\n",
            "[35,    40] loss: 0.096\n",
            "[36,    20] loss: 0.513\n",
            "[36,    40] loss: 0.377\n",
            "[37,    20] loss: 0.421\n",
            "[37,    40] loss: 0.286\n",
            "[38,    20] loss: 0.153\n",
            "[38,    40] loss: 0.131\n",
            "[39,    20] loss: 0.111\n",
            "[39,    40] loss: 0.076\n",
            "[40,    20] loss: 0.127\n",
            "[40,    40] loss: 0.071\n",
            "[41,    20] loss: 0.066\n",
            "[41,    40] loss: 0.064\n",
            "[42,    20] loss: 0.149\n",
            "[42,    40] loss: 0.149\n",
            "[43,    20] loss: 0.432\n",
            "[43,    40] loss: 0.301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLE5LnQkZXSI"
      },
      "source": [
        "#### confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw2RugH6WcEv"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in valid_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net.forward(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he3I4t3Yc1_o"
      },
      "source": [
        "x = [10,20,30,40,50,60,70,80,90,100]\n",
        "plt.plot(x,acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}