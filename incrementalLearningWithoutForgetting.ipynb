{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incrementalLearningWithoutForgetting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gzrd6SoDNp6d",
        "QObN0rGNN2Be"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/incrementalLearningWithoutForgetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUHNE0YdXMlR"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "from torch.nn.init import xavier_uniform_ \n",
        "from torch.nn.init import kaiming_uniform_"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UivF_HGCTWYe"
      },
      "source": [
        "### DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QleCp90XDa2a",
        "outputId": "f2e579c9-601a-41de-ff75-66faf788cbb2"
      },
      "source": [
        "# we build a transform to normalize images: Data normalization is an important step which ensures \n",
        "# each input parameter (pixel, in this case) has a similar data distribution. This makes convergence \n",
        "# faster while training the network.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 128\n",
        "\n",
        "trainset_raw = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "for i in range(len(trainset_raw)):\n",
        "  if(i==0):\n",
        "    trainset = [[trainset_raw[i][0], trainset_raw[i][1]]]\n",
        "  else:\n",
        "    trainset.append([trainset_raw[i][0], trainset_raw[i][1]])\n",
        "\n",
        "\n",
        "# DataLoader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "# batch_size = how many samples per batch to load\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXdZrK0zNwvw"
      },
      "source": [
        "### NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kAHBaHJ4Td1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def addOutputNodes(self, num_new_outputs):\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "\n",
        "        self.fc = nn.Linear(in_features, out_features + num_new_outputs)\n",
        "\n",
        "        #xavier initialization\n",
        "        xavier_uniform_(self.fc.weight)\n",
        "        \n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        \n",
        "\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1JeZ9NB4ZxS",
        "outputId": "95276996-5735-4620-b7ff-0fb0c26c009d"
      },
      "source": [
        "net = resnet32()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QObN0rGNN2Be"
      },
      "source": [
        "### LOSS & PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUMJGDLO4cR-"
      },
      "source": [
        "lr = 1\n",
        "decay = 0.0001\n",
        "epochs = 30\n",
        "momentum = 0.9\n",
        "factor = 5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLf5BCR-4c3X"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "bceLoss = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te6KvRNKN5k_"
      },
      "source": [
        "### TRAINING BCE LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BsI39t38kM"
      },
      "source": [
        "def training(trainloader, iteration, network, device, epochs, num_classes):\n",
        "  num_classes_till_previous_step = iteration * num_classes\n",
        "  num_current_classes = num_classes_till_previous_step + num_classes\n",
        "  total_classes = 100\n",
        "  distillation_loss = 0\n",
        "  old_net = copy.deepcopy(network)\n",
        "  old_net.eval()\n",
        "  \n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(num_classes)\n",
        "    network.to(device)\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)\n",
        "  print(\"before training: \", network.fc.weight.data)\n",
        " \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "    if (epoch == 49 or epoch == 63):\n",
        "      optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / factor\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      logits = network(inputs)\n",
        "      distilled_targets = get_one_hot(labels, num_current_classes, device)\n",
        "      \n",
        "      if iteration > 0:\n",
        "        logits_old = old_net(inputs)\n",
        "        distilled_targets[:, 0:num_classes_till_previous_step] = torch.sigmoid(logits_old)\n",
        "\n",
        "      loss = bceLoss(logits, distilled_targets) * (num_current_classes / total_classes)\n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward()\n",
        "      # update parameters\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      if i % 20 == 19:    \n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0\n",
        "\n",
        "  return network"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrwsyMN3_dO"
      },
      "source": [
        "def get_one_hot(target,num_class, device):\n",
        "  one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "  one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "  return one_hot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHr8sBA_N-zJ"
      },
      "source": [
        "### TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefaruFe3_DP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "546a2909-3c73-42b8-ff9b-cef46bebaa7e"
      },
      "source": [
        "\"\"\"\n",
        "def test(testloader, iteration, network, acc):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "         \n",
        "        \n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))\n",
        "  \"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef test(testloader, iteration, network, acc):\\n\\n  correct = 0\\n  total = 0\\n  print(\"ITERATION: \", iteration)\\n  \\n  # since we\\'re not training, we don\\'t need to calculate the gradients for our outputs\\n  with torch.no_grad():\\n      for data in testloader:\\n          images, labels = data[0].to(device), data[1].to(device)\\n\\n          # calculate outputs by running images through the network\\n          outputs = network.forward(images)\\n\\n          # the class with the highest energy is what we choose as prediction\\n          _, predicted = torch.max(outputs.data, 1)\\n          total += labels.size(0)\\n          correct += (predicted == labels).sum().item()\\n         \\n        \\n  acc.append(100*correct/total)\\n  print(f\\'Accuracy of the network on the {iteration} iteration: %d %%\\' % (100 * correct / total))\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LxjrgyTOBWN"
      },
      "source": [
        "### EXECUTION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bLZetGa4F_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2357016e-6298-418e-e2ee-276a4615fc9b"
      },
      "source": [
        "\"\"\"\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations= 10 \n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = [] \n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\n",
        "\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\n",
        "  \"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# divided our dataset into sample of 10 classes each\\n# train the network on the first 10 classes\\n# evaluate the network on the first 10 classes\\n# train the network on the second 10 classes (adding 10 output layers)\\n# evaluate the network on the first 20 classes\\niterations= 10 \\nnum_classes = 10\\ntest_set = [] #initialized here because we test over all the classes not only those one in which I train\\nacc = []\\nimport random\\n#indices = list(range(0,100))\\n#random.shuffle(indices)\\nfor i in range(iterations):\\n  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\\n  train_iter = [] \\n  for j in range(len(trainset)):\\n    if(trainset[j][-1] in classes_current_iter):\\n      test_set.append(trainset[j]) \\n      train_iter.append(trainset[j])\\n\\n\\n  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\\n  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \\n  training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\\n\\n  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQZSybAOH9C"
      },
      "source": [
        "### CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXP0RxiQ50mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a223a7ba-adf3-4d42-8b37-b57c8b313e40"
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in valid_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net.forward(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sklearn.metrics import plot_confusion_matrix\\nimport matplotlib.pyplot as plt\\n\\nconfusion_matrix = torch.zeros(100,100)\\n\\ncorrect = 0\\ntotal = 0\\n# since we\\'re not training, we don\\'t need to calculate the gradients for our outputs\\nwith torch.no_grad():\\n    for data in valid_loader:\\n        images, labels = data[0].to(device), data[1].to(device)\\n        # calculate outputs by running images through the network\\n        outputs = net.forward(images)\\n        # the class with the highest energy is what we choose as prediction\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\n        for t, p in zip(labels.view(-1), predicted.view(-1)):\\n          confusion_matrix[t.long(),p.long()] += 1\\n\\nplt.figure()\\nplt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\\nprint(\\'Accuracy of the network on the 10000 test images: %d %%\\' % (100 * correct / total))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TckH9XhBXBQb"
      },
      "source": [
        "### TEST (CONFUSION EACH STEP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO7gpTu1XLl-"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test(testloader, iteration, network, acc):\n",
        "  confusion_matrix = torch.zeros(iteration*10+10,iteration*10+10)\n",
        "  print(\"confusion matrix shape: \", confusion_matrix.shape)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "         \n",
        "          for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "            confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.plasma)\n",
        "  plt.show()\n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kxkDFX6DXo6"
      },
      "source": [
        "### RANDOM CLASSES\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jU3qySqDivk"
      },
      "source": [
        "EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKHoN8W9EJBw"
      },
      "source": [
        "import random\n",
        "indices = list(range(0,100))\n",
        "random.shuffle(indices)\n",
        "dict_classes = dict(zip(indices,range(100)))\n",
        "for i in range(len(trainset)):\n",
        "  trainset[i][1] = dict_classes[trainset[i][1]]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INaUfRGBDkPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53fce319-d25b-4326-800f-08697346cf3b"
      },
      "source": [
        "#TRYING TO RANDOMIZE CLASSES\n",
        "\n",
        "\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "#import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  #classes_current_iter = dict(zip(indices[i*num_classes : i*num_classes+num_classes],range(i*num_classes,i*num_classes+num_classes)))\n",
        "  # print(classes_current_iter)\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  #print(\"before training: \", net.fc.weight.data)\n",
        "  net = training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\n",
        "  print(\"after training: \", net.fc.weight.data)\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "before training:  tensor([[-6.3498e-02,  1.1210e-01, -1.3788e-02,  3.1274e-02, -4.6851e-02,\n",
            "         -4.2628e-03, -1.1135e-01,  1.2012e-01, -1.2710e-02,  7.8863e-02,\n",
            "          1.1938e-01, -9.0784e-02, -5.6986e-02, -4.2646e-02, -1.0545e-01,\n",
            "          2.1907e-02,  4.0610e-02, -6.2379e-02, -7.9124e-02,  1.0167e-01,\n",
            "          1.2095e-01, -8.9677e-02, -1.7733e-02, -3.4623e-02,  1.0746e-01,\n",
            "         -1.8046e-02, -1.1626e-01,  3.2486e-02,  1.2122e-01, -4.0854e-02,\n",
            "          6.6082e-02, -8.9463e-02,  6.9276e-03,  1.8394e-02,  7.7426e-02,\n",
            "          8.8702e-02, -8.0552e-02, -7.2759e-02,  4.1806e-02, -1.3864e-02,\n",
            "         -2.2892e-02, -4.0852e-02,  1.0024e-01, -1.6392e-02,  7.2795e-02,\n",
            "          7.1492e-02, -1.5284e-02,  7.2415e-02,  5.0230e-02, -1.0281e-01,\n",
            "          4.7741e-02, -9.7248e-02,  2.3327e-02, -1.8383e-02, -1.0437e-01,\n",
            "          2.5343e-02, -5.3377e-02,  6.2465e-02, -1.6827e-02,  1.2006e-01,\n",
            "         -3.5766e-02, -2.7988e-02,  1.5256e-02,  1.9696e-02],\n",
            "        [-2.0701e-02, -3.2248e-02,  7.8453e-02, -8.7003e-02, -6.5191e-02,\n",
            "          6.8766e-02, -1.0186e-01,  9.2422e-02, -3.9835e-02, -1.8495e-02,\n",
            "         -3.4679e-02, -3.1113e-02,  5.8934e-02,  1.1819e-01,  5.8771e-02,\n",
            "         -1.0268e-01,  6.9779e-02, -2.1839e-02, -5.3370e-02,  2.2643e-02,\n",
            "          1.1815e-01, -9.2611e-02, -4.8138e-02,  1.6934e-02, -9.8498e-02,\n",
            "          7.6534e-02,  4.0092e-02,  3.9927e-02, -6.5127e-03,  5.2816e-03,\n",
            "          1.1673e-01,  5.2266e-02,  4.7690e-02, -1.1652e-02,  5.4190e-02,\n",
            "         -1.2052e-01,  4.2192e-03, -5.9953e-02, -8.0330e-02,  3.1561e-02,\n",
            "          4.4247e-02, -9.6589e-02,  4.1805e-02,  5.1267e-02,  8.2901e-02,\n",
            "          2.3510e-02,  2.2432e-02, -2.6805e-02,  6.4319e-02,  6.5154e-02,\n",
            "          4.1256e-02,  6.2544e-02, -8.5075e-02, -1.2042e-01, -7.1954e-02,\n",
            "         -8.6991e-02, -1.2063e-01, -5.6307e-02,  8.7284e-02, -1.0390e-01,\n",
            "          9.7905e-02, -5.9737e-02,  8.5912e-02,  3.8265e-02],\n",
            "        [-1.1659e-01, -8.3708e-02,  5.5779e-02,  1.0158e-01, -2.7838e-02,\n",
            "          4.7019e-02, -8.7826e-02, -1.1835e-01,  9.6097e-02, -5.7371e-02,\n",
            "          9.3314e-02,  2.4860e-03,  9.1797e-02, -1.0918e-01,  2.7916e-02,\n",
            "         -4.3135e-02,  1.2237e-03,  6.8279e-03, -1.7943e-02, -9.8228e-03,\n",
            "         -1.0200e-01, -1.2493e-01, -8.2341e-03, -4.4589e-02, -6.3111e-02,\n",
            "          5.2846e-02, -1.2333e-01, -2.7237e-02, -1.8409e-02, -9.8598e-02,\n",
            "         -1.1302e-02,  7.0277e-03, -4.1978e-03, -5.2760e-02,  4.5214e-02,\n",
            "          4.1030e-02, -1.0933e-01, -3.6789e-02, -4.3229e-02,  1.1876e-01,\n",
            "         -1.0310e-01,  5.9305e-02, -1.1164e-01,  3.3291e-02, -6.8347e-02,\n",
            "          9.2117e-02,  5.2316e-02, -1.0553e-01,  4.3413e-02,  9.0579e-02,\n",
            "         -1.9798e-02,  4.1839e-02, -2.7359e-02,  2.6249e-02, -4.6234e-02,\n",
            "         -1.2131e-01, -8.2718e-02,  1.7718e-02, -1.0299e-01,  8.6674e-02,\n",
            "          1.2185e-01, -2.4260e-02,  5.2773e-02,  9.0694e-02],\n",
            "        [ 4.4054e-02,  8.3493e-02,  1.9950e-02, -1.7211e-02,  8.5811e-02,\n",
            "         -3.5480e-02, -2.4387e-02,  5.8406e-02, -3.5287e-02,  8.1020e-02,\n",
            "          7.0743e-02, -4.3658e-02,  6.5044e-02,  1.0391e-01,  9.9869e-02,\n",
            "         -6.6923e-02,  8.2271e-02,  3.1395e-02,  1.2413e-01, -3.8050e-02,\n",
            "         -9.4777e-02,  4.4345e-02, -1.2231e-01,  4.4667e-02,  9.7268e-02,\n",
            "          2.9306e-02,  4.9063e-02, -1.1997e-01,  7.5569e-02, -1.7052e-02,\n",
            "          3.1778e-02, -7.3455e-02,  6.4169e-02, -9.5391e-02,  5.8863e-02,\n",
            "         -1.1690e-01, -1.6055e-02, -3.3286e-02, -7.6180e-02, -2.8564e-02,\n",
            "         -6.2472e-04,  6.9491e-02,  6.3557e-03, -9.9650e-03,  2.2664e-02,\n",
            "          6.3653e-03, -3.0039e-02,  9.2897e-02, -2.5737e-02, -7.4716e-03,\n",
            "         -1.4776e-03,  5.5155e-02, -3.4963e-02, -2.9000e-02, -4.9086e-02,\n",
            "         -5.4595e-02,  2.5175e-02,  1.2308e-01,  5.3772e-02,  1.0820e-01,\n",
            "         -7.9144e-02, -7.5038e-02, -5.1118e-04, -5.6314e-02],\n",
            "        [-5.5013e-02, -1.1204e-01, -3.8244e-02, -3.2491e-02, -1.4410e-02,\n",
            "          5.8368e-02, -6.4320e-02, -8.9110e-02,  8.5884e-02,  6.1768e-02,\n",
            "          1.1317e-01,  2.1311e-02, -1.0192e-01,  3.2818e-02, -2.9091e-02,\n",
            "         -8.4353e-02, -4.3970e-02,  1.8576e-02,  7.3602e-02, -7.1449e-02,\n",
            "         -1.0309e-02, -3.7137e-02,  1.9170e-02,  3.6524e-02, -1.1348e-01,\n",
            "          7.3790e-02,  9.1812e-02,  8.2020e-03,  2.0247e-02,  8.6634e-02,\n",
            "          8.2174e-02,  1.1366e-01,  3.5095e-02,  5.3082e-03, -2.9325e-02,\n",
            "         -7.9318e-02,  1.1059e-01,  8.3257e-02,  5.1417e-02,  8.2242e-02,\n",
            "         -8.3929e-02, -9.3698e-02,  7.7536e-02, -1.1282e-01, -9.4875e-02,\n",
            "          1.7266e-02, -1.1621e-01,  5.3333e-03, -7.3317e-02,  8.3086e-02,\n",
            "         -6.8864e-02,  5.2336e-02,  1.1628e-01, -9.8422e-02,  3.9030e-02,\n",
            "          8.9255e-03,  1.1082e-01,  3.9801e-02,  6.9840e-02,  1.1155e-01,\n",
            "          2.8041e-02,  3.8344e-02, -4.6734e-02, -1.5972e-02],\n",
            "        [ 3.3819e-02, -6.2816e-02, -6.8825e-02,  9.0897e-02,  1.0789e-01,\n",
            "          1.0192e-01, -9.7500e-02, -5.6004e-02, -3.8925e-02,  5.1533e-02,\n",
            "          4.1163e-02,  5.2714e-02,  9.3659e-02, -3.2795e-02,  1.1142e-02,\n",
            "         -2.8660e-02, -1.6829e-02,  5.1939e-02,  6.7734e-02, -2.4144e-02,\n",
            "         -3.1166e-02, -1.2446e-01,  5.6336e-02,  6.1933e-02,  9.2669e-02,\n",
            "          9.2001e-02, -4.6390e-03, -7.4247e-02,  6.6684e-02,  3.1711e-02,\n",
            "          1.2230e-01,  1.0181e-01,  2.6164e-02,  6.0721e-02, -2.1484e-02,\n",
            "          3.8851e-02, -6.1027e-02, -1.2041e-01, -3.7466e-02,  6.2618e-02,\n",
            "         -3.2605e-03,  1.0704e-01,  8.4356e-02, -3.1641e-02, -3.2258e-02,\n",
            "          1.0063e-02,  9.6083e-02, -1.4927e-02, -7.8160e-02, -6.6894e-02,\n",
            "          8.9424e-02,  1.1471e-01, -9.0116e-02, -7.8817e-02, -1.0410e-02,\n",
            "         -2.4484e-02,  4.9819e-02,  4.2076e-02, -5.0312e-02,  7.6019e-02,\n",
            "          7.4113e-02,  1.7113e-02,  2.2455e-02, -1.1369e-02],\n",
            "        [ 6.9204e-02,  2.4766e-02, -8.7863e-02,  9.9444e-02,  5.1485e-02,\n",
            "         -9.9476e-03,  6.2228e-02, -1.1161e-01,  1.1983e-02,  1.1941e-01,\n",
            "          6.7639e-02, -1.2561e-03,  4.7068e-02,  2.5911e-02,  2.8242e-02,\n",
            "          6.8468e-02,  1.5140e-02,  9.0989e-02,  8.2927e-03,  4.7237e-02,\n",
            "         -4.4846e-02,  9.0544e-02, -7.9422e-02, -6.7586e-02, -3.2587e-02,\n",
            "         -4.4963e-02, -7.4097e-02, -7.8885e-02, -8.9285e-02, -6.4093e-02,\n",
            "         -9.9181e-03, -3.5255e-02, -1.5411e-02,  5.7311e-02, -1.0338e-01,\n",
            "          5.1976e-02,  5.2783e-02,  6.9098e-02,  8.1953e-02, -3.9333e-02,\n",
            "          1.1265e-01, -3.3421e-02, -8.0381e-02, -1.3439e-02, -2.4087e-02,\n",
            "         -3.6382e-02, -1.1309e-01,  6.3677e-02, -4.3736e-02, -3.9118e-02,\n",
            "         -7.7820e-02,  7.1230e-02, -5.7632e-02, -9.7531e-02,  2.8098e-02,\n",
            "          7.9558e-02,  7.6127e-02, -9.5160e-02,  5.1881e-02,  1.1685e-01,\n",
            "          4.6481e-02,  1.1979e-01, -2.1986e-03, -5.7153e-02],\n",
            "        [-9.8884e-02, -9.3002e-02,  7.0128e-02, -6.6856e-02, -7.0353e-02,\n",
            "         -8.2078e-02,  2.6996e-02, -9.4794e-03,  7.7168e-02, -3.4371e-03,\n",
            "          8.0484e-02, -5.2801e-02, -3.9695e-02,  6.6778e-02, -1.1407e-01,\n",
            "         -5.4580e-02,  1.4034e-02, -5.2872e-02,  6.9147e-02,  4.7264e-02,\n",
            "          1.0405e-01, -7.6947e-02,  3.8006e-02,  9.8613e-02, -3.5907e-02,\n",
            "         -3.2331e-03,  4.6178e-02, -6.5494e-02,  7.5741e-02, -5.5555e-03,\n",
            "          5.9572e-02,  6.4529e-02, -5.2327e-02,  1.2258e-01, -5.9496e-02,\n",
            "         -3.2494e-02,  3.0820e-02,  1.0234e-01, -1.1111e-01, -1.0866e-01,\n",
            "         -4.0354e-02,  3.3527e-02,  3.4147e-03, -1.5546e-03,  2.1427e-02,\n",
            "          1.1743e-01, -9.5332e-02,  2.5928e-02, -9.8421e-02, -2.1386e-02,\n",
            "         -4.0470e-02, -6.0527e-02,  4.2463e-02, -9.4726e-02,  3.8583e-02,\n",
            "          5.7485e-02, -3.2082e-02, -9.8939e-02, -1.0637e-01, -1.4455e-02,\n",
            "          5.4017e-02, -4.6277e-02, -1.2230e-02,  2.5132e-02],\n",
            "        [ 4.0014e-02,  4.2483e-02, -9.2205e-02, -8.3735e-02,  7.0548e-02,\n",
            "         -2.8168e-02,  5.8117e-02, -2.4036e-02, -1.0421e-01,  4.3283e-02,\n",
            "          9.8120e-02, -5.7745e-02, -1.7483e-02,  4.4731e-02, -3.0413e-03,\n",
            "          1.9138e-02, -6.1567e-02, -2.4480e-02,  6.2955e-02, -5.9749e-02,\n",
            "          9.6819e-03,  6.2801e-02, -6.5978e-02, -5.0927e-02,  7.2845e-02,\n",
            "         -2.1980e-02,  9.1920e-02,  7.0720e-02, -3.2112e-02, -5.9792e-02,\n",
            "         -9.0360e-02,  2.1685e-02,  7.1666e-02,  1.2394e-01,  8.1865e-02,\n",
            "         -8.4414e-02, -1.0450e-04, -1.6812e-02, -4.8059e-02,  4.9215e-02,\n",
            "         -2.3512e-02,  1.0717e-01,  3.6853e-02, -1.1083e-01,  2.9295e-02,\n",
            "         -1.0671e-01,  5.3224e-02,  8.3356e-02, -1.1097e-01, -1.0983e-01,\n",
            "         -1.2132e-01,  5.9147e-02, -8.7438e-02,  1.9459e-02,  1.2116e-01,\n",
            "          1.1235e-01, -1.1656e-01,  1.2051e-01,  3.7327e-02, -1.1614e-01,\n",
            "          2.0188e-02, -3.2363e-03,  5.8179e-02, -1.5798e-02],\n",
            "        [ 7.0899e-02, -1.0345e-01, -1.1328e-01, -1.0590e-01, -9.3786e-02,\n",
            "          3.9824e-02, -8.4840e-03,  1.3642e-02,  1.2145e-01,  1.2114e-01,\n",
            "          4.9872e-03,  1.0662e-01, -9.7155e-02, -5.0920e-03, -1.4469e-02,\n",
            "         -7.3130e-02, -1.0846e-02, -3.0686e-02, -7.2533e-02, -4.2380e-02,\n",
            "         -3.6243e-02, -7.1049e-02, -9.5227e-02, -8.2893e-02, -7.5602e-02,\n",
            "         -6.9317e-02,  2.2303e-02,  1.4140e-02, -8.3944e-02,  9.7277e-02,\n",
            "          3.2799e-02,  9.0082e-02, -9.4122e-02,  1.2346e-01, -1.4883e-02,\n",
            "         -6.8789e-02,  6.7765e-02,  7.8039e-02, -1.9927e-02, -8.1425e-02,\n",
            "          2.1240e-02, -1.1189e-01, -2.3293e-02,  1.1986e-01, -8.1864e-02,\n",
            "         -1.0639e-01,  5.9691e-02,  9.3051e-02, -5.0608e-02,  1.8609e-02,\n",
            "         -3.4297e-02, -7.7668e-02, -1.1573e-01,  3.8544e-02, -1.3731e-02,\n",
            "         -7.6641e-03,  5.1369e-02, -1.0596e-01,  1.1592e-01, -1.1192e-01,\n",
            "         -6.7784e-02, -6.8552e-02, -3.8773e-02,  1.0325e-01]], device='cuda:0')\n",
            "[1,    20] loss: 0.041\n",
            "[1,    40] loss: 0.031\n",
            "[2,    20] loss: 0.030\n",
            "[2,    40] loss: 0.028\n",
            "[3,    20] loss: 0.026\n",
            "[3,    40] loss: 0.025\n",
            "[4,    20] loss: 0.024\n",
            "[4,    40] loss: 0.023\n",
            "[5,    20] loss: 0.022\n",
            "[5,    40] loss: 0.022\n",
            "[6,    20] loss: 0.021\n",
            "[6,    40] loss: 0.021\n",
            "[7,    20] loss: 0.020\n",
            "[7,    40] loss: 0.019\n",
            "[8,    20] loss: 0.019\n",
            "[8,    40] loss: 0.018\n",
            "[9,    20] loss: 0.018\n",
            "[9,    40] loss: 0.017\n",
            "[10,    20] loss: 0.018\n",
            "[10,    40] loss: 0.017\n",
            "[11,    20] loss: 0.016\n",
            "[11,    40] loss: 0.015\n",
            "[12,    20] loss: 0.015\n",
            "[12,    40] loss: 0.014\n",
            "[13,    20] loss: 0.014\n",
            "[13,    40] loss: 0.014\n",
            "[14,    20] loss: 0.014\n",
            "[14,    40] loss: 0.013\n",
            "[15,    20] loss: 0.012\n",
            "[15,    40] loss: 0.012\n",
            "[16,    20] loss: 0.013\n",
            "[16,    40] loss: 0.013\n",
            "[17,    20] loss: 0.013\n",
            "[17,    40] loss: 0.013\n",
            "[18,    20] loss: 0.013\n",
            "[18,    40] loss: 0.012\n",
            "[19,    20] loss: 0.011\n",
            "[19,    40] loss: 0.010\n",
            "[20,    20] loss: 0.011\n",
            "[20,    40] loss: 0.011\n",
            "[21,    20] loss: 0.011\n",
            "[21,    40] loss: 0.009\n",
            "[22,    20] loss: 0.009\n",
            "[22,    40] loss: 0.008\n",
            "[23,    20] loss: 0.011\n",
            "[23,    40] loss: 0.011\n",
            "[24,    20] loss: 0.009\n",
            "[24,    40] loss: 0.008\n",
            "[25,    20] loss: 0.007\n",
            "[25,    40] loss: 0.007\n",
            "[26,    20] loss: 0.011\n",
            "[26,    40] loss: 0.009\n",
            "[27,    20] loss: 0.007\n",
            "[27,    40] loss: 0.006\n",
            "[28,    20] loss: 0.006\n",
            "[28,    40] loss: 0.006\n",
            "[29,    20] loss: 0.011\n",
            "[29,    40] loss: 0.011\n",
            "[30,    20] loss: 0.010\n",
            "[30,    40] loss: 0.009\n",
            "after training:  tensor([[-1.0242e-01,  2.1172e-01,  1.0289e-01, -1.8794e-01, -2.3610e-01,\n",
            "         -1.8576e-01, -2.5453e-01,  2.2342e-02, -8.1843e-02, -1.1052e-01,\n",
            "         -9.3366e-02, -1.7597e-01, -2.4313e-01, -2.2515e-01, -2.2922e-01,\n",
            "         -4.6335e-02, -1.2005e-01, -1.5216e-01, -1.9083e-01, -2.5754e-02,\n",
            "          3.6818e-01, -2.4839e-01, -2.1783e-02, -1.8531e-01,  1.1701e-01,\n",
            "         -1.4823e-01, -2.4826e-01, -1.6508e-01,  2.7096e-01, -2.0325e-01,\n",
            "         -9.6730e-02, -1.8898e-01,  1.5154e-01, -7.1167e-02,  1.6459e-02,\n",
            "         -8.2476e-03, -1.7528e-01, -1.8299e-01, -1.5451e-02, -1.1141e-01,\n",
            "         -1.3802e-01, -2.1138e-01,  3.7597e-01, -1.5382e-01, -1.1651e-01,\n",
            "          9.5634e-02, -1.7722e-01, -3.4825e-02, -1.1396e-01, -2.5547e-01,\n",
            "         -5.9934e-02, -1.8327e-01, -2.6782e-02, -1.2810e-01, -2.7388e-01,\n",
            "         -2.1076e-01, -1.7531e-01, -3.0808e-02, -1.2939e-01,  2.9617e-02,\n",
            "         -1.6741e-01,  3.0494e-02, -1.1953e-01, -1.1552e-01],\n",
            "        [-1.6161e-01, -1.9190e-01,  1.8646e-01, -2.4557e-01, -1.8002e-01,\n",
            "          2.0798e-01,  3.4898e-02, -1.3418e-01, -2.4002e-01, -2.2734e-01,\n",
            "         -1.8877e-01, -1.0158e-01, -8.1987e-02, -6.5632e-02, -9.9820e-02,\n",
            "         -5.9342e-02, -9.6228e-02, -1.3307e-02, -1.9973e-01, -1.3171e-01,\n",
            "         -2.4649e-02, -2.3081e-01, -1.0287e-01,  1.4075e-02, -1.8994e-01,\n",
            "         -1.3614e-01, -1.7144e-01,  2.2480e-01, -2.2940e-01, -1.3747e-01,\n",
            "          9.6076e-02, -8.7510e-03, -1.7647e-01, -1.5671e-01, -7.3128e-02,\n",
            "         -1.6964e-01, -1.4232e-01, -1.5717e-01, -4.4839e-02, -1.0703e-01,\n",
            "         -6.5452e-02, -2.1026e-01, -1.4064e-01, -1.1041e-01,  4.6065e-01,\n",
            "         -1.4139e-01,  2.1587e-02, -1.8400e-01,  3.2212e-01, -1.5479e-01,\n",
            "         -5.6099e-03, -6.1191e-02, -5.8279e-02, -1.8166e-01, -2.2646e-01,\n",
            "         -1.8417e-01, -2.4055e-01, -1.9299e-01,  2.1755e-02, -2.2542e-01,\n",
            "         -6.3704e-02, -2.0933e-01, -1.1031e-01, -1.8305e-01],\n",
            "        [-1.7764e-01, -1.6564e-01,  7.9780e-03,  5.4654e-02,  6.8647e-02,\n",
            "         -8.9190e-02, -1.5172e-01, -2.1290e-01,  3.3590e-02, -1.7022e-01,\n",
            "         -1.1648e-01, -1.4388e-01, -5.4204e-02, -2.8805e-01,  9.8974e-02,\n",
            "         -2.5629e-01, -9.1340e-02, -4.7219e-02, -1.1462e-01, -8.9228e-02,\n",
            "         -1.7923e-01, -2.2134e-01, -2.7737e-01, -1.9934e-01, -2.4047e-01,\n",
            "          2.3799e-01, -2.0535e-01, -1.6475e-01, -1.9417e-01, -2.9004e-01,\n",
            "         -1.6893e-01, -2.2527e-01, -1.5973e-01, -1.4809e-01,  1.4258e-01,\n",
            "         -1.2578e-02, -2.3600e-01, -1.6509e-01, -1.7398e-01,  4.3934e-01,\n",
            "         -1.6952e-01, -8.4439e-02, -1.3670e-01, -3.4534e-06, -2.8987e-01,\n",
            "         -1.4047e-01,  1.2430e-01, -1.5283e-01, -1.0536e-01,  2.5228e-01,\n",
            "          1.6023e-02, -1.5323e-01, -1.0044e-01, -6.7162e-02, -3.7055e-02,\n",
            "         -2.2615e-01, -1.5768e-01, -2.3533e-01, -2.5236e-01, -7.3223e-03,\n",
            "          3.5274e-02, -1.9727e-01,  1.3430e-01,  2.2366e-01],\n",
            "        [-1.3329e-01,  5.5069e-02, -2.0418e-01,  1.3734e-01, -8.0200e-02,\n",
            "         -2.5787e-01, -1.2669e-01,  2.6643e-01, -2.1794e-01,  6.0393e-02,\n",
            "         -1.2490e-01, -1.8763e-01, -6.8498e-02,  3.1786e-01,  2.9965e-01,\n",
            "         -2.7821e-01,  1.1803e-01, -2.0786e-02,  1.0424e-01,  8.0026e-02,\n",
            "         -2.5694e-01, -1.0994e-01, -2.8331e-01,  1.5319e-01, -1.8459e-01,\n",
            "         -6.8332e-02, -1.0939e-01, -2.1394e-01, -1.7205e-01, -2.3729e-01,\n",
            "         -1.6983e-01, -2.1406e-01, -1.0636e-01, -1.5517e-01, -4.3986e-02,\n",
            "         -1.8507e-01, -2.6085e-01, -4.1991e-03, -8.3677e-02, -1.6701e-01,\n",
            "         -1.7677e-01,  1.8689e-01, -1.9452e-01, -1.3204e-01, -2.6296e-01,\n",
            "          9.2229e-02, -1.6103e-01, -5.7410e-02, -1.6722e-01, -8.7637e-02,\n",
            "         -1.0580e-01, -1.6863e-01, -1.8908e-01, -1.8999e-01, -2.2633e-01,\n",
            "         -2.2366e-01, -1.5582e-02,  2.3088e-01, -1.8387e-01,  2.2263e-02,\n",
            "         -2.0555e-01, -2.5184e-01, -1.9615e-01, -1.9869e-01],\n",
            "        [-1.5623e-01, -2.4043e-01, -2.3899e-01, -2.6891e-01,  7.8878e-03,\n",
            "         -9.1822e-02, -2.1551e-01, -1.9570e-01, -9.7613e-02, -1.6063e-01,\n",
            "          9.9401e-02,  6.9962e-02, -1.9850e-01,  5.4086e-02, -2.0942e-01,\n",
            "         -2.7341e-01, -1.8361e-01, -9.4623e-02, -1.0305e-01, -1.8105e-01,\n",
            "         -1.1267e-01,  2.3725e-01, -2.0483e-01, -1.5740e-01, -1.8417e-01,\n",
            "          1.6206e-01, -8.3391e-02, -1.5532e-01,  5.5647e-02,  3.2241e-01,\n",
            "         -8.1139e-02, -1.2534e-01, -1.1519e-01, -1.7820e-01, -2.5175e-01,\n",
            "         -1.0939e-01,  2.4203e-01, -1.2720e-01,  2.3400e-02, -1.3417e-01,\n",
            "         -1.6647e-01, -2.5595e-01, -1.0451e-01, -1.9149e-01, -1.9964e-01,\n",
            "         -2.5446e-01, -2.3125e-01, -1.7036e-01, -1.7833e-01,  2.5357e-01,\n",
            "         -2.2063e-01,  1.0915e-02,  2.4907e-01, -1.6044e-01, -6.6914e-02,\n",
            "         -1.1381e-01,  1.3586e-02,  1.0057e-01,  6.6620e-02,  1.6415e-01,\n",
            "         -1.8336e-01, -1.3016e-01, -2.2165e-01, -2.3629e-01],\n",
            "        [ 4.6653e-02, -2.9224e-01, -2.2392e-01,  1.6925e-01,  2.7429e-01,\n",
            "          3.2669e-01, -2.1664e-01, -2.0026e-01, -1.1514e-01, -2.3043e-01,\n",
            "         -3.0860e-02,  2.5442e-01,  1.0356e-01, -1.9904e-01, -2.2687e-01,\n",
            "         -2.6541e-01, -1.8645e-01, -1.8681e-01,  1.5053e-01, -1.1542e-01,\n",
            "         -1.3134e-01, -2.4967e-01,  2.0677e-01, -2.0644e-01,  2.5111e-01,\n",
            "         -1.5448e-01, -1.8036e-01, -1.8095e-01, -1.7988e-01,  1.6371e-01,\n",
            "          9.1668e-02,  2.2715e-02, -1.2376e-01, -8.5736e-03, -2.6836e-01,\n",
            "         -1.0362e-01, -2.3018e-01, -2.1451e-01, -2.6708e-01, -1.0266e-01,\n",
            "         -1.4197e-01,  6.5449e-02,  1.8391e-02, -4.6530e-02, -1.5649e-01,\n",
            "         -9.6913e-03, -4.5884e-02, -1.6970e-01, -2.0501e-01, -1.7207e-01,\n",
            "         -1.3182e-01,  6.9172e-02, -2.1768e-01, -1.0290e-01, -1.8240e-01,\n",
            "         -1.5689e-01, -1.3751e-01, -1.1794e-01, -1.7936e-01,  5.7700e-02,\n",
            "          1.5422e-02, -1.6006e-01, -1.1302e-01, -1.7659e-01],\n",
            "        [ 2.4199e-02,  7.2222e-02, -2.3697e-01,  1.3934e-01, -1.6340e-01,\n",
            "         -1.7317e-01,  1.9866e-01, -2.2169e-01, -2.2829e-01,  4.6187e-02,\n",
            "         -2.0260e-02, -2.2842e-01,  1.9773e-01, -1.8624e-01, -1.5612e-01,\n",
            "          1.4227e-01, -1.8690e-01,  1.3331e-01,  4.5442e-02,  1.1333e-01,\n",
            "         -2.4241e-01,  1.5186e-01,  1.0563e-01, -2.3671e-01, -2.4040e-01,\n",
            "         -1.6534e-01, -1.7260e-01, -2.0476e-01, -2.1752e-01, -2.4320e-01,\n",
            "         -1.7309e-01, -2.7122e-01, -1.0543e-01, -8.7520e-02, -2.3260e-01,\n",
            "          4.9843e-01,  3.5529e-02, -9.2492e-02, -1.5462e-01, -1.2595e-01,\n",
            "          8.9440e-02, -2.0320e-01, -2.0712e-01, -1.8427e-01, -1.4655e-02,\n",
            "         -1.4907e-01, -2.1732e-01, -8.3698e-02, -2.9717e-02, -2.1856e-01,\n",
            "         -2.3268e-01,  8.7913e-02, -1.4421e-01, -2.1372e-01, -1.9397e-01,\n",
            "         -1.0482e-01, -1.0578e-01, -2.5277e-01, -7.3912e-02, -6.9836e-02,\n",
            "         -1.4918e-01,  8.4949e-02, -1.8622e-01, -1.7398e-01],\n",
            "        [-1.3481e-01, -2.7860e-01, -1.2120e-01, -1.4460e-01, -2.9420e-01,\n",
            "         -2.0969e-01, -1.2246e-01, -1.6364e-01,  1.2988e-01, -1.4791e-01,\n",
            "         -1.8027e-01, -1.9039e-01, -1.7304e-01, -3.9224e-02, -2.1273e-01,\n",
            "         -1.1897e-02,  2.3336e-01, -1.7760e-01, -4.9428e-03, -1.3359e-01,\n",
            "          2.8787e-02, -2.1222e-01,  3.7539e-02,  7.4215e-02, -3.0445e-02,\n",
            "         -8.9220e-02, -9.9792e-02, -1.7148e-01, -1.0078e-01, -1.2177e-01,\n",
            "         -1.7004e-01,  6.8010e-02, -2.2458e-01,  3.3307e-02, -2.6137e-01,\n",
            "         -1.6314e-01,  2.4157e-01,  1.4323e-01, -2.7221e-01, -2.1829e-01,\n",
            "         -1.3226e-01,  5.3518e-02, -1.9114e-01, -1.8845e-01, -9.3975e-02,\n",
            "          1.0192e-01, -2.0750e-01, -1.4132e-01, -1.9855e-01, -2.4627e-01,\n",
            "         -2.1600e-01, -2.1792e-01, -4.7744e-02, -1.9997e-01,  2.7549e-01,\n",
            "          1.1471e-01, -1.5526e-01, -2.5273e-01, -1.7829e-01, -2.1801e-01,\n",
            "          4.2310e-01,  1.6915e-01, -1.3300e-01,  2.6370e-02],\n",
            "        [-5.6155e-02, -1.2951e-01, -2.0479e-01, -2.6898e-01, -1.5921e-01,\n",
            "         -1.0664e-01, -9.6213e-02, -1.5704e-01, -2.6155e-01, -1.7927e-01,\n",
            "          2.4843e-01, -1.5752e-01, -7.5008e-02, -1.3476e-01, -1.8461e-01,\n",
            "         -2.3263e-02, -2.2108e-01, -1.5624e-01, -1.3838e-01, -1.8351e-01,\n",
            "         -1.7038e-01, -1.5225e-02, -1.7420e-01, -1.9276e-01, -1.3265e-02,\n",
            "         -1.7580e-01,  2.0153e-01,  6.7991e-02,  1.0241e-02, -1.7717e-01,\n",
            "         -1.9723e-01,  4.8113e-02,  2.2852e-01,  8.4795e-02,  5.8929e-05,\n",
            "         -1.8047e-01, -1.4762e-01, -1.1346e-01, -2.0534e-01, -8.4088e-02,\n",
            "         -4.2481e-02, -1.0808e-01, -6.4373e-02, -2.6784e-01, -8.9627e-02,\n",
            "         -2.5404e-01,  7.4056e-02,  7.8020e-02, -1.9959e-01, -2.7054e-01,\n",
            "         -2.1133e-01,  1.2104e-01, -1.9740e-01,  2.4674e-01,  1.1467e-01,\n",
            "          2.8088e-01, -2.0541e-01, -9.0612e-03, -7.4879e-02, -1.9809e-01,\n",
            "         -2.1099e-01, -6.6015e-02,  2.5486e-01, -1.5941e-01],\n",
            "        [ 2.0607e-01, -2.4299e-01, -1.2159e-01, -2.3038e-01, -2.4481e-01,\n",
            "         -1.0800e-01, -9.9765e-02,  5.6121e-02,  1.1630e-01,  2.8266e-01,\n",
            "         -1.1634e-01, -7.9390e-03, -2.0002e-01, -1.7339e-01, -1.5368e-01,\n",
            "         -1.6294e-01, -1.5373e-01, -1.2519e-01, -1.6538e-01, -1.0741e-01,\n",
            "         -1.4853e-01, -1.9247e-01, -1.7548e-01, -2.0577e-01, -1.7882e-01,\n",
            "         -1.9940e-01, -1.2464e-02, -1.0573e-02, -2.3695e-01, -7.1291e-02,\n",
            "          1.4242e-01,  5.9637e-03, -2.1472e-01,  1.2910e-01, -1.9497e-01,\n",
            "         -1.1833e-01, -1.3883e-01, -3.6545e-02, -4.7095e-02, -1.7978e-01,\n",
            "          1.7510e-01, -2.0024e-01,  5.8794e-02,  2.4164e-01, -2.4470e-01,\n",
            "         -2.1905e-01, -1.2324e-01,  1.5747e-01, -1.8779e-01, -2.5657e-01,\n",
            "          6.3849e-02, -2.0740e-01, -2.3776e-01,  1.1099e-02, -1.8126e-01,\n",
            "         -1.4450e-01,  4.3668e-02, -2.4404e-01,  9.7643e-02, -1.9452e-01,\n",
            "         -1.7390e-01, -1.4901e-01, -1.6128e-01,  7.9672e-02]], device='cuda:0')\n",
            "confusion matrix shape:  torch.Size([10, 10])\n",
            "ITERATION:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 0 iteration: 90 %\n",
            "Train the network, iteration:  1  on classes:  range(10, 20)\n",
            "before training:  tensor([[-0.1024,  0.2117,  0.1029,  ...,  0.0305, -0.1195, -0.1155],\n",
            "        [-0.1616, -0.1919,  0.1865,  ..., -0.2093, -0.1103, -0.1831],\n",
            "        [-0.1776, -0.1656,  0.0080,  ..., -0.1973,  0.1343,  0.2237],\n",
            "        ...,\n",
            "        [-0.0187, -0.0671, -0.2619,  ..., -0.1654,  0.1180,  0.0631],\n",
            "        [ 0.0067,  0.2265,  0.1211,  ..., -0.0179,  0.1129, -0.1342],\n",
            "        [-0.2589,  0.1941, -0.0045,  ...,  0.0443, -0.2203,  0.2387]],\n",
            "       device='cuda:0')\n",
            "[1,    20] loss: 0.062\n",
            "[1,    40] loss: 0.048\n",
            "[2,    20] loss: 0.044\n",
            "[2,    40] loss: 0.042\n",
            "[3,    20] loss: 0.040\n",
            "[3,    40] loss: 0.040\n",
            "[4,    20] loss: 0.039\n",
            "[4,    40] loss: 0.038\n",
            "[5,    20] loss: 0.038\n",
            "[5,    40] loss: 0.036\n",
            "[6,    20] loss: 0.037\n",
            "[6,    40] loss: 0.036\n",
            "[7,    20] loss: 0.035\n",
            "[7,    40] loss: 0.034\n",
            "[8,    20] loss: 0.033\n",
            "[8,    40] loss: 0.033\n",
            "[9,    20] loss: 0.036\n",
            "[9,    40] loss: 0.036\n",
            "[10,    20] loss: 0.036\n",
            "[10,    40] loss: 0.034\n",
            "[11,    20] loss: 0.032\n",
            "[11,    40] loss: 0.030\n",
            "[12,    20] loss: 0.034\n",
            "[12,    40] loss: 0.032\n",
            "[13,    20] loss: 0.030\n",
            "[13,    40] loss: 0.030\n",
            "[14,    20] loss: 0.034\n",
            "[14,    40] loss: 0.031\n",
            "[15,    20] loss: 0.029\n",
            "[15,    40] loss: 0.029\n",
            "[16,    20] loss: 0.028\n",
            "[16,    40] loss: 0.028\n",
            "[17,    20] loss: 0.031\n",
            "[17,    40] loss: 0.029\n",
            "[18,    20] loss: 0.029\n",
            "[18,    40] loss: 0.028\n",
            "[19,    20] loss: 0.026\n",
            "[19,    40] loss: 0.026\n",
            "[20,    20] loss: 0.033\n",
            "[20,    40] loss: 0.031\n",
            "[21,    20] loss: 0.029\n",
            "[21,    40] loss: 0.028\n",
            "[22,    20] loss: 0.031\n",
            "[22,    40] loss: 0.030\n",
            "[23,    20] loss: 0.028\n",
            "[23,    40] loss: 0.027\n",
            "[24,    20] loss: 0.029\n",
            "[24,    40] loss: 0.028\n",
            "[25,    20] loss: 0.026\n",
            "[25,    40] loss: 0.026\n",
            "[26,    20] loss: 0.028\n",
            "[26,    40] loss: 0.026\n",
            "[27,    20] loss: 0.031\n",
            "[27,    40] loss: 0.029\n",
            "[28,    20] loss: 0.028\n",
            "[28,    40] loss: 0.027\n",
            "[29,    20] loss: 0.029\n",
            "[29,    40] loss: 0.027\n",
            "[30,    20] loss: 0.028\n",
            "[30,    40] loss: 0.026\n",
            "after training:  tensor([[ 0.0274,  0.2927,  0.1831,  ...,  0.1522, -0.0736, -0.0346],\n",
            "        [-0.0872, -0.0728,  0.2335,  ..., -0.1291, -0.1373, -0.0347],\n",
            "        [-0.0595, -0.1339, -0.0363,  ..., -0.1625, -0.0767,  0.0189],\n",
            "        ...,\n",
            "        [-0.2384, -0.2670, -0.4461,  ..., -0.3166,  0.1431, -0.1809],\n",
            "        [-0.0417, -0.0105,  0.1066,  ..., -0.2050,  0.1895, -0.1594],\n",
            "        [-0.3152, -0.1110, -0.2382,  ..., -0.1231, -0.2785,  0.1914]],\n",
            "       device='cuda:0')\n",
            "confusion matrix shape:  torch.Size([20, 20])\n",
            "ITERATION:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 1 iteration: 56 %\n",
            "Train the network, iteration:  2  on classes:  range(20, 30)\n",
            "before training:  tensor([[ 0.0274,  0.2927,  0.1831,  ...,  0.1522, -0.0736, -0.0346],\n",
            "        [-0.0872, -0.0728,  0.2335,  ..., -0.1291, -0.1373, -0.0347],\n",
            "        [-0.0595, -0.1339, -0.0363,  ..., -0.1625, -0.0767,  0.0189],\n",
            "        ...,\n",
            "        [-0.1198,  0.0103,  0.0243,  ..., -0.2208,  0.0464, -0.0749],\n",
            "        [-0.1054,  0.1473,  0.0719,  ..., -0.0110, -0.0570, -0.1650],\n",
            "        [ 0.1754, -0.1264, -0.0853,  ...,  0.1037,  0.0594, -0.0228]],\n",
            "       device='cuda:0')\n",
            "[1,    20] loss: 0.080\n",
            "[1,    40] loss: 0.061\n",
            "[2,    20] loss: 0.058\n",
            "[2,    40] loss: 0.056\n",
            "[3,    20] loss: 0.055\n",
            "[3,    40] loss: 0.053\n",
            "[4,    20] loss: 0.051\n",
            "[4,    40] loss: 0.052\n",
            "[5,    20] loss: 0.051\n",
            "[5,    40] loss: 0.050\n",
            "[6,    20] loss: 0.051\n",
            "[6,    40] loss: 0.050\n",
            "[7,    20] loss: 0.050\n",
            "[7,    40] loss: 0.050\n",
            "[8,    20] loss: 0.052\n",
            "[8,    40] loss: 0.051\n",
            "[9,    20] loss: 0.049\n",
            "[9,    40] loss: 0.048\n",
            "[10,    20] loss: 0.055\n",
            "[10,    40] loss: 0.053\n",
            "[11,    20] loss: 0.052\n",
            "[11,    40] loss: 0.050\n",
            "[12,    20] loss: 0.048\n",
            "[12,    40] loss: 0.047\n",
            "[13,    20] loss: 0.047\n",
            "[13,    40] loss: 0.046\n",
            "[14,    20] loss: 0.046\n",
            "[14,    40] loss: 0.045\n",
            "[15,    20] loss: 0.046\n",
            "[15,    40] loss: 0.045\n",
            "[16,    20] loss: 0.049\n",
            "[16,    40] loss: 0.049\n",
            "[17,    20] loss: 0.050\n",
            "[17,    40] loss: 0.048\n",
            "[18,    20] loss: 0.050\n",
            "[18,    40] loss: 0.049\n",
            "[19,    20] loss: 0.047\n",
            "[19,    40] loss: 0.045\n",
            "[20,    20] loss: 0.044\n",
            "[20,    40] loss: 0.044\n",
            "[21,    20] loss: 0.046\n",
            "[21,    40] loss: 0.045\n",
            "[22,    20] loss: 0.047\n",
            "[22,    40] loss: 0.046\n",
            "[23,    20] loss: 0.057\n",
            "[23,    40] loss: 0.054\n",
            "[24,    20] loss: 0.050\n",
            "[24,    40] loss: 0.049\n",
            "[25,    20] loss: 0.053\n",
            "[25,    40] loss: 0.050\n",
            "[26,    20] loss: 0.047\n",
            "[26,    40] loss: 0.046\n",
            "[27,    20] loss: 0.046\n",
            "[27,    40] loss: 0.045\n",
            "[28,    20] loss: 0.048\n",
            "[28,    40] loss: 0.047\n",
            "[29,    20] loss: 0.046\n",
            "[29,    40] loss: 0.045\n",
            "[30,    20] loss: 0.044\n",
            "[30,    40] loss: 0.043\n",
            "after training:  tensor([[-0.0503,  0.2452,  0.0832,  ...,  0.0938, -0.0919,  0.0186],\n",
            "        [-0.0689, -0.0264,  0.1725,  ..., -0.0560, -0.1609, -0.0342],\n",
            "        [-0.0209, -0.0797, -0.0775,  ..., -0.0713, -0.0826, -0.0714],\n",
            "        ...,\n",
            "        [-0.3254, -0.0134, -0.0505,  ..., -0.2631, -0.1255, -0.2178],\n",
            "        [-0.2986,  0.1798, -0.2057,  ..., -0.2146, -0.2523, -0.2402],\n",
            "        [-0.0245, -0.3100,  0.0264,  ...,  0.2631, -0.0989, -0.2586]],\n",
            "       device='cuda:0')\n",
            "confusion matrix shape:  torch.Size([30, 30])\n",
            "ITERATION:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 2 iteration: 42 %\n",
            "Train the network, iteration:  3  on classes:  range(30, 40)\n",
            "before training:  tensor([[-0.0503,  0.2452,  0.0832,  ...,  0.0938, -0.0919,  0.0186],\n",
            "        [-0.0689, -0.0264,  0.1725,  ..., -0.0560, -0.1609, -0.0342],\n",
            "        [-0.0209, -0.0797, -0.0775,  ..., -0.0713, -0.0826, -0.0714],\n",
            "        ...,\n",
            "        [-0.0036,  0.2130,  0.0930,  ...,  0.0836, -0.2327, -0.0266],\n",
            "        [ 0.1257, -0.0453,  0.2183,  ..., -0.2142,  0.0515,  0.1641],\n",
            "        [ 0.1517, -0.1557, -0.0373,  ..., -0.0326,  0.1213, -0.0477]],\n",
            "       device='cuda:0')\n",
            "[1,    20] loss: 0.095\n",
            "[1,    40] loss: 0.083\n",
            "[2,    20] loss: 0.080\n",
            "[2,    40] loss: 0.078\n",
            "[3,    20] loss: 0.077\n",
            "[3,    40] loss: 0.076\n",
            "[4,    20] loss: 0.074\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}