{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incrementalLearningWithoutForgetting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gzrd6SoDNp6d",
        "QObN0rGNN2Be"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/incrementalLearningWithoutForgetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUHNE0YdXMlR"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "from torch.nn.init import xavier_uniform_ \n",
        "from torch.nn.init import kaiming_uniform_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UivF_HGCTWYe"
      },
      "source": [
        "### DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QleCp90XDa2a",
        "outputId": "8cd3f740-9e74-472e-fed6-070f4d11f782"
      },
      "source": [
        "# we build a transform to normalize images: Data normalization is an important step which ensures \n",
        "# each input parameter (pixel, in this case) has a similar data distribution. This makes convergence \n",
        "# faster while training the network.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 128\n",
        "\n",
        "trainset_raw = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "for i in range(len(trainset_raw)):\n",
        "  if(i==0):\n",
        "    trainset = [[trainset_raw[i][0], trainset_raw[i][1]]]\n",
        "  else:\n",
        "    trainset.append([trainset_raw[i][0], trainset_raw[i][1]])\n",
        "\n",
        "\n",
        "# DataLoader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "# batch_size = how many samples per batch to load\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXdZrK0zNwvw"
      },
      "source": [
        "### NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kAHBaHJ4Td1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def addOutputNodes(self, num_new_outputs):\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "\n",
        "        self.fc = nn.Linear(in_features, out_features + num_new_outputs)\n",
        "\n",
        "        #xavier initialization\n",
        "        # xavier_uniform_(self.fc.weight)\n",
        "\n",
        "        #kaiming initialization\n",
        "        # kaiming_uniform_(self.fc.weight)\n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        \n",
        "\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1JeZ9NB4ZxS",
        "outputId": "a93b0ef7-f354-411a-d36a-125dc3173807"
      },
      "source": [
        "net = resnet32()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QObN0rGNN2Be"
      },
      "source": [
        "### LOSS & PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUMJGDLO4cR-"
      },
      "source": [
        "lr = 0.01\n",
        "decay = 0.0001\n",
        "epochs = 10\n",
        "momentum = 0.9\n",
        "factor = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLf5BCR-4c3X"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "bceLoss = nn.BCELoss()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te6KvRNKN5k_"
      },
      "source": [
        "### TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IbM6obCwqXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d15cfd-a3bc-4988-f6d6-5c42b77b05d3"
      },
      "source": [
        "\"\"\"\n",
        "def training(trainloader, iteration, network, device, epochs, num_classes):\n",
        "  distillation_loss = 0\n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(num_classes)\n",
        "    network.to(device)\n",
        "\n",
        "  old_net = copy.deepcopy(network)\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      \n",
        "      # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      # forward: assign weights to each edge in each layer\n",
        "      outputs = network.forward(inputs) \n",
        "\n",
        "       # calculate the classification loss \n",
        "      classification_loss = criterion(outputs,labels) \n",
        "\n",
        "      if (iteration > 0):\n",
        "      # calculate the distillation loss\n",
        "        distillation_loss = dist_loss(outputs, old_net, inputs) \n",
        "      \n",
        "      loss = classification_loss + distillation_loss\n",
        "\n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward() \n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()  \n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "      if i % 20 == 19:    \n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0 \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef training(trainloader, iteration, network, device, epochs, num_classes):\\n  distillation_loss = 0\\n  if (iteration != 0):\\n    # add 10 output nodes to the network\\n    network.addOutputNodes(num_classes)\\n    network.to(device)\\n\\n  old_net = copy.deepcopy(network)\\n  \\n  #train the network\\n  for epoch in range(epochs):\\n\\n    running_loss = 0.0\\n    for i, data in enumerate(trainloader, 0):\\n\\n      inputs = data[0].to(device)\\n      labels = data[1].to(device)\\n      \\n      # Sets the gradients of all optimized torch.Tensor to zero.\\n      optimizer.zero_grad() \\n\\n      # forward: assign weights to each edge in each layer\\n      outputs = network.forward(inputs) \\n\\n       # calculate the classification loss \\n      classification_loss = criterion(outputs,labels) \\n\\n      if (iteration > 0):\\n      # calculate the distillation loss\\n        distillation_loss = dist_loss(outputs, old_net, inputs) \\n      \\n      loss = classification_loss + distillation_loss\\n\\n      # redesign the weights evaluating the performance of the network\\n      loss.backward() \\n\\n      # update parameters\\n      optimizer.step()  \\n\\n      running_loss += loss.item()\\n\\n      # print every 20 mini-batches the average value of the loss accumulated in each batch\\n      if i % 20 == 19:    \\n        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\\n        running_loss = 0.0 \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agoNfyi00-NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50b015e-1c19-4520-ceaf-1d6c4e1e1940"
      },
      "source": [
        " \"\"\"def dist_loss(outputs, old_net, inputs):\n",
        "    out_old = torch.sigmoid(old_net.forward(inputs))\n",
        "    out_old_new = torch.argmax(out_old, dim=1)\n",
        "    distillation_loss = criterion(outputs, out_old_new)\n",
        "    return distillation_loss\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def dist_loss(outputs, old_net, inputs):\\n   out_old = torch.sigmoid(old_net.forward(inputs))\\n   out_old_new = torch.argmax(out_old, dim=1)\\n   distillation_loss = criterion(outputs, out_old_new)\\n   return distillation_loss'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4KXtaXfRtcQ"
      },
      "source": [
        "### TRAINING BCE LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy-26TcJRtCd"
      },
      "source": [
        "def training(trainloader, iteration, network, device, epochs, num_classes):\n",
        "  num_classes_till_previous_step = iteration * num_classes\n",
        "  total_classes = num_classes_till_previous_step + num_classes\n",
        "  distillation_loss = 0\n",
        "  \n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(num_classes)\n",
        "    network.to(device)\n",
        "\n",
        "  old_net = copy.deepcopy(network)\n",
        "\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      \n",
        "      # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      # forward: assign weights to each edge in each layer\n",
        "      logits = network.forward(inputs)\n",
        "      classification_loss = criterion(logits, labels)\n",
        "\n",
        "      if iteration > 0:\n",
        "        logits_old = torch.sigmoid(old_net(inputs))\n",
        "        distilled_old = get_one_hot(labels, total_classes, device)\n",
        "        output = logits_old[:, 0:num_classes_till_previous_step]\n",
        "        distillation_loss = bceLoss(output, distilled_old)\n",
        "    \n",
        "\n",
        "      loss = classification_loss + distillation_loss\n",
        "      \n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward() \n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()  \n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "      if i % 20 == 19:    \n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI16O6imbB9K"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def training(trainloader, iteration, network, device, epochs, num_classes):\n",
        "  num_classes_till_previous_step = iteration * num_classes\n",
        "  total_classes = num_classes_till_previous_step + num_classes\n",
        "  distillation_loss = 0\n",
        "  \n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(num_classes)\n",
        "    network.to(device)\n",
        "\n",
        "  old_net = copy.deepcopy(network)\n",
        "\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      \n",
        "      # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "      optimizer.zero_grad() \n",
        "      q = torch.zeros(len(trainloader), total_classes).to(device)\n",
        "      # forward: assign weights to each edge in each layer\n",
        "      logits = network.forward(inputs)\n",
        "      classification_loss = criterion(logits, labels)\n",
        "      indices = i.cuda()\n",
        "      q[indices] = logits.data\n",
        "      q = Variable(q).to(device)\n",
        "\n",
        "      # Distilation loss for old classes\n",
        "      if iterations > 0:\n",
        "        logits = F.sigmoid(logits)\n",
        "        q_i = q[indices]\n",
        "        distillation_loss = sum(bceLoss(g[:,y], q_i[:,y]) for y in xrange(num_classes_till_previous_step))\n",
        "\n",
        "      loss = classification_loss + distillation_loss\n",
        "      \n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward() \n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()  \n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "      if i % 20 == 19:    \n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOI93FDcXALn"
      },
      "source": [
        "def get_one_hot(target,num_class, device):\n",
        "  one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
        "  one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
        "  return one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHr8sBA_N-zJ"
      },
      "source": [
        "### TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefaruFe3_DP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69b2c0a-2bec-4c18-9262-8461a76a5eb7"
      },
      "source": [
        "\"\"\"\n",
        "def test(testloader, iteration, network, acc):\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "         \n",
        "        \n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef test(testloader, iteration, network, acc):\\n\\n  correct = 0\\n  total = 0\\n  print(\"ITERATION: \", iteration)\\n  \\n  # since we\\'re not training, we don\\'t need to calculate the gradients for our outputs\\n  with torch.no_grad():\\n      for data in testloader:\\n          images, labels = data[0].to(device), data[1].to(device)\\n\\n          # calculate outputs by running images through the network\\n          outputs = network.forward(images)\\n\\n          # the class with the highest energy is what we choose as prediction\\n          _, predicted = torch.max(outputs.data, 1)\\n          total += labels.size(0)\\n          correct += (predicted == labels).sum().item()\\n         \\n        \\n  acc.append(100*correct/total)\\n  print(f\\'Accuracy of the network on the {iteration} iteration: %d %%\\' % (100 * correct / total))\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LxjrgyTOBWN"
      },
      "source": [
        "### EXECUTION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bLZetGa4F_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49ff4c6-c80b-4b56-9b80-d5bdef044d3e"
      },
      "source": [
        "\"\"\"\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations= 10 \n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = [] \n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\n",
        "\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# divided our dataset into sample of 10 classes each\\n# train the network on the first 10 classes\\n# evaluate the network on the first 10 classes\\n# train the network on the second 10 classes (adding 10 output layers)\\n# evaluate the network on the first 20 classes\\niterations= 10 \\nnum_classes = 10\\ntest_set = [] #initialized here because we test over all the classes not only those one in which I train\\nacc = []\\nimport random\\n#indices = list(range(0,100))\\n#random.shuffle(indices)\\nfor i in range(iterations):\\n  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\\n  train_iter = [] \\n  for j in range(len(trainset)):\\n    if(trainset[j][-1] in classes_current_iter):\\n      test_set.append(trainset[j]) \\n      train_iter.append(trainset[j])\\n\\n\\n  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\\n  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \\n  training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\\n\\n  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQZSybAOH9C"
      },
      "source": [
        "### CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXP0RxiQ50mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211f4896-e40d-4de0-ed53-92401afa291a"
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = torch.zeros(100,100)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in valid_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net.forward(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "          confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sklearn.metrics import plot_confusion_matrix\\nimport matplotlib.pyplot as plt\\n\\nconfusion_matrix = torch.zeros(100,100)\\n\\ncorrect = 0\\ntotal = 0\\n# since we\\'re not training, we don\\'t need to calculate the gradients for our outputs\\nwith torch.no_grad():\\n    for data in valid_loader:\\n        images, labels = data[0].to(device), data[1].to(device)\\n        # calculate outputs by running images through the network\\n        outputs = net.forward(images)\\n        # the class with the highest energy is what we choose as prediction\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\n        for t, p in zip(labels.view(-1), predicted.view(-1)):\\n          confusion_matrix[t.long(),p.long()] += 1\\n\\nplt.figure()\\nplt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\\nprint(\\'Accuracy of the network on the 10000 test images: %d %%\\' % (100 * correct / total))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TckH9XhBXBQb"
      },
      "source": [
        "### TEST (CONFUSION EACH STEP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO7gpTu1XLl-"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test(testloader, iteration, network, acc):\n",
        "  confusion_matrix = torch.zeros(iteration*10+10,iteration*10+10)\n",
        "  print(\"confusion matrix shape: \", confusion_matrix.shape)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "         \n",
        "          for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "            confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.show()\n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kxkDFX6DXo6"
      },
      "source": [
        "### RANDOM CLASSES\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jU3qySqDivk"
      },
      "source": [
        "EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKHoN8W9EJBw"
      },
      "source": [
        "import random\n",
        "indices = list(range(0,100))\n",
        "random.shuffle(indices)\n",
        "dict_classes = dict(zip(indices,range(100)))\n",
        "for i in range(len(trainset)):\n",
        "  trainset[i][1] = dict_classes[trainset[i][1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "INaUfRGBDkPP",
        "outputId": "8d6eed71-234d-472d-ae3c-9b9aedcf8142"
      },
      "source": [
        "#TRYING TO RANDOMIZE CLASSES\n",
        "\n",
        "\n",
        "# divided our dataset into sample of 10 classes each\n",
        "# train the network on the first 10 classes\n",
        "# evaluate the network on the first 10 classes\n",
        "# train the network on the second 10 classes (adding 10 output layers)\n",
        "# evaluate the network on the first 20 classes\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "acc = []\n",
        "#import random\n",
        "#indices = list(range(0,100))\n",
        "#random.shuffle(indices)\n",
        "for i in range(iterations):\n",
        "  #classes_current_iter = dict(zip(indices[i*num_classes : i*num_classes+num_classes],range(i*num_classes,i*num_classes+num_classes)))\n",
        "  # print(classes_current_iter)\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  training(train_loader, i, net, device, epochs, num_classes) # Train the network with 10 classes at a time\n",
        "  #print(\"Train_loader length: \",len(train_loader))\n",
        "  #print(\"valid_loader length: \",len(valid_loader))\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "tensor(2.4568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[1,    20] loss: 2.184\n",
            "tensor(2.0654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[1,    40] loss: 1.865\n",
            "tensor(1.7574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.7529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.8720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[2,    20] loss: 1.726\n",
            "tensor(1.6695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.6525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[2,    40] loss: 1.507\n",
            "tensor(1.6389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[3,    20] loss: 1.429\n",
            "tensor(1.2781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[3,    40] loss: 1.314\n",
            "tensor(1.2695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[4,    20] loss: 1.268\n",
            "tensor(1.1920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[4,    40] loss: 1.271\n",
            "tensor(1.1891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[5,    20] loss: 1.246\n",
            "tensor(1.1328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[5,    40] loss: 1.204\n",
            "tensor(1.1935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.4474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.5699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.3472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[6,    20] loss: 1.203\n",
            "tensor(1.1510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[6,    40] loss: 1.096\n",
            "tensor(1.0295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.2891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[7,    20] loss: 1.054\n",
            "tensor(0.9652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[7,    40] loss: 0.997\n",
            "tensor(0.9466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[8,    20] loss: 0.932\n",
            "tensor(0.7873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[8,    40] loss: 0.897\n",
            "tensor(0.7972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8661, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[9,    20] loss: 0.879\n",
            "tensor(0.7890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.1570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[9,    40] loss: 0.868\n",
            "tensor(0.8114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.6562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.6496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[10,    20] loss: 0.801\n",
            "tensor(0.7577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.0093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.7450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.6664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.8627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.6917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.9258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(0.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "[10,    40] loss: 0.823\n",
            "confusion matrix shape:  torch.Size([10, 10])\n",
            "ITERATION:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 0 iteration: 65 %\n",
            "Train the network, iteration:  1  on classes:  range(10, 20)\n",
            "tensor(5.1538, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d4af75dc3869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train the network, iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" on classes: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_current_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Train the network with 10 classes at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m#print(\"Train_loader length: \",len(train_loader))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m#print(\"valid_loader length: \",len(valid_loader))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5400b3a8358a>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(trainloader, iteration, network, device, epochs, num_classes)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdistilled_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_classes_till_previous_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdistillation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(distillation_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         raise ValueError(\n\u001b[1;32m   2754\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m         )\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([128, 20])) that is different to the input size (torch.Size([128, 10])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    }
  ]
}