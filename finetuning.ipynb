{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaJ3XsWQKGEOCI6AZLM2V0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Project_MLDL/blob/main/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00u7XedLIrBB"
      },
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import glob\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFnNd3nsMorl"
      },
      "source": [
        "total_classes = 100 # classes of CIFAR100\n",
        "iterations = 10 \n",
        "classes_per_iter = total_classes/iterations\n",
        "\n",
        "# parameters \n",
        "batch_size = 128\n",
        "lr = 0.01\n",
        "decay = 0.0001\n",
        "epochs = 70\n",
        "momentum = 0.9\n",
        "factor = 5\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "resNet18 = models.resnet18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxUIJIBjaF3g"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAtDdsNTJZyI",
        "outputId": "9972cc20-0ada-4969-e3bc-2427056d66a5"
      },
      "source": [
        "#import train and test datasets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train = CIFAR100(\"./data\", train = True, download=True, transform=transform)\n",
        "test = CIFAR100(\"./data\", train= False, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aibJRRKXK6px",
        "outputId": "7698059c-a164-4831-c224-f0b83fe860cd"
      },
      "source": [
        "#counting rows of dataset\n",
        "print(len(train), len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDEwZnH_cSVN"
      },
      "source": [
        "def incrementalFit(train_loader, valid_loader, network):\n",
        "  optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "  scheduler = MultiStepLR(optimizer, [int(0.7*epochs), int(0.9*epochs)], factor)\n",
        "  print(\"1\")\n",
        "  for epoch in range(epochs):\n",
        "    network.train()\n",
        "    scheduler.step()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    print(\"1\")\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        print(\"1\")\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        logits, feat = network.forward(inputs)  # feature vector only\n",
        "        prediction = network.predict(logits)  # make the prediction\n",
        "        loss_bx = loss(prediction, targets)  # CE loss\n",
        "        loss_bx.backward()\n",
        "        optimizer.step\n",
        "        train_loss += loss_bx.item()\n",
        "        _, predicted = prediction.max(1)\n",
        "        train_total += targets.size(0)\n",
        "        train_correct += predicted.eq(targets).sum().item\n",
        "    train_acc = 100. * train_correct / train_tot\n",
        "    print(train_acc)\n",
        "    network.eval()\n",
        "     # In each epoch, we do a full pass over the training data:\n",
        "     #for inputs, targets in valid_loader:\n",
        "#      #          inputs = inputs.to(device)\n",
        "      #          targets = targets.to(device)\n",
        "#\n",
        "      #          logits, feat = network.forward(inputs)  # feature vector only\n",
        "      #          prediction = network.predict(logits)  # make the prediction\n",
        "#\n",
        "      #          loss_bx = loss(prediction, targets)  # CE loss\n",
        "#\n",
        "      #          valid_loss += loss_bx.item()\n",
        "      #          _, predicted = prediction.max(1)\n",
        "      #          valid_total += targets.size(0)\n",
        "      #          valid_correct += predicted.eq(targets).sum().item()\n",
        "      #          \n",
        "      #          valid_acc = 100*valid_correct/valid_total\n",
        "\n",
        "# function to predict our train_loader and valid_loader\n",
        "def test(loader, network):\n",
        "\n",
        "  all_pred = []\n",
        "  all_labels = []\n",
        "\n",
        "  #compute prediction\n",
        "  for inputs, targets in loader:\n",
        "    outputs = network.forward(inputs)\n",
        "    predictions = network.predict(outputs).cpu().detach() #return score classes as logits\n",
        "    \n",
        "    _, predicted = prediction.max(1)\n",
        "\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    all_preds.extend(predicted.tolist())\n",
        "    all_labels.extend(targets.data.tolist())\n",
        "    return[100.*correct / total], all_preds, all_labels\n",
        "\n",
        "#function to plot confusion matrix\n",
        "def plotConfusionMatrix(confusionMatrixData, seed):\n",
        " fig,ax=plt.subplots(figsize=(10,10))\n",
        " sns.heatmap(confusionMatrixData,cmap='terrain',ax=ax)\n",
        " plt.ylabel('True label')\n",
        " plt.xlabel('Predicted label')\n",
        " plt.title(\"Confusion Matrix {} - seed: {}\".format(method, seed))\n",
        " plt.savefig(filename, format='png', dpi=300)\n",
        " plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "Zc0SFgsiLM16",
        "outputId": "7352ba94-70e0-4519-be11-aedd9af4c247"
      },
      "source": [
        "#iterate over the dataset 10 times (dividing 100 classes in 10) \n",
        "test = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "for i in range(iterations):\n",
        "  i = 0\n",
        "  classes_current_iter = range(i*iterations, i*iterations+iterations)\n",
        "  train_iter = [] \n",
        "  for i in range(len(train)):\n",
        "    if(train[i][-1] in classes_current_iter):\n",
        "      test.append(train[i]) \n",
        "      train_iter.append(train[i])\n",
        "\n",
        "  train_loader = DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "  valid_loader = DataLoader(test, shuffle = True, batch_size = batch_size, num_workers=2)\n",
        "\n",
        "  incrementalFit(train_loader, valid_loader, resNet18)\n",
        "\n",
        "  accuracy_train, preds_train, labels_train = test(train_loader, resNet18)\n",
        "  accuracy_valid, preds_valid, labels_valid = test(valid_loader, resNet18)\n",
        "\n",
        "  confusionMatrixData = confusion_matrix(preds_valid, labels_valid)\n",
        "  plotConfusionMatrix(confusionMatrixData, 12)\n",
        "    \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-51683ea4fb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mincrementalFit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresNet18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresNet18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-28cacc4b85d8>\u001b[0m in \u001b[0;36mincrementalFit\u001b[0;34m(train_loader, valid_loader, network)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# feature vector only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss_bx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CE loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U23Hx4w5MxO0",
        "outputId": "7fca302a-aae0-4aea-e2e0-4eeea9efa38a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOgK5xKUXosf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}